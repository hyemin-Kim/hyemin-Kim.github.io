<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python &gt;&gt; sklearn - (5) 비지도 학습 (Unsupervised Learning) | Hyemin Kim</title><meta name="keywords" content="Python,sklearn,Machine Learning,비지도 학습"><meta name="author" content="Hyemin Kim"><meta name="copyright" content="Hyemin Kim"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="차원 축소 (PCA, LDA); 군집화 (K-Means Clusteirng, DBSCAN); 군집화 평가 (silhouette score)">
<meta property="og:type" content="article">
<meta property="og:title" content="Python &gt;&gt; sklearn - (5) 비지도 학습 (Unsupervised Learning)">
<meta property="og:url" content="https://hyemin-kim.github.io/2020/08/06/S-Python-sklearn5/index.html">
<meta property="og:site_name" content="Hyemin Kim">
<meta property="og:description" content="차원 축소 (PCA, LDA); 군집화 (K-Means Clusteirng, DBSCAN); 군집화 평가 (silhouette score)">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg">
<meta property="article:published_time" content="2020-08-06T04:57:29.000Z">
<meta property="article:modified_time" content="2020-08-13T12:47:41.657Z">
<meta property="article:author" content="Hyemin Kim">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="sklearn">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="비지도 학습">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg"><link rel="shortcut icon" href="/img/favicon_m.png"><link rel="canonical" href="https://hyemin-kim.github.io/2020/08/06/S-Python-sklearn5/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="yandex-verification" content="{&quot;theme_color&quot;:{&quot;enable&quot;:true,&quot;main&quot;:&quot;#913d88&quot;,&quot;paginator&quot;:&quot;#963694&quot;,&quot;button_hover&quot;:&quot;#F06292&quot;,&quot;text_selection&quot;:&quot;#963694&quot;,&quot;link_color&quot;:&quot;#E91E63&quot;,&quot;meta_color&quot;:&quot;#858585&quot;,&quot;hr_color&quot;:&quot;#A4D8FA&quot;,&quot;code_foreground&quot;:&quot;#F47466&quot;,&quot;code_background&quot;:&quot;rgba(27, 31, 35, .05)&quot;,&quot;toc_color&quot;:&quot;#963694&quot;,&quot;blockquote_padding_color&quot;:&quot;#913d88&quot;,&quot;blockquote_background_color&quot;:&quot;#913d88&quot;}}"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '4.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-08-13 21:47:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Hyemin Kim" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">46</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">24</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#비지도-학습-unsupervised-learning"><span class="toc-text"> 비지도 학습 (Unsupervised Learning)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-비지도-학습의-개요"><span class="toc-text"> 1. 비지도 학습의 개요</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-차원-축소"><span class="toc-text"> 2. 차원 축소</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-데이터-로드-iris-데이터"><span class="toc-text"> 2-1. 데이터 로드 (iris 데이터)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-pca-차원-축소"><span class="toc-text"> 2-2. PCA 차원 축소</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-lda-차원-축소"><span class="toc-text"> 2-3. LDA 차원 축소</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-svd-특이값-분해"><span class="toc-text"> 2-4. SVD (특이값 분해)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-군집화"><span class="toc-text"> 3. 군집화</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-k-means-clustering"><span class="toc-text"> 3-1. K-Means Clustering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-dbscan"><span class="toc-text"> 3-2. DBSCAN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-실루엣-스코어-군집화-평가"><span class="toc-text"> 3-3. 실루엣 스코어 (군집화 평가)</span></a></li></ol></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Hyemin Kim</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Python &gt;&gt; sklearn - (5) 비지도 학습 (Unsupervised Learning)</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2020-08-06T04:57:29.000Z" title="Created 2020-08-06 13:57:29">2020-08-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-08-13T12:47:41.657Z" title="Updated 2020-08-13 21:47:41">2020-08-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E3%80%90Study%E3%80%91/">【Study】</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E3%80%90Study%E3%80%91/Python/">Python</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="비지도-학습-unsupervised-learning"><a class="markdownIt-Anchor" href="#비지도-학습-unsupervised-learning"></a> 비지도 학습 (Unsupervised Learning)</h1>
<p></p><ul class="markdownIt-TOC">
<li><a href="#1-%EB%B9%84%EC%A7%80%EB%8F%84-%ED%95%99%EC%8A%B5%EC%9D%98-%EA%B0%9C%EC%9A%94"><strong>1. 비지도 학습의 개요</strong></a></li>
<li><a href="#2-%EC%B0%A8%EC%9B%90-%EC%B6%95%EC%86%8C"><strong>2. 차원 축소</strong></a>
<ul>
<li><a href="#2-1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A1%9C%EB%93%9C-iris-%EB%8D%B0%EC%9D%B4%ED%84%B0">2-1. 데이터 로드 (iris 데이터)</a></li>
<li><a href="#2-2-pca-%EC%B0%A8%EC%9B%90-%EC%B6%95%EC%86%8C">2-2. PCA 차원 축소</a></li>
<li><a href="#2-3-lda-%EC%B0%A8%EC%9B%90-%EC%B6%95%EC%86%8C">2-3. LDA 차원 축소</a></li>
<li><a href="#2-4-svd-%ED%8A%B9%EC%9D%B4%EA%B0%92-%EB%B6%84%ED%95%B4">2-4. SVD (특이값 분해)</a></li>
</ul>
</li>
<li><a href="#3-%EA%B5%B0%EC%A7%91%ED%99%94"><strong>3. 군집화</strong></a>
<ul>
<li><a href="#3-1-k-means-clustering">3-1. K-Means Clustering</a></li>
<li><a href="#3-2-dbscan">3-2. DBSCAN</a></li>
<li><a href="#3-3-%EC%8B%A4%EB%A3%A8%EC%97%A3-%EC%8A%A4%EC%BD%94%EC%96%B4-%EA%B5%B0%EC%A7%91%ED%99%94-%ED%8F%89%EA%B0%80">3-3. 실루엣 스코어 (군집화 평가)</a></li>
</ul>
</li>
</ul>
<p></p>
<br>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br></pre></td></tr></tbody></table></figure>
  <br>
<h2 id="1-비지도-학습의-개요"><a class="markdownIt-Anchor" href="#1-비지도-학습의-개요"></a> <strong>1. 비지도 학습의 개요</strong></h2>
<p>비지도 학습 (Unsupervised Learning)은 기계 학습의 일종으로, 데이터가 어떻게 구성되어 있는지를 알아내는 문제의 범주에 속한다. 이 방법은 지도 학습 (Supervised Learning) 혹은 강화 학습 (Reinforcement Learning)과는 달리 <strong>입력값에 대한 목표치가 주어지지 않는다</strong></p>
<ul>
<li>
<p>차원 축소: PCA, LDA, SVD</p>
</li>
<li>
<p>군집화: KMeans Clustering, DBSCAN</p>
</li>
<li>
<p>군집화 평가</p>
<br>
</li>
</ul>
<h2 id="2-차원-축소"><a class="markdownIt-Anchor" href="#2-차원-축소"></a> <strong>2. 차원 축소</strong></h2>
<ul>
<li>feature의 갯수를 줄이는 것을 뛰어 넘어, 특징을 추출하는 역할응 하기도 함</li>
<li>계산 비용을 감소하는 효과</li>
<li>전반적인 데이터에 대한 이해도를 높이는 효과</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></tbody></table></figure>
<br>  
<h3 id="2-1-데이터-로드-iris-데이터"><a class="markdownIt-Anchor" href="#2-1-데이터-로드-iris-데이터"></a> 2-1. 데이터 로드 (iris 데이터)</h3>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = iris[<span class="string">'data'</span>]</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1.4, 0.2],
       [4.7, 3.2, 1.3, 0.2],
       [4.6, 3.1, 1.5, 0.2],
       [5. , 3.6, 1.4, 0.2]])
</code></pre>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(data, columns = iris[<span class="string">'feature_names'</span>])</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></tbody></table></figure>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'target'</span>] = iris[<span class="string">'target'</span>]</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></tbody></table></figure>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<br>
<h3 id="2-2-pca-차원-축소"><a class="markdownIt-Anchor" href="#2-2-pca-차원-축소"></a> 2-2. PCA 차원 축소</h3>
<blockquote>
<p>참고: <a href="https://excelsior-cjh.tistory.com/167" target="_blank" rel="noopener">PCA 원리 관련 블로그</a></p>
</blockquote>
<p>주성분 분석 (PCA, Principal Component Analysis) 는 선형 차원 축소 기법이다. 매우 인기 있게 사용되는 차원 축소 기법중 하나다.</p>
<p>PCA는 먼저 데이터에 가장 가까운 초평면(hyperplane)을 구한 다음, 데이터를 이 초평면에 투영(projection)시킨다. 주요 특징 중의 하나는 <strong>분산(variance)을 촤대한 보존</strong>한다는 점이다.</p>
<ul>
<li>
<p><strong>분산 보존</strong></p>
<p>PCA는 <strong>데이터의 분산이 최대</strong>가 되는 축을 찾는다. 즉, 원본 데이터셋과 투영된 데이터셋 간의 <strong>평균제곱거리</strong>를 <strong>최소화</strong>하는 축을 찾는다.</p>
</li>
<li>
<p><strong>PCA 실현 과정</strong></p>
<ol>
<li>학습 데이터셋에서 분산이 최대인 축(axis)을 찾는다</li>
<li>이렇게 찾은 첫 번째 축과 직교(orthogonal)하면서 분산이 최대인 두 번째 축을 찾는다</li>
<li>첫 번째 축과 두 번째 축에 직교하고 분산을 최대한 보존하는 세 번째 축을 찾는다</li>
<li><code>1~3</code>과 같은 방법으로 데이터셋의 차원(특성 수)만큼의 축을  찾는다</li>
</ol>
<p>이렇게 i-번째 축을 정의하는 **단위 벡터(unit vector)**를 i-번째 <strong>주성분</strong>(PC, Principle Component)이라고 한다.</p>
<br>
</li>
</ul>
<p><strong>&gt;&gt; sklearn에서 실현</strong></p>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" target="_blank" rel="noopener">[sklearn.decomposition.<strong>PCA</strong>] Documnet</a></p>
<ul>
<li>
<p>n_components에 1보다 작은 값을 넣으면, 분산을 기준으로 차원 축소</p>
</li>
<li>
<p>n_components에 1보다 큰 값을 넣으면, 해당 값을 기준으로 feature를 축소</p>
<br>
</li>
</ul>
<p><strong>(1) 주성분 2개로 지정</strong> (n_components = 2)</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 선언</span></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data scaling</span></span><br><span class="line">data_scaled = StandardScaler().fit_transform(df.loc[:, <span class="string">'sepal length (cm)'</span> : <span class="string">'petal width (cm)'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA 실행</span></span><br><span class="line">pca_data = pca.fit_transform(data_scaled)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></tbody></table></figure>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_scaled[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],
       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],
       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ],
       [-1.50652052,  0.09821729, -1.2833891 , -1.3154443 ],
       [-1.02184904,  1.24920112, -1.34022653, -1.3154443 ]])
</code></pre>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pca_data[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([[-2.26470281,  0.4800266 ],
       [-2.08096115, -0.67413356],
       [-2.36422905, -0.34190802],
       [-2.29938422, -0.59739451],
       [-2.38984217,  0.64683538]])
</code></pre>
  <br>
<p>주성분에 따른 데이터 시각화</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(pca_data[:, <span class="number">0</span>], pca_data[:, <span class="number">1</span>], c=df[<span class="string">'target'</span>]) <span class="comment"># c: color 기준</span></span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x201028bf148&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_39_1.png" alt="output_39_1"></p>
<br>
<p><strong>(2) 분산을 기준으로 차원축소</strong> (n_components &lt; 1)</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pca2 = PCA(n_components=<span class="number">0.99</span>)</span><br><span class="line">pca_data2 = pca2.fit_transform(data_scaled)</span><br><span class="line">pca_data2[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([[-2.26470281,  0.4800266 , -0.12770602],
       [-2.08096115, -0.67413356, -0.23460885],
       [-2.36422905, -0.34190802,  0.04420148],
       [-2.29938422, -0.59739451,  0.09129011],
       [-2.38984217,  0.64683538,  0.0157382 ]])
</code></pre>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)  <span class="comment"># Axe3D object</span></span><br><span class="line"></span><br><span class="line">sample_size = <span class="number">50</span></span><br><span class="line">ax.scatter(pca_data2[:,<span class="number">0</span>], pca_data2[:,<span class="number">1</span>], pca_data2[:,<span class="number">2</span>], alpha=<span class="number">0.6</span>, c=df[<span class="string">'target'</span>])</span><br><span class="line">plt.savefig(<span class="string">'./tmp.svg'</span>)</span><br><span class="line">plt.title(<span class="string">'ax.plot'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/S-Python-sklearn5/output_43_0.png" alt="output_43_0"></p>
<br>
<h3 id="2-3-lda-차원-축소"><a class="markdownIt-Anchor" href="#2-3-lda-차원-축소"></a> 2-3. LDA 차원 축소</h3>
<blockquote>
<p>참고 블로그:</p>
<ol>
<li><a href="https://blog.naver.com/mo223772/222051769650" target="_blank" rel="noopener">차원 축소 - LDA(Linear Discriminant Analysis) 개요</a></li>
<li><a href="https://blog.naver.com/jaehong7719/221926671654" target="_blank" rel="noopener">머신러닝 기초9 - LDA (Linear Discriminant Analysis)</a></li>
</ol>
</blockquote>
<p>LDA (Linear Discriminant Analysis): 선형 판별 분석법 (PCA와 유사)</p>
<p>LDA는 클래스(Class)분리를 최대화하는 축을 찾기 위해 클래스 간 분산(between-class scatter)과 내분 분산(within-class scatter)의 비율을 최대화하는 방식으로 차원을 축소함.</p>
<p>즉, 클래스 간 분산은 최대한 크게 가져가고, 클래스 내부의 분산은 최대한 작게 가져가는 방식이다.</p>
<br>  
<p><strong>&gt;&gt; sklearn에서 실현</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></tbody></table></figure>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 선언</span></span><br><span class="line">lda = LinearDiscriminantAnalysis(n_components=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data scaling</span></span><br><span class="line">data_scaled = StandardScaler().fit_transform(df.loc[:, <span class="string">'sepal length (cm)'</span> : <span class="string">'petal width (cm)'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># LDA 실행</span></span><br><span class="line">lda_data = lda.fit_transform(data_scaled, df[<span class="string">'target'</span>])</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lda_data[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([[-8.06179978,  0.30042062],
       [-7.12868772, -0.78666043],
       [-7.48982797, -0.26538449],
       [-6.81320057, -0.67063107],
       [-8.13230933,  0.51446253]])
</code></pre>
<br>
<p>시각화</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LDA</span></span><br><span class="line">plt.scatter(lda_data[:,<span class="number">0</span>], lda_data[:,<span class="number">1</span>], c=df[<span class="string">'target'</span>])</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x20102cd5608&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_57_1.png" alt="output_57_1"></p>
<p>PCA 결과와 비교</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PCA</span></span><br><span class="line">plt.scatter(pca_data[:,<span class="number">0</span>], pca_data[:,<span class="number">1</span>], c=df[<span class="string">'target'</span>])</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x20102ba6908&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_59_1.png" alt="output_59_1"></p>
<br>
<h3 id="2-4-svd-특이값-분해"><a class="markdownIt-Anchor" href="#2-4-svd-특이값-분해"></a> 2-4. SVD (특이값 분해)</h3>
<blockquote>
<p><a href="https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%9D%B4%EA%B0%92_%EB%B6%84%ED%95%B4" target="_blank" rel="noopener">위키문서</a></p>
</blockquote>
<p>SVD (Singular Value Decomposition):</p>
<ul>
<li>특이값 분해 기법이다</li>
<li>PCA와 유사한 차원 축소 기법이다</li>
<li>scikit-learn 패키지에서는 truncated SVD (aka LSA)을 사용한다</li>
<li>상품의 추천 시스템에도 활용되어지는 알고리즘 (추천시스템)</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> TruncatedSVD</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></tbody></table></figure>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
</style>
<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length (cm)</th>
      <th>sepal width (cm)</th>
      <th>petal length (cm)</th>
      <th>petal width (cm)</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">svd = TruncatedSVD(n_components = <span class="number">2</span>)</span><br><span class="line">data_scaled = StandardScaler().fit_transform(df.loc[:, <span class="string">'sepal length (cm)'</span> : <span class="string">'petal width (cm)'</span>])</span><br><span class="line">svd_data = svd.fit_transform(data_scaled)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svd_data[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([[-2.26470281,  0.4800266 ],
       [-2.08096115, -0.67413356],
       [-2.36422905, -0.34190802],
       [-2.29938422, -0.59739451],
       [-2.38984217,  0.64683538]])
</code></pre>
<br>  
<p>시각화</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SVD</span></span><br><span class="line">plt.scatter(svd_data[:,<span class="number">0</span>], svd_data[:,<span class="number">1</span>], c=df[<span class="string">'target'</span>])</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x20102b2ed08&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_71_1.png" alt="output_71_1"></p>
<p>PCA &amp; LDA와 비교</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PCA</span></span><br><span class="line">plt.scatter(pca_data[:,<span class="number">0</span>], pca_data[:,<span class="number">1</span>], c=df[<span class="string">'target'</span>])</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x20102ad7d88&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_73_1.png" alt="output_73_1"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LDA</span></span><br><span class="line">plt.scatter(lda_data[:,<span class="number">0</span>], lda_data[:,<span class="number">1</span>], c=df[<span class="string">'target'</span>])</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x20102d43e08&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_74_1.png" alt="output_74_1"></p>
<br>
<br>
<h2 id="3-군집화"><a class="markdownIt-Anchor" href="#3-군집화"></a> <strong>3. 군집화</strong></h2>
<h3 id="3-1-k-means-clustering"><a class="markdownIt-Anchor" href="#3-1-k-means-clustering"></a> 3-1. K-Means Clustering</h3>
<blockquote>
<p><a href="https://ko.wikipedia.org/wiki/K-%ED%8F%89%EA%B7%A0_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98" target="_blank" rel="noopener">위키문서</a></p>
</blockquote>
<p>군집화에서 가장 대중적으로 사용되는 알고리즘이다. centroid라는 중점을 기준으로 가강 가까운 포인트를 선택하는 군집화 기법이다</p>
<p><strong>원리:</strong> 주어진 데이터를 k개의 cluster로 묶는 방식, 거리 차이의 분산을 최소화하는 방식으로 동작.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image(<span class="string">'https://image.slidesharecdn.com/patternrecognitionbinoy-06-kmeansclustering-160317135729/95/pattern-recognition-binoy-k-means-clustering-13-638.jpg'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/S-Python-sklearn5/output_81_0.jpg" alt="output_81_0"></p>
<br>
<p><strong>사용되는 예제</strong></p>
<ul>
<li>스팸 문자 분류</li>
<li>뉴스 기사 분류</li>
</ul>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" target="_blank" rel="noopener">[sklearn.cluster.<strong>KMeans</strong>] Document</a></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kmeans = KMeans(n_clusters=<span class="number">3</span>)</span><br><span class="line">data_scaled = StandardScaler().fit_transform(df.loc[:, <span class="string">'sepal length (cm)'</span> : <span class="string">'petal width (cm)'</span>])</span><br><span class="line">cluster_data = kmeans.fit_transform(data_scaled)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster_data[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([[3.12119834, 0.21295824, 3.98940603],
       [2.6755083 , 0.99604549, 4.01793312],
       [2.97416665, 0.65198444, 4.19343668],
       [2.88014429, 0.9034561 , 4.19784749],
       [3.30022609, 0.40215457, 4.11157152]])
</code></pre>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kmeans.labels_</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2,
       0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,
       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2,
       2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0])
</code></pre>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(kmeans.labels_)</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x201043c7fc8&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_88_1.png" alt="output_88_1"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(df[<span class="string">'target'</span>])</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x2010301bec8&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_89_1.png" alt="output_89_1"></p>
<br>
<p>Hyper-parameter Tuning</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kmeans</span><br></pre></td></tr></tbody></table></figure>
<pre><code>KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,
       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',
       random_state=None, tol=0.0001, verbose=0)
</code></pre>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># max_iter: maximum number of iterations for a single run</span></span><br><span class="line">kmeans2 = KMeans(n_clusters=<span class="number">3</span>, max_iter=<span class="number">500</span>)</span><br><span class="line">data_scaled = StandardScaler().fit_transform(df.loc[:, <span class="string">'sepal length (cm)'</span> : <span class="string">'petal width (cm)'</span>])</span><br><span class="line">cluster_data2 = kmeans2.fit_transform(data_scaled)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(kmeans2.labels_)</span><br></pre></td></tr></tbody></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x20105525688&gt;
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_94_1.png" alt="output_94_1"></p>
<br>
<h3 id="3-2-dbscan"><a class="markdownIt-Anchor" href="#3-2-dbscan"></a> 3-2. DBSCAN</h3>
<p><strong>밀도 기반 클러스터링</strong><br>
(DBSCAN: Dencity-Based Spatial Clustering of Applications with Noise)</p>
<ul>
<li>밀도가 높은 부분을 클러스터링 하는 방식</li>
<li>어느 점을 기준으로 반경 x내에 점이 n개 이상 있으면 하나의 군집으로 인식하는 방식</li>
<li>KMeans 에서는 n_cluster의 갯수를 반드시 지정해 주어야 하나, DBSCAN에서는 필요없음</li>
<li>기하학적인 clustering도 잘 찾아냄</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image(<span class="string">'https://image.slidesharecdn.com/pydatanyc2015-151119175854-lva1-app6891/95/pydata-nyc-2015-automatically-detecting-outliers-with-datadog-26-638.jpg'</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="/images/S-Python-sklearn5/output_98_0.jpg" alt="output_98_0"></p>
  <br>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html" target="_blank" rel="noopener">[sklearn.cluster.<strong>DBSCAN</strong>] Document</a></p>
<p><strong>주의:</strong> 변환 시 <code>fit_transform()</code>대신 <strong><code>fit_predict()</code></strong> 를 쓴다</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># eps: The maximum distance between two samples for one to be considered as in the neighborhoood of the other</span></span><br><span class="line">dbscan = DBSCAN(eps=<span class="number">0.7</span>, min_samples=<span class="number">2</span>)</span><br><span class="line">data_scaled = StandardScaler().fit_transform(df.loc[:, <span class="string">'sepal length (cm)'</span> : <span class="string">'petal width (cm)'</span>])</span><br><span class="line">dbscan_data = dbscan.fit_predict(data_scaled)</span><br><span class="line">dbscan_data</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
        0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,
        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,
        1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  2,  1,
        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  1,
        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],
      dtype=int64)
</code></pre>
 <br>   
<h3 id="3-3-실루엣-스코어-군집화-평가"><a class="markdownIt-Anchor" href="#3-3-실루엣-스코어-군집화-평가"></a> 3-3. 실루엣 스코어 (군집화 평가)</h3>
<p>클러스터링의 품질을 정량적으로 평가해 주는 지표</p>
<ul>
<li>1: 클러스터링의 품질이 좋다</li>
<li>0: 클러스터링의 품질이 안좋다 (클러스터링의 의미 없음)</li>
<li>음수: 잘못 분류됨</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_samples, silhouette_score</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_scaled = StandardScaler().fit_transform(df.loc[:, <span class="string">'sepal length (cm)'</span> : <span class="string">'petal width (cm)'</span>])</span><br><span class="line">score = silhouette_score(data_scaled, kmeans.labels_)</span><br><span class="line">score</span><br></pre></td></tr></tbody></table></figure>
<pre><code>0.45994823920518635
</code></pre>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">samples = silhouette_samples(data_scaled, kmeans.labels_)</span><br><span class="line">samples[:<span class="number">5</span>]</span><br></pre></td></tr></tbody></table></figure>
<pre><code>array([0.73419485, 0.56827391, 0.67754724, 0.62050159, 0.72847412])
</code></pre>
<br>
<p><a href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html" target="_blank" rel="noopener">silhouette analysis 시각화 Document</a></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_silhouette</span><span class="params">(X, num_cluesters)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> n_clusters <span class="keyword">in</span> num_cluesters:</span><br><span class="line">        <span class="comment"># Create a subplot with 1 row and 2 columns</span></span><br><span class="line">        fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        fig.set_size_inches(<span class="number">18</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The 1st subplot is the silhouette plot</span></span><br><span class="line">        <span class="comment"># The silhouette coefficient can range from -1, 1 but in this example all</span></span><br><span class="line">        <span class="comment"># lie within [-0.1, 1]</span></span><br><span class="line">        ax1.set_xlim([<span class="number">-0.1</span>, <span class="number">1</span>])</span><br><span class="line">        <span class="comment"># The (n_clusters+1)*10 is for inserting blank space between silhouette</span></span><br><span class="line">        <span class="comment"># plots of individual clusters, to demarcate them clearly.</span></span><br><span class="line">        ax1.set_ylim([<span class="number">0</span>, len(X) + (n_clusters + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Initialize the clusterer with n_clusters value and a random generator</span></span><br><span class="line">        <span class="comment"># seed of 10 for reproducibility.</span></span><br><span class="line">        clusterer = KMeans(n_clusters=n_clusters, random_state=<span class="number">10</span>)</span><br><span class="line">        cluster_labels = clusterer.fit_predict(X)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># The silhouette_score gives the average value for all the samples.</span></span><br><span class="line">        <span class="comment"># This gives a perspective into the density and separation of the formed</span></span><br><span class="line">        <span class="comment"># clusters</span></span><br><span class="line">        silhouette_avg = silhouette_score(X, cluster_labels)</span><br><span class="line">        print(<span class="string">"For n_clusters ="</span>, n_clusters,</span><br><span class="line">              <span class="string">"The average silhouette_score is :"</span>, silhouette_avg)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Compute the silhouette scores for each sample</span></span><br><span class="line">        sample_silhouette_values = silhouette_samples(X, cluster_labels)</span><br><span class="line">    </span><br><span class="line">        y_lower = <span class="number">10</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_clusters):</span><br><span class="line">            <span class="comment"># Aggregate the silhouette scores for samples belonging to</span></span><br><span class="line">            <span class="comment"># cluster i, and sort them</span></span><br><span class="line">            ith_cluster_silhouette_values = \</span><br><span class="line">                sample_silhouette_values[cluster_labels == i]</span><br><span class="line">    </span><br><span class="line">            ith_cluster_silhouette_values.sort()</span><br><span class="line">    </span><br><span class="line">            size_cluster_i = ith_cluster_silhouette_values.shape[<span class="number">0</span>]</span><br><span class="line">            y_upper = y_lower + size_cluster_i</span><br><span class="line">    </span><br><span class="line">            color = cm.nipy_spectral(float(i) / n_clusters)</span><br><span class="line">            ax1.fill_betweenx(np.arange(y_lower, y_upper),</span><br><span class="line">                              <span class="number">0</span>, ith_cluster_silhouette_values,</span><br><span class="line">                              facecolor=color, edgecolor=color, alpha=<span class="number">0.7</span>)</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># Label the silhouette plots with their cluster numbers at the middle</span></span><br><span class="line">            ax1.text(<span class="number">-0.05</span>, y_lower + <span class="number">0.5</span> * size_cluster_i, str(i))</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># Compute the new y_lower for next plot</span></span><br><span class="line">            y_lower = y_upper + <span class="number">10</span>  <span class="comment"># 10 for the 0 samples</span></span><br><span class="line">    </span><br><span class="line">        ax1.set_title(<span class="string">"The silhouette plot for the various clusters."</span>)</span><br><span class="line">        ax1.set_xlabel(<span class="string">"The silhouette coefficient values"</span>)</span><br><span class="line">        ax1.set_ylabel(<span class="string">"Cluster label"</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># The vertical line for average silhouette score of all the values</span></span><br><span class="line">        ax1.axvline(x=silhouette_avg, color=<span class="string">"red"</span>, linestyle=<span class="string">"--"</span>)</span><br><span class="line">    </span><br><span class="line">        ax1.set_yticks([])  <span class="comment"># Clear the yaxis labels / ticks</span></span><br><span class="line">        ax1.set_xticks([<span class="number">-0.1</span>, <span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 2nd Plot showing the actual clusters formed</span></span><br><span class="line">        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)</span><br><span class="line">        ax2.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">'.'</span>, s=<span class="number">30</span>, lw=<span class="number">0</span>, alpha=<span class="number">0.7</span>,</span><br><span class="line">                    c=colors, edgecolor=<span class="string">'k'</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Labeling the clusters</span></span><br><span class="line">        centers = clusterer.cluster_centers_</span><br><span class="line">        <span class="comment"># Draw white circles at cluster centers</span></span><br><span class="line">        ax2.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], marker=<span class="string">'o'</span>,</span><br><span class="line">                    c=<span class="string">"white"</span>, alpha=<span class="number">1</span>, s=<span class="number">200</span>, edgecolor=<span class="string">'k'</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(centers):</span><br><span class="line">            ax2.scatter(c[<span class="number">0</span>], c[<span class="number">1</span>], marker=<span class="string">'$%d$'</span> % i, alpha=<span class="number">1</span>,</span><br><span class="line">                        s=<span class="number">50</span>, edgecolor=<span class="string">'k'</span>)</span><br><span class="line">    </span><br><span class="line">        ax2.set_title(<span class="string">"The visualization of the clustered data."</span>)</span><br><span class="line">        ax2.set_xlabel(<span class="string">"Feature space for the 1st feature"</span>)</span><br><span class="line">        ax2.set_ylabel(<span class="string">"Feature space for the 2nd feature"</span>)</span><br><span class="line">    </span><br><span class="line">        plt.suptitle((<span class="string">"Silhouette analysis for KMeans clustering on sample data "</span></span><br><span class="line">                      <span class="string">"with n_clusters = %d"</span> % n_clusters),</span><br><span class="line">                     fontsize=<span class="number">14</span>, fontweight=<span class="string">'bold'</span>)</span><br><span class="line">    </span><br><span class="line">        plt.show()</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_silhouette(data_scaled, [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br></pre></td></tr></tbody></table></figure>
<pre><code>For n_clusters = 2 The average silhouette_score is : 0.5817500491982808
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_112_1.png" alt="output_112_1"></p>
<pre><code>For n_clusters = 3 The average silhouette_score is : 0.45994823920518635
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_112_3.png" alt="output_112_3"></p>
<pre><code>For n_clusters = 4 The average silhouette_score is : 0.4188923398171004
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_112_5.png" alt="output_112_5"></p>
<pre><code>For n_clusters = 5 The average silhouette_score is : 0.34551099599809465
</code></pre>
<p><img src="/images/S-Python-sklearn5/output_112_7.png" alt="output_112_7"></p>
<ul>
<li>빨간 점선은 평균 실루엣 계수를 의미함</li>
</ul>
<br>
<br><script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/sklearn/">sklearn</a><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a><a class="post-meta__tags" href="/tags/%EB%B9%84%EC%A7%80%EB%8F%84-%ED%95%99%EC%8A%B5/">비지도 학습</a></div><div class="post_share"><div class="social-share" data-image="https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/08/11/E-Python-LinearRegression-1/"><img class="prev-cover" src="https://s1.ax1x.com/2020/08/25/dciYCV.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">【실습】 Python &gt;&gt; EDA &amp; Linear Regression -- 부동산 가격 예측</div></div></a></div><div class="next-post pull-right"><a href="/2020/08/04/S-Python-sklearn4/"><img class="next-cover" src="https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Python &gt;&gt; sklearn - (4) 앙상블 (Ensemble)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/08/13/E-Python-Classification-1/" title="【실습】 Python >> Classification -- 포켓몬 분류 분석"><img class="cover" src="https://s1.ax1x.com/2020/08/25/dcPqB9.png"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-13</div><div class="title">【실습】 Python >> Classification -- 포켓몬 분류 분석</div></div></a></div><div><a href="/2020/08/11/E-Python-LinearRegression-1/" title="【실습】 Python >> EDA & Linear Regression -- 부동산 가격 예측"><img class="cover" src="https://s1.ax1x.com/2020/08/25/dciYCV.png"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-11</div><div class="title">【실습】 Python >> EDA & Linear Regression -- 부동산 가격 예측</div></div></a></div><div><a href="/2020/07/17/S-Python-sklearn0/" title="Python >> sklearn -(0) sklearn 개요"><img class="cover" src="https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-17</div><div class="title">Python >> sklearn -(0) sklearn 개요</div></div></a></div><div><a href="/2020/07/26/S-Python-sklearn2/" title="Python >> sklearn - (2) 분류 (Classification)"><img class="cover" src="https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-26</div><div class="title">Python >> sklearn - (2) 분류 (Classification)</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></article></main><footer id="footer" style="background-image: url(https://ohiing.com/wp-content/uploads/2020/02/scikit-learn-2.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 By Hyemin Kim</div><div class="framework-info"><span>Framework </span><a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: 'ed00dae828f43e807ca1',
      clientSecret: '6127c1ef27fe0e15655c18f5ce3817472c83d2cd',
      repo: 'hyemin-Kim.github.io',
      owner: 'hyemin-Kim',
      admin: [''],
      id: 'a8bb82694f17b01d0c195c7d91750afe',
      language: 'en',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    $.getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js', initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>