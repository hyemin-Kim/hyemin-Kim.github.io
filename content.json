{"meta":{"title":"Hyemin Kim","subtitle":"김혜민 / 金慧敏","description":"","author":"Hyemin Kim","url":"https://hyemin-kim.github.io","root":"/"},"pages":[{"title":"","date":"2020-05-04T18:01:24.474Z","updated":"2020-05-04T18:01:24.474Z","comments":false,"path":"about/index.html","permalink":"https://hyemin-kim.github.io/about/index.html","excerpt":"","text":"Hello document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"","date":"2020-05-20T10:31:42.690Z","updated":"2020-05-04T13:34:00.910Z","comments":false,"path":"categories/index - default.html","permalink":"https://hyemin-kim.github.io/categories/index%20-%20default.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"Links","date":"2020-05-20T08:53:04.000Z","updated":"2020-05-21T11:40:00.304Z","comments":false,"path":"link/index.html","permalink":"https://hyemin-kim.github.io/link/index.html","excerpt":"","text":"Some Useful Links Github Hexo Themes Hexo Usage Hexo Plugins document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"Categories","date":"2020-04-30T15:00:00.000Z","updated":"2020-05-21T11:27:57.020Z","comments":false,"path":"categories/index.html","permalink":"https://hyemin-kim.github.io/categories/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"Tag Cloud","date":"2020-04-30T15:00:00.000Z","updated":"2020-05-21T14:01:11.233Z","comments":false,"path":"tags/index.html","permalink":"https://hyemin-kim.github.io/tags/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"tagcloud","date":"2020-05-08T05:30:56.000Z","updated":"2020-05-08T05:34:14.280Z","comments":false,"path":"tagcloud/index.html","permalink":"https://hyemin-kim.github.io/tagcloud/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"","date":"2020-05-20T08:48:36.782Z","updated":"2020-05-04T13:34:13.986Z","comments":false,"path":"tags/index - default.html","permalink":"https://hyemin-kim.github.io/tags/index%20-%20default.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"}],"posts":[{"title":"Python >> sklearn - (4) 앙상블 (Ensemble)","slug":"S-Python-sklearn4","date":"2020-08-04T11:40:35.000Z","updated":"2020-08-04T12:26:39.153Z","comments":true,"path":"2020/08/04/S-Python-sklearn4/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/04/S-Python-sklearn4/","excerpt":"","text":"앙상블 (Ensemble) 0. 데이터 셋 0-1. 데이터 로드 0-2. 데이터프레임 만들기 1. Training set / Test set 나누기 2. 평가 지표 만들기 2-1. 평가 지표 2-2. 모델 성능 확인을 위한 함수 3. 단일 회귀 모델 (지난 시간) (1) Linear Regression (2) Ridge (3) LASSO (4) ElasticNet (5) With Standard Scaling (6) Polynomial Features 4. 앙상블 (Ensemble) 알고리즘 4-1. 보팅 (Voting) &gt;&gt; 회귀 (Regression) &gt;&gt; 분류 (Classification) 4-2. 배깅 (Bagging) &gt;&gt; Random Forest 4-3. 부스팅 (Boosting) 4-3-1. Gradient Boost 4-3-2. XGBoost 4-3-3. LightGBM 4-4. 스태킹 (Stacking) 4-5. Weighted Blending 4-6. 앙상블 모델 정리 5. Cross Validation 5-1. Cross Validation 소개 5-2. Hyper-parameter 튜닝 (1) RandomizedSearchCV (2) GridSerchCV 머신러닝 앙상블이란 여러 개의 머신러닝 모델을 이용해 최적의 답을 찾아내는 기법이다. (여러 모델을 이용하여 데이터를 학습하고, 모든 모델의 예측결과를 평균하여 예측) 앙상블 기법의 종류 보팅 (Voting): 투표를 통해 결과 도출 배깅 (Bagging): 샘플 중복 생성을 통해 결과 도출 부스팅 (Boosting): 이전 오차를 보완하면서 가중치 부여 스태킹 (Stacking): 여러 모델을 기반으로 예측된 결과를 통해 meta 모델이 다시 한번 예측 참고자료 (블로그) 보팅 (Voting) 배경 (Bagging) 부스팅 (Boosting) 0. 데이터 셋 12345import pandas as pdimport numpy as npfrom IPython.display import Imagenp.set_printoptions(suppress=True) # If True, print floating point numbers instead of scientific notation 1from sklearn.datasets import load_boston 0-1. 데이터 로드 1data = load_boston() 1print(data['DESCR']) .. _boston_dataset: Boston house prices dataset --------------------------- **Data Set Characteristics:** :Number of Instances: 506 :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target. :Attribute Information (in order): - CRIM per capita crime rate by town - ZN proportion of residential land zoned for lots over 25,000 sq.ft. - INDUS proportion of non-retail business acres per town - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) - NOX nitric oxides concentration (parts per 10 million) - RM average number of rooms per dwelling - AGE proportion of owner-occupied units built prior to 1940 - DIS weighted distances to five Boston employment centres - RAD index of accessibility to radial highways - TAX full-value property-tax rate per $10,000 - PTRATIO pupil-teacher ratio by town - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town - LSTAT % lower status of the population - MEDV Median value of owner-occupied homes in $1000's :Missing Attribute Values: None :Creator: Harrison, D. and Rubinfeld, D.L. This is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/machine-learning-databases/housing/ ​ This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics &amp; Management, vol.5, 81-102, 1978. Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics ...', Wiley, 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter. The Boston house-price data has been used in many machine learning papers that address regression problems. .. topic:: References - Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261. - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann. ​ 0-2. 데이터프레임 만들기 12df = pd.DataFrame(data['data'], columns = data['feature_names'])df['MEDV'] = data['target'] 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 36.2 컬럼 소게 (feature 13 + target 1): CRIM: 범죄율 ZN: 25,000 square feet 당 주거용 토지의 비율 INDUS: 비소매(non-retail) 비즈니스 면적 비율 CHAS: 찰스 강 더미 변수 (통로가 하천을 향하면 1; 그렇지 않으면 0) NOX: 산화 질소 농도 (천만 분의 1) RM:주거 당 평균 객실 수 AGE: 1940 년 이전에 건축된 자가 소유 점유 비율 DIS: 5 개의 보스턴 고용 센터까지의 가중 거리 RAD: 고속도로 접근성 지수 TAX: 10,000 달러 당 전체 가치 재산 세율 PTRATIO 도시 별 학생-교사 비율 B: 1000 (Bk-0.63) ^ 2 여기서 Bk는 도시 별 검정 비율입니다. LSTAT: 인구의 낮은 지위 MEDV: 자가 주택의 중앙값 (1,000 달러 단위) 1. Training set / Test set 나누기 1from sklearn.model_selection import train_test_split 1x_train, x_test, y_train, y_test = train_test_split(df.drop('MEDV', 1), df['MEDV'], random_state=23) 1x_train.shape, y_train.shape ((379, 13), (379,)) 1x_test.shape, y_test.shape ((127, 13), (127,)) 2. 평가 지표 만들기 2-1. 평가 지표 (1) MAE (Mean Absolute Error) MAE (평균 절대 오차): 에측값과 실제값의 차이의 절대값에 대하여 평균을 낸 것 MAE=1n∑i=1n∣yi−yi^∣MAE = \\frac{1}{n} \\sum_{i=1}^n \\left\\vert y_i - \\widehat{y_i} \\right\\vert MAE=n1​i=1∑n​∣yi​−yi​​∣ (2) MSE (Mean Squared Error) MSE (평균 제곱 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 것 MSE=1n∑i=1n(yi−yi^)2MSE = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2 MSE=n1​i=1∑n​(yi​−yi​​)2 (3) RMSE (Root Mean Squared Error) RMSE (평균 제곱근 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 뒤 루트를 씌운 것 RMSE=1n∑i=1n(yi−yi^)2RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2} RMSE=n1​i=1∑n​(yi​−yi​​)2​ 2-2. 모델 성능 확인을 위한 함수 12# sklearn 평가지표 활용from sklearn.metrics import mean_absolute_error, mean_squared_error 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import matplotlib.pyplot as pltimport seaborn as snsmy_predictions = {}colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown', 'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick', 'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', 'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate', 'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', 'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato' ]# prediction plotdef plot_predictions(name_, actual, pred): df = pd.DataFrame({'actual': y_test, 'prediction': pred}) df = df.sort_values(by='actual').reset_index(drop=True) plt.figure(figsize=(12, 9)) plt.scatter(df.index, df['prediction'], marker='x', color='r') plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black') plt.title(name_, fontsize=15) plt.legend(['prediction', 'actual'], fontsize=12) plt.show()# evaluation plotdef mse_eval(name_, actual, pred): global predictions global colors plot_predictions(name_, actual, pred) mse = mean_squared_error(actual, pred) my_predictions[name_] = mse y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True) df = pd.DataFrame(y_value, columns=['model', 'mse']) print(df) min_ = df['mse'].min() - 10 max_ = df['mse'].max() + 10 length = len(df) plt.figure(figsize=(10, length)) ax = plt.subplot() ax.set_yticks(np.arange(len(df))) ax.set_yticklabels(df['model'], fontsize=15) bars = ax.barh(np.arange(len(df)), df['mse']) for i, v in enumerate(df['mse']): idx = np.random.choice(len(colors)) bars[i].set_color(colors[idx]) ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold') plt.title('MSE Error', fontsize=18) plt.xlim(min_, max_) plt.show()# remove modeldef remove_model(name_): global my_predictions try: del my_predictions[name_] except KeyError: return False return True# coefficients visulizationdef plot_coef(columns, coef): coef_df = pd.DataFrame(list(zip(columns, coef))) coef_df.columns=['feature', 'coef'] coef_df = coef_df.sort_values('coef', ascending=False).reset_index(drop=True) fig, ax = plt.subplots(figsize=(9, 7)) ax.barh(np.arange(len(coef_df)), coef_df['coef']) idx = np.arange(len(coef_df)) ax.set_yticks(idx) ax.set_yticklabels(coef_df['feature']) fig.tight_layout() plt.show() 3. 단일 회귀 모델 (지난 시간) 1234567from sklearn.linear_model import LinearRegressionfrom sklearn.linear_model import Ridgefrom sklearn.linear_model import Lassofrom sklearn.linear_model import ElasticNetfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScalerfrom sklearn.pipeline import make_pipelinefrom sklearn.preprocessing import PolynomialFeatures (1) Linear Regression 1234linear_reg = LinearRegression(n_jobs=-1)linear_reg.fit(x_train, y_train)linear_pred = linear_reg.predict(x_test)mse_eval('LinearRegression', y_test, linear_pred) model mse 0 LinearRegression 22.770784 (2) Ridge 1234ridge = Ridge(alpha=1)ridge.fit(x_train, y_train)ridge_pred = ridge.predict(x_test)mse_eval('Ridge(alpha=1)', y_test, ridge_pred) model mse 0 LinearRegression 22.770784 1 Ridge(alpha=1) 22.690411 (3) LASSO 1234lasso = Lasso(alpha=0.01)lasso.fit(x_train, y_train)lasso_pred = lasso.predict(x_test)mse_eval('Lasso(alpha=0.01)', y_test, lasso_pred) model mse 0 LinearRegression 22.770784 1 Ridge(alpha=1) 22.690411 2 Lasso(alpha=0.01) 22.635614 (4) ElasticNet 1234elasticnet = ElasticNet(alpha=0.5, l1_ratio=0.2)elasticnet.fit(x_train, y_train)elas_pred = elasticnet.predict(x_test)mse_eval('ElasticNet(l1_ratio=0.2)', y_test, elas_pred) model mse 0 ElasticNet(l1_ratio=0.2) 24.481069 1 LinearRegression 22.770784 2 Ridge(alpha=1) 22.690411 3 Lasso(alpha=0.01) 22.635614 (5) With Standard Scaling 1234567standard_elasticnet = make_pipeline( StandardScaler(), ElasticNet(alpha=0.5, l1_ratio=0.2))elas_scaled_pred = standard_elasticnet.fit(x_train, y_train).predict(x_test)mse_eval('Standard ElasticNet', y_test, elas_scaled_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 (6) Polynomial Features 123456789# 2-Degree Polynomial Features + Standard Scalingpoly_elasticnet = make_pipeline( PolynomialFeatures(degree=2, include_bias=False), StandardScaler(), ElasticNet(alpha=0.5, l1_ratio=0.2))poly_pred = poly_elasticnet.fit(x_train, y_train).predict(x_test)mse_eval('Poly ElasticNet', y_test, poly_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Poly ElasticNet 20.805986 4. 앙상블 (Ensemble) 알고리즘 [sklearn.ensemble] Document 앙상블 기법의 종류 보팅 (Voting): 투표를 통해 결과 도출 배깅 (Bagging): 샘플 중복 생성을 통해 결과 도출 부스팅 (Boosting): 이전 오차를 보완하면서 가중치 부여 스태킹 (Stacking): 여러 모델을 기반으로 예측된 결과를 통해 meta 모델이 다시 한번 예측 4-1. 보팅 (Voting) &gt;&gt; 회귀 (Regression) Voting은 단어 뜻 그대로 투표를 통해 최종 결과를 결정하는 방식이다. Voting과 Bagging은 모두 투표방식이지만, 다음과 같은 큰 차이점이 있다: Voting은 다른 알고리즘 model을 조합해서 사용함 Bagging은 같은 알고리즘 내에서 다른 sample 조합을 사용함 1from sklearn.ensemble import VotingRegressor 반드시, Tuple 형태로 모델을 정의해야 한다. 123456789# 보팅에 참여한 single models 지정single_models = [ ('linear_reg', linear_reg), ('ridge', ridge), ('lasso', lasso), ('elasticnet', elasticnet), ('standard_elasticnet', standard_elasticnet), ('poly_elasticnet', poly_elasticnet)] 12# voting regressor 만들기voting_regressor = VotingRegressor(single_models, n_jobs=-1) 1voting_regressor.fit(x_train, y_train) VotingRegressor(estimators=[('linear_reg', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)), ('ridge', Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=None, solver='auto', tol=0.001)), ('lasso', Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False, positive=False, pr... interaction_only=False, order='C')), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.2, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=None, selection='cyclic', tol=0.0001, warm_start=False))], verbose=False))], n_jobs=-1, weights=None) 12voting_pred = voting_regressor.predict(x_test)mse_eval('Voting Ensemble', y_test, voting_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 &gt;&gt; 분류 (Classification) 참고 자료 (Blog) 분류기 모델을 만들때, Voting 앙상블은 1가지의 중요한 parameter가 있다: voting = {‘hard’, ‘soft’} class를 0, 1로 분류 예측을 하는 이진 분류를 예로 들어 보자. (1) hard 로 설정한 경우 Hard Voting 방식에서는 결과 값에 대한 다수 class를 사용한다. 분류를 예측한 값이 1, 0, 0, 1, 1 이었다고 가정한다면 1이 3표, 0이 2표를 받았기 때문에 Hard Voting 방식에서는 1이 최종 값으로 예측을 하게 된다. (2) soft 로 설정한 경우 soft voting 방식은 각각의 확률의 평균 값을 계산한다음에 가장 확률이 높은 값으로 확정짓게 된다. 가령 class 0이 나올 확률이 (0.4, 0.9, 0.9, 0.4, 0.4)이었고, class 1이 나올 확률이 (0.6, 0.1, 0.1, 0.6, 0.6) 이었다면, class 0이 나올 최종 확률은 (0.4+0.9+0.9+0.4+0.4) / 5 = 0.44, class 1이 나올 최종 확률은 (0.6+0.1+0.1+0.6+0.6) / 5 = 0.4 가 되기 때문에 앞선 Hard Voting의 결과와는 다른 결과 값이 최종으로 선출되게 된다. 12from sklearn.ensemble import VotingClassifierfrom sklearn.linear_model import LogisticRegression, RidgeClassifier 1234models = [ ('Logit', LogisticRegression()), ('ridge', RidgeClassifier())] voting 옵션 지정 1vc = VotingClassifier(models, voting='soft') 4-2. 배깅 (Bagging) 참고 자료 (Blog) Bagging은 Bootstrap Aggregating의 줄임말이다. Bootstrap은 여러 개의 dataset을 중첩을 허용하게 하여 샘플링하여 분할하는 방식. 데이터 셋의 구성이 [1, 2, 3, 4, 5]로 되어 있다면, group 1 = [1, 2, 3] group 2 = [1, 3, 4] group 3 = [2, 3, 5] 1Image('https://teddylee777.github.io/images/2019-12-17/image-20191217015537872.png') Voting VS Bagging Voting은 여러 알고리즘의 조합에 대한 앙상블 Bagging은 하나의 단일 알고리즘에 대하여 여러 개의 샘플 조합으로 앙상블 대표적인 Bagging 앙상블 Random Forest Bagging &gt;&gt; Random Forest Decision Tree 기반 Bagging 앙상블 굉장히 인기있는 앙상블 모델 사용성이 쉽고, 성능도 우수함 [sklearn.ensemble.RandomForestRegressor] Document [sklearn.ensemble.RandomForestClassifier] Document 회귀 (Regression) Hyper-parameter의 default value로 모델 학습 1from sklearn.ensemble import RandomForestRegressor 12rfr = RandomForestRegressor(random_state=1)rfr.fit(x_train, y_train) RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse', max_depth=None, max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None, oob_score=False, random_state=1, verbose=0, warm_start=False) 12rfr_pred = rfr.predict(x_test)mse_eval('RandomForest Ensemble', y_test, rfr_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 7 RandomForest Ensemble 13.781191 주요 Hyper-parameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 max_depth: 깊어질 수 있는 최대 깊이. 과대적합 방지용 n_estimators: 암상블하는 트리의 갯수 max_features: best split을 판단할 때 최대로 사용할 feature의 갯수 {‘auto’, ‘sqrt’, ‘log2’}. 과대적합 방지용 min_samples_split: 트리가 분할할 때 최소 샘플의 갯수. default=2. 과대적합 방지용 1Image('https://teddylee777.github.io/images/2020-01-09/decistion-tree.png', width=600) With Hyper-parameter Tuning 1234rfr_t = RandomForestRegressor(random_state=1, n_estimators=500, max_depth=7, max_features='sqrt')rfr_t.fit(x_train, y_train)rfr_t_pred = rfr_t.predict(x_test)mse_eval('RandomForest Ensemble w/ Tuning', y_test, rfr_t_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 7 RandomForest Ensemble 13.781191 8 RandomForest Ensemble w/ Tuning 11.481491 4-3. 부스팅 (Boosting) 참고 자료 (Blog) 악한 학습기를 순차적으로 학습을 하되, 이전 학습에 대하여 잘멋 예측된 데이터에 가중치를 부여해 오차를 보완해 나가는 방식이다. 장점 성능이 매우 우수하다 (LightGBM, XGBoost) 단점 부스팅 알고리즘의 특성상 계속 약점(오분류/잔차)을 보완하려고 하기 때문에 잘못된 레이블링이나 아웃라이어에 필요 이상으로 민감할 수 있다 다른 앙상블 대비 학습 시간이 오래걸린다는 단점이 존재 1Image('https://keras.io/img/graph-kaggle-1.jpeg', width=800) 대표적인 Boosting 앙상블 AdaBoost GradientBoost LightGBM (LGBM) XGBoost 4-3-1. Gradient Boost 장점: 성능이 우수함 단점: 학습 시간이 너무 오래 걸린다 [sklearn.ensemble.GradientBoostingRegressor] Document 1from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier 123# default value로 학습gbr = GradientBoostingRegressor(random_state=1)gbr.fit(x_train, y_train) GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse', init=None, learning_rate=0.1, loss='ls', max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_iter_no_change=None, presort='deprecated', random_state=1, subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0, warm_start=False) 12gbr_pred = gbr.predict(x_test)mse_eval('GradientBoost Ensemble', y_test, gbr_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 7 RandomForest Ensemble 13.781191 8 GradientBoost Ensemble 13.451877 9 RandomForest Ensemble w/ Tuning 11.481491 주요 Hyper-parameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. default=0.1 (n_estimators와 같이 튜닝해야 함) n_estimators: 부스팅 스테이지 수. default=100 (Random Forest 트리의 갯수 설정과 비슷) subsample: 샘플 사용 비율 (max_features와 비슷). 과대적합 방지용 min_samples_split: 노드 분할시 최소 샘플의 갯수. default=2. 과대적합 방지용 There’s a trade-off between learning_rate and n_estimators. 둘의 곱을 유지하는 것이 좋다 123456# with hyper-parameter tuning# learning_rate=0.01 (without tuning n_estimators together)gbr_t = GradientBoostingRegressor(random_state=1, learning_rate=0.01)gbr_t.fit(x_train, y_train)gbr_t_pred = gbr_t.predict(x_test)mse_eval('GradientBoost Ensemble w/ tuning (lr=0.01)', y_test, gbr_t_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 RandomForest Ensemble 13.781191 9 GradientBoost Ensemble 13.451877 10 RandomForest Ensemble w/ Tuning 11.481491 12345# tuning: learning_rate=0.01, n_estimators=1000gbr_t2 = GradientBoostingRegressor(random_state=1, learning_rate=0.01, n_estimators=1000)gbr_t2.fit(x_train, y_train)gbr_t2_pred = gbr_t2.predict(x_test)mse_eval('GradientBoost Ensemble w/ tuning (lr=0.01, est=1000)', y_test, gbr_t2_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 RandomForest Ensemble 13.781191 9 GradientBoost Ensemble 13.451877 10 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 11 RandomForest Ensemble w/ Tuning 11.481491 12345# tuning: learning_rate=0.01, n_estimators=1000, subsample=0.8gbr_t3 = GradientBoostingRegressor(random_state=42, learning_rate=0.01, n_estimators=1000, subsample=0.7)gbr_t3.fit(x_train, y_train)gbr_t3_pred = gbr_t3.predict(x_test)mse_eval('GradientBoost Ensemble w/ tuning (lr=0.01, est=1000, subsample=0.7)', y_test, gbr_t3_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 RandomForest Ensemble 13.781191 9 GradientBoost Ensemble 13.451877 10 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 12 RandomForest Ensemble w/ Tuning 11.481491 4-3-2. XGBoost eXtreme Gradient Boosting [XGBoost] Document 주요 특징 scikit-learn 패키지 아님 성능이 우수함 GBM보다는 빠르고 성능도 향상됨 여전히 학습 속도가 느림 1pip install xgboost Requirement already satisfied: xgboost in d:\\anaconda\\lib\\site-packages (1.1.1) Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.4.1) Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.18.1) Note: you may need to restart the kernel to use updated packages. 1from xgboost import XGBRegressor, XGBClassifier 123# default value로 학습xgb = XGBRegressor(random_state=1)xgb.fit(x_train, y_train) XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1, importance_type='gain', interaction_constraints='', learning_rate=0.300000012, max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0, num_parallel_tree=1, objective='reg:squarederror', random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact', validate_parameters=1, verbosity=None) 12xgb_pred = xgb.predict(x_test)mse_eval('XGBoost', y_test, xgb_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 13 RandomForest Ensemble w/ Tuning 11.481491 주요 Hyper-parameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1 n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 max_depth: 트리의 깊이. 과대적합 방지용. default=3. subsample: 샘플 사용 비율. 과대적합 방지용. default=1.0 max_features: 최대로 사용할 feature의 비율. 과대적합 방지용. default=1.0 12345# with hyeper-parameter tuningxgb_t = XGBRegressor(random_state=1, learning_rate=0.01, n_estimators=1000, subsample=0.7, max_features=0.8, max_depth=7)xgb_t.fit(x_train, y_train)xgb_t_pred = xgb_t.predict(x_test)mse_eval('XGBoost w/ Tuning', y_test, xgb_t_pred) [16:55:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: Parameters: { max_features } might not be used. This may not be accurate due to some parameters are only used in language bindings but passed down to XGBoost core. Or some parameters are not used but slip through this verification. Please open an issue if you find above cases. ​ ​ model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 13 XGBoost w/ Tuning 11.987602 14 RandomForest Ensemble w/ Tuning 11.481491 4-3-3. LightGBM [LightGBM] Document 주요 특징 scikit-learn 패키지가 아님 성능이 우수함 속도도 매우 빠름 1pip install lightgbm Requirement already satisfied: lightgbm in d:\\anaconda\\lib\\site-packages (2.3.1) Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.4.1) Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.18.1) Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (from lightgbm) (0.22.1) Requirement already satisfied: joblib&gt;=0.11 in d:\\anaconda\\lib\\site-packages (from scikit-learn-&gt;lightgbm) (0.14.1) Note: you may need to restart the kernel to use updated packages. 1from lightgbm import LGBMRegressor, LGBMClassifier 123# default value 로 학습lgbm = LGBMRegressor(random_state=1)lgbm.fit(x_train, y_train) LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, importance_type='split', learning_rate=0.1, max_depth=-1, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31, objective=None, random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0) 12lgbm_pred = lgbm.predict(x_test)mse_eval('LightGBM', y_test, lgbm_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 LightGBM 12.882170 13 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 14 XGBoost w/ Tuning 11.987602 15 RandomForest Ensemble w/ Tuning 11.481491 주요 Hyperparameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1 n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 max_depth: 트리의 깊이. 과대적합 방지용. default=3. colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0 12345# with hyper-parameter tuninglgbm_t = LGBMRegressor(random_state=1, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.9, subsample=0.7, max_depth=5)lgbm_t.fit(x_train, y_train)lgbm_t_pred = lgbm_t.predict(x_test)mse_eval('LightGBM w/ Tuning', y_test, lgbm_t_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 LightGBM 12.882170 13 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 14 LightGBM w/ Tuning 12.200040 15 XGBoost w/ Tuning 11.987602 16 RandomForest Ensemble w/ Tuning 11.481491 4-4. 스태킹 (Stacking) 개별 모델이 예측한 데이터를 기반으로 final_estimators 종합하여 예측을 수행 성능을 극으로 끌오올릴 때 활용하기도 함 과대적합을 유발할 수 있다. (특히, 데이터셋이 적은 경우) [sklearn.ensemble.StackingRegressor] Document 1from sklearn.ensemble import StackingRegressor 12345stack_models = [ ('elasticnet', poly_elasticnet), ('randomforest', rfr_t), ('lgbm', lgbm_t)] 1234stack_reg = StackingRegressor(stack_models, final_estimator=xgb, n_jobs=-1)stack_reg.fit(x_train, y_train)stack_pred = stack_reg.predict(x_test)mse_eval('Stacking Ensemble', y_test, stack_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 15 LightGBM w/ Tuning 12.200040 16 XGBoost w/ Tuning 11.987602 17 RandomForest Ensemble w/ Tuning 11.481491 4-5. Weighted Blending 각 모델의 예측값에 대하여 weight를 곱해혀 최종 output 산출 모델에 대한 가중치를 조절하여, 최종 output을 산출함 가중치의 합은 1.0이 되도록 설정 12345final_outputs = { 'randomforest': rfr_t_pred, 'xgboost': xgb_t_pred, 'lgbm': lgbm_t_pred} 1234final_prediction=\\final_outputs['randomforest'] * 0.5\\+final_outputs['xgboost'] * 0.3\\+final_outputs['lgbm'] * 0.2\\ 1mse_eval('Weighted Blending', y_test, final_prediction) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 15 LightGBM w/ Tuning 12.200040 16 XGBoost w/ Tuning 11.987602 17 RandomForest Ensemble w/ Tuning 11.481491 18 Weighted Blending 10.585610 4-6. 앙상블 모델 정리 앙상블은 대체적으로 단일 모델 대비 성능이 좋다 앙상블을 앙상블하는 기법인 Stacking과 Weighted Blending도 참고해 볼만 하다 앙상블 모델은 적절한 Hyper-parameter Tuning이 중요하다 앙상블 모델은 대체적으로 학습시간이 더 오래 걸린다 따라서, 모델 튜닝을 하는 데에 시간이 오래 소유된다 5. Cross Validation 5-1. Cross Validation 소개 Cross Validation 알아보기 참고 자료: 딥러닝 모델의 K-겹 교차검증 (K-fold Cross Validation) 전에 진행했던 실습에서도 보였듯이, Hyper-parameter의 값은 모델의 성능을 좌우한다. 그러므로 예측 모델의 성능을 높이기 위해, Hyper-parameter Tuning이 매우 중요하다. 이를 실현하기 위해 저희는 Training data을 다시 Training set과 Validation set으로 나눈다. Trainging set에서 Hyper-parameter값을 바뀌가면서 모델 학습하고, Validation set에서 모델의 성능을 평가하여, 모델 성능을 제일 높일 수 있는 Hyper-parameter값을 선택한다 하지만, 데이터의 일부만 Validation set으로 사용해 모델 성능을 평가하게 되면, 훈련된 모델이 Test set에 대한 성능 평가의 신뢰성이 떨어질 수 있다. 이를 방지하기 위해 **K-fold Cross Validation (K-겹 교차검증)**을 많이 활용한다 K겹 교차 검증은 모든 데이터가 최소 한 번은 validation set으로 쓰이도록 한다 (아래의 그림을 보면, 데이터를 5개로 쪼개 매번 validation set을 바꿔나가는 것을 볼 수 있다) K번 검증을 통해 구한 K 개의 평가지표 값을 평균 내어 모델 성능을 평가한다 [예시] Estimation 1일 때, Training set: [2, 3, 4, 5] / Validation set: [1] Estimation 2일 때, Training set: [1, 3, 4, 5] / Validation set: [2] 1from sklearn.model_selection import KFold 12n_splits = 5kfold = KFold(n_splits=n_splits, random_state=1, shuffle = True) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 36.2 12X = np.array(df.drop('MEDV', 1))Y = np.array(df['MEDV']) 1lgbm_fold = LGBMRegressor(random_state=1) 123456789101112i = 1total_error = 0for train_index, test_index in kfold.split(X): x_train_fold, x_test_fold = X[train_index], X[test_index] y_train_fold, y_test_fold = Y[train_index], Y[test_index] lgbm_fold_pred = lgbm_fold.fit(x_train_fold, y_train_fold).predict(x_test_fold) error = mean_squared_error(y_test_fold, lgbm_fold_pred) print('Fold = {}, prediction score = {:.2f}'.format(i, error)) total_error += error i+=1print('---'*10)print('Average Error: %s' % (total_error / n_splits)) Fold = 1, prediction score = 9.76 Fold = 2, prediction score = 20.58 Fold = 3, prediction score = 6.95 Fold = 4, prediction score = 12.18 Fold = 5, prediction score = 10.87 ------------------------------ Average Error: 12.06743160435072 5-2. Hyper-parameter 튜닝 Hyper-parameter 튜닝 시 경우의 수가 너무 많으므로 우리는 자동화할 틸요가 있다 sklearn 패키지에서 자주 사용되는 hyper-parameter 튜닝을 돕는 클래스는 다음 2가지가 있다: RandomizedSerchCV GridSerchCV 적용하는 방법 사용할 Search 방법을 선택한다 hyper-parameter 도메인(값의 범위)을 설정한다 (max_depth, n_estimators… 등등) 학습을 시킨 후, 기다린다 도출된 결과 값을 모델에 적용하고 성능을 비교한다 (1) RandomizedSearchCV 모든 매개 변수 값이 시도되는 것이 아니라 지정된 분포에서 고정 된 수의 매개 변수 설정이 샘플링된다. 시도 된 매개 변수 설정의 수는 n_iter에 의해 제공됨. 주요 Hyper-parameter (LGBM) random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1 n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 max_depth: 트리의 깊이. 과대적합 방지용. default=3. colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0 1234567params = { 'learning_rate': [0.005, 0.01, 0.03, 0.05], 'n_estimators': [500, 1000, 2000, 3000], 'max_depth': [3, 5, 7], 'colsample_bytree': [0.8, 0.9, 1.0], 'subsample': [0.7, 0.8, 0.9, 1.0],} 1from sklearn.model_selection import RandomizedSearchCV 조절하여, 총 몇 회의 시도를 진행할 것인자 정의한다 12345(회수가 늘어나면, 더 좋은 parameter를 찾을 확률은 올라가지만, 그만큼 시간이 오래걸린다.)```pythonrcv_lgbm = RandomizedSearchCV(LGBMRegressor(), params, random_state=1, cv=5, n_iter=100, scoring='neg_mean_squared_error') 1rcv_lgbm.fit(x_train, y_train) RandomizedSearchCV(cv=5, error_score=nan, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, importance_type='split', learning_rate=0.1, max_depth=-1, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31, objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silen... subsample_freq=0), iid='deprecated', n_iter=100, n_jobs=None, param_distributions={'colsample_bytree': [0.8, 0.9, 1.0], 'learning_rate': [0.005, 0.01, 0.03, 0.05], 'max_depth': [3, 5, 7], 'n_estimators': [500, 1000, 2000, 3000], 'subsample': [0.7, 0.8, 0.9, 1.0]}, pre_dispatch='2*n_jobs', random_state=1, refit=True, return_train_score=False, scoring='neg_mean_squared_error', verbose=0) 1rcv_lgbm.best_score_ -11.132039701508374 1rcv_lgbm.best_params_ {'subsample': 0.8, 'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.9} 123lgbm_best = LGBMRegressor(learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, colsample_bytree=0.9)lgbm_best_pred = lgbm_best.fit(x_train, y_train).predict(x_test)mse_eval('RandomSearch LGBM', y_test, lgbm_best_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 RandomSearch LGBM 12.661917 15 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 16 LightGBM w/ Tuning 12.200040 17 XGBoost w/ Tuning 11.987602 18 RandomForest Ensemble w/ Tuning 11.481491 19 Weighted Blending 10.585610 (2) GridSerchCV 모든 매개 변수 값에 대하여 완전 탐색을 시도한다 따라서, 최적화할 parameter가 많다면, 시간이 매우 오래걸린다 1234567params = { 'learning_rate': [0.04, 0.05, 0.06], 'n_estimators': [800, 1000, 1200], 'max_depth': [3, 4, 5], 'colsample_bytree': [0.8, 0.85, 0.9], 'subsample': [0.8, 0.85, 0.9],} 1from sklearn.model_selection import GridSearchCV 1grid_search = GridSearchCV(LGBMRegressor(), params, cv=5, n_jobs=-1, scoring='neg_mean_squared_error') 1grid_search.fit(x_train, y_train) GridSearchCV(cv=5, error_score=nan, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, importance_type='split', learning_rate=0.1, max_depth=-1, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31, objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0), iid='deprecated', n_jobs=-1, param_grid={'colsample_bytree': [0.8, 0.85, 0.9], 'learning_rate': [0.04, 0.05, 0.06], 'max_depth': [3, 4, 5], 'n_estimators': [800, 1000, 1200], 'subsample': [0.8, 0.85, 0.9]}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='neg_mean_squared_error', verbose=0) 1grid_search.best_score_ -11.10039780445118 1grid_search.best_params_ {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.8} 123lgbm_best = LGBMRegressor(learning_rate=0.05, n_estimators=800, subsample=0.8, max_depth=3, colsample_bytree=0.9)lgbm_best_pred = lgbm_best.fit(x_train, y_train).predict(x_test)mse_eval('GridSearch LGBM', y_test, lgbm_best_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 GridSearch LGBM 12.794172 15 RandomSearch LGBM 12.661917 16 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 17 LightGBM w/ Tuning 12.200040 18 XGBoost w/ Tuning 11.987602 19 RandomForest Ensemble w/ Tuning 11.481491 20 Weighted Blending 10.585610 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"앙상블","slug":"앙상블","permalink":"https://hyemin-kim.github.io/tags/%EC%95%99%EC%83%81%EB%B8%94/"}]},{"title":"Python >> sklearn - (3) 회귀 (Regression)","slug":"S-Python-sklearn3","date":"2020-07-29T09:53:05.000Z","updated":"2020-07-29T10:16:41.634Z","comments":true,"path":"2020/07/29/S-Python-sklearn3/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/29/S-Python-sklearn3/","excerpt":"","text":"회귀 (Regression) 예측 0. 데이터 셋 0-1. 데이터 로드 0-2. 데이터프레임 만들기 1. Training set / Test set 나누기 2. 평가 지표 만들기 2-1. 평가 지표 계산식 2-2. 코딩으로 평가 지표 만들어 보기 2-3. sklearn의 평가 지표 활용하기 2-4. 모델 성능 확인을 위한 함수 3. 회귀 알고리즘 3-1. Linear Regression 3-2. Ridge &amp; LASSO &amp; ElasticNet (1) 개념 (2) 실습 4. Scaling 4-1. Scaler 소개 4-2. Scaling 후 모델 학습 – 파이프라인 활용 5. Polynomial Features [Supervised Learning] Document 특성: 수치형 값을 예측 (Y의 값이 연속형 수치로 표현) 예시: 주택 가격 예측 매출앵 예측 0. 데이터 셋 1234import pandas as pdimport numpy as npnp.set_printoptions(suppress=True) # If True, print floating point numbers instead of scientific notation 1from sklearn.datasets import load_boston [Boston Dataset] 0-1. 데이터 로드 1data = load_boston() 1print(data['DESCR']) # data description .. _boston_dataset: Boston house prices dataset --------------------------- **Data Set Characteristics:** :Number of Instances: 506 :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target. :Attribute Information (in order): - CRIM per capita crime rate by town - ZN proportion of residential land zoned for lots over 25,000 sq.ft. - INDUS proportion of non-retail business acres per town - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) - NOX nitric oxides concentration (parts per 10 million) - RM average number of rooms per dwelling - AGE proportion of owner-occupied units built prior to 1940 - DIS weighted distances to five Boston employment centres - RAD index of accessibility to radial highways - TAX full-value property-tax rate per $10,000 - PTRATIO pupil-teacher ratio by town - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town - LSTAT % lower status of the population - MEDV Median value of owner-occupied homes in $1000's :Missing Attribute Values: None :Creator: Harrison, D. and Rubinfeld, D.L. This is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/machine-learning-databases/housing/ ​ This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics &amp; Management, vol.5, 81-102, 1978. Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics ...', Wiley, 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter. The Boston house-price data has been used in many machine learning papers that address regression problems. .. topic:: References - Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261. - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann. ​ 0-2. 데이터프레임 만들기 1234567# step 1. features (X)# data['data'] - feature data; data['feature_names'] - feature column namesdf = pd.DataFrame(data['data'], columns = data['feature_names'])# step 2. target (y) 추가 df['MEDV'] = data['target'] 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 36.2 컬럼 소게 (feature 13 + target 1): CRIM: 범죄율 ZN: 25,000 square feet 당 주거용 토지의 비율 INDUS: 비소매(non-retail) 비즈니스 면적 비율 CHAS: 찰스 강 더미 변수 (통로가 하천을 향하면 1; 그렇지 않으면 0) NOX: 산화 질소 농도 (천만 분의 1) RM:주거 당 평균 객실 수 AGE: 1940 년 이전에 건축된 자가 소유 점유 비율 DIS: 5 개의 보스턴 고용 센터까지의 가중 거리 RAD: 고속도로 접근성 지수 TAX: 10,000 달러 당 전체 가치 재산 세율 PTRATIO 도시 별 학생-교사 비율 B: 1000 (Bk-0.63) ^ 2 여기서 Bk는 도시 별 검정 비율입니다. LSTAT: 인구의 낮은 지위 MEDV: 자가 주택의 중앙값 (1,000 달러 단위) 1. Training set / Test set 나누기 1from sklearn.model_selection import train_test_split 1x_train, x_test, y_train, y_test = train_test_split(df.drop('MEDV', 1), df['MEDV'], random_state=23) 1x_train.shape, y_train.shape ((379, 13), (379,)) 1x_test.shape, y_test.shape ((127, 13), (127,)) 1x_train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 112 0.12329 0.0 10.01 0.0 0.547 5.913 92.9 2.3534 6.0 432.0 17.8 394.95 16.21 301 0.03537 34.0 6.09 0.0 0.433 6.590 40.4 5.4917 7.0 329.0 16.1 395.75 9.50 401 14.23620 0.0 18.10 0.0 0.693 6.343 100.0 1.5741 24.0 666.0 20.2 396.90 20.32 177 0.05425 0.0 4.05 0.0 0.510 6.315 73.4 3.3175 5.0 296.0 16.6 395.60 6.29 69 0.12816 12.5 6.07 0.0 0.409 5.885 33.0 6.4980 4.0 345.0 18.9 396.90 8.79 1y_train.head() 112 18.8 301 22.0 401 7.2 177 24.6 69 20.9 Name: MEDV, dtype: float64 2. 평가 지표 만들기 2-1. 평가 지표 계산식 (1) MAE (Mean Absolute Error) MAE (평균 절대 오차): 에측값과 실제값의 차이의 절대값에 대하여 평균을 낸 것 MAE=1n∑i=1n∣yi−yi^∣MAE = \\frac{1}{n} \\sum_{i=1}^n \\left\\vert y_i - \\widehat{y_i} \\right\\vert MAE=n1​i=1∑n​∣yi​−yi​​∣ (2) MSE (Mean Squared Error) MSE (평균 제곱 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 것 MSE=1n∑i=1n(yi−yi^)2MSE = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2 MSE=n1​i=1∑n​(yi​−yi​​)2 (3) RMSE (Root Mean Squared Error) RMSE (평균 제곱근 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 뒤 루트를 씌운 것 RMSE=1n∑i=1n(yi−yi^)2RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2} RMSE=n1​i=1∑n​(yi​−yi​​)2​ 2-2. 코딩으로 평가 지표 만들어 보기 1import numpy as np 12actual = np.array([1, 2, 3])pred = np.array([3, 4, 5]) 12345# MAEdef my_mae(actual, pred): return np.abs(actual - pred).mean()my_mae(actual, pred) 2.0 12345# MSEdef my_mse(actual, pred): return ((actual - pred)**2).mean()my_mse(actual, pred) 4.0 12345# RMSEdef my_rmse(actual, pred): return np.sqrt(my_mse(actual, pred))my_rmse(actual, pred) 2.0 2-3. sklearn의 평가 지표 활용하기 1from sklearn.metrics import mean_absolute_error, mean_squared_error [sklearn.metrics.mean_absolute_error] [sklearn.metrics.mean_squared_error] 12# MAE (my_mae VS sklearn_mae)my_mae(actual, pred), mean_absolute_error(actual, pred) (2.0, 2.0) 12# MSE (my_mse VS sklearn_mse)my_mse(actual, pred), mean_squared_error(actual, pred) (4.0, 4.0) 2-4. 모델 성능 확인을 위한 함수 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import matplotlib.pyplot as pltimport seaborn as snsmy_predictions = {}colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown', 'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick', 'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', 'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate', 'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', 'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato' ]# prediction plotdef plot_predictions(name_, actual, pred): df = pd.DataFrame({'actual': y_test, 'prediction': pred}) df = df.sort_values(by='actual').reset_index(drop=True) plt.figure(figsize=(12, 9)) plt.scatter(df.index, df['prediction'], marker='x', color='r') plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black') plt.title(name_, fontsize=15) plt.legend(['prediction', 'actual'], fontsize=12) plt.show()# evaluation plotdef mse_eval(name_, actual, pred): global predictions global colors plot_predictions(name_, actual, pred) mse = mean_squared_error(actual, pred) my_predictions[name_] = mse y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True) df = pd.DataFrame(y_value, columns=['model', 'mse']) print(df) min_ = df['mse'].min() - 10 max_ = df['mse'].max() + 10 length = len(df) plt.figure(figsize=(10, length)) ax = plt.subplot() ax.set_yticks(np.arange(len(df))) ax.set_yticklabels(df['model'], fontsize=15) bars = ax.barh(np.arange(len(df)), df['mse']) for i, v in enumerate(df['mse']): idx = np.random.choice(len(colors)) bars[i].set_color(colors[idx]) ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold') plt.title('MSE Error', fontsize=18) plt.xlim(min_, max_) plt.show()# remove modeldef remove_model(name_): global my_predictions try: del my_predictions[name_] except KeyError: return False return True 3. 회귀 알고리즘 3-1. Linear Regression [sklearn.linear_model.LinearRegression] Document 1from sklearn.linear_model import LinearRegression 123model = LinearRegression(n_jobs=-1) # n_jobs: CPU코어의 사용model.fit(x_train, y_train)pred = model.predict(x_test) 1mse_eval('LinearRegression', y_test, pred) model mse 0 LinearRegression 22.770784 3-2. Ridge &amp; LASSO &amp; ElasticNet (1) 개념 참고 규제(Regularization): 학습이 과적합 되는 것을 방지하고자 일종의 penalty를 부여하는 것. [원리] penalty를 부여하여 가중치(β\\betaβ)를 축소함으로써 학습 모델의 예측 variance를 감소 시키는 것 &gt;&gt; L2 규제 &amp; Ridge (릿지) L2 규제 (L2 Regularization): 각 가중치 제곱의 합에 규제 강도 (Regularization Strength) λ\\lambdaλ 를 곱한다 L2&nbsp;규제=λ∑j=1pβj2=λ&nbsp;∥β∥22L2 \\ 규제 = \\lambda \\sum_{j=1}^p \\beta_j^2 = \\lambda\\ \\lVert \\beta \\rVert_2^2 L2&nbsp;규제=λj=1∑p​βj2​=λ&nbsp;∥β∥22​ l2&nbsp;norm:∥β∥2=∑j=1pβj2l_2 \\ norm: \\lVert \\beta \\rVert_2 = \\sqrt{\\sum_{j=1}^p \\beta_j^2} l2​&nbsp;norm:∥β∥2​=j=1∑p​βj2​​ Ridge: Loss Function에 L2 규제를 더한 값을 최소화 시키는 것 min⁡βj&nbsp;[∑i=1n(yi−β0−∑j=1pβjxij)+λ&nbsp;∑j=1pβj2]=min⁡βj&nbsp;[RSS+λ&nbsp;∑j=1pβj2]\\min_{\\beta_j} \\ \\left[ \\sum_{i=1}^n \\left( y_i-\\beta_0-\\sum_{j=1}^p\\beta_jx_{ij} \\right) + \\lambda\\ \\sum_{j=1}^p\\beta_j^2 \\right]= \\min_{\\beta_j} \\ \\left[ RSS + \\lambda\\ \\sum_{j=1}^p\\beta_j^2 \\right] βj​min​&nbsp;[i=1∑n​(yi​−β0​−j=1∑p​βj​xij​)+λ&nbsp;j=1∑p​βj2​]=βj​min​&nbsp;[RSS+λ&nbsp;j=1∑p​βj2​] λ\\lambdaλ 를 크게 하면 가중치(β\\betaβ) 가 더 많이 감소되고(규제를 중요시 함), λ\\lambdaλ 를 작게 하면 가중치(β\\betaβ) 가 증가한다(규제를 중요시하지 않음) &gt;&gt; L1 규제 &amp; LASSO (라쏘) L1 규제 (L1 Regularization): 각 가중치 절대값의 합에 규제 강도 (Regularization Strength) λ\\lambdaλ 를 곱한다 L1&nbsp;규제=λ∑j=1p∣βj∣=λ&nbsp;∥β∥1L1\\ 규제 = \\lambda \\sum_{j=1}^p \\left| \\beta_j \\right| = \\lambda \\ \\lVert \\beta \\rVert_1 L1&nbsp;규제=λj=1∑p​∣βj​∣=λ&nbsp;∥β∥1​ l1&nbsp;norm:∥β∥1=∑j=1p∣βj∣l1\\ norm: \\lVert \\beta \\rVert_1 = \\sum_{j=1}^p \\left| \\beta_j \\right| l1&nbsp;norm:∥β∥1​=j=1∑p​∣βj​∣ LASSO: Loss Function에 L1 규제를 더한 값을 최소화 시키는 것 min⁡βj&nbsp;[∑i=1n(yi−β0−∑j=1pβjxij)+λ∑j=1p∣βj∣]=min⁡βj&nbsp;[RSS+λ∑j=1p∣βj∣]\\min_{\\beta_j} \\ \\left[ \\sum_{i=1}^n \\left( y_i-\\beta_0-\\sum_{j=1}^p\\beta_jx_{ij} \\right) + \\lambda \\sum_{j=1}^p \\left| \\beta_j \\right| \\right]= \\min_{\\beta_j} \\ \\left[ RSS + \\lambda \\sum_{j=1}^p \\left| \\beta_j \\right| \\right] βj​min​&nbsp;[i=1∑n​(yi​−β0​−j=1∑p​βj​xij​)+λj=1∑p​∣βj​∣]=βj​min​&nbsp;[RSS+λj=1∑p​∣βj​∣] 어떤 가중치(β\\betaβ) 는 실제로 0이 된다. 즉, 모델에서 완전히 제외되는 특성이 생기는 것이다 &gt;&gt; ElasticNet l1_ratio (default=0.5) l1_ratio = 0 (L2 규제만 사용) l1_ratio = 1 (L1 규제만 사용) 0 &lt; l1_ratio &lt;1 (L1 and L2 규제 혼합사용) (2) 실습 &gt;&gt; Ridge [Document] 1from sklearn.linear_model import Ridge 예측 결과 확인 123456789# lambda (규제강도) 범위 설정alphas = [100, 10, 1, 0.1, 0.01, 0.001]# 모델 학습for alpha in alphas: ridge = Ridge(alpha = alpha) ridge.fit(x_train, y_train) ridge_pred = ridge.predict(x_test) mse_eval('Ridge(alpha={})'.format(alpha), y_test, ridge_pred) model mse 0 Ridge(alpha=100) 23.487453 1 LinearRegression 22.770784 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=0.1) 22.718126 4 Ridge(alpha=1) 22.690411 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=0.01) 22.764254 4 Ridge(alpha=0.1) 22.718126 5 Ridge(alpha=1) 22.690411 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=0.001) 22.770117 4 Ridge(alpha=0.01) 22.764254 5 Ridge(alpha=0.1) 22.718126 6 Ridge(alpha=1) 22.690411 coefficents 값 확인 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1ridge.coef_ # for the last alpha in 'alphas' array([ -0.09608448, 0.04753482, 0.0259022 , 3.24479273, -18.89579975, 4.06725732, 0.0020486 , -1.46883742, 0.28149275, -0.0094656 , -0.87454099, 0.01240815, -0.52406249]) 1234567891011121314# coefficients visulizationdef plot_coef(columns, coef): coef_df = pd.DataFrame(list(zip(columns, coef))) coef_df.columns=['feature', 'coef'] coef_df = coef_df.sort_values('coef', ascending=False).reset_index(drop=True) fig, ax = plt.subplots(figsize=(9, 7)) ax.barh(np.arange(len(coef_df)), coef_df['coef']) idx = np.arange(len(coef_df)) ax.set_yticks(idx) ax.set_yticklabels(coef_df['feature']) fig.tight_layout() plt.show() 1plot_coef(x_train.columns, ridge.coef_) # alpha = 0.001 alpha 값에 따른 coef의 차이 1234567ridge_1 = Ridge(alpha=1)ridge_1.fit(x_train, y_train)ridge_pred_1 = ridge_1.predict(x_test)ridge_100 = Ridge(alpha=100)ridge_100.fit(x_train, y_train)ridge_pred_100 = ridge_100.predict(x_test) 1plot_coef(x_train.columns, ridge_1.coef_) # alpha = 1 1plot_coef(x_train.columns, ridge_100.coef_) # alpha = 100 &gt;&gt; LASSO [Document] 1from sklearn.linear_model import Lasso 예측 결과 확인 123456789# lambda (규제강도) 범위 설정alphas = [100, 10, 1, 0.1, 0.01, 0.001]# 모델 학습for alpha in alphas: lasso = Lasso(alpha=alpha) lasso.fit(x_train, y_train) lasso_pred = lasso.predict(x_test) mse_eval('Lasso(alpha={})'.format(alpha), y_test, lasso_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Ridge(alpha=100) 23.487453 2 Ridge(alpha=10) 22.793119 3 LinearRegression 22.770784 4 Ridge(alpha=0.001) 22.770117 5 Ridge(alpha=0.01) 22.764254 6 Ridge(alpha=0.1) 22.718126 7 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Ridge(alpha=100) 23.487453 3 Ridge(alpha=10) 22.793119 4 LinearRegression 22.770784 5 Ridge(alpha=0.001) 22.770117 6 Ridge(alpha=0.01) 22.764254 7 Ridge(alpha=0.1) 22.718126 8 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Ridge(alpha=10) 22.793119 5 LinearRegression 22.770784 6 Ridge(alpha=0.001) 22.770117 7 Ridge(alpha=0.01) 22.764254 8 Ridge(alpha=0.1) 22.718126 9 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Ridge(alpha=0.1) 22.718126 10 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Ridge(alpha=0.1) 22.718126 10 Ridge(alpha=1) 22.690411 11 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Lasso(alpha=0.001) 22.753017 10 Ridge(alpha=0.1) 22.718126 11 Ridge(alpha=1) 22.690411 12 Lasso(alpha=0.01) 22.635614 coefficients 값 확인 123456789# alpha = 0.01lasso_01 = Lasso(alpha=0.01)lasso_01.fit(x_train, y_train)lasso_pred_01 = lasso_01.predict(x_test)# alpha = 100lasso_100 = Lasso(alpha=100)lasso_100.fit(x_train, y_train)lasso_pred_100 = lasso_100.predict(x_test) [alpha = 0.01] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1lasso_01.coef_ array([ -0.09427142, 0.04759954, 0.01255668, 3.08256139, -15.36800113, 4.07373679, -0.00100439, -1.40819927, 0.27152905, -0.0097157 , -0.84377679, 0.01249204, -0.52790174]) 1plot_coef(x_train.columns, lasso_01.coef_) [alpha = 100] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1lasso_100.coef_ array([-0. , 0. , -0. , 0. , -0. , 0. , -0. , 0. , -0. , -0.02078349, -0. , 0.00644409, -0. ]) 1plot_coef(x_train.columns, lasso_100.coef_) &gt;&gt; ElasticNet [Document] 1from sklearn.linear_model import ElasticNet 예측 결과 확인 1ratios = [0.2, 0.5, 0.8] 1234567# alpha = 0.5 로 고정for ratio in ratios: elasticnet = ElasticNet(alpha=0.1, l1_ratio=ratio) elasticnet.fit(x_train, y_train) elas_pred = elasticnet.predict(x_test) mse_eval('ElasticNet(l1_ratio={})'.format(ratio), y_test, elas_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Lasso(alpha=0.001) 22.753017 10 ElasticNet(l1_ratio=0.2) 22.749018 11 Ridge(alpha=0.1) 22.718126 12 Ridge(alpha=1) 22.690411 13 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 ElasticNet(l1_ratio=0.5) 22.787269 7 LinearRegression 22.770784 8 Ridge(alpha=0.001) 22.770117 9 Ridge(alpha=0.01) 22.764254 10 Lasso(alpha=0.001) 22.753017 11 ElasticNet(l1_ratio=0.2) 22.749018 12 Ridge(alpha=0.1) 22.718126 13 Ridge(alpha=1) 22.690411 14 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 ElasticNet(l1_ratio=0.8) 22.865628 6 Ridge(alpha=10) 22.793119 7 ElasticNet(l1_ratio=0.5) 22.787269 8 LinearRegression 22.770784 9 Ridge(alpha=0.001) 22.770117 10 Ridge(alpha=0.01) 22.764254 11 Lasso(alpha=0.001) 22.753017 12 ElasticNet(l1_ratio=0.2) 22.749018 13 Ridge(alpha=0.1) 22.718126 14 Ridge(alpha=1) 22.690411 15 Lasso(alpha=0.01) 22.635614 coefficients 값 확인 123456789# ㅣ1_ratio = 0.2elasticnet_2 = ElasticNet(alpha = 0.1, l1_ratio = 0.2)elasticnet_2.fit(x_train, y_train)elast_pred_2 = elasticnet_2.predict(x_test)# l1_ratio = 0.8elasticnet_8 = ElasticNet(alpha=0.1, l1_ratio = 0.8)elasticnet_8.fit(x_train, y_train)elast_pred_8 = elasticnet_8.predict(x_test) [ l1_ratio = 0.2 ] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1elasticnet_2.coef_ array([-0.09297585, 0.05293361, -0.03950412, 1.30126199, -0.41996826, 3.15838796, -0.00644646, -1.15290012, 0.25973467, -0.01231233, -0.77186571, 0.01201684, -0.60780037]) 1plot_coef(x_train.columns, elasticnet_2.coef_) [ l1_ratio = 0.8 ] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1elasticnet_8.coef_ array([-0.08797633, 0.05035601, -0.03058513, 1.51071961, -0. , 3.70247373, -0.01017259, -1.12431077, 0.24389841, -0.01189981, -0.73481448, 0.01259147, -0.573733 ]) 1plot_coef(x_train.columns, elasticnet_8.coef_) 4. Scaling 4-1. Scaler 소개 StandardScaler MinMaxScaler RobustScaler 1from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler 1x_train.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT count 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 mean 3.512192 11.779683 10.995013 0.076517 0.548712 6.266953 67.223483 3.917811 9.282322 404.680739 18.448549 357.048100 12.633773 std 8.338717 23.492842 6.792065 0.266175 0.115006 0.681796 28.563787 2.084167 8.583051 166.813256 2.154917 92.745266 7.259213 min 0.006320 0.000000 0.460000 0.000000 0.385000 3.561000 2.900000 1.129600 1.000000 188.000000 12.600000 2.520000 1.730000 25% 0.078910 0.000000 5.190000 0.000000 0.445000 5.876500 42.250000 2.150900 4.000000 278.000000 17.150000 375.425000 6.910000 50% 0.228760 0.000000 9.690000 0.000000 0.532000 6.208000 74.400000 3.414500 5.000000 330.000000 19.000000 392.110000 11.380000 75% 2.756855 19.000000 18.100000 0.000000 0.624000 6.611000 93.850000 5.400900 8.000000 666.000000 20.200000 396.260000 16.580000 max 73.534100 100.000000 27.740000 1.000000 0.871000 8.398000 100.000000 10.585700 24.000000 711.000000 22.000000 396.900000 37.970000 &gt;&gt; StandardScaler 평균(mean)을 0, 표준편차(std)를 1로 만들어 주는 scaler 123std_scaler = StandardScaler()std_scaled = std_scaler.fit_transform(x_train)round(pd.DataFrame(std_scaled).describe(), 2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 8 9 10 11 12 count 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 mean -0.00 0.00 0.00 -0.00 -0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 0.00 std 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 min -0.42 -0.50 -1.55 -0.29 -1.43 -3.97 -2.25 -1.34 -0.97 -1.30 -2.72 -3.83 -1.50 25% -0.41 -0.50 -0.86 -0.29 -0.90 -0.57 -0.88 -0.85 -0.62 -0.76 -0.60 0.20 -0.79 50% -0.39 -0.50 -0.19 -0.29 -0.15 -0.09 0.25 -0.24 -0.50 -0.45 0.26 0.38 -0.17 75% -0.09 0.31 1.05 -0.29 0.66 0.51 0.93 0.71 -0.15 1.57 0.81 0.42 0.54 max 8.41 3.76 2.47 3.47 2.81 3.13 1.15 3.20 1.72 1.84 1.65 0.43 3.49 &gt;&gt; MinMaxScaler min값과 max값을 0~1사이로 정규화 (Normalize) 123minmax_scaler = MinMaxScaler()minmax_scaled = minmax_scaler.fit_transform(x_train)round(pd.DataFrame(minmax_scaled).describe(), 2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 8 9 10 11 12 count 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 mean 0.05 0.12 0.39 0.08 0.34 0.56 0.66 0.29 0.36 0.41 0.62 0.90 0.30 std 0.11 0.23 0.25 0.27 0.24 0.14 0.29 0.22 0.37 0.32 0.23 0.24 0.20 min 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 25% 0.00 0.00 0.17 0.00 0.12 0.48 0.41 0.11 0.13 0.17 0.48 0.95 0.14 50% 0.00 0.00 0.34 0.00 0.30 0.55 0.74 0.24 0.17 0.27 0.68 0.99 0.27 75% 0.04 0.19 0.65 0.00 0.49 0.63 0.94 0.45 0.30 0.91 0.81 1.00 0.41 max 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 &gt;&gt; RobustScaler 중앙값(median)이 0, IQR(interquartile rage)이 1이 되도록 변환 outlier 처리에 유용 123robust_scaler = RobustScaler()robust_scaled = robust_scaler.fit_transform(x_train)round(pd.DataFrame(robust_scaled).median(), 2) 0 0.0 1 0.0 2 0.0 3 0.0 4 0.0 5 0.0 6 0.0 7 0.0 8 0.0 9 0.0 10 0.0 11 0.0 12 0.0 dtype: float64 4-2. Scaling 후 모델 학습 – 파이프라인 활용 1from sklearn.pipeline import make_pipeline 1234567891011121314# elasticnet(alpha=0.1, l1_ratio=0.2) &lt; without standard scaling &gt;elasticnet_no_scale = ElasticNet(alpha=0.1, l1_ratio=0.2)no_scale_pred = elasticnet_no_scale.fit(x_train, y_train).predict(x_test)mse_eval('No Standard ElasticNet', y_test, no_scale_pred)# elasticnet(alpha=0.1, l1_ratio=0.2) &lt; with standard scaling &gt;elasticnet_pipeline = make_pipeline( StandardScaler(), ElasticNet(alpha=0.1, l1_ratio=0.2))with_scale_pred = elasticnet_pipeline.fit(x_train, y_train).predict(x_test)mse_eval('With Standard ElasticNet', y_test, with_scale_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 ElasticNet(l1_ratio=0.8) 22.865628 6 Ridge(alpha=10) 22.793119 7 ElasticNet(l1_ratio=0.5) 22.787269 8 LinearRegression 22.770784 9 Ridge(alpha=0.001) 22.770117 10 Ridge(alpha=0.01) 22.764254 11 Lasso(alpha=0.001) 22.753017 12 ElasticNet(l1_ratio=0.2) 22.749018 13 No Standard ElasticNet 22.749018 14 Ridge(alpha=0.1) 22.718126 15 Ridge(alpha=1) 22.690411 16 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 With Standard ElasticNet 23.230164 5 Lasso(alpha=0.1) 22.979708 6 ElasticNet(l1_ratio=0.8) 22.865628 7 Ridge(alpha=10) 22.793119 8 ElasticNet(l1_ratio=0.5) 22.787269 9 LinearRegression 22.770784 10 Ridge(alpha=0.001) 22.770117 11 Ridge(alpha=0.01) 22.764254 12 Lasso(alpha=0.001) 22.753017 13 ElasticNet(l1_ratio=0.2) 22.749018 14 No Standard ElasticNet 22.749018 15 Ridge(alpha=0.1) 22.718126 16 Ridge(alpha=1) 22.690411 17 Lasso(alpha=0.01) 22.635614 5. Polynomial Features [Document] 다항식의 계수간 상호작용을 통해 새로운 feature를 생성한다. 예를 들면, [a, b] 2개의 feature가 존재한다고 가정하고, degree=2로 설정한다면, polynomial features 는 [1, a, b, a^2, ab, b^2]가 돤다 1from sklearn.preprocessing import PolynomialFeatures Polynomial Features 생성 1poly = PolynomialFeatures(degree=2, include_bias=False) 12poly_features = poly.fit_transform(x_train)[0]poly_features array([ 0.12329 , 0. , 10.01 , 0. , 0.547 , 5.913 , 92.9 , 2.3534 , 6. , 432. , 17.8 , 394.95 , 16.21 , 0.01520042, 0. , 1.2341329 , 0. , 0.06743963, 0.72901377, 11.453641 , 0.29015069, 0.73974 , 53.26128 , 2.194562 , 48.6933855 , 1.9985309 , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 100.2001 , 0. , 5.47547 , 59.18913 , 929.929 , 23.557534 , 60.06 , 4324.32 , 178.178 , 3953.4495 , 162.2621 , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.299209 , 3.234411 , 50.8163 , 1.2873098 , 3.282 , 236.304 , 9.7366 , 216.03765 , 8.86687 , 34.963569 , 549.3177 , 13.9156542 , 35.478 , 2554.416 , 105.2514 , 2335.33935 , 95.84973 , 8630.41 , 218.63086 , 557.4 , 40132.8 , 1653.62 , 36690.855 , 1505.909 , 5.53849156, 14.1204 , 1016.6688 , 41.89052 , 929.47533 , 38.148614 , 36. , 2592. , 106.8 , 2369.7 , 97.26 , 186624. , 7689.6 , 170618.4 , 7002.72 , 316.84 , 7030.11 , 288.538 , 155985.5025 , 6402.1395 , 262.7641 ]) 1x_train.iloc[0] CRIM 0.12329 ZN 0.00000 INDUS 10.01000 CHAS 0.00000 NOX 0.54700 RM 5.91300 AGE 92.90000 DIS 2.35340 RAD 6.00000 TAX 432.00000 PTRATIO 17.80000 B 394.95000 LSTAT 16.21000 Name: 112, dtype: float64 Polynomial Features + Standard Scaling 후 모델 학습 12345poly_pipeline = make_pipeline( PolynomialFeatures(degree=2, include_bias=False), StandardScaler(), ElasticNet(alpha=0.1, l1_ratio=0.2)) 1poly_pred = poly_pipeline.fit(x_train, y_train).predict(x_test) D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.61172784964583, tolerance: 3.2374824854881266 positive) 1mse_eval('Poly ElasticNet', y_test, poly_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 With Standard ElasticNet 23.230164 5 Lasso(alpha=0.1) 22.979708 6 ElasticNet(l1_ratio=0.8) 22.865628 7 Ridge(alpha=10) 22.793119 8 ElasticNet(l1_ratio=0.5) 22.787269 9 LinearRegression 22.770784 10 Ridge(alpha=0.001) 22.770117 11 Ridge(alpha=0.01) 22.764254 12 Lasso(alpha=0.001) 22.753017 13 ElasticNet(l1_ratio=0.2) 22.749018 14 No Standard ElasticNet 22.749018 15 Ridge(alpha=0.1) 22.718126 16 Ridge(alpha=1) 22.690411 17 Lasso(alpha=0.01) 22.635614 18 Poly ElasticNet 17.526214 2차 Polynomial Features 추가 후 학습된 모델의 성능이 많이 향상 된것을 확인할 수 있다 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"회귀","slug":"회귀","permalink":"https://hyemin-kim.github.io/tags/%ED%9A%8C%EA%B7%80/"}]},{"title":"Python >> sklearn - (2) 분류 (Classification)","slug":"S-Python-sklearn2","date":"2020-07-26T11:23:49.000Z","updated":"2020-07-30T07:54:02.033Z","comments":true,"path":"2020/07/26/S-Python-sklearn2/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/26/S-Python-sklearn2/","excerpt":"","text":"분류 (Classification) 0. 데이터 셋 0-1. iris 데이터 셋 0-2. 데이터프레임 만들기 0-3. 시각화로 데이터셋 파악하기 1. training set / validation set 나누기 2. 하이퍼 파라미터 (hyper-parameter) 튜닝 3. 분류 알고리즘 3-1. Logistic Regression 3-2. SGD (SGDClassifier) 3-3. KNN (KNeighborsClassifier) 3-4. SVM (SVC) 3-5. Decision Tree (DecisionTreeClassifier) 1. Decision Tree (의사 결정 나무): 나무 가지치기를 통해 소그룹으로 나누어 판별하는것 2. Decision Tree 분류 결과 시각화 3. 가지 치기 (pruning) 4. 모델 성능 평가 지표 4-1. 오차 행렬 (Confusion Matrix) 4-2. 정확도 (Accuracy) 4-3. 정밀도 (Precision) 4-4. 민감도 (Sensitivity) / 재현율 (Recall) 4-5. 특이도 (Specificity) 4-6. F1 Score 12import warningswarnings.filterwarnings('ignore') # 불필요한 경고 출력을 방지함 1import pandas as pd 0. 데이터 셋 sklearn.dataset 에서 제공해주는 다양한 샘플 데이터를 활용한다 여기서는 iris 데이터 셋을 활용한다 0-1. iris 데이터 셋 Mission: 꽃 종류 분류하기 iris 데이터 셋 1from sklearn.datasets import load_iris 12# iris 데이터 셋 로드iris = load_iris() iris 데이터 셋 구성 (key values): DESCR: 데이터 셋의 정보를 보여줌 data: feature data feature_names: feature data의 컬럼 이름 target: label data (수치형) target_names: label data의 value 이름 (문자형) 12# 데이터 셋 정보 확인하기print(iris['DESCR']) .. _iris_dataset: Iris plants dataset -------------------- **Data Set Characteristics:** :Number of Instances: 150 (50 in each of three classes) :Number of Attributes: 4 numeric, predictive attributes and the class :Attribute Information: - sepal length in cm - sepal width in cm - petal length in cm - petal width in cm - class: - Iris-Setosa - Iris-Versicolour - Iris-Virginica :Summary Statistics: ============== ==== ==== ======= ===== ==================== Min Max Mean SD Class Correlation ============== ==== ==== ======= ===== ==================== sepal length: 4.3 7.9 5.84 0.83 0.7826 sepal width: 2.0 4.4 3.05 0.43 -0.4194 petal length: 1.0 6.9 3.76 1.76 0.9490 (high!) petal width: 0.1 2.5 1.20 0.76 0.9565 (high!) ============== ==== ==== ======= ===== ==================== :Missing Attribute Values: None :Class Distribution: 33.3% for each of 3 classes. :Creator: R.A. Fisher :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov) :Date: July, 1988 The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken from Fisher's paper. Note that it's the same as in R, but not as in the UCI Machine Learning Repository, which has two wrong data points. This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda &amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. .. topic:: References - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950). - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis. (Q327.D83) John Wiley &amp; Sons. ISBN 0-471-22361-1. See page 218. - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System Structure and Classification Rule for Recognition in Partially Exposed Environments\". IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-2, No. 1, 67-71. - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\". IEEE Transactions on Information Theory, May 1972, 431-433. - See also: 1988 MLC Proceedings, 54-64. Cheeseman et al\"s AUTOCLASS II conceptual clustering system finds 3 classes in the data. - Many, many more ... 123# data 불러오기data = iris['data']data[:5] array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5. , 3.6, 1.4, 0.2]]) 123# feature names 확인하기feature_names = iris['feature_names']feature_names ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] [해석] sepal: 꽃 받침; petal: 꽃잎 123# label data 확인하기target = iris['target']target[:5] array([0, 0, 0, 0, 0]) 12# target names 확인하기iris['target_names'] array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10') 0-2. 데이터프레임 만들기 123# feature data 먼저 생성하기df_iris = pd.DataFrame(data, columns = feature_names)df_iris.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 123# target column 추가하기df_iris['target'] = targetdf_iris.head() # 최종 dataframe .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 0-3. 시각화로 데이터셋 파악하기 12import matplotlib.pyplot as pltimport seaborn as sns 1. Sepal data로 보는 꽃 종류 1df_iris.columns Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target'], dtype='object') 123sns.scatterplot('sepal width (cm)', 'sepal length (cm)', hue='target', palette='muted', data=df_iris)plt.title('Sepal')plt.show() 2. petal data로 보는 꽃 종류 123sns.scatterplot('petal width (cm)', 'petal length (cm)', hue='target', palette='muted', data=df_iris)plt.title('Petal')plt.show() 3. 3D plot로 보는 꽃 종류 (PCA 이용) 1234567891011121314151617from mpl_toolkits.mplot3d import Axes3Dfrom sklearn.decomposition import PCAfig = plt.figure(figsize=(8, 6))ax = Axes3D(fig, elev=-150, azim=110)X_reduced = PCA(n_components=3).fit_transform(df_iris.drop('target', 1))ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=df_iris['target'], cmap=plt.cm.Set1, edgecolor='k', s=40)ax.set_title(\"Iris 3D\")ax.set_xlabel(\"x\")ax.w_xaxis.set_ticklabels([])ax.set_ylabel(\"y\")ax.w_yaxis.set_ticklabels([])ax.set_zlabel(\"z\")ax.w_zaxis.set_ticklabels([])plt.show() 1. training set / validation set 나누기 1from sklearn.model_selection import train_test_split 1x_train, x_valid, y_train, y_valid = train_test_split(df_iris.drop('target', 1), df_iris['target']) 1x_train.shape, y_train.shape ((112, 4), (112,)) 1x_valid.shape, y_valid.shape ((38, 4), (38,)) 1sns.countplot(y_train) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1cb7aaaeec8&gt; 'target’값이 0, 1, 2인 데이터가 Original dataset으로 부터 랜덤으로 뽑히기 때문에 비율의 차이가 존재할 수 있다. 따라서 기계학습할 때 sample size가 큰 데이터 위주로 학습하여 모델의 예측성능이 떨어질 수 있다. (위 상황에서, 학습된 머신러닝 모델이 sample size가 큰 target=1인 경우를 좀 더 잘 예측하고, target=2에 대한 예측도가 떨어질 수 있다) 이를 방지하기 위해 우리는 stratify옵션을 이용하여 label의 class 분포를 균등하게 배분한다. 1x_train, x_valid, y_train, y_valid = train_test_split(df_iris.drop('target', 1), df_iris['target'], stratify=df_iris['target']) 1sns.countplot(y_train) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1cb7b17b508&gt; 1x_train.shape, y_train.shape ((112, 4), (112,)) 1x_valid.shape, y_valid.shape ((38, 4), (38,)) 2. 하이퍼 파라미터 (hyper-parameter) 튜닝 모델 학습할 때 설정 한 옵션들은 **하이퍼 파라미터 (hyper-parameter)**라고 한다. 설정한 값에 따라 모델 성능도 달라질 수 있다. 각 알고리즘 별, hyper-parameter의 종류가 매우 다양하다. 다음 두 가지 parameter는 기본적으로 설정해주는 것이 좋다: random_state: sampling seed 설정 (항상 동일하게 sampling 하기) n_jobs=-1: CPU를 모두 사용 (학습속도가 빠름) 3. 분류 알고리즘 3-1. Logistic Regression [sklearn.linear_model.LogisticRegression] Document Logistic Regression, SVM(Support Vector Machine)과 같은 알고리즘은 이진(Binary Class) 분류만 가능한다. (2개의 클래스 판별만 가능한다.) 하지만, 3개 이상의 클래스에 대한 판별 **[다중 클래스(Multi-Class) 분류]**을 진행하는 경우, 다음과 같은 전략으로 판별한다. one-vs-one (OvO): K 개의 클래스가 존재할 때, 이 중 2개의 클래스 조합을 선택하여 K(K−1)/2 개의 이진 클래스 분류 문제를 풀고 이진판별을 통해 가장 많은 판별값을 얻은 클래스를 선택하는 방법이다. one-vs-rest (OvR): K 개의 클래스가 존재할 때, 클래스들을 “k번째 클래스(one)” &amp; \"나머지(rest)\"로 나누어서 K개의 개별 이진 분류 문제를 푼다. 즉, 각각의 클래스에 대해 표본이 속하는지(y=1) 속하지 않는지(y=0)의 이진 분류 문제를 푸는 것이다. OvO와 달리 클래스 수만큼의 이진 분류 문제를 풀면 된다. 대부분 OvsR 전략을 선호합니다. 1from sklearn.linear_model import LogisticRegression step 1: 모델 선언 1lr = LogisticRegression(random_state=0) step 2: 모델 학습 1lr.fit(x_train, y_train) LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=0, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False) step 3: 예측 1prediction = lr.predict(x_valid) 1prediction[:5] array([0, 1, 2, 2, 0]) step 4: 평가 1(prediction == y_valid).mean() # 정확도 0.9473684210526315 3-2. SGD (SGDClassifier) [sklearn.linear_model.SGDClassifier] Document stochastic gradient descent (SGD): 확률적 경사 하강법 1from IPython.display import Image 12# 출처: https://machinelearningnotepad.wordpress.com/Image('https://machinelearningnotepad.files.wordpress.com/2018/04/yk1mk.png', width=500) 1from sklearn.linear_model import SGDClassifier step 1: 모델 선언 1sgd = SGDClassifier(random_state=0) step 2: 모델 학습 1sgd.fit(x_train, y_train) SGDClassifier(alpha=0.0001, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5, random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False) step 3: 예측 1prediction = sgd.predict(x_valid) step 4: 평가 1(prediction == y_valid).mean() 0.9473684210526315 Change hyper-parameter values: e.g.: penalty = ‘l1’, random_state = 1, n_jobs = -1 1sgd2 = SGDClassifier(penalty='l1', random_state=1, n_jobs=-1) 1sgd2.fit(x_train, y_train) SGDClassifier(alpha=0.0001, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l1', power_t=0.5, random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False) 1prediction2 = sgd2.predict(x_valid) 1(prediction2 == y_valid).mean() 1.0 3-3. KNN (KNeighborsClassifier) [sklearn.neighbors.KNeighborsClassifier] Document KNN (K Nearest Neighbors): K 최근접 이웃 알고리즘 새로운 데이터의 분류 결과가 K 개 최근접 이웃의 클래스에 의해서 결정되며, 데이터는 가장 많이 할당되는 클래스로 분류하게 된다. 12# 출처: 데이터 캠프Image('https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final_a1mrv9.png') 1from sklearn.neighbors import KNeighborsClassifier 12# 1. 모델 선언knn = KNeighborsClassifier() 12# 2. 모델 학습knn.fit(x_train, y_train) # default: n_neighbors=5 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform') 12# 3. 예측prediction = knn.predict(x_valid) 12# 4. 평가(prediction == y_valid).mean() 0.9210526315789473 n_neighnors를 9개로 설정하여 다시 예측해본다: 123knn2 = KNeighborsClassifier(n_neighbors=9)knn2.fit(x_train, y_train)knn2_pred = knn2.predict(x_valid) 1(knn2_pred == y_valid).mean() 0.9473684210526315 3-4. SVM (SVC) [sklearn.svm.SVC] Document 새로운 데이터가 어느 카테고리에 속할지 판단하는 비확률적 이진 선형 분류 모델을 만듦. 경계로 표현되는 데이터들 중 가장 큰 폭을 가진 경계를 찾는 알고리즘. 1Image('https://csstudy.files.wordpress.com/2011/03/screen-shot-2011-02-28-at-5-53-26-pm.png') SVM은 Logistic Regression과 같이 이진 분류만 가능하다. (2개의 클래스 판별만 가능) 3개 이상의 클래스인 경우: OvsR 전략 사용 1from sklearn.svm import SVC # SVC: Support Vector Classification 123svc = SVC(random_state=0)svc.fit(x_train, y_train)svc_pred = svc.predict(x_valid) 1svc # hyper-parameter 확인 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf', max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001, verbose=False) 1(svc_pred == y_valid).mean() 0.9473684210526315 각 클래스 별 확률값을 return해주는 decision_function() 1svc.decision_function(x_valid)[:5] array([[ 2.22273426, 1.18194657, -0.25426485], [-0.22060229, 2.23192595, 0.91725911], [-0.23638817, 1.18969144, 2.17593611], [-0.23457057, 1.07146337, 2.22588253], [ 2.22808358, 1.16872302, -0.25381783]]) 1svc_pred[:5] array([0, 1, 2, 2, 0]) 확률값이 제일 높은 클래스로 분류(예측) 된 것을 확인하실 수 있다 3-5. Decision Tree (DecisionTreeClassifier) [sklearn.tree.DecisionTreeClassifier] Document 1. Decision Tree (의사 결정 나무): 나무 가지치기를 통해 소그룹으로 나누어 판별하는것 1Image('https://www.researchgate.net/profile/Ludmila_Aleksejeva/publication/293194222/figure/fig1/AS:669028842487827@1536520314657/Decision-tree-for-Iris-dataset.png', width=500) 1from sklearn.tree import DecisionTreeClassifier 1dt = DecisionTreeClassifier(random_state=0) 1dt.fit(x_train, y_train) DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=0, splitter='best') 1dt_pred = dt.predict(x_valid) 1(dt_pred == y_valid).mean() 0.9210526315789473 2. Decision Tree 분류 결과 시각화 123from sklearn.tree import export_graphvizfrom IPython.display import Imageimport numpy as np 방법 1: pydot을 사용하여 \"dot 파일\"을 \"png 이미지\"로 전환 (참고) 1pip install pydot Collecting pydotNote: you may need to restart the kernel to use updated packages. Downloading pydot-1.4.1-py2.py3-none-any.whl (19 kB) Requirement already satisfied: pyparsing&gt;=2.1.4 in d:\\anaconda\\lib\\site-packages (from pydot) (2.4.6) Installing collected packages: pydot Successfully installed pydot-1.4.1 ​ 12345678910111213# 참고: https://niceman.tistory.com/169import pydot# .dot결과 생성export_graphviz(dt, out_file='tree.dot', feature_names=feature_names, class_names=np.unique(iris['target_names']))# Encoding(graph,) = pydot.graph_from_dot_file('tree.dot', encoding='utf8')# .dot파일을 .png이미지로 저장graph.write_png('tree.png')Image(filename = 'tree.png', width=600) 방법 2: graphviz.Source이용 (참고) 1pip install -U graphviz Requirement already up-to-date: graphviz in d:\\anaconda\\lib\\site-packages (0.14.1) Note: you may need to restart the kernel to use updated packages. 1import graphviz 123456# 참고: https://www.kaggle.com/vaishvik25/titanic-eda-fe-3-model-decision-tree-vizfrom sklearn.tree import DecisionTreeClassifier, export_graphviztree_dot = export_graphviz(dt,out_file=None, feature_names=feature_names, class_names=np.unique(iris['target_names']))tree = graphviz.Source(tree_dot)tree gini계수: 불순도를 의미함. gini계수가 높을 수록 엔트로피(Entropy)가 큼. 즉, 클래스가 혼잡하게 섞여 있음. 3. 가지 치기 (pruning) Overfitting을 방지하기 위해 적당히 가지 치기를 진행한다. 1234# 수동으로 max_depth 설정dt2 = DecisionTreeClassifier(max_depth=2)dt2.fit(x_train, y_train)dt2_pred = dt2.predict(x_valid) 1(dt2_pred == y_valid).mean() 0.9210526315789473 123tree2_dot = export_graphviz(dt2,out_file=None, feature_names=feature_names, class_names=np.unique(iris['target_names']))tree2 = graphviz.Source(tree2_dot)tree2 4. 모델 성능 평가 지표 참고자료: 분류성능평가지표 - Precision(정밀도), Recall(재현율) and Accuracy(정확도) 4-1. 오차 행렬 (Confusion Matrix) 4-2. 정확도 (Accuracy) 정확도 (Accuracy): 모델이 샘플을 올바르게 예측하는 비율 Accuracy=TP+TNTP+FP+TN+FNAccuracy = \\frac{TP+TN}{TP+FP+TN+FN} Accuracy=TP+FP+TN+FNTP+TN​ !!정확도의 함정!! 정확도는 모델의 성능을 가장 지관적으로 나타낼 수 있는 평가 지표다. 하지만, 만약 Actual positive sample과 Actual negative sample의 비율이 차이가 많이 나면 정확도의 함정에 빠질 수 있다. 즉, 모두 positive / negative로 예측 했을 때 모델의 정확도가 매우 높은 경우다. 이 경우에 예측 정확도가 높지만, 모델의 예측 성능이 좋다라고 말할 수는 없다. 유방암 환자 데이터셋을 이용하여 한번 이해해 볼게요. 123from sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_splitimport numpy as np 1cancer = load_breast_cancer(유방암 환자 데이터셋) 1print(cancer['DESCR']) # describe .. _breast_cancer_dataset: Breast cancer wisconsin (diagnostic) dataset -------------------------------------------- **Data Set Characteristics:** :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.0) - concavity (severity of concave portions of the contour) - concave points (number of concave portions of the contour) - symmetry - fractal dimension (\"coastline approximation\" - 1) The mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius. - class: - WDBC-Malignant - WDBC-Benign :Summary Statistics: ===================================== ====== ====== Min Max ===================================== ====== ====== radius (mean): 6.981 28.11 texture (mean): 9.71 39.28 perimeter (mean): 43.79 188.5 area (mean): 143.5 2501.0 smoothness (mean): 0.053 0.163 compactness (mean): 0.019 0.345 concavity (mean): 0.0 0.427 concave points (mean): 0.0 0.201 symmetry (mean): 0.106 0.304 fractal dimension (mean): 0.05 0.097 radius (standard error): 0.112 2.873 texture (standard error): 0.36 4.885 perimeter (standard error): 0.757 21.98 area (standard error): 6.802 542.2 smoothness (standard error): 0.002 0.031 compactness (standard error): 0.002 0.135 concavity (standard error): 0.0 0.396 concave points (standard error): 0.0 0.053 symmetry (standard error): 0.008 0.079 fractal dimension (standard error): 0.001 0.03 radius (worst): 7.93 36.04 texture (worst): 12.02 49.54 perimeter (worst): 50.41 251.2 area (worst): 185.2 4254.0 smoothness (worst): 0.071 0.223 compactness (worst): 0.027 1.058 concavity (worst): 0.0 1.252 concave points (worst): 0.0 0.291 symmetry (worst): 0.156 0.664 fractal dimension (worst): 0.055 0.208 ===================================== ====== ====== :Missing Attribute Values: None :Class Distribution: 212 - Malignant, 357 - Benign :Creator: Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian :Donor: Nick Street :Date: November, 1995 This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2 Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/ .. topic:: References - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995. - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171. 123data = cancer['data']target = cancer['target']feature_names = cancer['feature_names'] 123# 데이터 프레임 생성df = pd.DataFrame(data = data, columns = feature_names)df['target'] = target 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension ... worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension target 0 17.99 10.38 122.80 1001.0 0.11840 0.27760 0.3001 0.14710 0.2419 0.07871 ... 17.33 184.60 2019.0 0.1622 0.6656 0.7119 0.2654 0.4601 0.11890 0 1 20.57 17.77 132.90 1326.0 0.08474 0.07864 0.0869 0.07017 0.1812 0.05667 ... 23.41 158.80 1956.0 0.1238 0.1866 0.2416 0.1860 0.2750 0.08902 0 2 19.69 21.25 130.00 1203.0 0.10960 0.15990 0.1974 0.12790 0.2069 0.05999 ... 25.53 152.50 1709.0 0.1444 0.4245 0.4504 0.2430 0.3613 0.08758 0 3 11.42 20.38 77.58 386.1 0.14250 0.28390 0.2414 0.10520 0.2597 0.09744 ... 26.50 98.87 567.7 0.2098 0.8663 0.6869 0.2575 0.6638 0.17300 0 4 20.29 14.34 135.10 1297.0 0.10030 0.13280 0.1980 0.10430 0.1809 0.05883 ... 16.67 152.20 1575.0 0.1374 0.2050 0.4000 0.1625 0.2364 0.07678 0 5 rows × 31 columns target: 0: Malignant (악성종양); 1: Benign (양성종양) 12pos = df.loc[df['target'] == 1] # 앙성 sampleneg = df.loc[df['target'] == 0] # 음성 sample 1pos.shape, neg.shape ((357, 31), (212, 31)) 시범용 sample data를 생성: 양성 환자 357 + 음성 환자 5 1sample = pd.concat([pos, neg[:5]], sort=True) 1x_train, x_test, y_train, y_test = train_test_split(sample.drop('target',1), sample['target'], random_state=42) 1x_train.shape, y_train.shape ((271, 30), (271,)) 1x_test.shape, y_test.shape ((91, 30), (91,)) 1234# 모델 정의 및 학습model = LogisticRegression()model.fit(x_train, y_train)model_pred = model.predict(x_test) Confusion Matrix 1from sklearn.metrics import confusion_matrix 1confusion_matrix(y_test, model_pred) array([[ 1, 0], [ 2, 88]], dtype=int64) 1234sns.heatmap(confusion_matrix(y_test, model_pred), annot=True, cmap='Reds')plt.xlabel('Predict')plt.ylabel('Actual')plt.show() 정확도 (Accuracy) 12# logistic 모델 정확도(model_pred == y_test).mean() 0.978021978021978 12345# 모두 양성으로 예측한 경우my_pred = np.ones(shape=y_test.shape)# 정확도(my_pred == y_test).mean() 0.989010989010989 정확도만 놓고 본다면, 무조건 양성 환자로 예측하는 분류기가 성능이 더 좋다. 하지만 무조건 양성 환자로 예측해서 예측율이 98.9%로 말하는 의사는 당영히 자질이 좋은 의사라고 볼 수 없다 정확도(Accuracy)만 보고 분류기의 성능을 판별하는 것은 위와 같은 오류에 빠질 수 있다. 이를 보완하기 위해 다음과 같은 지표들도 같이 활용하게 된다 4-3. 정밀도 (Precision) 정밀도 (Precision): 양성 예측의 정확도. 즉, Positive Prediction 중에서 올바르게 예측되는 비율 Precision=TPTP+FPPrecision=\\frac{TP}{TP+FP} Precision=TP+FPTP​ 1from sklearn.metrics import precision_score 1precision_score(y_test, model_pred) 1.0 4-4. 민감도 (Sensitivity) / 재현율 (Recall) 민감도 (Sensitivity) / 재현율 (Recall): 분류기가 양성 샘플에 대한 식별력을 나타남. 즉, Positive Condition 중에서 올바르게 예측되는 비율. True Positive Rate (TPR) 이라고도 불린다. Sensitivity/Recall=TPTP+FNSensitivity / Recall = \\frac{TP}{TP+FN} Sensitivity/Recall=TP+FNTP​ 1from sklearn.metrics import recall_score 1recall_score(y_test, model_pred) 0.9777777777777777 4-5. 특이도 (Specificity) 특이도 (Specificity): 분류기가 음성 샘플에 대한 식별력을 나타남. 즉, Negative Condition 중에서 올바르게 예측되는 비율. True Negative Rate (TNR) 이라고도 불린다. Specificity=TNTN+FPSpecificity = \\frac{TN}{TN+FP} Specificity=TN+FPTN​ 4-6. F1 Score F1 Score: 정밀도(Precision)와 재현율(Recall)의 조화 평균을 나타나는 지표임. 데이터 label이 불균형 구조일 때, 모델의 성능을 정확하게 평가할 수 있으며, 성능을 하나의 숫자로 표현할 수 있다. F1&nbsp;Score=2∗Precision∗RecallPrecision+Recall=TPTP+FN+FP2F1\\ Score = 2*\\frac{Precision * Recall}{Precision + Recall}=\\frac{TP}{TP+\\frac{FN+FP}{2}} F1&nbsp;Score=2∗Precision+RecallPrecision∗Recall​=TP+2FN+FP​TP​ 1from sklearn.metrics import f1_score 1f1_score(y_test, model_pred) 0.9887640449438202 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"분류","slug":"분류","permalink":"https://hyemin-kim.github.io/tags/%EB%B6%84%EB%A5%98/"}]},{"title":"Python >> sklearn - (1) 전처리","slug":"S-Python-sklearn1","date":"2020-07-17T07:37:50.000Z","updated":"2020-07-17T09:02:10.992Z","comments":true,"path":"2020/07/17/S-Python-sklearn1/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/17/S-Python-sklearn1/","excerpt":"","text":"전처리 (Pre-Processing) 개요 1. 전처리의 정의 2. 전처리의 종류 실습 – Titanic 0. 데이터 셋 파악 1. train / validation 셋 나누기 2. 결측치 처리 2-0. 결측치 확인 2-1. Numerical Column의 결측치 처리 2-2. Categorical Column의 결측치 처리 3. Label Encoding: 문자(categorivcal)를 수치(numerical)로 변환 4. 원 핫 인코딩 (One Hot Encoding) 5. Normalize (정규화) 6. Standard Scaling (표준화) 개요 1. 전처리의 정의 데이터 전처리는 데이터 분석에 적합하게 데이터를 가공/ 변경/ 처리/ 클리닝하는 과정이다 2. 전처리의 종류 결측치 - Imputer 이상치 정규화 (Normalization) 0~1사이의 분포로 조정 xnew=x−xminxmax−xminx_{new} = \\frac{x-x_{min}}{x_{max}-x_{min}}xnew​=xmax​−xmin​x−xmin​​ 표준화 (Standardization) 평균을 0, 표준편차를 1로 맞춤 xnew=x−μσx_{new} = \\frac{x-\\mu}{\\sigma}xnew​=σx−μ​ 샘플링 (over/under sampling) 피처 공학 (Feature Engineering) feature 생성/ 연산 구간 생성, 스케일 변경 실습 – Titanic 12import numpy as npimport pandas as pd 12train = pd.read_csv('train.csv')test = pd.read_csv('test.csv') 0. 데이터 셋 파악 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S PassengerId: 승객 아이디 Survived: 생존 여부, 1: 생존, 0: 사망 Pclass: 등급 Name: 성함 Sex: 성별 Age: 나이 SibSp: 형제, 자매, 배우자 수 Parch: 부모, 자식 수 Ticket: 티켓번호 Fare: 요즘 Cabin: 좌석번호 Embarked: 탑승 항구 1. train / validation 셋 나누기 STEP 1. feature &amp; label 정의하기 123feature = [ 'Pclass', 'Sex', 'Age', 'Fare'] 123label = [ 'Survived'] 1train[feature].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Pclass Sex Age Fare 0 3 male 22.0 7.2500 1 1 female 38.0 71.2833 2 3 female 26.0 7.9250 3 1 female 35.0 53.1000 4 3 male 35.0 8.0500 1train[label].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived 0 0 1 1 2 1 3 1 4 0 STEP 2. 적절한 비율로 train / validation set 나누기 1from sklearn.model_selection import train_test_split reference: &lt; train_test_split &gt; Document train_test_split ( X, y, test_size=…, random_state=…, shuffle=True ) test_size: validation set에 할당할 비율 (20% -&gt; 0.2) random_state: random seed 설정 shuffle: 기본 True: shuffle the data before splitting 1x_train, x_valid, y_train, y_valid = train_test_split(train[feature], train[label], test_size=0.2, random_state=30, shuffle=True) 1x_train.shape, y_train.shape ((712, 4), (712, 1)) 1x_valid.shape, y_valid.shape ((179, 4), (179, 1)) 2. 결측치 처리 2-0. 결측치 확인 방법 1. pandas의 info() 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 방법 2. pandas의 isnull() 합계를 구하는 sum()을 통해 한 눈에 확인할 수 있다 1train.isnull().sum() PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 개별 column의 결측치 확인하기 1train['Age'].isnull().sum() 177 2-1. Numerical Column의 결측치 처리 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 1. Pandas의 \"fillna()\"를 사용: 1개의 column을 처리할 때 a. 숫자\"0\"으로 채우기 1train['Age'].fillna(0).describe() count 891.000000 mean 23.799293 std 17.596074 min 0.000000 25% 6.000000 50% 24.000000 75% 35.000000 max 80.000000 Name: Age, dtype: float64 b. 통계값(평균)으로 채우기 1train['Age'].fillna(train['Age'].mean()).describe() count 891.000000 mean 29.699118 std 13.002015 min 0.420000 25% 22.000000 50% 29.699118 75% 35.000000 max 80.000000 Name: Age, dtype: float64 2. sklearn의 \"SimpleImputer\"를 사용: 2개 이상의 column을 한 번에 처리할 때 reference: Impute 도큐먼트 SimplrImputer 도큐먼트 SimpleImputer( *, missing_values=nan, strategy=‘mean’, fill_value=None, verbose=0, copy=True, add_indicator=False ) strategy: “mean” / “median” / “most_frequent” / “constant” 1from sklearn.impute import SimpleImputer a. 숫자\"0\"으로 채우기 12# STEP 1. imputer 만들기imputer = SimpleImputer(strategy='constant', fill_value=0) 12# STEP 2. fit() 을 통해 결측치에 대한 학습을 진행하기imputer.fit(train[['Age', 'Pclass']]) SimpleImputer(add_indicator=False, copy=True, fill_value=0, missing_values=nan, strategy='constant', verbose=0) 123# STEP 3. transform() 을 통해 실제 결측치에 대해 처리하기result = imputer.transform(train[['Age', 'Pclass']])result array([[22., 3.], [38., 1.], [26., 3.], ..., [ 0., 3.], [26., 1.], [32., 3.]]) 12# STEP 4. 처리 결과를 original data에 대입train[['Age', 'Pclass']] = result 1train[['Age', 'Pclass']].isnull().sum() Age 0 Pclass 0 dtype: int64 fit_transform() 은 fit()과 transform()을 한 번에 해주는 합수다. 1train = pd.read_csv('train.csv') 1train[['Age', 'Pclass']].isnull().sum() Age 177 Pclass 0 dtype: int64 12# STEP 1. imputer 만들기imputer = SimpleImputer(strategy='constant', fill_value=0) 12# STEP 2. fit and transformresult = imputer.fit_transform(train[['Age', 'Pclass']]) 12# STEP 3. 결과 대입train[['Age', 'Pclass']] = result 1train[['Age', 'Pclass']].isnull().sum() Age 0 Pclass 0 dtype: int64 1train[['Age', 'Pclass']].describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age Pclass count 891.000000 891.000000 mean 23.799293 2.308642 std 17.596074 0.836071 min 0.000000 1.000000 25% 6.000000 2.000000 50% 24.000000 3.000000 75% 35.000000 3.000000 max 80.000000 3.000000 b. 통계값(평균)으로 채우기 1train = pd.read_csv('train.csv') 1train[['Age', 'Pclass']].isnull().sum() Age 177 Pclass 0 dtype: int64 123imputer = SimpleImputer(strategy='mean')result = imputer.fit_transform(train[['Age', 'Pclass']])train[['Age', 'Pclass']] = result 1train[['Age', 'Pclass']].isnull().sum() Age 0 Pclass 0 dtype: int64 1train[['Age', 'Pclass']].describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age Pclass count 891.000000 891.000000 mean 29.699118 2.308642 std 13.002015 0.836071 min 0.420000 1.000000 25% 22.000000 2.000000 50% 29.699118 3.000000 75% 35.000000 3.000000 max 80.000000 3.000000 2-2. Categorical Column의 결측치 처리 1train = pd.read_csv('train.csv') 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 1. Pandas의 \"fillna()\"를 사용: 1개의 column을 처리할 때 1train['Embarked'].fillna('S') 0 S 1 C 2 S 3 S 4 S .. 886 S 887 S 888 S 889 C 890 Q Name: Embarked, Length: 891, dtype: object 2. sklearn의 \"SimpleImputer\"를 사용: 2개 이상의 column을 한 번에 처리할 때 123imputer = SimpleImputer(strategy = 'most_frequent')result = imputer.fit_transform(train[['Embarked', 'Cabin']])train[['Embarked', 'Cabin']] = result 1train[['Embarked', 'Cabin']].isnull().sum() Embarked 0 Cabin 0 dtype: int64 3. Label Encoding: 문자(categorivcal)를 수치(numerical)로 변환 기계학습을 위해서 모든 문자로된 데이터는 수치로 변환해야 한다 12train = pd.read_csv('train.csv')train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 1train['Sex'] 0 male 1 female 2 female 3 female 4 male ... 886 male 887 female 888 female 889 male 890 male Name: Sex, Length: 891, dtype: object 방법 1: convert함수를 직접 정의하기 1train['Sex'].value_counts() male 577 female 314 Name: Sex, dtype: int64 123456# STEP 1. 함수 정의def convert(data): if data == 'female': return 1 elif data == 'male': return 0 12# STEP 2. 함수 applytrain['Sex'].apply(convert) 0 0 1 1 2 1 3 1 4 0 .. 886 0 887 1 888 1 889 0 890 0 Name: Sex, Length: 891, dtype: int64 방법 2: sklearn의 “LabelEncoder” 사용 변환 규칙: value name의 alphabet 순서대로 0, 1, 2… 숫자를 부여 1from sklearn.preprocessing import LabelEncoder 1train['Sex'].value_counts() male 577 female 314 Name: Sex, dtype: int64 1le = LabelEncoder() 1train['Sex_num'] = le.fit_transform(train['Sex']) 1train['Sex_num'].value_counts() 1 577 0 314 Name: Sex_num, dtype: int64 12# class 확인le.classes_ array(['female', 'male'], dtype=object) 12# 숫자 -&gt; 문자le.inverse_transform([0, 1, 1, 0, 0, 1, 1]) array(['female', 'male', 'male', 'female', 'female', 'male', 'male'], dtype=object) NaN 값이 포함되어 있으면, LabeEncoder가 정상 동작하지 않음 1train['Embarked'] 0 S 1 C 2 S 3 S 4 S .. 886 S 887 S 888 S 889 C 890 Q Name: Embarked, Length: 891, dtype: object 1train['Embarked'].value_counts() S 644 C 168 Q 77 Name: Embarked, dtype: int64 1le.fit_transform(train['Embarked']) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in _encode(values, uniques, encode, check_unknown) 111 try: --&gt; 112 res = _encode_python(values, uniques, encode) 113 except TypeError: D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in _encode_python(values, uniques, encode) 59 if uniques is None: ---&gt; 60 uniques = sorted(set(values)) 61 uniques = np.array(uniques, dtype=values.dtype) TypeError: '&lt;' not supported between instances of 'float' and 'str' ​ During handling of the above exception, another exception occurred: TypeError Traceback (most recent call last) &lt;ipython-input-38-86525b1fc929&gt; in &lt;module&gt; ----&gt; 1 le.fit_transform(train['Embarked']) D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in fit_transform(self, y) 250 \"\"\" 251 y = column_or_1d(y, warn=True) --&gt; 252 self.classes_, y = _encode(y, encode=True) 253 return y 254 D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in _encode(values, uniques, encode, check_unknown) 112 res = _encode_python(values, uniques, encode) 113 except TypeError: --&gt; 114 raise TypeError(\"argument must be a string or number\") 115 return res 116 else: TypeError: argument must be a string or number 1train['Embarked'] = train['Embarked'].fillna('S') 1train['Embarked'] = le.fit_transform(train['Embarked']) 1train['Embarked'] 0 2 1 0 2 2 3 2 4 2 .. 886 2 887 2 888 2 889 0 890 1 Name: Embarked, Length: 891, dtype: int32 1train['Embarked'].value_counts() 2 646 0 168 1 77 Name: Embarked, dtype: int64 4. 원 핫 인코딩 (One Hot Encoding) pd.get_dummies ( df_name [ ‘col_name’ ] ) 1train = pd.read_csv('train.csv') 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB \"Embarked\"를 살펴보기 12# Unique Value 확인하기train['Embarked'].value_counts() S 644 C 168 Q 77 Name: Embarked, dtype: int64 123# NA 채우기train['Embarked'] = train['Embarked'].fillna('S')train['Embarked'].value_counts() S 646 C 168 Q 77 Name: Embarked, dtype: int64 123# Label Encoding (문자 to 숫자)train['Embarked_num'] = LabelEncoder().fit_transform(train['Embarked'])train['Embarked_num'].value_counts() 2 646 0 168 1 77 Name: Embarked_num, dtype: int64 Embarked는 탑승 항구의 이니셜을 나타낸다. 우리는 LabelEncoder를 통해서 값을 수치형으로 변환해주었다, 하지만 이대로 데이터를 기계학습 시키면, 기계는 데이터 안에서 관계를 학습한다. 예를 들면, ‘S’= 2, ‘Q’= 1 이라고 되어 있는데, Q+Q=S가 된다라고 학습해버린다 그렇기 때문에, 우리는 각 unique value를 별도의 column으로 분리하고, 값에 해당하는 column는 True (1), 나머지 column는 False (0) 를 갖게 한다.이것이 바로 원 핫 인코딩 이다. 1train['Embarked'][:6] 0 S 1 C 2 S 3 S 4 S 5 Q Name: Embarked, dtype: object 1train['Embarked_num'][:6] 0 2 1 0 2 2 3 2 4 2 5 1 Name: Embarked_num, dtype: int32 12one_hot = pd.get_dummies(train['Embarked_num'][:6])one_hot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 0 0 1 1 1 0 0 2 0 0 1 3 0 0 1 4 0 0 1 5 0 1 0 12one_hot.columns = ['C', 'Q', 'S']one_hot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C Q S 0 0 0 1 1 1 0 0 2 0 0 1 3 0 0 1 4 0 0 1 5 0 1 0 원핫인코딩은 카테고리의 특성을(계절, 항구, 성별, 종류…) 가지는 column에 대해서 적용한다 5. Normalize (정규화) 정규화: column간에 다른 min,max 값을 가지는 경우, 정규화를 통해 min / max 의 척도를 맞추어 주는 작업이다 sklearn.preprocessing --&gt; MinMaxScaler() 예: 영화평점 네이버 영화평점 (0점 ~ 10점): [2, 4, 6, 8, 10] 넷플릭스 영화평점 (0점 ~ 5점): [1, 2, 3, 4, 5] 123movie = {'naver': [2, 4, 6, 8, 10], 'netflix': [1, 2, 3, 4, 5] } 12movie = pd.DataFrame(data=movie)movie .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } naver netflix 0 2 1 1 4 2 2 6 3 3 8 4 4 10 5 1from sklearn.preprocessing import MinMaxScaler 1min_max_scaler = MinMaxScaler() 1min_max_movie = min_max_scaler.fit_transform(movie) 1pd.DataFrame(min_max_movie, columns = ['naver', 'netfllix']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } naver netfllix 0 0.00 0.00 1 0.25 0.25 2 0.50 0.50 3 0.75 0.75 4 1.00 1.00 6. Standard Scaling (표준화) 표준화: 평균이 0, 표준편차가 1이 되도록 변환해주는 작업 sklearn.preprocessing --&gt; StandardScaler() 12from sklearn.preprocessing import StandardScalerstandard_scaler = StandardScaler() 123# 샘플데이터 생성x = np.arange(10)x[9] = 1000 # oulier 추가 1x.mean(), x.std() (103.6, 298.8100399919654) 12# 원본 데이터 표준화하기scaled = standard_scaler.fit_transform(x.reshape(-1, 1)) 1scaled.mean(), scaled.std() (4.4408920985006264e-17, 1.0) 1round(scaled.mean(), 2), scaled.std() # mean값 반올림 (0.0, 1.0) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"}]},{"title":"Python >> sklearn -(0) sklearn 개요","slug":"S-Python-sklearn0","date":"2020-07-17T07:36:59.000Z","updated":"2020-07-17T08:23:44.120Z","comments":true,"path":"2020/07/17/S-Python-sklearn0/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/17/S-Python-sklearn0/","excerpt":"","text":"scikit-learn 개요 Install Package Import Functions from Sub-packages 3 Steps to Fit Model and Do Prediction &lt; scikit-learn &gt; Homepage scikit-learn 패키지는 지도학습, 비지도학습 등 대부분의 머신러닝 알고리즘을 제공하고 있으며, Python에서 머신러닝을 수행할 때 굉장히 많이 쓰이는 패키지 중의 하나다 Install Package 1pip install -U scikit-learn # -U: Update Note: you may need to restart the kernel to use updated packages. ​ Usage: D:\\Anaconda\\python.exe -m pip install [options] &lt;requirement specifier&gt; [package-index-options] ... D:\\Anaconda\\python.exe -m pip install [options] -r &lt;requirements file&gt; [package-index-options] ... D:\\Anaconda\\python.exe -m pip install [options] [-e] &lt;vcs project url&gt; ... D:\\Anaconda\\python.exe -m pip install [options] [-e] &lt;local project path&gt; ... D:\\Anaconda\\python.exe -m pip install [options] &lt;archive url/path&gt; ... no such option: -: Import Functions from Sub-packages 12from sklearn.linear_model import LinearRegressionfrom sklearn.model_selection import train_test_split 3 Steps to Fit Model and Do Prediction STEP 1. 모델 정의 12from sklearn.linear_model import LinearRegressionmodel = LinearRegression() STEP 2. 학습 (Fit in Training set) 명령어: model_name .fit 1model.fit(x_train, y_train) STEP 3. 예측 (Predict in Test set) 명령어: model_name .predict 1prediction = model.predict(x_test) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"}]},{"title":"Python >> Seaborn - (2) 통계 기반의 시각화","slug":"S-Python-Seaborn2","date":"2020-07-03T10:18:20.000Z","updated":"2020-07-03T13:19:50.303Z","comments":true,"path":"2020/07/03/S-Python-Seaborn2/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/03/S-Python-Seaborn2/","excerpt":"","text":"통계 기반의 시각화 0. 통계 기반의 시각화를 제공해주는 Seaborn 1. countplot 1-1. 세로로 그리기 1-2. 가로로 그리기 1-3. 색상 팔레트 설정 2. distplot 2-1. 기본 displot 2-2. 데이터가 Series일 경우 2-3. rugplot 2-4. kde (kernel density) 2-5. 가로로 표현하기 2-6. 컬러 바꾸기 3. heatmap 3-1. 기본 heatmap 3-2. pivot table을 활용하여 그리기 3-3. correlation(상관관계)를 시각화 4. pairplot 4-1. 기본 pairplot 그리기 4-2. hue 옵션으로 특성 구분 4-3. 컬러 팔레트 적용 4-4. 사이즈 적용 5. violinplot 5-1. 기본 violinplot 그리기 5-2. 비교 분포 확인 5-3. 가로로 뉘인 violinplot 5-4. hue 옵션으로 분포 비교 6. lmplot 6-1. 기본 lmplot 6-2. hue 옵션으로 다중 선형관계 그리기 6-3. col 옵션을 추가하여 그래프를 별도로 그려볼 수 있다 7. relplot 7-1. 기본 relplot 7-2. col 옵션으로 그래프 분할 7-3. row와 column에 표기할 데이터 column 선택 7-4. 컬러 팔레트 적용 8. jointplot 8-1. 기본 jointplot 그리기 8-2. 선형관계를 표현하는 regression 라인 그리기 8-3. hex 밀도 보기 8-4. 등고선 모양으로 밀집도 확인하기 1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns 12plt.rcParams[\"figure.figsize\"] = (9, 6) # figure size 설정plt.rcParams[\"font.size\"] = 14 # fontsize 설정 0. 통계 기반의 시각화를 제공해주는 Seaborn reference: Seaborn 공식 도큐먼트 seaborn 라이브러리가 매력적인 이유는 바로 통계 차트다. 이번 실습에서는 seaborn의 다양한 통계 차트 중 대표적인 차트 몇 개를 뽑아서 다뤄볼 예정이다. 그럼 먼저 실습에 사용되는 Dataset을 한번 살펴볼게요. Dataset — \"Titanic\" 12titanic = sns.load_dataset('titanic')titanic .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone 0 0 3 male 22.0 1 0 7.2500 S Third man True NaN Southampton no False 1 1 1 female 38.0 1 0 71.2833 C First woman False C Cherbourg yes False 2 1 3 female 26.0 0 0 7.9250 S Third woman False NaN Southampton yes True 3 1 1 female 35.0 1 0 53.1000 S First woman False C Southampton yes False 4 0 3 male 35.0 0 0 8.0500 S Third man True NaN Southampton no True ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 886 0 2 male 27.0 0 0 13.0000 S Second man True NaN Southampton no True 887 1 1 female 19.0 0 0 30.0000 S First woman False B Southampton yes True 888 0 3 female NaN 1 2 23.4500 S Third woman False NaN Southampton no False 889 1 1 male 26.0 0 0 30.0000 C First man True C Cherbourg yes True 890 0 3 male 32.0 0 0 7.7500 Q Third man True NaN Queenstown no True 891 rows × 15 columns survived: 생존여부 pclass: 좌석등급 (숫자) sex: 성별 age: 나이 sibsp: 형제자매 + 배우자 숫자 parch: 부모 + 자식 숫자 fare: 요금 embarked: 탑승 항구 class: 좌석등급 (영문) who: 사람 구분 deck: 데크 embark_town: 탑승 항구 (영문) alive: 생존여부 (영문) alone: 혼자인지 여부 Dataset — \"tips\" 12tips = sns.load_dataset('tips')tips .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 ... ... ... ... ... ... ... ... 239 29.03 5.92 Male No Sat Dinner 3 240 27.18 2.00 Female Yes Sat Dinner 2 241 22.67 2.00 Male Yes Sat Dinner 2 242 17.82 1.75 Male No Sat Dinner 2 243 18.78 3.00 Female No Thur Dinner 2 244 rows × 7 columns total_bill: 총 합계 요금표 tip: 팁 sex: 성별 smoker: 흡연자 여부 day: 요일 time: 식사 시간 size: 식사 인원 12# 배경 설정sns.set(style='darkgrid') 1. countplot 항목별 갯수를 세어주는 countplot 해당 column을 구성하고 있는 value들을 자동으로 구분하여 보여준다 reference: &lt;sns.countplot&gt; Document sns.countplot ( x=None, y=None, hue=None, data=None, color=None, palette=None ) 1-1. 세로로 그리기 12sns.countplot(x='class', hue='who', data=titanic)plt.show() 1-2. 가로로 그리기 12sns.countplot(y='class', hue='who', data=titanic)plt.show() 1-3. 색상 팔레트 설정 12sns.countplot(x='class', hue='who', palette='copper', data= titanic)plt.show() 2. distplot matplotlib의 hist그래프와 kdeplot을 통합한 그래프다. 분포와 밀도를 확인할 수 있음 reference: &lt;sns.distplot&gt; Document sns.displot ( a, hist=True, kde=True, rug=False, vertical=False, color=None ) hist: histogram kde: kernel density estimate rug: rugplot vertical: If True, observed values are on y-axis 123# 샘플 데이터 생성x = np.random.randn(100)x array([-3.39765920e-01, -1.48664049e+00, -5.57926444e-01, 3.25206560e-01, -7.46665762e-01, -3.10926812e-01, -2.14536012e+00, 1.25905620e+00, -2.07806423e-01, 5.56377038e-01, -2.20574498e+00, -1.15138577e-01, -3.32417471e-01, 1.13927613e-01, -7.29559442e-01, -1.31243715e+00, -8.27477111e-01, -1.24455099e+00, -5.44035731e-02, -1.85399773e+00, -1.62571613e+00, 3.89312791e-01, 1.26815698e+00, -7.43355761e-01, -1.34113997e+00, 2.67291801e-02, -4.74142344e-01, -1.07662894e+00, -2.35607451e+00, 1.90337236e-01, -1.18577255e+00, -1.23238300e+00, 9.39298755e-01, -2.69078751e-01, -3.50418097e-01, 1.92109121e+00, -1.46520490e-01, 3.90810577e-01, -6.60511307e-01, -1.46288431e+00, 1.26314685e+00, 2.38384651e-01, 8.03730080e-01, 2.83340226e-01, -1.24219159e+00, -1.50458389e+00, -1.60213592e-01, 3.97086657e-01, 1.27321390e-01, -1.13722876e+00, -1.48448425e+00, 1.36136226e+00, -2.34669327e-01, -1.32679409e+00, 1.59032718e+00, 7.53779845e-01, -7.48815568e-01, 7.34822673e-03, 5.57358372e-01, 1.78429993e+00, -1.50510591e+00, -3.87983571e-01, -7.57372493e-01, 6.25354827e-01, 1.44857563e-01, 7.78608476e-01, -6.61441801e-02, -1.24836018e+00, 1.77522984e+00, 1.60497019e-01, -1.18893624e+00, 1.93951152e+00, -9.34504796e-01, 1.82000588e+00, -1.91594654e+00, -1.13118210e+00, -4.13371342e-01, -5.07021131e-01, 1.57792370e+00, -2.52509848e+00, 1.86695906e-01, -1.18412859e+00, 1.49572473e-01, -3.53669860e-01, 1.38877682e+00, 2.53212949e-02, 7.79387552e-01, -7.41508306e-01, 4.10007279e-01, 1.96517288e-02, -5.69215198e-01, 1.45113980e+00, -8.80722624e-01, 1.35468793e+00, -1.67677998e-03, -1.14952039e+00, 8.90718244e-01, -4.10411520e-01, 6.17620908e-01, 2.96993057e-01]) 2-1. 기본 displot 12sns.distplot(x) # x: numpy arrayplt.show() 2-2. 데이터가 Series일 경우 12x = pd.Series(x, name='x variable')x 0 -0.339766 1 -1.486640 2 -0.557926 3 0.325207 4 -0.746666 ... 95 -1.149520 96 0.890718 97 -0.410412 98 0.617621 99 0.296993 Name: x variable, Length: 100, dtype: float64 12sns.distplot(x) # x: Seriesplt.show() x가 Seires일 때는: 그래프에서 x label이 자동으로 Series 이름(column name) 으로 나타남 2-3. rugplot 데이터 위치를 x축 위에 작은 선분(rug)으로 나타내어 데이터들의 위치 밒 분포를 보여준다 12sns.distplot(x, rug=True, hist=False, kde=True)plt.show() 2-4. kde (kernel density) kde 는 histogram보다 부드러운 형태의 분포 곧선을 보여주는 방법 12sns.distplot(x, rug=False, hist=False, kde=True)plt.show() 2-5. 가로로 표현하기 12sns.distplot(x, vertical=True)plt.show() 2-6. 컬러 바꾸기 12sns.distplot(x, color='r')plt.show() 3. heatmap 색상으로 표현할 수 있는 다양한 정보를 일정한 이미지위에 열분포 형태의 비쥬얼한 그래픽으로 출력하는 것이 특정이다 주로 활용되는 경우: pivot table의 데이터를 시각화할 때 데이터의 상관관계를 살펴볼 때 reference: &lt;sns.heatmap&gt; Document sns.heatmap ( data, annot=None, cmap=None ) annot: If True, write the data value in each cell 3-1. 기본 heatmap 123uniform_data = np.random.rand(10, 12)sns.heatmap(uniform_data, annot=True)plt.show() 컬러가 진할수록 숫자가 0에 가깝고, 연할수록 1에 가깝다 3-2. pivot table을 활용하여 그리기 1tips .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 ... ... ... ... ... ... ... ... 239 29.03 5.92 Male No Sat Dinner 3 240 27.18 2.00 Female Yes Sat Dinner 2 241 22.67 2.00 Male Yes Sat Dinner 2 242 17.82 1.75 Male No Sat Dinner 2 243 18.78 3.00 Female No Thur Dinner 2 244 rows × 7 columns 12pivot = tips.pivot_table(index='day', columns='size', values='tip')pivot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } size 1 2 3 4 5 6 day Thur 1.83 2.442500 2.692500 4.218000 5.000000 5.3 Fri 1.92 2.644375 3.000000 4.730000 NaN NaN Sat 1.00 2.517547 3.797778 4.123846 3.000000 NaN Sun NaN 2.816923 3.120667 4.087778 4.046667 5.0 12sns.heatmap(pivot, cmap='Blues', annot=True)plt.show() 3-3. correlation(상관관계)를 시각화 corr() 함수는 데이터의 상관관계를 보여줌 1titanic.corr() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass age sibsp parch fare adult_male alone survived 1.000000 -0.338481 -0.077221 -0.035322 0.081629 0.257307 -0.557080 -0.203367 pclass -0.338481 1.000000 -0.369226 0.083081 0.018443 -0.549500 0.094035 0.135207 age -0.077221 -0.369226 1.000000 -0.308247 -0.189119 0.096067 0.280328 0.198270 sibsp -0.035322 0.083081 -0.308247 1.000000 0.414838 0.159651 -0.253586 -0.584471 parch 0.081629 0.018443 -0.189119 0.414838 1.000000 0.216225 -0.349943 -0.583398 fare 0.257307 -0.549500 0.096067 0.159651 0.216225 1.000000 -0.182024 -0.271832 adult_male -0.557080 0.094035 0.280328 -0.253586 -0.349943 -0.182024 1.000000 0.404744 alone -0.203367 0.135207 0.198270 -0.584471 -0.583398 -0.271832 0.404744 1.000000 12sns.heatmap(titanic.corr(), annot=True, cmap='YlGnBu')plt.show() 4. pairplot pairplot은 grid 형태로 각 집합의 조합에 대해 히스토그램과 분포도를 그린다. (숫자형 column에 대해서만 그려줌) reference: &lt;sns.pairplot&gt; Document sns.pairplot ( data, hue=None, palette=None, height=2.5 ) 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 4-1. 기본 pairplot 그리기 12sns.pairplot(tips)plt.show() 4-2. hue 옵션으로 특성 구분 12sns.pairplot(tips, hue='size')plt.show() 4-3. 컬러 팔레트 적용 12sns.pairplot(tips, hue='size', palette='rainbow')plt.show() 4-4. 사이즈 적용 12sns.pairplot(tips, hue='size', palette='rainbow', height=4)plt.show() 5. violinplot 마이올린처럼 생긴 violinplot다. column에 대한 데이터의 비교 분포도를 확인할 수 있다. 곡선형 부분 (뚱뚱한 부분)은 데이터의 분포를 나타냄 양쪽 끝 뾰족한 부분은 데이터의 최소값과 최대값을 나타냄 reference: &lt;sns.violinplot&gt; Document sns.violinplot ( x=None. y=None, hue=None, data=None, split=False ) split: When using hue nesting with a variable that takes two levels, setting split to True will draw half of a violin for each level. This can make it easier to directly compare the distributions. 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 5-1. 기본 violinplot 그리기 12sns.violinplot(x=tips['total_bill'])plt.show() 5-2. 비교 분포 확인 x, y축을 지정해줌으로써 바이올린을 분할하여 비교 분포를 볼 수 있다 12sns.violinplot(x='day', y='total_bill', data=tips)plt.show() 5-3. 가로로 뉘인 violinplot x축, y축 변경 12sns.violinplot(y='day', x='total_bill', data=tips)plt.show() 5-4. hue 옵션으로 분포 비교 사실 hue옵션을 사용하지 않으면 바이올린이 대칭이기 때문에 분포의 큰 의미는 없다. 하지만, hue옵션을 주면, 단일 column에 대한 바이올린 모양의 비교를 할 수 있다. 12sns.violinplot(x='day', y='total_bill', hue='smoker', data=tips, palette='muted')plt.show() split 옵션으로 바이올린을 합쳐서 볼 수 있다 12sns.violinplot(x='day', y='total_bill', hue='smoker', data=tips, palette='muted', split=True)plt.show() violinplot은 이런 경우에 많이 활용된다 6. lmplot lmport (initial: 소문자 L) 은 column간의 선형관계를 확인하기에 용이한 차트임. 또한, outlier도 같이 짐작해 볼 수 있다. reference: &lt;sns.lmplot&gt; Document sns.lmplot ( x, y, data, hue=None, col=None, col_wrap=None, row=None, height=5 ) 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 6-1. 기본 lmplot 12sns.lmplot(x='total_bill', y='tip', data=tips, height=6)plt.show() 6-2. hue 옵션으로 다중 선형관계 그리기 아래의 그래프를 통하여 비흡연자가, 흡연자 대비 좀 더 가파른 선형관계를 가지는 것을 볼 수 있다 12sns.lmplot(x='total_bill', y='tip', hue='smoker', data=tips, height=6)plt.show() 6-3. col 옵션을 추가하여 그래프를 별도로 그려볼 수 있다 또한, col_wrap으로 한 줄에 표기할 column의 갯수를 명시할 수 있다 12sns.lmplot(x='total_bill', y='tip', hue='smoker', col='day', col_wrap=2, data=tips, height=6)plt.show() 7. relplot 두 column간 상관관계를 보지만 lmport처럼 선형관계를 따로 그려주지 않다 reference: &lt;sns.replot&gt; Document sns.relplot ( x, y, data, hue=None, col=None, row=None, height=5, palette=None ) 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 7-1. 기본 relplot 12sns.relplot(x='total_bill', y='tip', hue='day', data=tips)plt.show() 7-2. col 옵션으로 그래프 분할 12sns.relplot(x='total_bill', y='tip', hue='day', col='time', data=tips)plt.show() 7-3. row와 column에 표기할 데이터 column 선택 12sns.relplot(x='total_bill', y='tip',hue='day', col='time', row='sex', data=tips)plt.show() 7-4. 컬러 팔레트 적용 12sns.relplot(x='total_bill', y='tip', hue='day', col='time', row='sex', data=tips, palette='CMRmap_r')plt.show() 8. jointplot jointplot은 scatter(산점도)와 histogram(분포)을 동시에 그려줌.(숫자형 데이터만) reference: &lt;sns.jointplot&gt; Document sns.jointplot ( x, y, data=None, kind=‘scatter’, height=6 ) kind: kind of plot to draw. {‘scatter’, ‘reg’, ‘resid’, ‘kde’, ‘hex’} 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 8-1. 기본 jointplot 그리기 default 로 \"scatter plot\"을 그린다 (kind=‘scatter’) 12sns.jointplot(x='total_bill', y='tip', data=tips)plt.show() 8-2. 선형관계를 표현하는 regression 라인 그리기 옵션: kind='reg’ 12sns.jointplot('total_bill', 'tip', data=tips, kind='reg')plt.show() 8-3. hex 밀도 보기 옵션: kind='hex’ 12sns.jointplot('total_bill', 'tip', data=tips, kind='hex')plt.show() 8-4. 등고선 모양으로 밀집도 확인하기 kind=‘kde’ 옵션으로 데이터의 밀집도를 보다 부드러운 선으로 확인할 수 있다 12iris = sns.load_dataset('iris')iris .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 setosa 1 4.9 3.0 1.4 0.2 setosa 2 4.7 3.2 1.3 0.2 setosa 3 4.6 3.1 1.5 0.2 setosa 4 5.0 3.6 1.4 0.2 setosa ... ... ... ... ... ... 145 6.7 3.0 5.2 2.3 virginica 146 6.3 2.5 5.0 1.9 virginica 147 6.5 3.0 5.2 2.0 virginica 148 6.2 3.4 5.4 2.3 virginica 149 5.9 3.0 5.1 1.8 virginica 150 rows × 5 columns 12sns.jointplot('sepal_width', 'petal_length', data=iris, kind='kde', color='g')plt.show() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Seaborn","slug":"Seaborn","permalink":"https://hyemin-kim.github.io/tags/Seaborn/"}]},{"title":"Python >> Seaborn - (1) Seaborn을 활용한 다양한 그래프 그리기","slug":"S-Python-Seaborn1","date":"2020-07-03T10:14:58.000Z","updated":"2020-07-03T13:19:31.789Z","comments":true,"path":"2020/07/03/S-Python-Seaborn1/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/03/S-Python-Seaborn1/","excerpt":"","text":"Seaborn을 활용한 다양한 그래프 그리기 0. Seaborn 개요 0-1. seaborn 에서만 제공되는 통계 기반 plot 0-2. 아름다운 스타일링 0-3. 컬러 팔레트 0-4. pandas 데이터프레임과 높은 호환성 1. Scatterplot 1-1. x, y, color, area 설정하기 1-2. cmap과 alpha 2. Barplot, Barhplot 2-1. 기본 Barplot 그리기 2-2. 기본 Barhplot 그리기 2-3. Barplot에서 비교 그래프 그리기 3. Line Plot 3-1. 기본 lineplot 그리기 3-2. 2개 이상의 그래프 그리기 3-3. 마커 스타일링 3-4. 라인 스타일 변경하기 4. Areaplot (Filled Area) 5.Histogram 5-1. 기본 Histogram 그리기 5-2. 다중 Histogram 그리기 6. Pie Chart 7. Box Plot 7-1. 기본 박스플롯 생성 7-2. 다중 박스플롯 생성 7-3. Box Plot 축 바꾸기 7-4. Outlier 마커 심볼과 컬러 변경 reference: pyplot 공식 도튜먼트 살펴보기 seaborn 공식 도큐먼트 살펴보기 1234567import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom IPython.display import Image# seabornimport seaborn as sns 12plt.rcParams[\"figure.figsize\"] = (9, 6) # figure size 설정plt.rcParams[\"font.size\"] = 14 # fontsize 설정 0. Seaborn 개요 seaborn은 matplotlib을 더 사용하게 쉽게 해주는 라이브러리다. matplotlib으로 대부분의 시각화는 가능하지만, 다음과 같은 이유로 많은 사람들이 seaborn을 선호한다. 비교: matplotlib을 활용한 다양한 그래프 그리기 0-1. seaborn 에서만 제공되는 통계 기반 plot 1tips = sns.load_dataset(\"tips\") (1) violinplot 123sns.violinplot(x=\"day\", y=\"total_bill\", data=tips)plt.title('violin plot')plt.show() (2) countplot 123sns.countplot(tips['day'])plt.title('countplot')plt.show() (3) relplot 123sns.relplot(x='tip', y='total_bill', data=tips)plt.title('relplot')plt.show() (4) lmplot 123sns.lmplot(x='tip', y='total_bill', data=tips)plt.title('lmplot')plt.show() (5) heatmap 123plt.title('heatmap')sns.heatmap(tips.corr(), annot=True, linewidths=1)plt.show() 0-2. 아름다운 스타일링 (1) default color의 예쁜 조합 seaborn의 최대 장점 중의 하나가 아름다운 컬러팔레트다. 스타일링에 크게 신경 쓰지 않아도 default 컬러가 예쁘게 조합해준다. matplotlib VS seaborn 12plt.bar(tips['day'], tips['total_bill'])plt.show() 12sns.barplot(x=\"day\", y=\"total_bill\", data=tips, palette=\"colorblind\")plt.show() (2) 그래프 배경 설정 그래프의 배경 (grid 스타일)을 설정할 수 있음. sns.set_style(’…’) whitegrid: white background + grid darkgrid: dark background + grid white: white background (without grid) dark: dark background (without grid) 123sns.set_style('darkgrid')sns.barplot(x=\"day\", y=\"total_bill\", data=tips, palette=\"colorblind\")plt.show() 123sns.set_style('white')sns.barplot(x=\"day\", y=\"total_bill\", data=tips, palette=\"colorblind\")plt.show() 0-3. 컬러 팔레트 자세한 컬러팔레트는 공식 도큐먼트를 참고 123456sns.palplot(sns.light_palette((210, 90, 60), input=\"husl\"))sns.palplot(sns.dark_palette(\"muted purple\", input=\"xkcd\"))sns.palplot(sns.color_palette(\"BrBG\", 10))sns.palplot(sns.color_palette(\"BrBG_r\", 10))sns.palplot(sns.color_palette(\"coolwarm\", 10))sns.palplot(sns.diverging_palette(255, 133, l=60, n=10, center=\"dark\")) 1sns.barplot(x=\"tip\", y=\"total_bill\", data=tips, palette='coolwarm') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5bf62888&gt; 1sns.barplot(x=\"tip\", y=\"total_bill\", data=tips, palette='Reds') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba59e40988&gt; 0-4. pandas 데이터프레임과 높은 호환성 1tips .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 ... ... ... ... ... ... ... ... 239 29.03 5.92 Male No Sat Dinner 3 240 27.18 2.00 Female Yes Sat Dinner 2 241 22.67 2.00 Male Yes Sat Dinner 2 242 17.82 1.75 Male No Sat Dinner 2 243 18.78 3.00 Female No Thur Dinner 2 244 rows × 7 columns 1234sns.catplot(x=\"sex\", y=\"total_bill\", data=tips, kind=\"bar\")plt.show() hue옵션: bar를 새로운 기준으로 분할 12345sns.catplot(x=\"sex\", y=\"total_bill\", hue=\"smoker\", data=tips, kind=\"bar\")plt.show() col / row 옵션: 그래프 자체를 새로운 기준으로 분할 123456sns.catplot(x=\"sex\", y=\"total_bill\", hue=\"smoker\", col=\"time\", data=tips, kind=\"bar\")plt.show() xtick, ytick, xlabel, ylabel을 알아서 생성해 줌 legend까지 자동으로 생성해 줌 뿐만 아니라, 신뢰 구간도 알아서 계산하여 생성함 1. Scatterplot reference: &lt;sns.scatterplot&gt; Document sns.scatterplot ( x, y, size=None, sizes=None, hue=None, palette=None, color=‘auto’, alpha=‘auto’… ) sizes 옵션: size의 선택범위를 설정. (사아즈의 min, max를 설정) hue 옵션: 컬러의 구별 기준이 되는 grouping variable 설정 color 옵션: cmap에 컬러를 지정하면, 컬러 값을 모두 같게 가겨갈 수 있음 alpha 옵션: 투명도 (0~1) 1sns.set_style('darkgrid') 1-1. x, y, color, area 설정하기 12345# 데이터 생성x = np.random.rand(50)y = np.random.rand(50)colors = np.arange(50)area = x * y * 1000 (1) matplotlib 12plt.scatter(x, y, s=area, c=colors)plt.show() (2) seaborn 12sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), hue=area, palette='coolwarm')plt.show() [Tip] Palette 이름이 생각안나면: palette 값을 임의로 주고 실행하여 오류 경고창에 정확한 palette 이름을 보여줌 12sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), hue=area, palette='coolwarm111')plt.show() --------------------------------------------------------------------------- ValueError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\seaborn\\relational.py in numeric_to_palette(self, data, order, palette, norm) 248 try: --&gt; 249 cmap = mpl.cm.get_cmap(palette) 250 except (ValueError, TypeError): D:\\Anaconda\\lib\\site-packages\\matplotlib\\cm.py in get_cmap(name, lut) 182 \"Colormap %s is not recognized. Possible values are: %s\" --&gt; 183 % (name, ', '.join(sorted(cmap_d)))) 184 ValueError: Colormap coolwarm111 is not recognized. Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, twilight, twilight_r, twilight_shifted, twilight_shifted_r, viridis, viridis_r, vlag, vlag_r, winter, winter_r 1-2. cmap과 alpha (1) matplotlib 12345678910111213plt.figure(figsize=(12, 6))plt.subplot(131)plt.scatter(x, y, s=area, c='blue', alpha=0.1)plt.title('alpha=0.1')plt.subplot(132)plt.title('alpha=0.5')plt.scatter(x, y, s=area, c='red', alpha=0.5)plt.subplot(133)plt.title('alpha=1.0')plt.scatter(x, y, s=area, c='green', alpha=1.0)plt.show() (2) seaborn 123456789101112131415plt.figure(figsize=(12, 6))plt.subplot(131)sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), color='blue', alpha=0.1)plt.title('alpha=0.1')plt.subplot(132)plt.title('alpha=0.5')sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), color='red', alpha=0.5)plt.subplot(133)plt.title('alpha=1.0')sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), color='green', alpha=0.9)plt.show() 2. Barplot, Barhplot reference: &lt;sns.barplot&gt; Document sns.boxplot ( x, y, hue=None, data=None, alpha=‘auto’, palette=None / color=None ) 2-1. 기본 Barplot 그리기 (1) matplotlib 12345678910111213x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,4))plt.bar(x, y, alpha = 0.7, color = 'red')plt.title('Subjects')plt.xticks(rotation=20)plt.ylabel('Grades')plt.show() (2) seaborn 12345678910111213x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,4))sns.barplot(x, y, alpha=0.8, palette='YlGnBu')plt.title('Subjects')plt.xticks(rotation=20)plt.ylabel('Grades')plt.show() 2-2. 기본 Barhplot 그리기 (1) matplotlib plt.barh 함수 사용 bar 함수에서 xticks / ylabel 로 설정했던 부분이 barh 함수에서 yticks / xlabel 로 변경함 12345678910111213x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,5))plt.barh(x, y, alpha = 0.7, color = 'red')plt.title('Subjects')plt.yticks(x)plt.xlabel('Grades')plt.show() (2) seaborn sns.barplot 함수를 그대로 사용 barplot함수 안에 x와 y의 위치를 교환 xticks설정이 변경 불필요; 하지만 ylabel설정은 xlable로 변경 필요 1234567891011x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,5))sns.barplot(y, x, alpha=0.9, palette=\"YlOrRd\")plt.xlabel('Grades')plt.title('Subjects')plt.show() 2-3. Barplot에서 비교 그래프 그리기 (1) matplotlib 12345678910111213141516171819202122232425262728x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.bar(x - width/2, y_1, width, alpha = 0.5)axes.bar(x + width/2, y_2, width, alpha = 0.8)# ticks &amp; label 설정plt.xticks(x)axes.set_xticklabels(x_label)plt.ylabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() 123456789101112131415161718192021222324252627x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.barh(x - width/2, y_1, width, alpha = 0.5, color = \"green\")axes.barh(x + width/2, y_2, width, alpha = 0.5, color = \"blue\")# ticks &amp; label 설정plt.yticks(x)axes.set_yticklabels(x_label)plt.xlabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() (2) seaborn Seaborn에서는 위의 matplotlib과 조금 다른 방식을 취한다. seaborn에서 hue옵션으로 매우 쉽게 비교 barplot을 그릴 수 있음. sns.barplot ( x, y, hue=…, data=…, palette=… ) 실전 tip. 그래프를 임의로 그려야 하는 경우 -&gt; matplotlib DataFrame을 가지고 그리는 경우 -&gt; seaborn 12titanic = sns.load_dataset('titanic')titanic.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone 0 0 3 male 22.0 1 0 7.2500 S Third man True NaN Southampton no False 1 1 1 female 38.0 1 0 71.2833 C First woman False C Cherbourg yes False 2 1 3 female 26.0 0 0 7.9250 S Third woman False NaN Southampton yes True 3 1 1 female 35.0 1 0 53.1000 S First woman False C Southampton yes False 4 0 3 male 35.0 0 0 8.0500 S Third man True NaN Southampton no True 12sns.barplot(x='sex', y='survived', hue='pclass', data=titanic, palette='muted')plt.show() 3. Line Plot reference: &lt;sns.lineplot&gt; Document sns.lineplot ( x, y, label=…, color=None, alpha=‘auto’, marker=None, linestyle=None ) 기본 옵션은 matplotlib의 plt.plot과 비슷 함수만 plt.plot에서 sns.lineplot로 바꾸면 됨 plt.legend() 명령어 따로 쓸 필요없음 배경이 whitegrid / darkgrid 로 설정되어 있을 시 plt.grid() 명령어 불필요 3-1. 기본 lineplot 그리기 (1) matplotlib 12345678910x = np.arange(0, 10, 0.1)y = 1 + np.sin(x)plt.plot(x, y)plt.xlabel('x value')plt.ylabel('y value')plt.title('sin graph', fontsize=16)plt.show() (2) seaborn 1234567sns.lineplot(x, y) # 함수만 변경하면 됨 (plt.plot -&gt; sns.lineplot)plt.xlabel('x value')plt.ylabel('y value')plt.title('sin graph', fontsize=16)plt.show() 3-2. 2개 이상의 그래프 그리기 12345678910111213x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1 + np.cos(x)sns.lineplot(x, y_1,label='1+sin', color='blue', alpha = 0.3) # label 설정값을 legend에 나타날 수 있음sns.lineplot(x, y_2, label='1+cos', color='red', alpha = 0.7)plt.xlabel(\"x value\")plt.ylabel(\"y value\")plt.title(\"sin and cos graph\", fontsize = 18)plt.show() 3-3. 마커 스타일링 marker: 마커 옵션 12345678910111213x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)sns.lineplot(x, y_1, label='1+sin', color='blue', alpha=0.3, marker='o')sns.lineplot(x, y_2, label='1+cos', color='red', alpha=0.7, marker='+')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.show() 3-4. 라인 스타일 변경하기 linestyle: 라인 스타일 변경하기 12345678910111213x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)sns.lineplot(x, y_1, label='1+sin', color='blue', linestyle=':')sns.lineplot(x, y_2, label='1+cos', color='red', linestyle='-.')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.show() 4. Areaplot (Filled Area) Seaborn에서는 areaplot을 지원하지 않음 matplotlib을 활용하여 구현해야 함 5.Histogram reference: &lt;sns.distplot&gt; Document sns.distplot ( x, bins=None, hist=True, kde=True, vertical=False ) bins: hist bins 갯수 설정 hist: Whether to plot a (normed) histogram kde: Whether to plot a gaussian kernel density estimate vertical: If True, observed values are on y-axis 5-1. 기본 Histogram 그리기 (1) matplotlib 12345678N = 100000bins = 30x = np.random.randn(N)plt.hist(x, bins=bins)plt.show() (2) seaborn Histogram + Density Function (default) 123456N = 100000bins = 30x = np.random.randn(N)sns.distplot(x, bins=bins) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5cc800c8&gt; Histogram Only 1sns.distplot(x, bins=bins, hist=True, kde=False, color='g') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5cd09788&gt; Density Function Only 1sns.distplot(x, bins=bins, hist=False, kde=True, color='g') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5c7cc208&gt; 수평 그래프 1sns.distplot(x, bins=bins, vertical=True, color='r') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5c250108&gt; 5-2. 다중 Histogram 그리기 matplotlib 에서의 방법을 사용 12345678910111213141516N = 100000bins = 30x = np.random.randn(N)fig, axes = plt.subplots(1, 3, sharey = True, tight_layout = True)fig.set_size_inches(12, 5)axes[0].hist(x, bins = bins)axes[1].hist(x, bins = bins*2)axes[2].hist(x, bins = bins*4)plt.show() 6. Pie Chart Seaborn에서는 pie plot을 지원하지 않음 matplotlib을 활용하여 구현해야 함 7. Box Plot reference: &lt;sns.boxplot&gt; Document sns.baxplot ( *x=None, y=None, hue=None, data=None, orient=None, width=0.8 * ) hue: 비교 그래프를 그릴 때 나눔 기준이 되는 Variable 설정 orient: “v” / “h”. Orientation of the plot (vertical or horizontal) width: box의 넓이 7-1. 기본 박스플롯 생성 샘플 데이터 생성 123456# DGPspread = np.random.rand(50) * 100center = np.ones(25) * 50flier_high = np.random.rand(10) * 100 + 100flier_low = np.random.rand(10) * -100data = np.concatenate((spread, center, flier_high, flier_low)) (1) matplotlib 12plt.boxplot(data)plt.show() (2) seaborn 12sns.boxplot(data, orient='v', width=0.2)plt.show() 7-2. 다중 박스플롯 생성 seaborn에서는 hue옵션으로 매우 쉽게 비교 boxplot을 그릴 수 있으며 주로 DataFrame을 가지고 그릴 때 활용한다. barplot과 마찬가지로, 용도에 따라 적절한 library를 사용한다 실전 Tip. 그래프를 임의로 그려야 하는 경우 -&gt; matplotlit DataFrame을 가지고 그리는 경우 -&gt; seaborn (1) matplotlib 1234567891011121314151617# DGPspread1 = np.random.rand(50) * 100center1 = np.ones(25) * 50flier_high1 = np.random.rand(10) * 100 + 100flier_low1 = np.random.rand(10) * -100data1 = np.concatenate((spread1, center1, flier_high1, flier_low1))spread2 = np.random.rand(50) * 100center2 = np.ones(25) * 40flier_high2 = np.random.rand(10) * 100 + 100flier_low2 = np.random.rand(10) * -100data2 = np.concatenate((spread2, center2, flier_high2, flier_low2))data1.shape = (-1, 1)data2.shape = (-1, 1)data = [data1, data2, data2[::2, 0]] 12plt.boxplot(data)plt.show() (2) seaborn 12titanic = sns.load_dataset('titanic')titanic.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone 0 0 3 male 22.0 1 0 7.2500 S Third man True NaN Southampton no False 1 1 1 female 38.0 1 0 71.2833 C First woman False C Cherbourg yes False 2 1 3 female 26.0 0 0 7.9250 S Third woman False NaN Southampton yes True 3 1 1 female 35.0 1 0 53.1000 S First woman False C Southampton yes False 4 0 3 male 35.0 0 0 8.0500 S Third man True NaN Southampton no True 12sns.boxplot(x='pclass', y='age', hue='survived', data=titanic)plt.show() 7-3. Box Plot 축 바꾸기 (1) 단일 boxplot orient옵션: orient = \"h\"로 설정 123456# DGPspread = np.random.rand(50) * 100center = np.ones(25) * 50flier_high = np.random.rand(10) * 100 + 100flier_low = np.random.rand(10) * -100data = np.concatenate((spread, center, flier_high, flier_low)) 1sns.boxplot(data, orient='h', width=0.3) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5e866188&gt; (2) 다중 boxplot x, y 변수 교환 orient = “h” 12sns.boxplot(y='pclass', x='age', hue='survived', data=titanic, orient='h')plt.show() 7-4. Outlier 마커 심볼과 컬러 변경 flierprops = … 옵션 사용 (matplotlib과 동일) 123456outlier_marker = dict(markerfacecolor='r', marker='D')plt.title('Changed Outlier Symbols', fontsize=15)sns.boxplot(data, orient='v', width=0.2, flierprops=outlier_marker)plt.show() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Seaborn","slug":"Seaborn","permalink":"https://hyemin-kim.github.io/tags/Seaborn/"}]},{"title":"Python >> Matplotlib - (2) 다양한 그래프 그리기","slug":"S-Python-Matplotlib2","date":"2020-06-28T05:12:32.000Z","updated":"2020-07-03T12:52:46.206Z","comments":true,"path":"2020/06/28/S-Python-Matplotlib2/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/28/S-Python-Matplotlib2/","excerpt":"","text":"matplotlib을 활용한 다양한 그래프 그리기 1. Scatterplot 1-1. x, y, colors, area 설정하기 1-2. cmap과 alpha 2. Barplot, Barhplot 2-1. 기본 barplot 그리기 2-2. 기본 Barhplot 그리기 2-3. Barplot에서 비교 그래프 그리기 3. Line Plot 3-1. 기본 lineplot 그리기 3-2. 2개 이상의 그래프 그리기 3-3. 마커 스타일링 3-4. 라인 스타일링 4. Areaplot (Filled Area) 4-1. 기본 areaplot 그리기 4-2. 경계선을 굵게 그리고 area는 옅게 그리는 효과 적용 4-3. 여러 그래프를 겹쳐서 표현 5. Histogram 5-1. 기본 Histogram 그리기 5-2. 다중 Histogram 그리기 5-3. Y축에 Density 표기 6. Pie Chart 7. Box Plot 7-1. 기본 박스플롯 생성 7-2. 다중 박스플롯 생성 7-3. Box Plot 축 바꾸기 7-4. Outlier 마커 심볼과 컬러 변경 8. 3D 그래프 그리기 8-1. 밑그림 그리기 (canvas) 8-2. 3D plot 그리기 8-3. 3d-scatter 그리기 8-4. contour3D 그리기 (등고선) 9. imshow 123import matplotlib.pyplot as pltimport pandas as pdimport numpy as np 12plt.rcParams[\"figure.figsize\"] = (9, 6) # figure size 설정plt.rcParams[\"font.size\"] = 14 # fontsize 설정 1. Scatterplot reference: &lt;plt.scatter&gt; Document plt.scatter( x, y, s=None, c=None, cmap=None, alpha=None ) s: marker size c: color cmap: colormap alpha: between 0 and 1 Data 생성 12# 0~1 사이의 random value 50 개 생성np.random.rand(50) array([0.65532609, 0.19008877, 0.72343673, 0.63981883, 0.07531076, 0.67080518, 0.93282479, 0.04750706, 0.81240348, 0.40032198, 0.59662026, 0.25797641, 0.37315105, 0.6266855 , 0.50732916, 0.55803591, 0.63610033, 0.88673444, 0.99751021, 0.03723629, 0.07695327, 0.44247 , 0.5245731 , 0.41263818, 0.8009583 , 0.57238283, 0.58647938, 0.9882001 , 0.88993497, 0.5396632 , 0.24683042, 0.0838774 , 0.0826096 , 0.89701004, 0.78305308, 0.21027637, 0.93441558, 0.05756907, 0.6299839 , 0.05833447, 0.24247082, 0.9057054 , 0.1585265 , 0.45569918, 0.85597115, 0.43875418, 0.96962923, 0.17476189, 0.68713067, 0.832518 ]) 12# 0 부터 50 개의 value 생성np.arange(50) array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]) 1-1. x, y, colors, area 설정하기 plt.scatter ( x, y, s = , c = ) s: 점의 넓이. area 값이 커지면 넓이도 커진다 c: 임의 값을 color 값으로 변환 1234567x = np.random.rand(50)y = np.random.rand(50)colors = np.arange(50)area = x * y * 1000plt.scatter(x, y, s = area, c = colors)plt.show() 1-2. cmap과 alpha cmap에 컬러를 지정하면, 컬러 값을 모두 같게 가져갈 수도 있다 alpha값은 투명도를 나타내며 0~1 사이의 값을 지정해 둘 수 있으며, 0에 가까울 수록 투명한 값을 가진다 123456789101112131415plt.figure(figsize=(12 ,6))plt.subplot(131)plt.scatter(x, y, s = area, cmap = 'blue', alpha = 0.1)plt.title('alpha = 0.1') plt.subplot(132)plt.scatter(x, y, s = area, cmap = 'blue', alpha = 0.5)plt.title('alpha = 0.5') plt.subplot(133)plt.scatter(x, y, s = area, cmap = 'blue', alpha = 1.0)plt.title('alpha = 1.0')plt.show() 2. Barplot, Barhplot reference: &lt;plt.bar&gt; Document plt.bar(x, height, width = 0.8, align = ‘center’, alpha = …, color = … ) x: The x coordinates of the bars height: The height(s) of the bars width: The width(s) of the bars (default: 0.8) align: Alignment of the bars to the x coordinates: {‘center’, ‘edge’} 2-1. 기본 barplot 그리기 12345678910111213141516x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]# figure sizeplt.figure(figsize = (7,4))# 수직 barplotplt.bar(x, y, alpha = 0.7, color = 'red')# titleplt.title('Subjects')# y labelplt.ylabel('Grades')plt.show() 문자열이 겹히는 현상 발생했다. 이를 해결하는 방법은 2가지다: 문자열 화전: plt.xtick(rotation = …) barh(수평바 그래프) 사용 12345678910111213141516171819x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]# figure sizeplt.figure(figsize = (7,4))# 수직 barplotplt.bar(x, y, alpha = 0.7, color = 'red')# titleplt.title('Subjects')# x ticksplt.xticks(rotation = 20)# y labelplt.ylabel('Grades')plt.show() 2-2. 기본 Barhplot 그리기 barh 함수에서는 xticks / ylabel 로 설정했던 부분을 yticks / xlabel 로 변경함 12345678910111213141516171819x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]# figure sizeplt.figure(figsize = (7,4))# 수직 barplotplt.barh(x, y, alpha = 0.7, color = 'green')# titleplt.title('Subjects')# y ticks# plt.yticks(x)# x labelplt.xlabel('Grades')plt.show() 2-3. Barplot에서 비교 그래프 그리기 reference: Grouped bar chart with labels (1) barplot 12345678910111213141516171819202122232425262728x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.bar(x - width/2, y_1, width, alpha = 0.5)axes.bar(x + width/2, y_2, width, alpha = 0.8)# ticks &amp; label 설정plt.xticks(x)axes.set_xticklabels(x_label)plt.ylabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() (2) barhplot 123456789101112131415161718192021222324252627x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.barh(x - width/2, y_1, width, alpha = 0.5, color = \"green\")axes.barh(x + width/2, y_2, width, alpha = 0.5, color = \"blue\")# ticks &amp; label 설정plt.yticks(x)axes.set_yticklabels(x_label)plt.xlabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() 3. Line Plot plt.plot ( x, y, label=…, color=…, alpha=…, marker=…, linestyle=…) 3-1. 기본 lineplot 그리기 123456789101112x = np.arange(0, 10, 0.1)y = 1 + np.sin(x)plt.plot(x, y)plt.xlabel('x value')plt.ylabel('y value')plt.title('sin graph', fontsize = 16)plt.grid()plt.show() 3-2. 2개 이상의 그래프 그리기 label: line 이름 (legend에 나타남) color: 컬러 옵션 alpha: 투명도 옵션 123456789101112131415x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1 + np.cos(x)plt.plot(x, y_1,label='1+sin', color='blue', alpha = 0.3) # label 설정값을 legend에 나타날 수 있음plt.plot(x, y_2, label='1+cos', color='red', alpha = 0.7)plt.xlabel(\"x value\")plt.ylabel(\"y value\")plt.title(\"sin and cos graph\", fontsize = 18)plt.grid()plt.legend()plt.show() 3-3. 마커 스타일링 marker: 마커 옵션 123456789101112131415x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)plt.plot(x, y_1, label='1+sin', color='blue', alpha=0.3, marker='o')plt.plot(x, y_2, label='1+cos', color='red', alpha=0.7, marker='+')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.grid()plt.legend()plt.show() 3-4. 라인 스타일링 linestyle: 라인 스타일 변경 옵션 123456789101112131415x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)plt.plot(x, y_1, label='1+sin', color='blue', linestyle=':')plt.plot(x, y_2, label='1+cos', color='red', linestyle='-.')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.grid()plt.legend()plt.show() 4. Areaplot (Filled Area) reference: &lt;plt.fill_between&gt; Document plt.fill_between (x, y, color=…, alpha=…) 4-1. 기본 areaplot 그리기 12y = np.random.randint(low=5, high=10, size=20)y array([8, 8, 7, 6, 5, 8, 6, 9, 8, 8, 5, 5, 6, 6, 5, 5, 6, 8, 9, 5]) 1234567x = np.arange(1,21)y = np.random.randint(low=5, high=10, size=20)# fill_between으로 색칠하기plt.fill_between(x, y, color = \"green\", alpha = 0.6)plt.show() 4-2. 경계선을 굵게 그리고 area는 옅게 그리는 효과 적용 1234plt.fill_between(x, y, color='green', alpha=0.3)plt.plot(x, y, color='green', alpha=0.7)plt.show() 4-3. 여러 그래프를 겹쳐서 표현 123456789101112x = np.arange(0, 10, 0.05)y_1 = np.cos(x) + 1y_2 = np.sin(x) + 1y_3 = y_1 * y_2 / np.piplt.fill_between(x, y_1, label='1+cos', color='green', alpha=0.1)plt.fill_between(x, y_2, label='1+sin', color='blue', alpha=0.2)plt.fill_between(x, y_3, label='sin*cos/pi', color='red', alpha=0.3)plt.legend()plt.show() 많이 겹치는 부분이 어디인지 확인하고 싶을 때 많이 활용됨 5. Histogram reference: &lt;plt.hist&gt; Document plt.hist (x, bins = …) 5-1. 기본 Histogram 그리기 12345678N = 100000bins = 30x = np.random.randn(N)plt.hist(x, bins = bins)plt.show() 5-2. 다중 Histogram 그리기 fig, axs = plt.subplots (row, column, sharey = True, tight_layout = True) axes[i].hist ( x, bins = …) sharey: 다중 그래프가 같은 y축을 share tight_layout: graph의 패딩을 자동으로 조절해주어 fit한 graph를 생성 12345678910111213141516N = 100000bins = 30x = np.random.randn(N)fig, axes = plt.subplots(1, 3, sharey = True, tight_layout = True)fig.set_size_inches(12, 5)axes[0].hist(x, bins = bins)axes[1].hist(x, bins = bins*2)axes[2].hist(x, bins = bins*4)plt.show() 5-3. Y축에 Density 표기 pdf(확률 밀도 함수): density = True cdf(누적 확률 함수): density = True, cumulatice = True 1234567891011121314N = 100000bins = 30x = np.random.randn(N)fig, axes = plt.subplots(1, 2, tight_layout = True)fig.set_size_inches(12, 4)# density=True 값을 통하여 Y축에 density를 표기할 수 있다axes[0].hist(x, bins = bins, density = True, cumulative = True) #cdf: 누적확률함수axes[1].hist(x, bins = bins, density = True) # pdf: 확률밀도함수plt.show() 6. Pie Chart reference: &lt;plt.pie&gt; Document plt.pie( x, explode=None, labels=None, colors=None, autopct=None, shadow=False, startangle=None,…) pie chart 옵션 explode: 파이에서 툭 튀어져 나온 비율 autopct: 퍼센트 자동으로 표기 shadow: 그림자 표시 startangle: 파이를 그리기 시작할 각도 리턴을 받는 인자 texts: label에 대한 텍스트 효과 autotexts: 파이 위에 그려지는 텍스트 효과 12345678910111213141516171819202122232425labels = ['Samsung', 'Huawei', 'Apple', 'Xiaomi', 'Oppo', 'Etc']sizes = [20.4, 15.8, 10.5, 9, 7.6, 36.7]explode = (0.3, 0, 0, 0, 0, 0)# text, autotext 인자를 활용하여 텍스트 스타일링을 적용한다patches, texts, autotexts = plt.pie(sizes, explode = explode, labels = labels, autopct = \"%1.1f%%\", shadow = True, startangle=90)plt.title('Smartphone Pie', fontsize=15)# label 텍스트에 대한 스타일 적용for t in texts: t.set_fontsize(12) t.set_color('gray') # pie 위의 텍스트에 대한 스타일 적용for t in autotexts: t.set_fontsize(18) t.set_color('white') plt.show() 7. Box Plot reference: &lt;plt.boxplot&gt; Document plt.boxplot (data, vert=True, flierprops = …) vert: boxplot 축 바꾸기 (If True: 수직 boxplot; If not: 수평 boxplot) flierprops: oulier marker 설정 (Symbol &amp; Color) 샘플 데이터 생성 123456# Data Generation Process (DGP)spread = np.random.rand(50) * 100center = np.ones(25) * 50flier_high = np.random.rand(10) * 100 + 100flier_low = np.random.rand(10) * -100data = np.concatenate((spread, center, flier_high, flier_low)) 7-1. 기본 박스플롯 생성 123plt.boxplot(data)plt.tight_layoutplt.show() 7-2. 다중 박스플롯 생성 다중 그래프 생성을 위해서는 data 자체가 2차원으로 구성되어 있어야 한다 row와 column으로 구성된 DataFrame에서 Column은 x축에 Row는 Y축에 구성되어 있음 1234567891011121314151617# DGPspread1 = np.random.rand(50) * 100center1 = np.ones(25) * 50flier_high1 = np.random.rand(10) * 100 + 100flier_low1 = np.random.rand(10) * -100data1 = np.concatenate((spread1, center1, flier_high1, flier_low1))spread2 = np.random.rand(50) * 100center2 = np.ones(25) * 40flier_high2 = np.random.rand(10) * 100 + 100flier_low2 = np.random.rand(10) * -100data2 = np.concatenate((spread2, center2, flier_high2, flier_low2))data1.shape = (-1, 1)data2.shape = (-1, 1)data = [data1, data2, data2[::2, 0]] 12plt.boxplot(data)plt.show() 7-3. Box Plot 축 바꾸기 vert = False 옵션을 사용 1234plt.boxplot(data, vert = False)plt.title('Horizontal Box Plot', fontsize = 16)plt.show() 7-4. Outlier 마커 심볼과 컬러 변경 flierprops = … 옵션 사용 123456outlier_marker = dict(markerfacecolor = 'r', marker = 'D') # red diamondplt.boxplot(data, flierprops = outlier_marker)plt.title('Change Outlier Symbols', fontsize = 16)plt.show() 8. 3D 그래프 그리기 reference: mplot3d tutorial 3D 로 그래프를 그리기 위해서는 mplot3d를 추가로 import 해야 함 1from mpl_toolkits import mplot3d 8-1. 밑그림 그리기 (canvas) 12fig = plt.figure()ax = plt.axes(projection = '3d') 8-2. 3D plot 그리기 Axes = plt.axes(projection = ‘3d’) Axes .plot (x, y, z, color=…, alpha=…, marker=…) Axes .plot3D (x, y, z, color=…, alpha=…, marker=…) 12345678910# projection = 3d로 설정ax = plt.axes(projection = '3d')# x, y, z 데이터 생성z = np.linspace(0, 15, 1000)x = np.sin(z)y = np.cos(z)ax.plot(x, y, z, 'gray')plt.show() 12345678910111213# projection = 3d로 설정ax = plt.axes(projection = '3d')# x, y, z 데이터 생성sample_size = 100x = np.cumsum(np.random.normal(0, 1, sample_size)) # cumsum: 누적 합y = np.cumsum(np.random.normal(0, 1, sample_size))z = np.cumsum(np.random.normal(0, 1, sample_size))ax.plot3D(x, y, z, alpha=0.6, marker='o')plt.title('ax.plot')plt.show() 8-3. 3d-scatter 그리기 reference: &lt;Axes.scatter&gt; Document Axes = fig.add_subplot(111, projection=‘3d’) # Axe3D object Axes .scatter( x, y, z, s=None, c=None, marker=None, cmap=None, alpha=None, …) s: marker size c: marker color 12345678910111213fig = plt.figure(figsize=(10, 5))ax = fig.add_subplot(111, projection='3d') # Axe3D objectsample_size = 500x = np.cumsum(np.random.normal(0, 5, sample_size))y = np.cumsum(np.random.normal(0, 5, sample_size))z = np.cumsum(np.random.normal(0, 5, sample_size))ax.scatter(x, y, z, c=z, s=20, alpha=0.5, cmap='Greens')plt.title('ax.scatter')plt.show() 컬러가 찐한 부분에 데이터가 더 많이 몰려있음 8-4. contour3D 그리기 (등고선) Axes = plt.axes(projection=‘3d’) Axes .contour3D (x, y, z ) 12345678910111213x = np.linspace(-6, 6, 30)y = np.linspace(-6, 6, 30)x, y = np.meshgrid(x, y)z = np.sin(np.sqrt(x**2 + y**2))fig = plt.figure(figsize=(12, 6))ax = plt.axes(projection='3d')ax.contour3D(x, y, z, 20, cmap='Reds')plt.title(\"ax.contour3D\")plt.show() 9. imshow 이미지 데이터가 numpy array에서는 숫자형식으로 표현됨 명령어imshow는 이 컬러숫자들을 이미지로 변환하여 보여줌 예제: sklearn.datasets안의 load_digits데이터 load_digits 는 0~16 값을 가지는 array로 이루어져 있다 1개의 array는 8 X 8 배열 안에 표현되어 있다 숫자는 0~9까지 이루어져있다 12345from sklearn.datasets import load_digitsdigits = load_digits()X = digits.images[:10] # 앞에 10개 image를 뽑아서 저장함X[0] # 첫번째 image의 컬러숫자를 살펴보자 array([[ 0., 0., 5., 13., 9., 1., 0., 0.], [ 0., 0., 13., 15., 10., 15., 5., 0.], [ 0., 3., 15., 2., 0., 11., 8., 0.], [ 0., 4., 12., 0., 0., 8., 8., 0.], [ 0., 5., 8., 0., 0., 9., 8., 0.], [ 0., 4., 11., 0., 1., 12., 7., 0.], [ 0., 2., 14., 5., 10., 12., 0., 0.], [ 0., 0., 6., 13., 10., 0., 0., 0.]]) 지금 한 위치에 숫자 하나밖에 없어서 컬러는 흑백으로 나옴. 숫자가 클수록 black에 가깝고, 작을수록 white에 가까움 12345678fig, axes = plt.subplots(nrows=2, ncols=5, sharex=True, figsize=(12, 6), sharey=True)for i in range(10): axes[i//5][i%5].imshow(X[i], cmap='Blues') axes[i//5][i%5].set_title(str(i), fontsize=20) plt.tight_layout()plt.show() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"}]},{"title":"Python >> Matplotlib - (1) 기본 canvas 그리기 및 스타일링","slug":"S-Python-Matplotlib1","date":"2020-06-28T05:12:24.000Z","updated":"2020-07-03T12:27:12.453Z","comments":true,"path":"2020/06/28/S-Python-Matplotlib1/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/28/S-Python-Matplotlib1/","excerpt":"","text":"기본적인 canvas 그리기 및 스타일링 1. 밑 그림 그리기 1-1. 단일 그래프 (single graph) 1-2. 다중 그래프 (multiple graphs) 1-3. 그래프 배열 (subplot / subplots) 2. 주요 스타일 옵션 2-1. 타이틀 2-2. X, Y축 Label 설정 2-3. X, Y축 Tick 조정 (rotation) 2-4. 범례 (Legend) 설정 2-5. X와 Y의 한계점(Limit) 설정 2-6. 스타일 세부 설정 - 마커, 라인, 컬러 2-7. 그리드 (grid) 설정 reference: pyplot 공식 Document 살펴보기 123import matplotlib.pyplot as pltimport pandas as pdimport numpy as np 1# plt.rcParams[\"figure.figsize\"] = (12, 9) # figure size 설정 1. 밑 그림 그리기 1-1. 단일 그래프 (single graph) plt.plot(df_name) plt.show() 12345678## data 생성data = np.arange(1, 100)## plotplt.plot(data)## 그래프만 보여주는 코드 (타 실행 결과 생략하고 그래프만 보여줌)plt.show() 1-2. 다중 그래프 (multiple graphs) 여러 그래프를 같은 canvas 안에 그리기: 명령어 plt.plot(df_name) 를 연속 사용 새 그래프를 새로운 canvas 안에 그리기: 세 그래프를 그리기 전에 plt.figure()명령어를 추가 (1) 1개의 canvas 안에 다중 그래프 그리기 123456789data1 = np.arange(1, 51)data2 = np.arange(51, 101)plt.plot(data1)plt.plot(data2)plt.plot(data2 + 50)plt.show() (2) 새로운 canvas에서 새 그래프를 그리기 figure()는 새로운 그래프 canvas를 생성한다 12345678910data1 = np.arange(100, 201)data2 = np.arange(200, 301)plt.plot(data)plt.figure() # figure() 명령어를 추가plt.plot(data2)plt.plot(data2 + 50)plt.show() 1-3. 그래프 배열 (subplot / subplots) 여러 개 plot을 지정된 행,열수에 따라 배열해주기: plt.subplot(row, column, index) # 각 plot의 좌표 설정 plt.subplots(행의 갯수, 열의 갯수) # 행,열수 설정 (1) subplot (plot의 좌표를 설정하기) 이 방법은 그래프마다 설정해줘야 함 plt.subplot(row, column, index) # 콤마를 제거해도 됨 123456789data1 = np.arange(100, 201)plt.subplot(2, 1, 1)plt.plot(data1)data2 = np.arange(200, 301)plt.subplot(2, 1, 2)plt.plot(data2)plt.show() 위의 코드와 동일하나, \"콤마\"를 제거한 상태 123456789data1 = np.arange(100, 201)plt.subplot(211) # 콤마를 생략함: 211 -&gt; row : 2, col: 1, index : 1plt.plot(data1)data2 = np.arange(200, 301)plt.subplot(212) # 콤마를 생략함plt.plot(data2)plt.show() 12345678910111213data1 = np.arange(100, 201)plt.subplot(1, 3, 1)plt.plot(data1)data2 = np.arange(200, 301)plt.subplot(1, 3, 2)plt.plot(data2)data3 = np.arange(300, 401)plt.subplot(1, 3, 3)plt.plot(data3)plt.show() (2) subplots (배열 기준인 행,열수를 지정하기) subplot와 다르게 subplots()명령어는 한번만 설정해주면 됨 plt.subplots(행의 갯수, 열의 갯수) 123456789101112131415data = np.arange(1, 51)# 밑 그림fig, axes = plt.subplots(2, 3)# plotaxes[0, 0].plot(data)axes[0, 1].plot(data * data)axes[0, 2].plot(data ** 3) # data^3axes[1, 0].plot(data % 10)axes[1, 1].plot(-data)axes[1, 2].plot(data // 20)plt.tight_layout()plt.show() 2. 주요 스타일 옵션 1234from IPython.display import Image# 출처: matplotlib.orgImage('https://matplotlib.org/_images/anatomy.png') 2-1. 타이틀 타이틀 추가: plt.title(\"…\") 타이틀 fontsize 설정: plt.title(\"…\", fontsize = … ) 1234plt.plot([1,2,3], [3,6,9])plt.plot([1,2,3], [2,4,9])plt.title(\"이것은 타이틀 입니다\") Text(0.5, 1.0, '이것은 타이틀 입니다') 1234plt.plot([1,2,3], [3,6,9])plt.plot([1,2,3], [2,4,9])plt.title(\"타이틀 fontsize를 키웁니다\", fontsize = 20) Text(0.5, 1.0, '타이틀 fontsize를 키웁니다') 2-2. X, Y축 Label 설정 plt.xlabel ( “x_name”, fontsize = …) plt.ylabel ( “y_name”, fontsize = …) 123456789plt.plot([1,2,3], [3,6,9])plt.plot([1,2,3], [2,4,9])# 타이틀 설정plt.title(\"Label 설정 예제\", fontsize = 16)# X축 &amp; Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16) Text(0, 0.5, 'Y축') 2-3. X, Y축 Tick 조정 (rotation) Tick은 X, Y축에 위치한 눈금을 말한다 rotation 명령어를 통해 Tick의 각도를 조절할 수 있다 plt.xticks ( rotation = … ) plt.yticks ( rotation = … ) Rotation 각도는 역시개방향 회전각도를 말한다 1234567891011121314plt.plot(np.arange(10), np.arange(10)*2)plt.plot(np.arange(10), np.arange(10)**2)plt.plot(np.arange(10), np.log(np.arange(10)))# titleplt.title(\"X, Y축 Tick 조정\", fontsize = 16)# X축, Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16)# X tick, Y tick rotation 조정plt.xticks(rotation = 90)plt.yticks(rotation = 30) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log This is separate from the ipykernel package so we can avoid doing imports until (array([-10., 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.]), &lt;a list of 11 Text yticklabel objects&gt;) 2-4. 범례 (Legend) 설정 plt.legend ( [ “name1” , “name2” , … ], fontsize = …) 1234567891011121314151617plt.plot(np.arange(10), np.arange(10)*2)plt.plot(np.arange(10), np.arange(10)**2)plt.plot(np.arange(10), np.log(np.arange(10)))# titleplt.title(\"범례(Legend) 설정\", fontsize = 16)# X축, Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16)# X tick, Y tick rotation 조정plt.xticks(rotation = 90)plt.yticks(rotation = 30)# legend 설정plt.legend([\"2x\", \"x^2\", \"logx\"], fontsize = 14) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log This is separate from the ipykernel package so we can avoid doing imports until &lt;matplotlib.legend.Legend at 0x173a5712888&gt; 2-5. X와 Y의 한계점(Limit) 설정 plt.xlim ( a, b ) plt.ylim ( c, d ) 123456789101112131415161718192021plt.plot(np.arange(10), np.arange(10)*2)plt.plot(np.arange(10), np.arange(10)**2)plt.plot(np.arange(10), np.log(np.arange(10)))# titleplt.title(\"X축, Y축 Limit 설정\", fontsize = 16)# X축, Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16)# X tick, Y tick rotation 조정plt.xticks(rotation = 90)plt.yticks(rotation = 30)# legend 설정plt.legend([\"2x\", \"x^2\", \"logx\"], fontsize = 14)# x, y limit 설정plt.xlim(0, 5)plt.ylim(0, 20) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log This is separate from the ipykernel package so we can avoid doing imports until (0, 20) 2-6. 스타일 세부 설정 - 마커, 라인, 컬러 reference: 세부 Document 확인하기 스타일 세부 설정은 마커, 선의 동류 설정, 드리고 컬러가 있으며, 문다열로 세부설정을 하게 된다 (1) marker의 종류 ‘.’ point marker ‘,’ pixel marker ‘o’ circle marker ‘v’ triangle_down marker ‘^’ triangle_up marker ‘&lt;’ triangle_left marker ‘&gt;’ triangle_right marker ‘1’ tri_down marker ‘2’ tri_up marker ‘3’ tri_left marker ‘4’ tri_right marker 's ’ square marker ‘p’ pentagon marker ‘*’ star marker ‘h’ hexagon1 marker ‘H’ hexagon2 marker ‘+’ plus marker ‘x’ x marker ‘D’ diamond marker ‘d’ thin_diamond marker ‘|’ vline marker ‘_’ hline marker 123456789101112# marker 스타일 설정plt.plot(np.arange(10), np.arange(10)*2, marker='o', markersize=5)plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='v', markersize=10)plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='+', markersize=15)plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='*', markersize=20)# 타이틀 &amp; font 설정plt.title('마커 스타일 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (2) line의 종류 ‘-’ solid line style ‘–’ dashed line style ‘-.’ dash-dot line style ‘:’ dotted line style 12345678910111213# line 스타일 설정plt.plot(np.arange(10), np.arange(10)*2, marker='o', linestyle='')plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='o', linestyle='-')plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='v', linestyle='--')plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='+', linestyle='-.')plt.plot(np.arange(10), np.arange(10)*2 - 40, marker='*', linestyle=':')# 타이틀 &amp; font 설정plt.title('다양한 선의 종류 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (3) color의 종류 ‘b’ blue ‘g’ green ‘r’ red ‘c’ cyan ‘m’ magenta ‘y’ yellow ‘k’ black ‘w’ white more choices: matplotlib.colors (e.g. “purple”, “#008000”) 123456789101112# color 설정plt.plot(np.arange(10), np.arange(10)*2, marker='o', linestyle='-', color='b')plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='v', linestyle='--', color='c')plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='+', linestyle='-.', color='y')plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='*', linestyle=':', color='r')# 타이틀 &amp; font 설정plt.title('색상 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (4) Format: '[marker][line][color]' example: ‘b’ # blue markers with default shape ‘or’ # red circles ‘-g’ # green solid line ‘–’ # dashed line with default color ‘^k:’ # black triangle_up markers connected by a dotted line Each of them is optional. If not provided, the value from the style cycle is used. Exception: If line is given, but no marker, the data will be a line without markers. 123456789101112# \"marker + line + color\" format 설정plt.plot(np.arange(10), np.arange(10)*2, \"o-r\")plt.plot(np.arange(10), np.arange(10)*2 - 10, 'v--b')plt.plot(np.arange(10), np.arange(10)*2 - 20, '+y')plt.plot(np.arange(10), np.arange(10)*2 - 30, ':k')# 타이틀 &amp; font 설정plt.title('marker/line + color 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (5) 색상 투명도 설정 alpha = … (0.0 ~ 1.0) 123456789101112# color 투명도 설정plt.plot(np.arange(10), np.arange(10)*2, color='b', alpha=0.1)plt.plot(np.arange(10), np.arange(10)*2 - 10, color='b', alpha=0.3)plt.plot(np.arange(10), np.arange(10)*2 - 20, color='b', alpha=0.6)plt.plot(np.arange(10), np.arange(10)*2 - 30, color='b', alpha=1.0)# 타이틀 &amp; font 설정plt.title('투명도 (alpha) 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') 2-7. 그리드 (grid) 설정 그리드 (grid) 추가: plt.grid() 1234567891011121314plt.plot(np.arange(10), np.arange(10)*2, marker='o', linestyle='-', color='b')plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='v', linestyle='--', color='c')plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='+', linestyle='-.', color='y')plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='*', linestyle=':', color='r')# 타이틀 &amp; font 설정plt.title('그리드 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20)# grid 옵션 추가plt.grid() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"}]},{"title":"Python >> Matplotlib 개요","slug":"S-Python-Matplotlib0","date":"2020-06-28T05:11:58.000Z","updated":"2020-06-28T05:42:20.736Z","comments":true,"path":"2020/06/28/S-Python-Matplotlib0/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/28/S-Python-Matplotlib0/","excerpt":"","text":"시각화 library – [matplotlib] 개요 matplotlib: 파이썬 기반 시각화 라이브러리 1. 불러오기 2. matplotlib 주요 장점 3. matplotlib 주요 단점 4. matplotlib 웹사이트 matplotlib: 파이썬 기반 시각화 라이브러리 1. 불러오기 1import matplotlib.pyplot 1import matplotlib.pyplot as plt # alias 설정 pandas도 matplotlib을 내장 2. matplotlib 주요 장점 파이썬 표준 시각화 도구라고 불릴 만큼 다양한 기능 지원 세부 옵션을 통하여 아름다운 스타일링 가능 보다 다양한 그래프를 그릴 수 있음 pandas와 연동이 용이함 3. matplotlib 주요 단점 한글에 대한 완벽한 지원 X 한글 사용시 추가설정 필요 (설정방법은 [Python &gt;&gt; Pandas 시각화] 안의 [0.준비 - 한글폰트 깨짐현상 해결]을 참조) 세부 기능이 많으나, 사용성이 복잡하다고 느낄 수 있음 4. matplotlib 웹사이트 http://matplotlib.org/ 여거시 matplotlib의 Documents, Samples 들을 볼 수 있음 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"사각화","slug":"사각화","permalink":"https://hyemin-kim.github.io/tags/%EC%82%AC%EA%B0%81%ED%99%94/"}]},{"title":"Python >> Pandas 시각화","slug":"S-Python-Pandas-visual","date":"2020-06-25T05:09:37.000Z","updated":"2020-06-25T05:28:17.721Z","comments":true,"path":"2020/06/25/S-Python-Pandas-visual/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/25/S-Python-Pandas-visual/","excerpt":"","text":"Pandas - 데이터 시각화 0. 준비 – 한글폰트 깨짐현상 해결 1. Plot 그래프 line 그래프 bar 그래프 히스토그램 (hist) 커널 밀도 그래프 (kde) 고밀도 산점도 그래프 (hexbin) 박스 플롯 (box) area plot 파이 그래프 (pie plot) 산점도 그래프 (scatter plot) 1import pandas as pd 1df = pd.read_csv(\"house_price_clean.csv\") 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 4 인천 60㎡이하 2015 10 3488 ... ... ... ... ... ... 3288 경남 60㎡초과 85㎡이하 2020 2 3065 3289 경남 85㎡초과 102㎡이하 2020 2 3247 3290 제주 60㎡이하 2020 2 4039 3291 제주 60㎡초과 85㎡이하 2020 2 3962 3292 제주 102㎡초과 2020 2 3601 3293 rows × 5 columns 0. 준비 – 한글폰트 깨짐현상 해결 reference: 주피터 노트북(Jupyter notebook) - Matplotlib 한글 깨짐 현상 해결 matplotlib/seaborn으로 시각화할 때 한글 폰트 깨짐현상 해결방법 Jupyter Notebook에서 그래프를 그릴 때 한글 깨짐 현상이 발생한다 1df.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x179eb070ac8&gt; 우리는 설정 파일을 수정하여 한글 폰트를 영구 등록함으로써 이 문제를 해결할 수 있다 (1) 설정 파일 위치 찾기 1234import matplotlib as mpl#font 설정 파일 위치 출력mpl.matplotlib_fname() 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\matplotlibrc' (2) 설정 파일 수정하기 맨 마지막 matplotlibrc 는 우리가 수정해야할 파일의 이름이다 step 1. 한글 폰트 적용 수정전: # font.family : sans-serif 수정후: font.family : Malgun Gothic step 2. minus 깨짐 방지 수정전: # axes.unicode_minus : True ## use unicode for the minus symbol 수정후: axes.unicode_minus : False ## use unicode for the minus symbol (3) Tip: 전역으로 시각화 figsize 조절 12import matplotlib.pyplot as pltplt.rcParams['figure.figsize'] = (8, 5) 설정을 완료한 후 jupyter notebook의 kernel을 리셋하고 다시 그래프를 그리면, 한글폰트가 깨지지 않고 잘 출력되는 것을 확인하실 수 있다. 1df.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f01b0c48&gt; 1. Plot 그래프 df_name [ col_name ] .plot ( kind = ‘…’ ) plot은 일반 선그래프를 나타난다 kind 옵션을 통해 원하는 그패프를 그릴 수 있다 kind 옵션: line: 선 그래프 bar: 바 그래프 barh: 수평 바 프래프 hist: 히스토르램 kde: 커널 밀도 그래프 hexbin: 고밀도 산점도 그래프 box: 박스 플롯 area: 면적 그래프 pie: 파이 그래프 scatter: 산점도 그래프 line 그래프 line 그래프는 데이터가 연속적인 경우 사용하기 적절하다. (예를 들면, 주가 데이터) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 4 인천 60㎡이하 2015 10 3488 ... ... ... ... ... ... 3288 경남 60㎡초과 85㎡이하 2020 2 3065 3289 경남 85㎡초과 102㎡이하 2020 2 3247 3290 제주 60㎡이하 2020 2 4039 3291 제주 60㎡초과 85㎡이하 2020 2 3962 3292 제주 102㎡초과 2020 2 3601 3293 rows × 5 columns (1) 모든 observation의 분양가 살펴보기 12# index - 분양가df[\"분양가\"].plot(kind = 'line') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f01a0bc8&gt; (2) 연도에 따른 서울 분양가 변화 추세 123# select \"서울\" datadf_seoul = df.loc[df[\"지역\"] == \"서울\"]df_seoul .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 64 서울 60㎡이하 2015 11 6320 ... ... ... ... ... ... 3178 서울 102㎡초과 2020 1 8779 3234 서울 60㎡이하 2020 2 8193 3235 서울 60㎡초과 85㎡이하 2020 2 8140 3236 서울 85㎡초과 102㎡이하 2020 2 13835 3237 서울 102㎡초과 2020 2 9039 212 rows × 5 columns 123# group by \"year\" df_seoul_year = df_seoul.groupby('연도').mean()df_seoul_year .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 월 분양가 연도 2015 11.0 6201.000000 2016 6.5 6674.520833 2017 6.5 6658.729167 2018 6.5 7054.687500 2019 6.5 8735.083333 2020 1.5 9647.375000 12# line plotdf_seoul_year[\"분양가\"].plot(kind = 'line') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f028b5c8&gt; bar 그래프 bar 그패프는 그룹별로 비교할 때 유용하다 지역별 평균 분양가 살펴보기 1df.groupby(\"지역\")[\"분양가\"].mean() 지역 강원 2448.156863 경기 4133.952830 경남 2858.932367 경북 2570.465000 광주 3055.043750 대구 3679.620690 대전 3176.127389 부산 3691.981132 서울 7308.943396 세종 2983.543147 울산 2990.373913 인천 3684.302885 전남 2326.250000 전북 2381.416268 제주 3472.677966 충남 2534.950000 충북 2348.183962 Name: 분양가, dtype: float64 12# 수직 바 그래프df.groupby(\"지역\")[\"분양가\"].mean().plot(kind = 'bar') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f028b548&gt; 12# 수평 바 그래프df.groupby(\"지역\")[\"분양가\"].mean().plot(kind = 'barh') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179edd9d4c8&gt; 히스토그램 (hist) 히스토그램은 분포-빈도 를 시각화하여 보여준다. 가로축에는 분포를, 세로축에는 빈도가 시각화되어 보여짐. 1df[\"분양가\"].plot(kind = \"hist\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f021cc88&gt; 커널 밀도 그래프 (kde) 히스토그램과 유사하게 밀도를 보여주는 그래프다 히스토그램과 유사한 모양새를 각추고 있다 하지만 히스토그램과 다르게 부드러운 라인을 가지고 있다 1df[\"분양가\"].plot(kind = \"kde\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f043d608&gt; 고밀도 산점도 그래프 (hexbin) hexbin은 고밀고 산점도 그래프다 x와 y 키 값을 넣어 주어야 한다 x, y 값 모두 numeric value 이어야한다 데이터의 밀도를 추정한다 1df.plot(kind = \"hexbin\", x = \"분양가\", y = \"연도\", gridsize = 20) &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f028a9c8&gt; 박스 플롯 (box) 1df_seoul = df.loc[df[\"지역\"] == \"서울\"] 1df_seoul[\"분양가\"].plot(kind = \"box\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f226d748&gt; box plot 해석 IQR (Inter Quantile Range) = 3Q - 1Q Upper fence = 75th Percentile + 1.5*IQR Lower fence = 25th Percentile - 1.5*IQR box plot은 데이터 outlier 감지할 때 가장 많이 활용되며, 25%, median, 75% 분위값을 활용하는 용도로도 많이 활용된다 area plot area plot은 line 그래프에서 아래 area를 모두 색칠해 주는 것이 특징이다. 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 4 인천 60㎡이하 2015 10 3488 ... ... ... ... ... ... 3288 경남 60㎡초과 85㎡이하 2020 2 3065 3289 경남 85㎡초과 102㎡이하 2020 2 3247 3290 제주 60㎡이하 2020 2 4039 3291 제주 60㎡초과 85㎡이하 2020 2 3962 3292 제주 102㎡초과 2020 2 3601 3293 rows × 5 columns 1df.groupby(\"월\")[\"분양가\"].count().plot(kind = \"line\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f22a6688&gt; 1df.groupby(\"월\")[\"분양가\"].count().plot(kind = \"area\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f2267588&gt; 파이 그래프 (pie plot) pie는 대표적으로 데이터의 점유율을 보유줄 때 유용하다 연도별 분양가 데이터 점유율 1df.groupby(\"연도\")[\"분양가\"].count().plot(kind = 'pie') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f224fec8&gt; 산점도 그래프 (scatter plot) 점으로 데이터를 표기해준다 x, y값을 넣어주어야한다 (hexbin과 유사) x축과 y축을 지정해주면 그에 맞는 데이터 분포를 볼 수 있다 역시 numeric column 만 지정할 수 있다 1df.plot(x = \"월\", y = \"분양가\", kind = \"scatter\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f23372c8&gt; document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"}]},{"title":"【실습】 Python >> Pandas 전처리 -- 부동산 데이터","slug":"E-Python-Pandas-Pre-1","date":"2020-06-22T10:14:57.000Z","updated":"2020-06-23T16:35:19.434Z","comments":true,"path":"2020/06/22/E-Python-Pandas-Pre-1/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/22/E-Python-Pandas-Pre-1/","excerpt":"","text":"&lt;Pandas 전처리&gt; 실습 – 부동산 데이터 0. 샘플데이터 1. column 이름 제정의 (rename) 2. Data Overview 2-1. Data Shape 확인하기 2-2. 걸측값과 Data Type 확인하기 2-3. 통계값 확인하기 3. 데이터 타입 변환 3-1. str.strip()을 활용하여 공백이 있는 데이터의 공백 없애기 3-2. 빈 공백에 0을 넣어주기 3-3. NaN 값은 fillna로 채워주기 3-4. str.replace() 를 활용하여 콤마를 제거하기 3-5. str.replace()를 활용하여 “-” 제거하기 3-6. 규모구분 column에 불필요한 “전용면적” 제거하기 4. 전처리 내용 복습하기 5. 지역별 분양가격을 확인해보기 5-1. 지역별 평균 분양가격 확인해보기 5-2. 분양가격이 100보다 작은 행을 제거해보기 5-3. 지역별 “분양가격” 데이터의 갯수를 확인해보기 5-4. 지역별 제일 비싼 분양가를 확인해보기 6. 연도별 평균 분양가격을 확인해보기 7. 피벗테이블 활용하기 8. 연도별, 규모별 가격을 알아보기 1import pandas as pd 0. 샘플데이터 공공데이터포털 에서 제공하는 공공데이터 “민간 아파트 가격동향” 를 활용한다. 1df = pd.read_csv(\"seoul_house_price.csv\") 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격(㎡) 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 전용면적 60㎡이하 2020 2 4039 4502 제주 전용면적 60㎡초과 85㎡이하 2020 2 3962 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4504 제주 전용면적 102㎡초과 2020 2 3601 4505 rows × 5 columns 1. column 이름 제정의 (rename) [목표] 분양가격 column의 이름을 재정의: “분양가격(m2)​” --&gt; “분양가격” 1df = df.rename(columns = {\"분양가격(㎡)\" : \"분양가격\"}) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 전용면적 60㎡이하 2020 2 4039 4502 제주 전용면적 60㎡초과 85㎡이하 2020 2 3962 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4504 제주 전용면적 102㎡초과 2020 2 3601 4505 rows × 5 columns 2. Data Overview 2-1. Data Shape 확인하기 1df.shape (4505, 5) 2-2. 걸측값과 Data Type 확인하기 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 4505 entries, 0 to 4504 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 지역명 4505 non-null object 1 규모구분 4505 non-null object 2 연도 4505 non-null int64 3 월 4505 non-null int64 4 분양가격 4210 non-null object dtypes: int64(2), object(3) memory usage: 176.1+ KB 2-3. 통계값 확인하기 1df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 연도 월 count 4505.000000 4505.000000 mean 2017.452830 6.566038 std 1.311432 3.595519 min 2015.000000 1.000000 25% 2016.000000 3.000000 50% 2017.000000 7.000000 75% 2019.000000 10.000000 max 2020.000000 12.000000 3. 데이터 타입 변환 [목표] &lt;object 타입&gt;으로 되어있는 \"분양가격\"을 &lt;int 타입&gt;으로 변환하기 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-193-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: invalid literal for int() with base 10: ' ' !! “분양가격” column에 “2칸 공백” 값이 있어서 Error가 납니다 3-1. str.strip()을 활용하여 공백이 있는 데이터의 공백 없애기 df_name [ “col_name” ] .str.strip() 1df.loc[df[\"분양가격\"] == ' '] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 28 광주 전용면적 85㎡초과 102㎡이하 2015 10 29 광주 전용면적 102㎡초과 2015 10 34 대전 전용면적 102㎡초과 2015 10 81 제주 전용면적 60㎡이하 2015 10 113 광주 전용면적 85㎡초과 102㎡이하 2015 11 114 광주 전용면적 102㎡초과 2015 11 119 대전 전용면적 102㎡초과 2015 11 166 제주 전용면적 60㎡이하 2015 11 198 광주 전용면적 85㎡초과 102㎡이하 2015 12 199 광주 전용면적 102㎡초과 2015 12 204 대전 전용면적 102㎡초과 2015 12 251 제주 전용면적 60㎡이하 2015 12 283 광주 전용면적 85㎡초과 102㎡이하 2016 1 284 광주 전용면적 102㎡초과 2016 1 289 대전 전용면적 102㎡초과 2016 1 336 제주 전용면적 60㎡이하 2016 1 1df[\"분양가격\"] = df[\"분양가격\"].str.strip(' ') 1df.loc[df[\"분양가격\"] == \" \"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 3-2. 빈 공백에 0을 넣어주기 1df.loc[df[\"분양가격\"] == '', \"분양가격\"] = 0 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-198-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: cannot convert float NaN to integer !! “분양가격” column에 “NaN” 값이 있어서 Error가 또 납니다 ㅠㅠ 3-3. NaN 값은 fillna로 채워주기 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 전용면적 60㎡이하 2020 2 4039 4502 제주 전용면적 60㎡초과 85㎡이하 2020 2 3962 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4504 제주 전용면적 102㎡초과 2020 2 3601 4505 rows × 5 columns 1df.loc[df[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 368 광주 전용면적 85㎡초과 102㎡이하 2016 2 NaN 369 광주 전용면적 102㎡초과 2016 2 NaN 374 대전 전용면적 102㎡초과 2016 2 NaN 388 강원 전용면적 85㎡초과 102㎡이하 2016 2 NaN 421 제주 전용면적 60㎡이하 2016 2 NaN ... ... ... ... ... ... 4461 세종 전용면적 60㎡이하 2020 2 NaN 4488 전남 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4493 경북 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4499 경남 전용면적 102㎡초과 2020 2 NaN 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 295 rows × 5 columns 1df[\"분양가격\"] = df[\"분양가격\"].fillna(0) 1df.loc[df[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-203-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: invalid literal for int() with base 10: '6,657' !! 이번에는 \",\"가 들어간 데이터가 문제네요… 3-4. str.replace() 를 활용하여 콤마를 제거하기 1df.loc[df[\"분양가격\"] == \"6,657\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 2125 서울 전체 2017 11 6,657 1df[\"분양가격\"] = df[\"분양가격\"].str.replace(',', '') 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-206-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: cannot convert float NaN to integer !! 다시 NaN값이 생겨서 fillna로 채워줍니다. 1df[\"분양가격\"] = df[\"분양가격\"].fillna(0) 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-208-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: invalid literal for int() with base 10: '-' !! 이번에는 \"-\"가 멀썽이네요… 3-5. str.replace()를 활용하여 “-” 제거하기 1df[\"분양가격\"] = df[\"분양가격\"].str.replace(\"-\", \"\") 1df.loc[df[\"분양가격\"] == \"\", \"분양가격\"] = 0 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-211-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: cannot convert float NaN to integer 1df[\"분양가격\"] = df[\"분양가격\"].fillna(0) 1df[\"분양가격\"] = df[\"분양가격\"].astype(int) 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 4505 entries, 0 to 4504 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 지역명 4505 non-null object 1 규모구분 4505 non-null object 2 연도 4505 non-null int64 3 월 4505 non-null int64 4 분양가격 4505 non-null int32 dtypes: int32(1), int64(2), object(2) memory usage: 158.5+ KB 이제 드디어 “분양가격” column의 Type을 int로 성공적으로 바꿨습니다!!! 3-6. 규모구분 column에 불필요한 “전용면적” 제거하기 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 1df[\"규모구분\"] = df[\"규모구분\"].str.replace(\"전용면적\", \"\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 4. 전처리 내용 복습하기 방급 진행 했던 전처리 과정을 복습해봅시다! 1df2 = pd.read_csv(\"seoul_house_price.csv\") (1) 콤마가 있는 경우 df_name [ “col_name” ] .str.replace (’,’, ‘’) 1df2.iloc[2125] 지역명 서울 규모구분 전체 연도 2017 월 11 분양가격(㎡) 6,657 Name: 2125, dtype: object 1df2 = df2.rename(columns = {\"분양가격(㎡)\" : \"분양가격\"}) 1df2[\"분양가격\"] = df2[\"분양가격\"].str.replace(\",\", \"\") 1df2.iloc[2125] 지역명 서울 규모구분 전체 연도 2017 월 11 분양가격 6657 Name: 2125, dtype: object (2) - 가 있는 경우 df_name [ “col_name” ] **.str.replace(’-’, ‘’) 1df2.loc[df2[\"분양가격\"] == \"-\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 3683 광주 전용면적 85㎡초과 102㎡이하 2019 5 - 3686 대전 전용면적 60㎡이하 2019 5 - 3688 대전 전용면적 85㎡초과 102㎡이하 2019 5 - 3690 울산 전체 2019 5 - 3691 울산 전용면적 60㎡이하 2019 5 - 3692 울산 전용면적 60㎡초과 85㎡이하 2019 5 - 3693 울산 전용면적 85㎡초과 102㎡이하 2019 5 - 3694 울산 전용면적 102㎡초과 2019 5 - 3696 세종 전용면적 60㎡이하 2019 5 - 1df2[\"분양가격\"] = df2[\"분양가격\"].str.replace(\"-\", \"\") 1df2.loc[df2[\"분양가격\"] == \"-\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (3) 공백이 2개 들어간 경우 df_name [ “col_name” ] **.str.strip(\" \") 1df2.loc[df2[\"분양가격\"] == \" \"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 28 광주 전용면적 85㎡초과 102㎡이하 2015 10 29 광주 전용면적 102㎡초과 2015 10 34 대전 전용면적 102㎡초과 2015 10 81 제주 전용면적 60㎡이하 2015 10 113 광주 전용면적 85㎡초과 102㎡이하 2015 11 114 광주 전용면적 102㎡초과 2015 11 119 대전 전용면적 102㎡초과 2015 11 166 제주 전용면적 60㎡이하 2015 11 198 광주 전용면적 85㎡초과 102㎡이하 2015 12 199 광주 전용면적 102㎡초과 2015 12 204 대전 전용면적 102㎡초과 2015 12 251 제주 전용면적 60㎡이하 2015 12 283 광주 전용면적 85㎡초과 102㎡이하 2016 1 284 광주 전용면적 102㎡초과 2016 1 289 대전 전용면적 102㎡초과 2016 1 336 제주 전용면적 60㎡이하 2016 1 1df2[\"분양가격\"] = df2[\"분양가격\"].str.strip(\" \") 1df2.loc[df2[\"분양가격\"] == \" \"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (4) 빈 칸을 0으로 채우기 df_name.loc [ df_name [ “col_name” ] == “” , “col_name”] = 0 1df2.loc[df2[\"분양가격\"] == \"\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 28 광주 전용면적 85㎡초과 102㎡이하 2015 10 29 광주 전용면적 102㎡초과 2015 10 34 대전 전용면적 102㎡초과 2015 10 81 제주 전용면적 60㎡이하 2015 10 113 광주 전용면적 85㎡초과 102㎡이하 2015 11 114 광주 전용면적 102㎡초과 2015 11 119 대전 전용면적 102㎡초과 2015 11 166 제주 전용면적 60㎡이하 2015 11 198 광주 전용면적 85㎡초과 102㎡이하 2015 12 199 광주 전용면적 102㎡초과 2015 12 204 대전 전용면적 102㎡초과 2015 12 251 제주 전용면적 60㎡이하 2015 12 283 광주 전용면적 85㎡초과 102㎡이하 2016 1 284 광주 전용면적 102㎡초과 2016 1 289 대전 전용면적 102㎡초과 2016 1 336 제주 전용면적 60㎡이하 2016 1 3683 광주 전용면적 85㎡초과 102㎡이하 2019 5 3686 대전 전용면적 60㎡이하 2019 5 3688 대전 전용면적 85㎡초과 102㎡이하 2019 5 3690 울산 전체 2019 5 3691 울산 전용면적 60㎡이하 2019 5 3692 울산 전용면적 60㎡초과 85㎡이하 2019 5 3693 울산 전용면적 85㎡초과 102㎡이하 2019 5 3694 울산 전용면적 102㎡초과 2019 5 3696 세종 전용면적 60㎡이하 2019 5 1df2.loc[df2[\"분양가격\"] == \"\", \"분양가격\"] = 0 1df2.loc[df2[\"분양가격\"] == \"\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (5) NaN 값을 0으로 바꾸기 df_name.loc [ df_name [ “col_name” ] .isna() ] df_name [ “col_name” ].fillna(0) 1df2.loc[df2[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 368 광주 전용면적 85㎡초과 102㎡이하 2016 2 NaN 369 광주 전용면적 102㎡초과 2016 2 NaN 374 대전 전용면적 102㎡초과 2016 2 NaN 388 강원 전용면적 85㎡초과 102㎡이하 2016 2 NaN 421 제주 전용면적 60㎡이하 2016 2 NaN ... ... ... ... ... ... 4461 세종 전용면적 60㎡이하 2020 2 NaN 4488 전남 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4493 경북 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4499 경남 전용면적 102㎡초과 2020 2 NaN 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 295 rows × 5 columns 1df2[\"분양가격\"] = df2[\"분양가격\"].fillna(0) 1df2.loc[df2[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (6) column type 바꾸기 df_name [ “col_name” ] .astype(…) 1df2[\"분양가격\"].astype(int) 0 5841 1 5652 2 5882 3 5721 4 5879 ... 4500 3955 4501 4039 4502 3962 4503 0 4504 3601 Name: 분양가격, Length: 4505, dtype: int32 5. 지역별 분양가격을 확인해보기 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 60㎡이하 2020 2 4039 4502 제주 60㎡초과 85㎡이하 2020 2 3962 4503 제주 85㎡초과 102㎡이하 2020 2 0 4504 제주 102㎡초과 2020 2 3601 4505 rows × 5 columns 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 4505 entries, 0 to 4504 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 지역명 4505 non-null object 1 규모구분 4505 non-null object 2 연도 4505 non-null int64 3 월 4505 non-null int64 4 분양가격 4505 non-null int32 dtypes: int32(1), int64(2), object(2) memory usage: 158.5+ KB 5-1. 지역별 평균 분양가격 확인해보기 1df.groupby(\"지역명\")[\"분양가격\"].mean() 지역명 강원 2339.807547 경기 4072.667925 경남 2761.275472 경북 2432.128302 광주 2450.728302 대구 3538.920755 대전 2479.135849 부산 3679.920755 서울 7225.762264 세종 2815.098113 울산 1826.101887 인천 3578.433962 전남 2270.177358 전북 2322.060377 제주 2979.407547 충남 2388.324528 충북 2316.871698 Name: 분양가격, dtype: float64 5-2. 분양가격이 100보다 작은 행을 제거해보기 특정 조건에 만족하는 행을 제거하고자 할 때는 index를 list로 가져온다 idx = df.loc [ 조건식 ] .index drop을 활용하여 행을 제거한다 df_name = df_name .drop (idx, axis = 0) 1idx = df.loc[df[\"분양가격\"] &lt; 100].index 1idx Int64Index([ 28, 29, 34, 81, 113, 114, 119, 166, 198, 199, ... 4418, 4448, 4453, 4458, 4459, 4461, 4488, 4493, 4499, 4503], dtype='int64', length=320) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 60㎡이하 2020 2 4039 4502 제주 60㎡초과 85㎡이하 2020 2 3962 4503 제주 85㎡초과 102㎡이하 2020 2 0 4504 제주 102㎡초과 2020 2 3601 4505 rows × 5 columns 1df = df.drop(idx, axis = 0) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4498 경남 85㎡초과 102㎡이하 2020 2 3247 4500 제주 전체 2020 2 3955 4501 제주 60㎡이하 2020 2 4039 4502 제주 60㎡초과 85㎡이하 2020 2 3962 4504 제주 102㎡초과 2020 2 3601 4185 rows × 5 columns 다시 한 번 지역명으로 group을 묶어 분양가격을 확인해보자! 1df.groupby(\"지역명\")[\"분양가격\"].mean() 지역명 강원 2412.642023 경기 4072.667925 경남 2814.376923 경북 2547.486166 광주 3049.028169 대구 3663.335938 대전 3128.433333 부산 3679.920755 서울 7225.762264 세종 2984.004000 울산 3043.503145 인천 3633.275862 전남 2304.969349 전북 2348.648855 제주 3432.795652 충남 2501.604743 충북 2316.871698 Name: 분양가격, dtype: float64 5-3. 지역별 “분양가격” 데이터의 갯수를 확인해보기 1df.groupby(\"지역명\")[\"분양가격\"].count() 지역명 강원 257 경기 265 경남 260 경북 253 광주 213 대구 256 대전 210 부산 265 서울 265 세종 250 울산 159 인천 261 전남 261 전북 262 제주 230 충남 253 충북 265 Name: 분양가격, dtype: int64 5-4. 지역별 제일 비싼 분양가를 확인해보기 1df.groupby(\"지역명\")[\"분양가격\"].max() 지역명 강원 3906 경기 5670 경남 4303 경북 3457 광주 4881 대구 5158 대전 4877 부산 4623 서울 13835 세종 3931 울산 3594 인천 5188 전남 3053 전북 3052 제주 5462 충남 3201 충북 2855 Name: 분양가격, dtype: int32 6. 연도별 평균 분양가격을 확인해보기 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 1df.groupby(\"연도\")[\"분양가격\"].mean() 연도 2015 2788.707819 2016 2934.250000 2017 3143.311795 2018 3326.951034 2019 3693.422149 2020 3853.960526 Name: 분양가격, dtype: float64 7. 피벗테이블 활용하기 행 인덱스: 연도 열 인덱스: 규모구분 값: 분양가 (평균) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 1pd.pivot_table(df, index = \"연도\", columns = \"규모구분\", values = \"분양가격\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 규모구분 102㎡초과 60㎡이하 60㎡초과 85㎡이하 85㎡초과 102㎡이하 전체 연도 2015 2980.977778 2712.583333 2694.490196 2884.395833 2694.862745 2016 3148.099476 2848.144279 2816.965686 3067.380435 2816.073529 2017 3427.649746 3112.538071 2981.950980 3204.075145 3008.279412 2018 3468.355932 3286.184783 3227.458128 3467.184211 3235.098522 2019 4039.854839 3486.910112 3538.545918 3933.538462 3515.974490 2020 4187.566667 3615.968750 3594.852941 4532.090909 3603.911765 8. 연도별, 규모별 가격을 알아보기 1df.groupby([\"연도\", \"규모구분\"])[\"분양가격\"].mean() 연도 규모구분 2015 102㎡초과 2980.977778 60㎡이하 2712.583333 60㎡초과 85㎡이하 2694.490196 85㎡초과 102㎡이하 2884.395833 전체 2694.862745 2016 102㎡초과 3148.099476 60㎡이하 2848.144279 60㎡초과 85㎡이하 2816.965686 85㎡초과 102㎡이하 3067.380435 전체 2816.073529 2017 102㎡초과 3427.649746 60㎡이하 3112.538071 60㎡초과 85㎡이하 2981.950980 85㎡초과 102㎡이하 3204.075145 전체 3008.279412 2018 102㎡초과 3468.355932 60㎡이하 3286.184783 60㎡초과 85㎡이하 3227.458128 85㎡초과 102㎡이하 3467.184211 전체 3235.098522 2019 102㎡초과 4039.854839 60㎡이하 3486.910112 60㎡초과 85㎡이하 3538.545918 85㎡초과 102㎡이하 3933.538462 전체 3515.974490 2020 102㎡초과 4187.566667 60㎡이하 3615.968750 60㎡초과 85㎡이하 3594.852941 85㎡초과 102㎡이하 4532.090909 전체 3603.911765 Name: 분양가격, dtype: float64 예쁘게 출력이 안되어서 보기가 힘들때는 pd.DataFrame()으로 한 번 더 감싸주면 됩니다. 1pd.DataFrame(df.groupby([\"연도\", \"규모구분\"])[\"분양가격\"].mean()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 분양가격 연도 규모구분 2015 102㎡초과 2980.977778 60㎡이하 2712.583333 60㎡초과 85㎡이하 2694.490196 85㎡초과 102㎡이하 2884.395833 전체 2694.862745 2016 102㎡초과 3148.099476 60㎡이하 2848.144279 60㎡초과 85㎡이하 2816.965686 85㎡초과 102㎡이하 3067.380435 전체 2816.073529 2017 102㎡초과 3427.649746 60㎡이하 3112.538071 60㎡초과 85㎡이하 2981.950980 85㎡초과 102㎡이하 3204.075145 전체 3008.279412 2018 102㎡초과 3468.355932 60㎡이하 3286.184783 60㎡초과 85㎡이하 3227.458128 85㎡초과 102㎡이하 3467.184211 전체 3235.098522 2019 102㎡초과 4039.854839 60㎡이하 3486.910112 60㎡초과 85㎡이하 3538.545918 85㎡초과 102㎡이하 3933.538462 전체 3515.974490 2020 102㎡초과 4187.566667 60㎡이하 3615.968750 60㎡초과 85㎡이하 3594.852941 85㎡초과 102㎡이하 4532.090909 전체 3603.911765 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (7) 기타","slug":"S-Python-Pandas-Pre7","date":"2020-06-20T13:28:42.000Z","updated":"2020-06-23T16:53:03.553Z","comments":true,"path":"2020/06/20/S-Python-Pandas-Pre7/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/20/S-Python-Pandas-Pre7/","excerpt":"","text":"기타 1. 데이터 타입별 column 선택 (select_dtypes) 문자열이 있는 column만 선택 / 배제 2. One-hot-encoding (원핫인코딩) 1import pandas as pd 1df = pd.read_csv(\"korean-idol.csv\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1. 데이터 타입별 column 선택 (select_dtypes) 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 문자열이 있는 column만 선택 / 배제 df_name .select_dtypes (include = ‘object’) df_name .select_dtypes (exclude = ‘object’) (1) 문자열 column만 선택 1df.select_dtypes(include = 'object') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 혈액형 0 지민 방탄소년단 빅히트 남자 1995-10-13 A 1 지드래곤 빅뱅 YG 남자 1988-08-18 A 2 강다니엘 NaN 커넥트 남자 1996-12-10 A 3 뷔 방탄소년단 빅히트 남자 1995-12-30 AB 4 화사 마마무 RBW 여자 1995-07-23 A 5 정국 방탄소년단 빅히트 남자 1997-09-01 A 6 민현 뉴이스트 플레디스 남자 1995-08-09 O 7 소연 아이들 큐브 여자 1998-08-26 B 8 진 방탄소년단 빅히트 남자 1992-12-04 O 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 A 10 태연 소녀시대 SM 여자 1989-03-09 A 11 차은우 아스트로 판타지오 남자 1997-03-30 B 12 백호 뉴이스트 플레디스 남자 1995-07-21 AB 13 JR 뉴이스트 플레디스 남자 1995-06-08 O 14 슈가 방탄소년단 빅히트 남자 1993-03-09 O (2) 문자열 column 배제 (문자열이 아닌 column만 선택) 1df.select_dtypes(exclude = 'object') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 0 173.6 10523260 1 177.0 9916947 2 180.0 8273745 3 178.0 8073501 4 162.1 7650928 5 178.0 5208335 6 182.3 4989792 7 NaN 4668615 8 179.2 4570308 9 167.1 4036489 10 NaN 3918661 11 183.0 3506027 12 175.0 3301654 13 176.0 3274137 14 174.0 2925442 문자열이 포함된 DataFrame의 연산으로 발생되는 Error문제는 이 방법을 이용하여 해결할 수 있다 1df + 10 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py in na_arithmetic_op(left, right, op, str_rep) 148 try: --&gt; 149 result = expressions.evaluate(op, str_rep, left, right) 150 except TypeError: D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in evaluate(op, op_str, a, b, use_numexpr) 207 if use_numexpr: --&gt; 208 return _evaluate(op, op_str, a, b) 209 return _evaluate_standard(op, op_str, a, b) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_numexpr(op, op_str, a, b) 120 if result is None: --&gt; 121 result = _evaluate_standard(op, op_str, a, b) 122 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_standard(op, op_str, a, b) 69 with np.errstate(all=\"ignore\"): ---&gt; 70 return op(a, b) 71 TypeError: can only concatenate str (not \"int\") to str ​ 1df.select_dtypes(exclude = 'object') + 10 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 0 183.6 10523270 1 187.0 9916957 2 190.0 8273755 3 188.0 8073511 4 172.1 7650938 5 188.0 5208345 6 192.3 4989802 7 NaN 4668625 8 189.2 4570318 9 177.1 4036499 10 NaN 3918671 11 193.0 3506037 12 185.0 3301664 13 186.0 3274147 14 184.0 2925452 (3) “문자열 column” / “비문자열 column” 의 column명을 추출 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 12obj_cols = df.select_dtypes(include = 'object').columnsobj_cols Index(['이름', '그룹', '소속사', '성별', '생년월일', '혈액형'], dtype='object') 12num_cols = df.select_dtypes(exclude = 'object').columnsnum_cols Index(['키', '브랜드평판지수'], dtype='object') 1df[num_cols] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 0 173.6 10523260 1 177.0 9916947 2 180.0 8273745 3 178.0 8073501 4 162.1 7650928 5 178.0 5208335 6 182.3 4989792 7 NaN 4668615 8 179.2 4570308 9 167.1 4036489 10 NaN 3918661 11 183.0 3506027 12 175.0 3301654 13 176.0 3274137 14 174.0 2925442 2. One-hot-encoding (원핫인코딩) One-hot-encoding: Categorical data를 dummy data로 변환시키는 방법 Dummy data로 변환 시 한개의 요소는 True (1) 로, 나머지 요소는 Flase (0) 로 변환시킨다 pd.get_dummies (df_name [ ‘col_name’ ], prefix = “…”) prefix: dummy data 로 분리된 새 column들의 column name에 접두사 붙이기 1df['혈액형'] 0 A 1 A 2 A 3 AB 4 A 5 A 6 O 7 B 8 O 9 A 10 A 11 B 12 AB 13 O 14 O Name: 혈액형, dtype: object 1pd.get_dummies(df['혈액형']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A AB B O 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 1 0 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 0 1 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 0 1 0 12 0 1 0 0 13 0 0 0 1 14 0 0 0 1 1pd.get_dummies(df['혈액형'], prefix = '혈액형') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형_A 혈액형_AB 혈액형_B 혈액형_O 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 1 0 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 0 1 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 0 1 0 12 0 1 0 0 13 0 0 0 1 14 0 0 0 1 categorical data의 각 카테고리가 숫자형식으로 표현됐을 때 one-hot-encoding이 더 중요해지는 이유: categorical data의 각 카테고리를 상징하는 숫자들은 그저 분류의 의미를 가질 뿐, 숫자의 크기 자체는 아무 의미도 없고, 숫자들의 연산도 역시 무의미하다. 하지만 이를 one-hot-encoding 작업 없이 머신러닝 알고리즘에 바로 넣으면 컴퓨터가 이 숫자들을 대소비교가 가능하고 연산이 가능하는 \"숫자\"로 인식하게 되므로 카테고리 간에 잘못된 관계를 맺을 수 있음. 따라서 이런 경우에는 one-hot-encoding 작업이 꼭 필요하다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 123456blood_map = { 'A': 0, 'B': 1, 'AB': 2, 'O': 3,} 1df[\"혈액형_code\"] = df[\"혈액형\"].map(blood_map) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 혈액형_code 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 2 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 0 1df[\"혈액형_code\"].value_counts() 0 7 3 4 2 2 1 2 Name: 혈액형_code, dtype: int64 1df[\"혈액형_code\"] 0 0 1 0 2 0 3 2 4 0 5 0 6 3 7 1 8 3 9 0 10 0 11 1 12 2 13 3 14 3 Name: 혈액형_code, dtype: int64 1pd.get_dummies(df[ \"혈액형_code\" ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 0 1 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 1 0 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 1 0 0 12 0 0 1 0 13 0 0 0 1 14 0 0 0 1 1pd.get_dummies(df[\"혈액형_code\"], prefix = \"혈액형\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형_0 혈액형_1 혈액형_2 혈액형_3 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 0 1 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 1 0 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 1 0 0 12 0 0 1 0 13 0 0 0 1 14 0 0 0 1 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (6) 데이터프레임의 산술연산","slug":"S-Python-Pandas-Pre6","date":"2020-06-20T13:28:21.000Z","updated":"2020-06-23T16:52:30.215Z","comments":true,"path":"2020/06/20/S-Python-Pandas-Pre6/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/20/S-Python-Pandas-Pre6/","excerpt":"","text":"데이터프레임의 산술연산 1. Column 과 Column 간 연산 (+, -, *, /, %) 2. Column 과 숫자 간 연산 (+, -, *, /, %) 3. 복합 연산 4. mean(), sum() 을 axis 기준으로 연산 5. NaN 값이 존재할 경우 연산 6. DataFrame 과 DataFrame 간 연산 6-1. 문자열이 포함된 Series / DataFrame의 연산은 불가하다 6-2. 두 DataFrame의 column 이름은 같으나 column 순서만 바뀌어 있는 경우 6-3. 행의 갯수가 다른 경우 1import pandas as pd 1import numpy as np 예제 DataFrame 생성 1df = pd.DataFrame({\"통계\": [60, 70, 80, 85, 75], \"미술\": [50, 55, 80, 100, 95], \"체육\": [70, 65, 50, 95, 100] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 1. Column 과 Column 간 연산 (+, -, *, /, %) 1type(df[\"통계\"]) pandas.core.series.Series 즉 Series 과 Series 간의 연산 1df[\"통계\"] + df[\"미술\"] + df[\"체육\"] 0 180 1 190 2 210 3 280 4 270 dtype: int64 1df[\"통계\"] - df[\"미술\"] 0 10 1 15 2 0 3 -15 4 -20 dtype: int64 1df[\"통계\"] * df[\"미술\"] 0 3000 1 3850 2 6400 3 8500 4 7125 dtype: int64 1df[\"통계\"] / df[\"미술\"] 0 1.200000 1 1.272727 2 1.000000 3 0.850000 4 0.789474 dtype: float64 1df[\"통계\"] % df[\"미술\"] 0 10 1 15 2 0 3 85 4 75 dtype: int64 2. Column 과 숫자 간 연산 (+, -, *, /, %) 1df[\"통계\"] 0 60 1 70 2 80 3 85 4 75 Name: 통계, dtype: int64 1df[\"통계\"] + 10 0 70 1 80 2 90 3 95 4 85 Name: 통계, dtype: int64 1df[\"통계\"] - 10 0 50 1 60 2 70 3 75 4 65 Name: 통계, dtype: int64 1df[\"통계\"] * 10 0 600 1 700 2 800 3 850 4 750 Name: 통계, dtype: int64 1df[\"통계\"] / 10 0 6.0 1 7.0 2 8.0 3 8.5 4 7.5 Name: 통계, dtype: float64 1df[\"통계\"] % 10 0 0 1 0 2 0 3 5 4 5 Name: 통계, dtype: int64 3. 복합 연산 1df = pd.DataFrame({\"통계\": [60, 70, 80, 85, 75], \"미술\": [50, 55, 80, 100, 95], \"체육\": [70, 65, 50, 95, 100] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 1df[\"통계미술+10\"] = df[\"통계\"] + df[\"미술\"] + 10 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 통계미술+10 0 60 50 70 120 1 70 55 65 135 2 80 80 50 170 3 85 100 95 195 4 75 95 100 180 1df[\"통계\"] + df[\"미술\"] - df[\"체육\"] 0 40 1 60 2 110 3 90 4 70 dtype: int64 4. mean(), sum() 을 axis 기준으로 연산 1df = pd.DataFrame({\"통계\": [60, 70, 80, 85, 75], \"미술\": [50, 55, 80, 100, 95], \"체육\": [70, 65, 50, 95, 100] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 (1) 각 column의 모든 row 값의 합 구하기 1df.sum(axis = 0) 통계 370 미술 380 체육 380 dtype: int64 (2) 각 column의 모든 row 값의 평균 구하기 1df.mean(axis = 0) 통계 74.0 미술 76.0 체육 76.0 dtype: float64 (3) 각 row의 모든 column 값의 합 구하기 1df.sum(axis = 1) 0 180 1 190 2 210 3 280 4 270 dtype: int64 (4) 각 row의 모든 column 값의 평균 구하기 1df.mean(axis = 1) 0 60.000000 1 63.333333 2 70.000000 3 93.333333 4 90.000000 dtype: float64 5. NaN 값이 존재할 경우 연산 NaN 값이 포함된 모든 연산의 결과가 다 NaN 값이다 1df = pd.DataFrame({\"통계\": [60, np.nan, 80, 85, 75], \"미술\": [50, 55, np.nan, 100, 95], \"체육\": [70, 65, 50, 95, np.nan] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60.0 50.0 70.0 1 NaN 55.0 65.0 2 80.0 NaN 50.0 3 85.0 100.0 95.0 4 75.0 95.0 NaN 1df[\"통계\"] / 2 0 30.0 1 NaN 2 40.0 3 42.5 4 37.5 Name: 통계, dtype: float64 11000 / df[\"통계\"] 0 16.666667 1 NaN 2 12.500000 3 11.764706 4 13.333333 Name: 통계, dtype: float64 1df[\"통계\"] / np.nan 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN Name: 통계, dtype: float64 1np.nan / df[\"통계\"] 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN Name: 통계, dtype: float64 6. DataFrame 과 DataFrame 간 연산 6-1. 문자열이 포함된 Series / DataFrame의 연산은 불가하다 1df1 = pd.DataFrame({'통계': [60, 70, 80, 85, 75], '미술': [50, 55, 80, 100, 95], '체육': [70, 65, 50, 95, 100] }) 1df2 = pd.DataFrame({'통계': ['good', 'bad', 'ok' , 'good', 'ok'], '미술': [50, 60 , 80, 100, 95], '체육': [70, 65, 50, 70 , 100] }) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 good 50 70 1 bad 60 65 2 ok 80 50 3 good 100 70 4 ok 95 100 1df1 + df2 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py in na_arithmetic_op(left, right, op, str_rep) 148 try: --&gt; 149 result = expressions.evaluate(op, str_rep, left, right) 150 except TypeError: D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in evaluate(op, op_str, a, b, use_numexpr) 207 if use_numexpr: --&gt; 208 return _evaluate(op, op_str, a, b) 209 return _evaluate_standard(op, op_str, a, b) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_numexpr(op, op_str, a, b) 120 if result is None: --&gt; 121 result = _evaluate_standard(op, op_str, a, b) 122 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_standard(op, op_str, a, b) 69 with np.errstate(all=\"ignore\"): ---&gt; 70 return op(a, b) 71 TypeError: unsupported operand type(s) for +: 'int' and 'str' 1df2 + 10 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py in na_arithmetic_op(left, right, op, str_rep) 148 try: --&gt; 149 result = expressions.evaluate(op, str_rep, left, right) 150 except TypeError: D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in evaluate(op, op_str, a, b, use_numexpr) 207 if use_numexpr: --&gt; 208 return _evaluate(op, op_str, a, b) 209 return _evaluate_standard(op, op_str, a, b) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_numexpr(op, op_str, a, b) 120 if result is None: --&gt; 121 result = _evaluate_standard(op, op_str, a, b) 122 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_standard(op, op_str, a, b) 69 with np.errstate(all=\"ignore\"): ---&gt; 70 return op(a, b) 71 TypeError: can only concatenate str (not \"int\") to str 6-2. 두 DataFrame의 column 이름은 같으나 column 순서만 바뀌어 있는 경우 연산시 자동으로 column 이름 기준으로 연산 된다 12df1 = pd.DataFrame({'미술': [10, 20, 30, 40, 50], '통계':[60, 70, 80, 90, 100] })df2 = pd.DataFrame({'통계': [10, 20, 30, 40, 50], '미술': [60, 70, 80, 90, 100] }) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 1df1 + df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 70 70 1 90 90 2 110 110 3 130 130 4 150 150 6-3. 행의 갯수가 다른 경우 행 index 기준으로 연산하되, 하나의 DataFrame에만 존재하는 행은 연산결과가 NaN으로 나옴 12df1 = pd.DataFrame({'미술': [10, 20, 30, 40, 50, 60], '통계':[60, 70, 80, 90, 100, 110] })df2 = pd.DataFrame({'통계': [10, 20, 30, 40, 50], '미술': [60, 70, 80, 90, 100] }) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 5 60 110 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 1df1 * df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 600.0 600.0 1 1400.0 1400.0 2 2400.0 2400.0 3 3600.0 3600.0 4 5000.0 5000.0 5 NaN NaN document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (5) column 값을 변환시키는 방법","slug":"S-Python-Pandas-Pre5","date":"2020-06-19T12:11:52.000Z","updated":"2020-06-23T16:51:01.668Z","comments":true,"path":"2020/06/19/S-Python-Pandas-Pre5/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/19/S-Python-Pandas-Pre5/","excerpt":"","text":"DataFrame의 column 값을 변환시키는 방법 1. apply + 일반 함수 1-1. (목표) ‘성별’ column의 “남자” / \"여자\"를 1 / 2로 바꾼다 1-2. (목표) cm당 브랜드 평판지수를 구한다 (브랜드평판지수 / 키) 2. apply + lamda 함수 3. map + map 함수 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. apply + 일반 함수 apply는 Series나 DataFrame에 좀 더 구체적인 로직을 적용하고 싶은 경우 활용한다 apply를 적용하기 위해서는 함수가 먼저 정의되어야한다 apply는 정의한 로직 함수를 인자로 넘겨준다 Series에 적용할 경우: df_name [ “col_name” ] .apply( func ) DataFrame에 적용할 경우: df_name .apply( func, axis = 1) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1-1. (목표) ‘성별’ column의 “남자” / \"여자\"를 1 / 2로 바꾼다 변환 규칙: 남자: 1 여자: 2 기타: -1 (1) 로직 함수 정의 [주의] 반드시 return 값이 존재하여야한다 12345def male_or_female(x): if x == \"남자\": return 1 elif x == \"여자\": return 2 (2) apply로 DataFrame에 적용 1df[\"성별_NEW\"] = df[\"성별\"].apply(male_or_female) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 1 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 1 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 2 1-2. (목표) cm당 브랜드 평판지수를 구한다 (브랜드평판지수 / 키) 변환 규칙: 키: 178 브랜드평판지수: 99000 값: 99000 / 178 (1) 로직 함수 정의 123def cm_to_brand(df): value = df[\"브랜드평판지수\"] / df[\"키\"] return value (2) apply로 DataFrame에 적용 1df.apply(cm_to_brand, axis = 1) 0 60617.857143 1 56027.949153 2 45965.250000 3 45356.747191 4 47198.815546 5 29260.308989 6 27371.321997 7 NaN 8 25503.950893 9 24156.128067 10 NaN 11 19158.617486 12 18866.594286 13 18603.051136 14 16812.885057 dtype: float64 2. apply + lamda 함수 df_name [ “col_name” ] .apply (lambda_func) lambda는 1줄로 작성하는 간단 함수식이다 return을 별도로 멱기하지 않는다 (1) male_or_female 함수 1male_or_female = lambda x: 1 if x == \"남자\" else 0 1df[\"성별\"].apply(male_or_female) 0 1 1 1 2 1 3 1 4 0 5 1 6 1 7 0 8 1 9 1 10 0 11 1 12 1 13 1 14 1 Name: 성별, dtype: int64 (2) 실제로는 간단한 계산식을 적용하려는 경우에 많이 사용한다 1df[\"키/2\"] = df[\"키\"].apply(lambda x: x / 2) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW 키/2 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 86.80 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 1 88.50 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 90.00 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 1 89.00 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 2 81.05 apply에 함수식을 만들어서 적용해주는 것과 동일하기 때문에, 복잠한 조건식은 &lt;함수&gt;로, 간단한 계산식은 &lt; lambda &gt; 로 적용하면 된다 3. map + map 함수 df_name [ “col_name” ] .map ( map_func ) Step 1: dictionary 형식으로 map 함수를 정의하기 Step 2: DataFrame / Series에 map 함수를 적용 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW 키/2 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 86.80 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 1 88.50 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 90.00 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 1 89.00 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 2 81.05 1234my_map = { \"남자\": \"male\", \"여자\": \"female\"} 1df[\"성별\"].map(my_map) 0 male 1 male 2 male 3 male 4 female 5 male 6 male 7 female 8 male 9 male 10 female 11 male 12 male 13 male 14 male Name: 성별, dtype: object document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (4) Series의 Type 변환하기","slug":"S-Python-Pandas-Pre4","date":"2020-06-19T06:53:13.000Z","updated":"2020-06-23T16:49:03.475Z","comments":true,"path":"2020/06/19/S-Python-Pandas-Pre4/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/19/S-Python-Pandas-Pre4/","excerpt":"","text":"Series의 Type 변환하기 1. Series의 Type 1-1. Type 확인하기 1-2. Type 변환하기 1-3. 날짜 (datatime) 타입 변환하기 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. Series의 Type 1-1. Type 확인하기 df_name.info() 명령어를 사용하여 Dataframe의 Series Type을 확인할 수 있다 df_name [ “col_name” ] .dtypes 명령어를 사용하여 특정 Series의 Type을 확인할 수 있다 Series Type object: 일반 문자영 타입 float: 실수 int: 정수 category: 카테고리 datatime: 시간 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 1df[\"이름\"].dtypes dtype('O') 1-2. Type 변환하기 df_name [ “col_name” ] .astype(…) e.g. “키” column을 float에서 int로 변환해보기 1df[\"키\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-12-c145a39acdb2&gt; in &lt;module&gt; ----&gt; 1 df[\"키\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 866 867 if not np.isfinite(arr).all(): --&gt; 868 raise ValueError(\"Cannot convert non-finite values (NA or inf) to integer\") 869 870 elif is_object_dtype(arr): ValueError: Cannot convert non-finite values (NA or inf) to integer “키” column에 NaN값이 존재하기 때문에 Error 발생! column에 NaN 값이 있는 경우: 면저 NaN 값을 다른 값으로 대체한 후 Type을 변환할 수 있다 1df[\"키\"] = df[\"키\"].fillna(-1) 1df[\"키\"] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df[\"키\"].astype(int) 0 173 1 177 2 180 3 178 4 162 5 178 6 182 7 -1 8 179 9 167 10 -1 11 183 12 175 13 176 14 174 Name: 키, dtype: int32 1-3. 날짜 (datatime) 타입 변환하기 (1) datetime 타입으로 변환하기 pd.to_datetime ( df_name [ “col_nema”] ) 1df[\"생년월일\"] 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: object 1pd.to_datetime(df[\"생년월일\"]) 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: datetime64[ns] 변환된 것을 원래 column에 다시 대입을 해줘야 정상적으로 변환된 값이 들어간다 12df[\"생년월일\"] = pd.to_datetime(df[\"생년월일\"])df[\"생년월일\"] 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: datetime64[ns] (2) datatime 타입을 활용하기 df_name [ “datetime_col” ] .dt 을 활용하여 매우 손쉽게 년, 월, 일, 요일 등등 날짜 정보를 세부적으로 추출해낼 수 있다 년: df_name [ “datetime_col” ] .dt.year 월: df_name [ “datetime_col” ] .dt.month 일: df_name [ “datetime_col” ] .dt.day 요일: df_name [ “datetime_col” ] .dt.dayofweek 주: df_name [ “datetime_col” ] .dt.weekofyear 1df[\"생년월일\"] 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: datetime64[ns] 년 추출: 1df[\"생년월일\"].dt.year 0 1995 1 1988 2 1996 3 1995 4 1995 5 1997 6 1995 7 1998 8 1992 9 1994 10 1989 11 1997 12 1995 13 1995 14 1993 Name: 생년월일, dtype: int64 월 추출: 1df[\"생년월일\"].dt.month 0 10 1 8 2 12 3 12 4 7 5 9 6 8 7 8 8 12 9 3 10 3 11 3 12 7 13 6 14 3 Name: 생년월일, dtype: int64 일 추출: 1df[\"생년월일\"].dt.day 0 13 1 18 2 10 3 30 4 23 5 1 6 9 7 26 8 4 9 22 10 9 11 30 12 21 13 8 14 9 Name: 생년월일, dtype: int64 요일 추출: 월 [0], 화 [1], 수 [2], 목 [3], 금 [4], 토 [5], 일 [6] 1df[\"생년월일\"].dt.dayofweek 0 4 1 3 2 1 3 5 4 6 5 0 6 2 7 2 8 4 9 1 10 3 11 6 12 4 13 3 14 1 Name: 생년월일, dtype: int64 주 추출: 1df[\"생년월일\"].dt.weekofyear 0 41 1 33 2 50 3 52 4 29 5 36 6 32 7 35 8 49 9 12 10 10 11 13 12 29 13 23 14 10 Name: 생년월일, dtype: int64 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (3) DataFrame의 합침 및 병합","slug":"S-Python-Pandas-Pre3","date":"2020-06-19T06:52:54.000Z","updated":"2020-06-23T16:46:15.090Z","comments":true,"path":"2020/06/19/S-Python-Pandas-Pre3/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/19/S-Python-Pandas-Pre3/","excerpt":"","text":"DataFrame의 합침 및 병합 1. DataFrame 합치기 (concat) 1-1. Row 기준 합치기 (밑으로 합침) 1-2. column 기준으로 합치기 (옆으로 합침) 2. DataFrame 병합하기 (merge) 2-0. 예제 데이터 만들기 2-1. left, right 방식 2-2. inner, outer 방식 2-3. column명은 다르지만, 동일한 성질의 데이터 인 경우? 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1df2 = pd.read_csv('korean-idol-2.csv') 1. DataFrame 합치기 (concat) 1-1. Row 기준 합치기 (밑으로 합침) df_concat = pd.concat ( [ df_name1 , df_name2 ], sort = False) df_concat .reset_index (drop = True) 합칠 데이터프리임을 list로 묶어준다. sort=False 옵션을 주어 column의 순서가 유지되도록 한다 합친 dataframe을 새 변수에 대입한 뒤 reset_index 옵션으로 index를 초기화한다 (아님 각각 원래의 index을 가지고 있음) reseet_index에서 drop=True 옵션을 사용해 원래의 행 index가 새로 index column으로 생성되지 않도록 한다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_copy = df.copy() (1) sort 옵션 sort = False: column 순서 유지; sort = True: column을 이름순으로 재정열 1pd.concat([df, df_copy], sort = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1pd.concat([df, df_copy], sort = True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 그룹 브랜드평판지수 생년월일 성별 소속사 이름 키 혈액형 0 방탄소년단 10523260 1995-10-13 남자 빅히트 지민 173.6 A 1 빅뱅 9916947 1988-08-18 남자 YG 지드래곤 177.0 A 2 NaN 8273745 1996-12-10 남자 커넥트 강다니엘 180.0 A 3 방탄소년단 8073501 1995-12-30 남자 빅히트 뷔 178.0 AB 4 마마무 7650928 1995-07-23 여자 RBW 화사 162.1 A 5 방탄소년단 5208335 1997-09-01 남자 빅히트 정국 178.0 A 6 뉴이스트 4989792 1995-08-09 남자 플레디스 민현 182.3 O 7 아이들 4668615 1998-08-26 여자 큐브 소연 NaN B 8 방탄소년단 4570308 1992-12-04 남자 빅히트 진 179.2 O 9 핫샷 4036489 1994-03-22 남자 스타크루이엔티 하성운 167.1 A 10 소녀시대 3918661 1989-03-09 여자 SM 태연 NaN A 11 아스트로 3506027 1997-03-30 남자 판타지오 차은우 183.0 B 12 뉴이스트 3301654 1995-07-21 남자 플레디스 백호 175.0 AB 13 뉴이스트 3274137 1995-06-08 남자 플레디스 JR 176.0 O 14 방탄소년단 2925442 1993-03-09 남자 빅히트 슈가 174.0 O 0 방탄소년단 10523260 1995-10-13 남자 빅히트 지민 173.6 A 1 빅뱅 9916947 1988-08-18 남자 YG 지드래곤 177.0 A 2 NaN 8273745 1996-12-10 남자 커넥트 강다니엘 180.0 A 3 방탄소년단 8073501 1995-12-30 남자 빅히트 뷔 178.0 AB 4 마마무 7650928 1995-07-23 여자 RBW 화사 162.1 A 5 방탄소년단 5208335 1997-09-01 남자 빅히트 정국 178.0 A 6 뉴이스트 4989792 1995-08-09 남자 플레디스 민현 182.3 O 7 아이들 4668615 1998-08-26 여자 큐브 소연 NaN B 8 방탄소년단 4570308 1992-12-04 남자 빅히트 진 179.2 O 9 핫샷 4036489 1994-03-22 남자 스타크루이엔티 하성운 167.1 A 10 소녀시대 3918661 1989-03-09 여자 SM 태연 NaN A 11 아스트로 3506027 1997-03-30 남자 판타지오 차은우 183.0 B 12 뉴이스트 3301654 1995-07-21 남자 플레디스 백호 175.0 AB 13 뉴이스트 3274137 1995-06-08 남자 플레디스 JR 176.0 O 14 방탄소년단 2925442 1993-03-09 남자 빅히트 슈가 174.0 O (2) reset_index 옵션 reset_index(): index가 초기화됨, 원래의 index가 새로 index column으로 저장됨 reset_index(drop = True): index가 초기화됨, 원래의 index가 새로 index column으로 생성되지 않음 1df_concat = pd.concat([df, df_copy], sort = False) 1df_concat.reset_index() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } index 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 15 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 16 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 17 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 18 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 19 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 20 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 21 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 22 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 23 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 24 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 25 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 26 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 27 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 28 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 29 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df_concat.reset_index(drop = True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 15 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 16 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 17 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 18 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 19 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 20 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 21 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 22 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 23 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 24 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 25 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 26 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 27 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 28 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 29 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1-2. column 기준으로 합치기 (옆으로 합침) column 기준으로 합치고자 할 때는 axis = 1 옵션을 준다: pd.concat ( [df_name1, df_name2], axis = 1) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df2 = pd.read_csv('korean-idol-2.csv') 1df2.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 지드래곤 3500 3 2 강다니엘 3200 4 3 뷔 3050 4 4 화사 4300 3 1pd.concat([df, df2], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000 3 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 지드래곤 3500 3 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200 4 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 뷔 3050 4 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300 3 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 정국 2900 5 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400 6 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 소연 4500 5 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200 4 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300 4 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700 3 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850 5 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900 4 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 JR 4100 3 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 슈가 4150 3 행의 갯수가 맞지 않을 시 두 DataFrame이 행 index기준으로 합치게 됨 행 갯수가 적은 DataFrame의 빈칸에는 NaN로 채워지게 됨 12df3 = df2.drop([3,5])df3 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 지드래곤 3500 3 2 강다니엘 3200 4 4 화사 4300 3 6 민현 3400 6 7 소연 4500 5 8 진 4200 4 9 하성운 4300 4 10 태연 3700 3 11 차은우 3850 5 12 백호 3900 4 13 JR 4100 3 14 슈가 4150 3 1pd.concat([df, df3], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 지드래곤 3500.0 3.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 소연 4500.0 5.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 JR 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 슈가 4150.0 3.0 12df4 = df2.drop([13, 14])pd.concat([df,df4], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 지드래곤 3500.0 3.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 뷔 3050.0 4.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 정국 2900.0 5.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 소연 4500.0 5.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 NaN NaN NaN 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 NaN NaN NaN 2. DataFrame 병합하기 (merge) concat과 merge의 차이: concat: row 나 column 기준으로 단순하게 이어 붙히기 merge: 특정 고유한 키(unique id) 값을 기준으로 병합하기 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df2.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 지드래곤 3500 3 2 강다니엘 3200 4 3 뷔 3050 4 4 화사 4300 3 df와 df2는 \"이름\"이라는 column이 겹친다 따라서, 우리는 \"이름\"을 기준으로 두 DataFrame을 병합할 수 있다 pd.merge (left_df, right_df, on = “기준 column”, how = “…” ) left_df와 right_df 에는 병합할 두 DataFrame을 대입한다 on 에는 병합의 기준이 되는 column을 넣어 준다 how 에는 ‘left’, ‘right’, ‘inner’, 'outer’라는 4가지의 병합 방식중 한가지를 택한다 2-0. 예제 데이터 만들기 1df_right = df2.drop([1,3,5,7]) 1df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 2 강다니엘 3200 4 4 화사 4300 3 6 민현 3400 6 8 진 4200 4 9 하성운 4300 4 10 태연 3700 3 11 차은우 3850 5 12 백호 3900 4 13 JR 4100 3 14 슈가 4150 3 12df_right = df_right.reset_index(drop = True)df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 5 하성운 4300 4 6 태연 3700 3 7 차은우 3850 5 8 백호 3900 4 9 JR 4100 3 10 슈가 4150 3 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 concat로 합치는 경우: 데이터가 행 index기준으로 합치게 되기 때문에 이름이 다른 시람의 데이터가 합치게 된다 1pd.concat([df, df_right], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 강다니엘 3200.0 4.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 화사 4300.0 3.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 민현 3400.0 6.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 진 4200.0 4.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 하성운 4300.0 4.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 태연 3700.0 3.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 차은우 3850.0 5.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 백호 3900.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 JR 4100.0 3.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 슈가 4150.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 NaN NaN NaN 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 NaN NaN NaN 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 NaN NaN NaN 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 NaN NaN NaN 따리서, 우리는 merge를 사용하여 두 DataFrame를 “이름” 기준으로 병합한다 2-1. left, right 방식 \"left\"옵션을 부여할 때: left DataFrame에 키 값이 존재하면 해당 데이터를 유지하고, 병합한 right DataFrame의 값은 NaN이 대입 됨 반대로, \"right\"옵션을 부여할 때 right DataFrame을 기준으로 병합하게 됨 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 5 하성운 4300 4 6 태연 3700 3 7 차은우 3850 5 8 백호 3900 4 9 JR 4100 3 10 슈가 4150 3 1pd.merge(df, df_right, on = \"이름\", how = \"left\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 NaN NaN 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 NaN NaN 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150.0 3.0 1pd.merge(df, df_right, on = \"이름\", how = \"right\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000 3 1 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200 4 2 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300 3 3 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400 6 4 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200 4 5 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300 4 6 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700 3 7 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850 5 8 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900 4 9 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100 3 10 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150 3 현재, left DataFrame이 더 많은 데이터를 보유하고 있으니, right를 기준으로 병합하면 DataFrame 사이즈가 줄어드게 된다 2-2. inner, outer 방식 inner 방식은 두 DataFrame에 모두 키 값이 존재하는 경우만 병합한다 (교집합과 비슷) outer 방식은 하나의 DataFrame에만 키 값이 존재하더라도 모두 병합한다 (합집합과 비슷) outer 방식에서는 없는 값은 NaN으로 대입된다 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 5 하성운 4300 4 6 태연 3700 3 7 차은우 3850 5 8 백호 3900 4 9 JR 4100 3 10 슈가 4150 3 1pd.merge(df, df_right, on = \"이름\", how = 'inner') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000 3 1 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200 4 2 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300 3 3 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400 6 4 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200 4 5 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300 4 6 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700 3 7 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850 5 8 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900 4 9 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100 3 10 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150 3 1pd.merge(df, df_right, on = \"이름\", how = 'outer') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 NaN NaN 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 NaN NaN 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150.0 3.0 2-3. column명은 다르지만, 동일한 성질의 데이터 인 경우? pd.merge ( left_df, right_df, left_on = “left_col”, right_on = “right_col”, how = “…” ) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_right.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 1df_right.columns = [\"성함\", \"연봉\", \"기족수\"] 1df_right.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 성함 연봉 기족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 df의 \"이름\"과 df_right의 \"성함\"은 column name이 다르지만, 동일한 성질의 데이터다. 이럴 때는 left_on, right_on 옵션을 사용해 기준 column을 지정한다 1pd.merge(df, df_right, left_on = \"이름\", right_on = \"성함\", how = \"outer\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성함 연봉 기족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 NaN NaN NaN 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 NaN NaN NaN 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 JR 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 슈가 4150.0 3.0 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (2) 결측값 및 중복값 처리","slug":"S-Python-Pandas-Pre2","date":"2020-06-17T15:07:04.000Z","updated":"2020-06-23T16:45:00.840Z","comments":true,"path":"2020/06/18/S-Python-Pandas-Pre2/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/18/S-Python-Pandas-Pre2/","excerpt":"","text":"결측값 및 중복값 처리 1. 결측값을 제거하기 – dropna() 2. 결측값을 채워주기 – fillna 2-1. NA값을 특정 숫자로 채우기 2-2. NA값을 통계값으로 채우기 3. 중복된 값을 제거하기 – drop_duplicates 3-1. column의 중복값 제거 3-2. 행 전체 제거 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 결측값을 제거하기 – dropna() 결측값이 있는 행을 제거: (1) df_name .dropna() (2) df_name .dropna(axis=0) 결측값이 있는 열을 제거: df_name .dropna(axis=1) NA가 하나라도 있는 경우 제거: df_name .dropna(axis=0, how = ‘any’) 모두가 NA인 경우 제거: df_name .dropna(axis=0, how = ‘all’) 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 (1) 결측값이 있는 행 제거 1df.dropna() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.dropna(axis = 0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 (2) 결측 값이 있는 열 제거 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 1df.dropna(axis=1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 성별 생년월일 혈액형 브랜드평판지수 0 지민 빅히트 남자 1995-10-13 A 10523260 1 지드래곤 YG 남자 1988-08-18 A 9916947 2 강다니엘 커넥트 남자 1996-12-10 A 8273745 3 뷔 빅히트 남자 1995-12-30 AB 8073501 4 화사 RBW 여자 1995-07-23 A 7650928 5 정국 빅히트 남자 1997-09-01 A 5208335 6 민현 플레디스 남자 1995-08-09 O 4989792 7 소연 큐브 여자 1998-08-26 B 4668615 8 진 빅히트 남자 1992-12-04 O 4570308 9 하성운 스타크루이엔티 남자 1994-03-22 A 4036489 10 태연 SM 여자 1989-03-09 A 3918661 11 차은우 판타지오 남자 1997-03-30 B 3506027 12 백호 플레디스 남자 1995-07-21 AB 3301654 13 JR 플레디스 남자 1995-06-08 O 3274137 14 슈가 빅히트 남자 1993-03-09 O 2925442 (3) NA가 하나라도 있는 경우 행 제거 1df.dropna(axis=0, how = 'any') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 (4) 모두가 NA인 경우 행 제거 1import numpy as np 1df.iloc[10] = np.nan 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489.0 10 NaN NaN NaN NaN NaN NaN NaN NaN 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442.0 1df.dropna(axis=0, how = 'all') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442.0 2. 결측값을 채워주기 – fillna df_name [ 'na_col_name ’ ] .fillna(fill_value) 결측값을 채운 데이터프레임을 유지시키려면: (1) inplace = True 옵션을 추가함 (2) 원 dataframe에 다시 대입함 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB \"키\"에 2개의 데이터가 누락, \"그룹\"에 1개의 데이터가 누락된 것을 확인할 수 있다 2-1. NA값을 특정 숫자로 채우기 df_name[ 'na_col_name ’ ] .fillna (new_value, inplace = True) df_name[ 'na_col_name ’ ] = df_name[ 'na_col_name ’ ] .fillna (new_value) e.g. 누락된 ‘키’ 값을 '-1’로 채워줌 1df['키'].fillna(-1) 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 이때는 원 데이터가 변화되지 않음. 1df['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 수정된 데이터를 유지시키려면: &lt;방법1&gt; 1df2 = df.copy() 1df2['키'].fillna(-1, inplace = True) 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 &lt;방법2&gt; 1df2 = df.copy() 1df2['키'] = df2['키'].fillna(-1) 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 2-2. NA값을 통계값으로 채우기 df_name[ 'na_col_name ’ ] .fillna (df_name[ 'na_col_name ’ ] .mean(), inplace = True) df_name[ 'na_col_name ’ ] = df_name[ 'na_col_name ’ ] .fillna (df_name[ 'na_col_name ’ ] .mean()) 1df2 = df.copy() 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 (1) 평균으로 대체 1df2['키'].mean() 175.79230769230767 1df2['키'].fillna(df2['키'].mean(), inplace = True) 1df2['키'] = df2['키'].fillna(df2['키'].mean()) 1df2['키'] 0 173.600000 1 177.000000 2 180.000000 3 178.000000 4 162.100000 5 178.000000 6 182.300000 7 175.792308 8 179.200000 9 167.100000 10 175.792308 11 183.000000 12 175.000000 13 176.000000 14 174.000000 Name: 키, dtype: float64 (2) 중위값으로 대체 1df2 = df.copy() 1df2['키'].median() 177.0 1df2['키'].fillna(df2['키'].median(), inplace = True) 1df2['키'] = df2['키'].fillna(df2['키'].median()) 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 177.0 8 179.2 9 167.1 10 177.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 3. 중복된 값을 제거하기 – drop_duplicates 1df = pd.read_csv('korean-idol.csv') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 3-1. column의 중복값 제거 df_name [“col_name”] .drop_duplicates( keep = … ) 여러 개 중복값 (NaN 포함) 중에서 기본적으로 첫번째 것만 유지시키고 나머지는 다 제거한다 하지만 keep 옵션으로 유지하고 싶은 데이터를 선택할 수 있다. [keep: ‘first’ / ‘last’] 이때는 해당 위치의 값만 삭제되고 행 자체는 유지된다 (1) 중복값 중의 첫번째를 유지시킴 (default) 1df['키'] 0 173.6 1 177.0 2 180.0 3 NaN 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df['키'].drop_duplicates() # remove 2nd \"178.0\" &amp; 2nd \"NaN\" 0 173.6 1 177.0 2 180.0 3 NaN 4 162.1 5 178.0 6 182.3 8 179.2 9 167.1 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df['키'].drop_duplicates(keep='first') 0 173.6 1 177.0 2 180.0 3 NaN 4 162.1 5 178.0 6 182.3 8 179.2 9 167.1 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 (2) 중복값 중의 마지막을 유지시킴 1df['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df['키'].drop_duplicates(keep='last') 0 173.6 1 177.0 2 180.0 4 162.1 5 178.0 6 182.3 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 이때는 해당위치의 값만 제거되고 행 자체는 유지됨 1df['키'] = df['키'].drop_duplicates(keep='last') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 NaN AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 3-2. 행 전체 제거 df_name .drop_duplicates(“col_name”, keep = …) 지정한 column에서 중복값이 포함되어 있으면 중복값을 포함한 행을 전체 제거 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 NaN AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df['그룹'] 0 방탄소년단 1 빅뱅 2 NaN 3 방탄소년단 4 마마무 5 방탄소년단 6 뉴이스트 7 아이들 8 방탄소년단 9 핫샷 10 소녀시대 11 아스트로 12 뉴이스트 13 뉴이스트 14 방탄소년단 Name: 그룹, dtype: object 1df.drop_duplicates('그룹') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 1df.drop_duplicates('그룹', keep = 'last') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (1) row & column 의 추가 및 제거","slug":"S-Python-Pandas-Pre1","date":"2020-06-17T15:02:25.000Z","updated":"2020-06-23T16:39:44.452Z","comments":true,"path":"2020/06/18/S-Python-Pandas-Pre1/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/18/S-Python-Pandas-Pre1/","excerpt":"","text":"row &amp; column 의 추가 및 제거 1. row의 추가 2. column의 추가 3. row의 제거 4. column의 제거 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1. row의 추가 df_name .append ( {…} , ignore_index = True ) dictionary 형태의 데이터를 만들어 준다음 append() 함수를 사용하여 데이터를 추가할 수 있다. ignore_index=True옵션을 반드시 같이 추가해야한다 1df = df.append({'이름': '홍길동', '그룹': 'a그룹', '소속사':'A사', '성별': '남자', '생년월일': '1990-01-01', '키': 185.0, '혈액형': 'B', '브랜드평판지수': 12345678}, ignore_index=True) 1df.tail() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 15 홍길동 a그룹 A사 남자 1990-01-01 185.0 B 12345678 2. column의 추가 새로운 column을 만들고 값을 대입해주면, column이 쉽게 추가될 수 있다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df['국적'] = '대한민국' 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 국적 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 대한민국 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 대한민국 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 대한민국 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 대한민국 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 대한민국 새로운 column의 값을 다르게 부여하고 싶다면 loc 함수를 활용하면 된다 1df.loc[ df['이름'] == '지드래곤', '국적'] = 'korea' 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 국적 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 대한민국 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 korea 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 대한민국 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 대한민국 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 대한민국 3. row의 제거 하나의 행: df_name .drop (index_num, axis = 0) 복수의 행: df_name .drop ( [ index_num1, index_num2 ], axis = 0) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop(3, axis = 0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop([3, 5], axis = 0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4. column의 제거 하나의 열: df_name .drop ( ‘col_name’, axis = 1) 복수의 열: df_name .drop ( [ ‘col_name1’, ‘col_name2’ ], axis = 1) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop(\"그룹\", axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 큐브 여자 1998-08-26 NaN B 4668615 8 진 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 SM 여자 1989-03-09 NaN A 3918661 11 차은우 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop([\"그룹\", \"소속사\"], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 남자 1995-10-13 173.6 A 10523260 1 지드래곤 남자 1988-08-18 177.0 A 9916947 2 강다니엘 남자 1996-12-10 180.0 A 8273745 3 뷔 남자 1995-12-30 178.0 AB 8073501 4 화사 여자 1995-07-23 162.1 A 7650928 5 정국 남자 1997-09-01 178.0 A 5208335 6 민현 남자 1995-08-09 182.3 O 4989792 7 소연 여자 1998-08-26 NaN B 4668615 8 진 남자 1992-12-04 179.2 O 4570308 9 하성운 남자 1994-03-22 167.1 A 4036489 10 태연 여자 1989-03-09 NaN A 3918661 11 차은우 남자 1997-03-30 183.0 B 3506027 12 백호 남자 1995-07-21 175.0 AB 3301654 13 JR 남자 1995-06-08 176.0 O 3274137 14 슈가 남자 1993-03-09 174.0 O 2925442 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 데이터 파악 - (7) 기타","slug":"S-Python-Pandas7","date":"2020-06-17T06:12:40.000Z","updated":"2020-06-23T16:56:11.819Z","comments":true,"path":"2020/06/17/S-Python-Pandas7/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/17/S-Python-Pandas7/","excerpt":"","text":"기타 1. 피벗테이블 2. GroupBy (그룹으로 묶어 보기) 3. Multi-Index (복합 인덱스) 3-1. Multi-Index 적용 3-2. Multi-Index 데이터 프레임을 피벗테이블로 변환 3-3. 인덱스 초기화 (reset_index) 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 피벗테이블 데이터 열 중에서 두 개의 열을 각각 행 인덱스, 열 인덱스로 사용하여 데이터를 조회하여 펼쳐놓은 건을 의미함 왼쪽에 나타나는 인덱스를 행 인덱스, 상단에 나타나는 인덱스를 열 인덱스라고 부른다 pd.pivot_table(df_name, index = “col_name_분류기준1”, columns = “col_name_분류기준2”, values = “col_name_조회대상”, aggfunc = …) index는 행 인덱스 columns는 열 인덱스 values는 조회하고 싶은 값 aggfunc는 value를 산출하는 연산법 (1) e.g.: aggfunc = np.sum / np.mean (2) 설정하지 않은 경우 기본적으로 평균값을 구한다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1pd.pivot_table(df, index = \"소속사\", columns = \"혈액형\", values = \"키\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형 A AB B O 소속사 RBW 162.1 NaN NaN NaN YG 177.0 NaN NaN NaN 빅히트 175.8 178.0 NaN 176.60 스타크루이엔티 167.1 NaN NaN NaN 커넥트 180.0 NaN NaN NaN 판타지오 NaN NaN 183.0 NaN 플레디스 NaN 175.0 NaN 179.15 1import numpy as np 1pd.pivot_table(df, index = \"그룹\", columns = \"혈액형\", values = \"브랜드평판지수\", aggfunc = np.sum) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형 A AB B O 그룹 뉴이스트 NaN 3301654.0 NaN 8263929.0 마마무 7650928.0 NaN NaN NaN 방탄소년단 15731595.0 8073501.0 NaN 7495750.0 빅뱅 9916947.0 NaN NaN NaN 소녀시대 3918661.0 NaN NaN NaN 아스트로 NaN NaN 3506027.0 NaN 아이들 NaN NaN 4668615.0 NaN 핫샷 4036489.0 NaN NaN NaN 2. GroupBy (그룹으로 묶어 보기) groupby는 데이터를 그룹으로 묶어 분석할 때 활용한다 소속사별 키의 평균, 성별 키의 평균 등 특정, 그룹별 통계 및 데이터의 성질을 확인하고자 할 때 활용한다 groupby와 함께 count() - 갯수 sum() - 합계 mean() - 평균 var() - 분산 std() -표준편차 min() / max() - 최소값, 최대값 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.groupby(\"소속사\") &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000024E760EC288&gt; 1df.groupby('소속사').count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 성별 생년월일 키 혈액형 브랜드평판지수 소속사 RBW 1 1 1 1 1 1 1 SM 1 1 1 1 0 1 1 YG 1 1 1 1 1 1 1 빅히트 5 5 5 5 5 5 5 스타크루이엔티 1 1 1 1 1 1 1 커넥트 1 0 1 1 1 1 1 큐브 1 1 1 1 0 1 1 판타지오 1 1 1 1 1 1 1 플레디스 3 3 3 3 3 3 3 산술 통계는 자동으로 산술통계가 가능한 열만 출력됨. 1df.groupby('그룹').mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 그룹 뉴이스트 177.766667 3.855194e+06 마마무 162.100000 7.650928e+06 방탄소년단 176.560000 6.260169e+06 빅뱅 177.000000 9.916947e+06 소녀시대 NaN 3.918661e+06 아스트로 183.000000 3.506027e+06 아이들 NaN 4.668615e+06 핫샷 167.100000 4.036489e+06 1df.groupby('성별').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 성별 남자 2123.2 68599637 여자 162.1 16238204 특정 열만 출력하고 싶다면? 1df.groupby('혈액형')['키'].mean() 혈액형 A 172.966667 AB 176.500000 B 183.000000 O 177.875000 Name: 키, dtype: float64 3. Multi-Index (복합 인덱스) 3-1. Multi-Index 적용 행 인덱스를 복합적으로 구성하고 싶은 경우는 인덱스를 리스트로 만들어 준다 df_name .groupby([‘col_name_1’,‘col_name_2’]) .mean() 데이터를 먼저 col_1기준으로 분류한 다음, col_2기준으로 한번 더 분류한다. 2번 분류 후의 데이터에 대해 산술통계값을 구한다 1df.groupby(['혈액형', '성별']).mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 혈액형 성별 A 남자 175.140 7591755.20 여자 162.100 5784794.50 AB 남자 176.500 5687577.50 B 남자 183.000 3506027.00 여자 NaN 4668615.00 O 남자 177.875 3939919.75 3-2. Multi-Index 데이터 프레임을 피벗테이블로 변환 Multi-Index로 된 데이터프레임을 피벗테이블 형태로 다시 변환해줄 수 있다 df_name .unstack( ‘col_열’ ) col_열: groupby에서 선택한 두 column중 pivot table의 열인덱스로 지정해주고 싶은 column명을 입력 1df2 = df.groupby(['혈액형', '성별']).mean() 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 혈액형 성별 A 남자 175.140 7591755.20 여자 162.100 5784794.50 AB 남자 176.500 5687577.50 B 남자 183.000 3506027.00 여자 NaN 4668615.00 O 남자 177.875 3939919.75 1df2.unstack('혈액형') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } 키 브랜드평판지수 혈액형 A AB B O A AB B O 성별 남자 175.14 176.5 183.0 177.875 7591755.2 5687577.5 3506027.0 3939919.75 여자 162.10 NaN NaN NaN 5784794.5 NaN 4668615.0 NaN 1df2.unstack('성별') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } 키 브랜드평판지수 성별 남자 여자 남자 여자 혈액형 A 175.140 162.1 7591755.20 5784794.5 AB 176.500 NaN 5687577.50 NaN B 183.000 NaN 3506027.00 4668615.0 O 177.875 NaN 3939919.75 NaN 3-3. 인덱스 초기화 (reset_index) reset_index() 는 Multi-Index로 구성된 데이터 프레임의 인덱스를 초기화해 준다 그 의미는 Multi-Index로 구성된 데이터 프레임 중의 index들을 dataframe의 column으로 변환시키는 것 df_name = df_name .reset_index() 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 혈액형 성별 A 남자 175.140 7591755.20 여자 162.100 5784794.50 AB 남자 176.500 5687577.50 B 남자 183.000 3506027.00 여자 NaN 4668615.00 O 남자 177.875 3939919.75 1df2 = df2.reset_index() 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형 성별 키 브랜드평판지수 0 A 남자 175.140 7591755.20 1 A 여자 162.100 5784794.50 2 AB 남자 176.500 5687577.50 3 B 남자 183.000 3506027.00 4 B 여자 NaN 4668615.00 5 O 남자 177.875 3939919.75 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (6) 결측값 확인 및 추출","slug":"S-Python-Pandas6","date":"2020-06-11T16:21:05.000Z","updated":"2020-06-23T16:55:47.756Z","comments":true,"path":"2020/06/12/S-Python-Pandas6/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/12/S-Python-Pandas6/","excerpt":"","text":"결측값 확인 및 추출 1. 결측값에 대하여 2. column별 (비)결측값 개수 확인 – info() 3. (비)결측값 위치 확인 3-1. 전체 Data 3-2. 특정 column 4. (비)결측값 추출 4-1. 해당 column만 추출 4-2. 전체 column 추출 4-3. 지정한 column 추출 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 결측값에 대하여 Null 값은 비어있는 값, 고급 언어로 결측값이다 pandas 에서는 NaN =&gt; Not a Number 로 표기 된다 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2. column별 (비)결측값 개수 확인 – info() info() 로 각 column별의 결측값(NaN) 개수를 쉽게 확인할 수 있다. 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 3. (비)결측값 위치 확인 .isna() .isnull() .notna() .notnull() 3-1. 전체 Data df_name .명령어 (1) 결측값 = True 1df.isna() 1df.isnull() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 False False False False False False False False 1 False False False False False False False False 2 False True False False False False False False 3 False False False False False False False False 4 False False False False False False False False 5 False False False False False False False False 6 False False False False False False False False 7 False False False False False True False False 8 False False False False False False False False 9 False False False False False False False False 10 False False False False False True False False 11 False False False False False False False False 12 False False False False False False False False 13 False False False False False False False False 14 False False False False False False False False (2) 비결측값 = True 1df.notna() 1df.notnull() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 True True True True True True True True 1 True True True True True True True True 2 True False True True True True True True 3 True True True True True True True True 4 True True True True True True True True 5 True True True True True True True True 6 True True True True True True True True 7 True True True True True False True True 8 True True True True True True True True 9 True True True True True True True True 10 True True True True True False True True 11 True True True True True True True True 12 True True True True True True True True 13 True True True True True True True True 14 True True True True True True True True 3-2. 특정 column df_name [ ‘col_name’ ] .명령어 (1) 결측값 = True 1df['그룹'].isna() 1df['그룹'].isnull() 0 False 1 False 2 True 3 False 4 False 5 False 6 False 7 False 8 False 9 False 10 False 11 False 12 False 13 False 14 False Name: 그룹, dtype: bool (2) 비결측값 = True 1df['그룹'].notna() 1df['그룹'].notnull() 0 True 1 True 2 False 3 True 4 True 5 True 6 True 7 True 8 True 9 True 10 True 11 True 12 True 13 True 14 True Name: 그룹, dtype: bool 4. (비)결측값 추출 4-1. 해당 column만 추출 결측값: df_name [ ‘col_name’] [ df_name [ ‘col_name’ ] .isna() / isnull() ] 비결측값: df_name [ ‘col_name’ ] [df_name [ ‘col_name’ ] .notna() / notnull()] 1df['그룹'][df['그룹'].isna()] 2 NaN Name: 그룹, dtype: object 1df['그룹'][df['그룹'].notnull()] 0 방탄소년단 1 빅뱅 3 방탄소년단 4 마마무 5 방탄소년단 6 뉴이스트 7 아이들 8 방탄소년단 9 핫샷 10 소녀시대 11 아스트로 12 뉴이스트 13 뉴이스트 14 방탄소년단 Name: 그룹, dtype: object 4-2. 전체 column 추출 결측값: df_name .loc [df_name [ ‘col_name’ ] .isna() / isnull() ] 비결측값: df_name .loc [df_name ['col_name] .notna() / notnull() ] 1df.loc[df['그룹'].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1df.loc[df['그룹'].notnull()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4-3. 지정한 column 추출 결측값: df_name .loc [df_name [ ‘na_col_name’ ] .isna() / isnull() , [‘col_name1’, ‘col_name2’, …]] 비결측값: df_name .loc [df_name ['na_col_name] .notna() / notnull() , [‘col_name1’, ‘col_name2’, …]] 1df.loc[df['그룹'].isna(), ['이름', '소속사']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 2 강다니엘 커넥트 1df.loc[df['그룹'].notnull(), ['이름', '소속사']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 0 지민 빅히트 1 지드래곤 YG 3 뷔 빅히트 4 화사 RBW 5 정국 빅히트 6 민현 플레디스 7 소연 큐브 8 진 빅히트 9 하성운 스타크루이엔티 10 태연 SM 11 차은우 판타지오 12 백호 플레디스 13 JR 플레디스 14 슈가 빅히트 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (5) 범위선택","slug":"S-Python-Pandas5","date":"2020-05-24T12:58:03.000Z","updated":"2020-06-23T16:55:22.707Z","comments":true,"path":"2020/05/24/S-Python-Pandas5/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas5/","excerpt":"","text":"범위선택 1. 단일 column을 선택하는 방법 2. index &amp; column 범위 선택 (range selection) 2-1. 단순 index에 대한 범위 선택 2-2. index &amp; column 범위선택 – loc 2-3. index &amp; column 범위선택 – iloc (position으로 색인) 3. index &amp; column 조건범위선택 – Boolean Indexing 3-1. 조건에 만족한 row들의 모든 column을 추출 3-2. 조건에 만족한 row들의 특정 column들을 추출 4. index &amp; column 조건범위선택 – inis을 활용란 색인 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 단일 column을 선택하는 방법 df_name [ 'col_name ’ ] df_name [ \"col_name \" ] df_name .col_name 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df['이름'] 1df[\"이름\"] 1df.이름 0 지민 1 지드래곤 2 강다니엘 3 뷔 4 화사 5 정국 6 민현 7 소연 8 진 9 하성운 10 태연 11 차은우 12 백호 13 JR 14 슈가 Name: 이름, dtype: object 2. index &amp; column 범위 선택 (range selection) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2-1. 단순 index에 대한 범위 선택 1df[:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1df.head(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 2-2. index &amp; column 범위선택 – loc df_name .loc [행(index) 범위, (열)column 범위] 행 범위는 “:” “:b” “a:b” 등 형식을 사용 열 범위는 'column name ’ ['column name1 ', 'column name2 '] 'column name1 ’ : 'column name2 ’ 등 형식을 사용 주의: pandas의 loc에서 범위 a : b는 index a &amp; index b 모두 포함 numpy에서는 index a 포함, index b 미포함 1df.loc[:, '이름'] 0 지민 1 지드래곤 2 강다니엘 3 뷔 4 화사 5 정국 6 민현 7 소연 8 진 9 하성운 10 태연 11 차은우 12 백호 13 JR 14 슈가 Name: 이름, dtype: object 1df.loc[:, ['이름', '생년월일']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 생년월일 0 지민 1995-10-13 1 지드래곤 1988-08-18 2 강다니엘 1996-12-10 3 뷔 1995-12-30 4 화사 1995-07-23 5 정국 1997-09-01 6 민현 1995-08-09 7 소연 1998-08-26 8 진 1992-12-04 9 하성운 1994-03-22 10 태연 1989-03-09 11 차은우 1997-03-30 12 백호 1995-07-21 13 JR 1995-06-08 14 슈가 1993-03-09 1df.loc[3:8, ['이름', '생년월일']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 생년월일 3 뷔 1995-12-30 4 화사 1995-07-23 5 정국 1997-09-01 6 민현 1995-08-09 7 소연 1998-08-26 8 진 1992-12-04 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.loc[2:5, '이름':'생년월일'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 2 강다니엘 NaN 커넥트 남자 1996-12-10 3 뷔 방탄소년단 빅히트 남자 1995-12-30 4 화사 마마무 RBW 여자 1995-07-23 5 정국 방탄소년단 빅히트 남자 1997-09-01 2-3. index &amp; column 범위선택 – iloc (position으로 색인) 행(index) 범위 선택은 loc와 동일 열(column) 범위는 'column 명’대신 column position을 사용 행 범위는 “:” “:b” “a:b” 등 형식을 사용 열 범위는 “c” “[c, d]” “c:d” 등 형식을 사용 주의: pandas의 iloc에서 범위 a : b는 index a 포함, index b 미포함 (numpy와 동일) pandas의 loc에서 범위 a : b는 index a &amp; index b 모두 포함 1df.iloc[:, [0, 2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 0 지민 빅히트 1 지드래곤 YG 2 강다니엘 커넥트 3 뷔 빅히트 4 화사 RBW 5 정국 빅히트 6 민현 플레디스 7 소연 큐브 8 진 빅히트 9 하성운 스타크루이엔티 10 태연 SM 11 차은우 판타지오 12 백호 플레디스 13 JR 플레디스 14 슈가 빅히트 1df.iloc[1:5, [0, 2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 1 지드래곤 YG 2 강다니엘 커넥트 3 뷔 빅히트 4 화사 RBW 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.iloc[1:5, 0:4] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 1 지드래곤 빅뱅 YG 남자 2 강다니엘 NaN 커넥트 남자 3 뷔 방탄소년단 빅히트 남자 4 화사 마마무 RBW 여자 3. index &amp; column 조건범위선택 – Boolean Indexing Boolean indexing은 Numpy에서의 Boolean indexing과 같은 원리다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 3-1. 조건에 만족한 row들의 모든 column을 추출 df [조건 ] 1df['키'] &gt; 180 0 False 1 False 2 False 3 False 4 False 5 False 6 True 7 False 8 False 9 False 10 False 11 True 12 False 13 False 14 False Name: 키, dtype: bool 1df[df['키'] &gt; 180] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3-2. 조건에 만족한 row들의 특정 column들을 추출 방법 1. df_name [조건 ] [column범위 ] 1df[ df['키'] &gt; 180 ] ['이름'] 6 민현 11 차은우 Name: 이름, dtype: object 1df [ df['키'] &gt; 180 ] [['이름', '키']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 키 6 민현 182.3 11 차은우 183.0 방법 2. loc를 활용: df_name.loc[ 조건 , column범위 ] 【추천】 1df.loc[ df['키'] &gt; 180, '이름' ] 6 민현 11 차은우 Name: 이름, dtype: object 1df.loc[ df['키'] &gt; 180, ['이름', '그룹'] ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 6 민현 뉴이스트 11 차은우 아스트로 1df.loc[ df['키'] &gt; 180, '이름' : '성별'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 6 민현 뉴이스트 플레디스 남자 11 차은우 아스트로 판타지오 남자 4. index &amp; column 조건범위선택 – inis을 활용란 색인 column값이 미리 정의한 list에 속한다는 조건을 걸고자 할 때 사용한다 1my_condition = ['플레디스', 'SM'] 1df['소속사'].isin(my_condition) 0 False 1 False 2 False 3 False 4 False 5 False 6 True 7 False 8 False 9 False 10 True 11 False 12 True 13 True 14 False Name: 소속사, dtype: bool 1df.loc[ df['소속사'].isin(my_condition) ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 1df.loc[ df['소속사'].isin(my_condition) , ['이름', '소속사'] ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 6 민현 플레디스 10 태연 SM 12 백호 플레디스 13 JR 플레디스 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (4) 정렬","slug":"S-Python-Pandas4","date":"2020-05-24T08:07:08.000Z","updated":"2020-06-23T16:54:53.058Z","comments":true,"path":"2020/05/24/S-Python-Pandas4/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas4/","excerpt":"","text":"정렬 (sort) 1. index 순으로 정렬 2. column의 value순으로 정렬 2-1. 단일 column 기준 2-2. 복수 column 기준 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1. index 순으로 정렬 오름차순 정렬: df_name.sort_index() (default) 내림차순 정렬: df_name.sort_index(ascending = False) 1df.sort_index() # 오름차순 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.sort_index(ascending = False) # 내림차순 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 2. column의 value순으로 정렬 오름차순 정렬: df_name.sort_values(by = ‘col_name’) 내림차순 정렬: df_name.sort_values(by = ‘col_name’, ascending = False) 2-1. 단일 column 기준 1df.sort_values(by='키') # 오름차순 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 1df.sort_values(by = '키', ascending = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 2-2. 복수 column 기준 먼저 column1 기준으로 정렬하고, column1 값이 동일한 row들은 column2기준으로 정렬: df_name .sort_value ( by = [ ‘col_name 1’ , ‘col_name 2’ ] ) 1df.sort_values(by = ['키', '브랜드평판지수']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 1df.sort_values(by = ['키', '브랜드평판지수'], ascending = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (3) 기본정보 & 통계정보 파악","slug":"S-Python-Pandas3","date":"2020-05-24T08:06:08.000Z","updated":"2020-06-23T16:54:35.835Z","comments":true,"path":"2020/05/24/S-Python-Pandas3/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas3/","excerpt":"","text":"기본정보 &amp; 통계정보 파악 1. 파일 읽어오기 (csv) 2. 기본 행&amp;열 정보 알아보기 (column, index, info) 2-1. column (열) 이름 출력하기 2-2. column (열) 이름 재정의하기 2-3. index (행) 정보 출력하기 2-4. info (기본적인 column 정보와 데이터 타입) 3. 형태 (shape) 알아보기 4. 상위 5개, 하위 5개의 정보만 보기 5. 통계 정보 알아보기 5-1. 전체 통계 정보 5-2. 최소값(min), 최대값(max), 중앙값(median), 최빈값(mode) 5-3. 합계(sum), 평균(mean), 분산(var), 표준편차(std) 5-4. 갯수를 세는 count 1import pandas as pd 1. 파일 읽어오기 (csv) 1df = pd.read_csv('korean-idol.csv') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2. 기본 행&amp;열 정보 알아보기 (column, index, info) 2-1. column (열) 이름 출력하기 df_name .columns 1df.columns Index(['이름', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ 2-2. column (열) 이름 재정의하기 (1) 전체 column 이름 df_name .columns = […] 예: “이름” --&gt; “name”: 1new_col = ['name', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'] 1df.columns = new_col 1df.columns Index(['name', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ (2) 개별 column 이름 df_name .rename ( columns = { “old_name” : “new_name” } ) ​ 1df = pd.read_csv('korean-idol.csv') 1df.columns Index(['이름', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ 1df = df.rename(columns = {\"이름\" : \"name\"}) 1df.columns Index(['name', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ 2-3. index (행) 정보 출력하기 df_name .index 1df.index RangeIndex(start=0, stop=15, step=1) 2-4. info (기본적인 column 정보와 데이터 타입) df_name .info() Tip: info메소드는 주로 빠진 값 (null 값)과 데이터 타입을 볼 때 활용함 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 name 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB “object” type은 주로 문자형 데이터를 가리킴. 3. 형태 (shape) 알아보기 shape는 tuple형태로 반환되며, 첫번째는 row, 두번째는 column의 숫자를 의미함. 1df.shape (15, 8) 4. 상위 5개, 하위 5개의 정보만 보기 상위 5개 row: df_name .head() 하위 5개 row: df_name .tail() 상위 n개 row: df_name .head(n) 하위 n개 row: df_name .tail(n) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.tail() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.head(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1df.tail(2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 5. 통계 정보 알아보기 통계값은 산술 연산이 가능한 숫자형 (float / int) 인 column을 다룬다 5-1. 전체 통계 정보 df_name .describe() 산술 연산이 가능한 column만 출력됨 1df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 count 13.000000 1.500000e+01 mean 175.792308 5.655856e+06 std 5.820576 2.539068e+06 min 162.100000 2.925442e+06 25% 174.000000 3.712344e+06 50% 177.000000 4.668615e+06 75% 179.200000 7.862214e+06 max 183.000000 1.052326e+07 5-2. 최소값(min), 최대값(max), 중앙값(median), 최빈값(mode) 최소값: df_name [ ‘col_name’ ] .min() 최대값: df_name [ ‘col_name’ ] .max() 중앙값: df_name [ ‘col_name’ ] .median() 최빈값: df_name [ ‘col_name’ ] .mode() 1df['키'].min() 162.1 1df['키'].max() 183.0 1df['키'].median() 177.0 1df['키'].mode() 0 178.0 dtype: float64 5-3. 합계(sum), 평균(mean), 분산(var), 표준편차(std) 합계(sum): df_name [ ‘col_name’ ] .sum() 평균(mean): df_name [ ‘col_name’ ] .mean() 분산(variance): df_name [ ‘col_name’ ] .var() 표준편차(standard deviation): df_name [ ‘col_name’ ] .std() 1df['키'].sum() 2285.3 1df['키'].mean() 175.7923076923077 1df['키'].var() 33.879102564102595 1df['키'].std() 5.820575793175672 5-4. 갯수를 세는 count df_name [ ‘col_name’ ] .count 1df['키'].count() 13 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (2) 파일 불러오기 및 복사","slug":"S-Python-Pandas2","date":"2020-05-24T06:04:59.000Z","updated":"2020-06-23T16:54:11.248Z","comments":true,"path":"2020/05/24/S-Python-Pandas2/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas2/","excerpt":"","text":"파일 불러오기 및 복사 1. csv파일 읽어오기 – \"pd.read_csv\" 1-1. Jupyter Notebook 기반 1-2. Colab 기반 2. Excle파일 읽어오기 – \"pd.read_excel\" 2-1. Jupyter Notebook 기반 2-2. Colab 기반 3. 복사 (copy) 1. csv파일 읽어오기 – \"pd.read_csv\" 1-1. Jupyter Notebook 기반 1import pandas as pd 1pd.read_csv('korean-idol.csv') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1-2. Colab 기반 방법 1. 로컬에서 파일 읽어오기 123456from google.colab import filesmyfile = files.upload()import iopd.read_csv(io.BytesIO(myfile['korean-idol.csv'])) 방법 2: 구글 드라이브에 있는 샘플 파일 읽어오기 123456789from google.colab import drivedrive.mount('/content/drive')# 나타나는 link에 따라 google drive 로그인하여 link복사, # 'Enter your authorization code:'에서 복사된 link를 입력filename = 'colab 왼쪽 목록에서 파일 경로를 복사하여 붙혀놓기'pd.read_csv(filename) 2. Excle파일 읽어오기 – \"pd.read_excel\" 2-1. Jupyter Notebook 기반 1pd.read_excel('korean-idol.xlsx') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2-2. Colab 기반 구글 드라이브에 있는 샘플 파일 읽어오기 123456from google.colab import drivedrive.mount('/content/drive')filename = '파일 경로 붙혀놓기'pd.read_excel(filename) 3. 복사 (copy) dataframe을 복사할 때 \"df_name.copy()\"를 사용한다 \"=\"를 사용하여 원본데이터를 \"복사\"하면 복사된 데이터를 수정할 때 원본 데이터도 같이 변화한다 1df = pd.read_csv('korean-idol.csv') 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_new = df 1df_new.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_new['이름'] = 0 1df_new.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 0 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 0 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 0 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 0 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 0 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 0 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 0 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 0 마마무 RBW 여자 1995-07-23 162.1 A 7650928 이렇게 되는 이유는 두 dataframe이 같은 메모리 주소를 참조하기 때문이다. 1hex(id(df_new)) '0x25109f6e6c8' 1hex(id(df)) '0x25109f6e6c8' 원본 데이터를 유지 시키고, 새로운 변수에 복사할 때 copy() 를 사용한다 1df = pd.read_csv('korean-idol.csv') 1df_copy = df.copy() 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_copy.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 복사된 dataframe이 원본 데이터와 같은 메모리 주소를 참조한다. 1hex(id(df)) '0x25109fefa48' 1hex(id(df_copy)) '0x25109ff4408' copy본을 수정할 때 원본 데이터가 유지된다 1df_copy['이름'] = 0 1df_copy.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 0 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 0 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 0 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 0 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (1) Series와 DataFrame","slug":"S-Python-Pandas1","date":"2020-05-22T11:37:46.000Z","updated":"2020-06-23T16:53:52.755Z","comments":true,"path":"2020/05/22/S-Python-Pandas1/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/22/S-Python-Pandas1/","excerpt":"","text":"Series &amp; DataFrame 1. pandas 패키지 로드 2. pandas의 Series 와 DataFrame 2-1. Series 2-2. DataFrame 방법 1. list로 만들기 방법 2. dict로 만들기 2-3. index를 특정column으로 지정하기 2-4. column = Series 1. pandas 패키지 로드 1import pandas 별칭은 주로 pd로 사용한다 1import pandas as pd 1pd &lt;module 'pandas' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'&gt; 2. pandas의 Series 와 DataFrame 1차원, 1개의 column은 Series라고 한다 2-1. Series Series 생성: pd.Series(“list”) pd.Series(“list_name”) (1) pd.Series(“list”) 1pd.Series([1, 2, 3, 4]) 0 1 1 2 2 3 3 4 dtype: int64 (2) pd.Series(“list_name”) 1a = [1, 2, 3, 4] 1pd.Series(a) 0 1 1 2 2 3 3 4 dtype: int64 1mylist = [1, 2, 3, 4] 1pd.Series(mylist) 0 1 1 2 2 3 3 4 dtype: int64 2-2. DataFrame 방법 1. list로 만들기 123company1 = [['삼성', 2000, '스마트폰'], ['현대', 1000, '자동차'], ['네이버', 500, '포털']] 1pd.DataFrame(company1) .dataframe tbody tr th:only-of-type { vertical-align: middle } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 &lt;활용을 하기 위해 DataFrame을 변수에 지정하기&gt; 1df1 = pd.DataFrame(company1) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 &lt;제목컬럼 만들기&gt; – “dfname.column = [ ]” 1df1.columns = ['기업명', '매출액', '업종'] 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 주의: column명의 개수는 반드시 DataFrame의 column수와 동일해야 함 방법 2. dict로 만들기 1234company2 = {'기업명': ['삼성', '현대', '네이버'], '매출액': [2000, 1000, 500], '업종': ['스므트폰', '자동차', '포털'] } 1df2 = pd.DataFrame(company2) 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 0 삼성 2000 스므트폰 1 현대 1000 자동차 2 네이버 500 포털 2-3. index를 특정column으로 지정하기 “dfname.index = [ ]” 명령을 사용한다 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 1df1.index = df1['기업명'] 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 기업명 삼성 삼성 2000 스마트폰 현대 현대 1000 자동차 네이버 네이버 500 포털 2-4. column = Series 1df1['매출액'] 기업명 삼성 2000 현대 1000 네이버 500 Name: 매출액, dtype: int64 1type(df1['매출액']) pandas.core.series.Series document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Numpy - (4) 행렬. Broadcasting","slug":"S-Python-Numpy4","date":"2020-05-20T07:55:34.000Z","updated":"2020-06-11T17:09:58.983Z","comments":true,"path":"2020/05/20/S-Python-Numpy4/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/20/S-Python-Numpy4/","excerpt":"행렬 (덧셈, 뺄셈, 곱셈). Broadcasting.","text":"행렬 (덧셈, 뺄셈, 곱셈). Broadcasting. 목록 1. 행렬 - 덧셈 1-1. 덧셈 1-2. Sum – Matrix안의 계산 2. 행렬 - 뺄셈 3. 행렬 - 곱셈 3-1. 일반 곱셈 3-2. dot product / 내적곱 4. Broadcasting 4-1. 숫자의 연산 4-2. array (배열)의 broadcasting 1import numpy as np 1. 행렬 - 덧셈 행렬의 shape이 같아야 덧셈 가능 1-1. 덧셈 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 4, 5], [1, 2, 3]]) 1a + b array([[4, 6, 8], [3, 5, 7]]) 12a = np.array([[1, 2, 3], [2, 3, 4]]) 123b = np.array([[1, 2], [3, 4], [5, 6]]) 1a + b # shape이 다르면 error발생 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-7-37f7d36ad418&gt; in &lt;module&gt; ----&gt; 1 a + b # shape이 다르면 error발생 ValueError: operands could not be broadcast together with shapes (2,3) (3,2) 1-2. Sum – Matrix안의 계산 명령어: np.sum(‘array_name’, axis = ‘0/1/…’) 주의: 계산할 때 axis의 방향대로 Sum을 구한다. 예를 들면, 2darray에서, axis = 0 이면: 수직방향으로 Sum을 구한다 axis = 1 이면: 수평방향으로 Sum을 구한다 12a = np.array([[1, 2, 3], [2, 3, 4]]) 1np.sum(a, axis = 0) array([3, 5, 7]) 1np.sum(a, axis = 1) array([6, 9]) 2. 행렬 - 뺄셈 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 4, 5], [1, 2, 3]]) 1a - b array([[-2, -2, -2], [ 1, 1, 1]]) 12a = np.array([[1, 2, 3], [2, 3, 4]]) 123b = np.array([[1, 2], [3, 4], [5, 6]]) 1a - b # shape이 다르면 error발생 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-18-e62ba154daaa&gt; in &lt;module&gt; ----&gt; 1 a - b # shape이 다르면 error발생 ValueError: operands could not be broadcast together with shapes (2,3) (3,2) 3. 행렬 - 곱셈 3-1. 일반 곱셈 일반곱셈은 덧셈과 뺏셈이랑 동일하게 같은 위치에 있는 애들끼리 곱한다. [shape이 완전 같아야 함] 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 4, 5], [1, 2, 3]]) 1a * b array([[ 3, 8, 15], [ 2, 6, 12]]) 3-2. dot product / 내적곱 [맞닿는 shape이 같아야 함] 12a = np.array([[1, 2, 3], [2, 3, 4]]) 123b = np.array([[1, 2], [3, 4], [5, 6]]) 1a.shape, b.shape ((2, 3), (3, 2)) 방법 1: np.dot(a, b) 1np.dot(a, b) array([[22, 28], [31, 40]]) 방법2: a.dot(b) 1a.dot(b) array([[22, 28], [31, 40]]) 4. Broadcasting 4-1. 숫자의 연산 array a 의 모든 원소에 3을 더하고 싶다면: 단순히 행렬 덧셈을 사용할 때: 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 3, 3], [3, 3, 3]]) 1a + b array([[4, 5, 6], [5, 6, 7]]) Broadcasting 사용할 때: 12a = np.array([[1, 2, 3], [2, 3, 4]]) 1a + 3 array([[4, 5, 6], [5, 6, 7]]) 1a - 3 array([[-2, -1, 0], [-1, 0, 1]]) 1a * 3 array([[ 3, 6, 9], [ 6, 9, 12]]) 1a / 3 array([[0.33333333, 0.66666667, 1. ], [0.66666667, 1. , 1.33333333]]) 4-2. array (배열)의 broadcasting original array의 shape이 유지됨. 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[1], [2]]) 1a.shape, b.shape ((2, 3), (2, 1)) 1a * b array([[1, 2, 3], [4, 6, 8]]) 12a = np.array([[1, 2, 3], [2, 3, 4]]) 1b = np.array([1, 2, 3]) 1a * b array([[ 1, 4, 9], [ 2, 6, 12]]) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python >> Numpy - (3) 수열. 정렬","slug":"S-Python-Numpy3","date":"2020-05-19T17:10:54.000Z","updated":"2020-06-11T17:09:51.726Z","comments":true,"path":"2020/05/20/S-Python-Numpy3/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/20/S-Python-Numpy3/","excerpt":"arange. range. 정렬(sort &amp; argsort)","text":"arange. range. 정렬(sort &amp; argsort) 목록 1. arange란? 1-1. 순서대로 리스트에 값을 생성하려면? 1-2. arange를 사용해서 쉽게 생성하기 1-3. keyword인자를 사용해보기 1-4. 홀수의 값만 생성 2. range (Numpy와는 상관없는 Python문법) 3. 정렬 3-1. 1차원 정렬 3-2. N차원 정렬 3-3. index를 반환하는 argsort 1import numpy as np 1. arange란? arange와 range를 같이 보고 이해하면 됨 [실제 상황 예시] 우리는 순차적인 값을 생성할 때가 많다. 예를 들면: 회원에 대한 가입번호 부여 100개 한정 판매 상품에 대한 고유 번호 부여 이 밖에도 데이터 관리를 위한 인덱스를 차례대로 부여하는 것은 매우 흔한 일이다. 1-1. 순서대로 리스트에 값을 생성하려면? 1~10까지 값을 생성하려면? 1arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1arr [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1-2. arange를 사용해서 쉽게 생성하기 np.arange(a, b): a 부터 b-1 까지 생성한다 (a포함, b미포함) 1arr = np.arange(1, 11) 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 1-3. keyword인자를 사용해보기 np.arange(start = a, stop = b) 1arr = np.arange(start=1, stop=11) 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 1arr = np.arange(stop=11, start=1) # start &amp; stop 지정했기 때문에 순서 바꿔도 됨 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 1arr = np.arange(11,1) # start &amp; stop 지정 안하면 순서 바꿨을 때 오류 남 1arr array([], dtype=int32) 1-4. 홀수의 값만 생성 1~10 사이의 값중 홀수만 생성 step 키워드 활용 np.arange(start, stop, step) 1arr = np.arange(1, 11, 2) 1arr array([1, 3, 5, 7, 9]) 1arr = np.arange(start=1, stop=11, step=2) 1arr array([1, 3, 5, 7, 9]) 2. range (Numpy와는 상관없는 Python문법) range는 말 그대로 범위를 지정해 주는 것이다 보통 for-in 의 반복문에서 많이 사용된다 arange와는 다르게 array형태로 저장되어있지 않고 그냥 가볍게 바로바로 쓴다 arange 구문 활용시 1arr = np.arange(1, 11) 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 12for i in arr: print(i) 1 2 3 4 5 6 7 8 9 10 range 구문 활용시 12for i in range(1, 11): print(i) 1 2 3 4 5 6 7 8 9 10 12for i in range(1, 11, 2): print(i) 1 3 5 7 9 3. 정렬 3-1. 1차원 정렬 1차원 정렬은 매우 간단함 오름차순으로 정렬: np.sort(arr) 내림차순으로 정렬: np.sort(arr)[::-1] 1arr = np.array([1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1arr array([ 1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1np.sort(arr) array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 1np.sort(arr)[::-1] array([10, 9, 8, 8, 7, 6, 5, 4, 3, 2, 1]) 하지만, 그냥 이상태에서는 정렬된 이 값들이 유지가 안됨 값을 sort 된 상태로 유지시키려면: 변수로 다시 지정해주기 np.sort(arr) 대신 arr.sort() 쓴다 [arr자체에 sort명령을 씌워줌] 1arr array([ 1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1np.sort(arr) array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 1arr # np.sort 만 실행했을 때 유지가 안됨 array([ 1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1arr2 = np.sort(arr) # 방법1: arr2로 지정하기 1arr2 array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 1arr.sort() # 방법2: arr.sort 사용하기 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 3-2. N차원 정렬 N차원 정렬에서는 axis 중요함. (즉, 정렬 기준이 되는 축) 123arr2d = np.array([[5, 6, 7, 8], [4, 3, 2, 1], [10, 9, 12, 11]]) 1arr2d.shape (3, 4) 열 정렬 (왼쪽에서 오른쪽으로 정렬) – axis 1을 기준으로 삼 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 1) # 정렬 후 array([[ 5, 6, 7, 8], [ 1, 2, 3, 4], [ 9, 10, 11, 12]]) 행 정렬 (위에서 아래로 정렬) – axis 0을 기준으로 삼 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 0) # 정렬 후 array([[ 4, 3, 2, 1], [ 5, 6, 7, 8], [10, 9, 12, 11]]) 3-3. index를 반환하는 argsort 정렬한 결과에는 값을 반환하는 것이 아닌 index를 반환한다 열 정렬 (왼쪽에서 오른쪽으로 정렬) 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 1) # sort 정렬 후 array([[ 5, 6, 7, 8], [ 1, 2, 3, 4], [ 9, 10, 11, 12]]) 1np.argsort(arr2d, axis = 1) # argsort 정렬 후 array([[0, 1, 2, 3], [3, 2, 1, 0], [1, 0, 3, 2]], dtype=int64) 행 정렬 (위에서 아래로 정렬) 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 0) # sort 정렬 후 array([[ 4, 3, 2, 1], [ 5, 6, 7, 8], [10, 9, 12, 11]]) 1np.argsort(arr2d, axis = 0) # argsort 정렬 후 array([[1, 1, 1, 1], [0, 0, 0, 0], [2, 2, 2, 2]], dtype=int64) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python >> Numpy - (2) Slicing. 인덱싱","slug":"S-Python-Numpy2","date":"2020-05-19T12:55:06.000Z","updated":"2020-06-11T17:09:45.587Z","comments":true,"path":"2020/05/19/S-Python-Numpy2/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/19/S-Python-Numpy2/","excerpt":"슬라이싱 (Slicing). Fancy 인덱싱. Boolean 인덱싱.","text":"슬라이싱 (Slicing). Fancy 인덱싱. Boolean 인덱싱. 목록 1. 슬라이싱 (Slicing) 1-1. index 지정하여 색인 1차원 array 2차원 array 1-2. 범위 색인 1차원 array 2차원 array 2. Fancy 인덱싱 2-1. 1차원 array 2-2. 2차원 array 3. Boolean 인덱싱 3-1. True와 False값으로 색인하기 3-2. 조건필터 1. 슬라이싱 (Slicing) 1import numpy as np 베열의 부분 선택 (과일을 슬라이스해서 부분만 먹듯…) 1arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1arr.shape (10,) 1-1. index 지정하여 색인 1차원 array 1arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1arr[0] # index: 앞에서 부터 0, 1, 2, ... 0 1arr[5] 5 1arr[10] # index가 넘으면 error남 --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-7-ff656e92d79c&gt; in &lt;module&gt; ----&gt; 1 arr[10] IndexError: index 10 is out of bounds for axis 0 with size 10 1arr[-1] # 뒤에서 부터 1번째. index: 뒤에서 부터 -1, -2, -3,... 9 1arr[-10] 0 1arr[-11] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-10-91f133f07612&gt; in &lt;module&gt; ----&gt; 1 arr[-11] IndexError: index -11 is out of bounds for axis 0 with size 10 2차원 array 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 1arr2d.shape (3, 4) arr2d[행, 열] 1arr2d[0, 2] 3 1arr2d[2, 1] 10 1-2. 범위 색인 1차원 array arr[a, b] – arr의 “index a” 부터 \"index b-1\"까지 (a 포함, b 미포함) index: 1 이상 1arr array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1arr[1:] # index 1 포함 array([1, 2, 3, 4, 5, 6, 7, 8, 9]) index: 5 미만 1arr[:5] # index 5 미포함 array([0, 1, 2, 3, 4]) index: 1이상 5미만 1arr[1:5] # index 1 포함 &amp; index 5 미포함 array([1, 2, 3, 4]) index: -1까지 1arr[:-1] # index -1 (index 9) 미포함 array([0, 1, 2, 3, 4, 5, 6, 7, 8]) 2차원 array 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) row(행)을 모두 가져오려는 경우 1arr2d[0,:] # 0번 행의 모든 열 가져오기 array([1, 2, 3, 4]) colomn(열)을 모두 가져오려는 경우 1arr2d[:,2] array([ 3, 7, 11]) 부분적으로 가져오려는 경우 1arr2d[:2, :] # 0,1번 행의 모든 열 가져오기 array([[1, 2, 3, 4], [5, 6, 7, 8]]) 1arr2d[:2, 2:] # 0,1번 행의 2,3번 열 가져오기 array([[3, 4], [7, 8]]) 2. Fancy 인덱싱 fancy인덱싱은 범위가 아닌 특정 index의 집합의 값을 선택하여 추출하고 싶을 때 활용한다 1arr = np.array([10, 23, 2, 7, 90, 65, 32, 66, 70]) 2-1. 1차원 array 방법 1: 추출하고 싶은 index의 집합을 **[꺾쇠 괄호로]**묶어서 추출 1arr[[1, 3, 5]] array([23, 7, 65]) 방법 2: 추출하고 싶은 index의 집합을 변수에 지정한 후 추출 1idx = [1, 3, 5] 1arr[index] array([23, 7, 65]) 2-2. 2차원 array 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 1arr2d[[0,1], :] array([[1, 2, 3, 4], [5, 6, 7, 8]]) 1arr2d[:, [1,3]] array([[ 2, 4], [ 6, 8], [10, 12]]) 3. Boolean 인덱싱 조건 필터링을 통하여 Boolean값을 이용한 색인 1arr = np.array([1, 2, 3, 4, 5, 6, 7]) 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 3-1. True와 False값으로 색인하기 boolean index의 수가 꼭 array의 index와 같아야 됨! 1myTrueFalse = [True, False, True] 1arr[myTrueFalse] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-43-9c52b39d81ae&gt; in &lt;module&gt; ----&gt; 1 arr[myTrueFalse] IndexError: boolean index did not match indexed array along dimension 0; dimension is 7 but corresponding boolean dimension is 3 1myTrueFalse = [True, False, True, False, True, False, True] 1arr[myTrueFalse] array([1, 3, 5, 7]) 3-2. 조건필터 조건 연산자를 활용하여 필터를 생성할 수 있다 1arr2d array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) 1arr2d &gt; 2 # \"2보다 크다\"라는 조건의 만족여부에 따라 Boolean index 생성 array([[False, False, True, True], [ True, True, True, True], [ True, True, True, True]]) 위 Boolean index를 다시 array에 적용하여 해당 부분을 추출: arr2d[조건필터] 1arr2d[arr2d &gt; 2] # 1차원 array로 반환 array([ 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) 1arr2d[arr2d &lt; 5] array([1, 2, 3, 4]) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python >> Numpy - (1) Numpy. array","slug":"S-Python-Numpy1","date":"2020-05-18T15:07:32.000Z","updated":"2020-06-25T09:04:02.406Z","comments":true,"path":"2020/05/19/S-Python-Numpy1/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/19/S-Python-Numpy1/","excerpt":"Numpy개요. Numpy import하기. nd array 생성. array에서의 데이터 타입","text":"Numpy개요. Numpy import하기. nd array 생성. array에서의 데이터 타입 목록 1. Numpy 개요 1-1. Numpy이란? 1-2. 별칭 - np 1-3. array (배열) 1-4. shape(차원) &amp; axis(축) 2. Numpy import하기 2-1. 별칭 (alias) 지정하기 (항상 해주세요!) 3. ndarray 생성하기 – \"np.array([…])\" 3-1. list로 부터 생성하기 – “np.array(list_name)” 3-2. shape확인하기 – “array_name .shape” 4. array에서의 data type 4-1. list에서의 data type 4-2. array에서의 data type case 1. int와 float타입이 혼재된 경우 case 2. int와 float 타입이 혼재되었으나, dtype을 지정한 경우 case 3. int / float 와 str 타입이 혼재된 경우 case 4. int와 str 타입이 혼재되어 있고 dtype이 int로 지정한 경우 1. Numpy 개요 1-1. Numpy이란? Numpy: 수학, 과학 계산용 패키지 ​ 1-2. 별칭 - np 1import numpy as np 1-3. array (배열) 배열: 여러 값들의 그룹 &lt; 1차원 배열 &gt; numpy.array([1, 2, 3, 4]) &lt; 2차원 배열 &gt; numpy.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]) &lt; n차원 배열 &gt; (nd array: n dimention array) 1-4. shape(차원) &amp; axis(축) shape은 차원의 수 를 확인 (3, ) =&gt; 3 X 1의 배열 (4,3) =&gt; 4 X 3의 배열 (2,5,3) =&gt; 2 X 5 X 3의 배열 axis는 기준이 되는 축 axis는 앞에서 부터 0, 1, 2… nd array의 축: axis 0, axis 1, axis 2, … axis n 2. Numpy import하기 1import numpy 1numpy &lt;module 'numpy' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'&gt; 2-1. 별칭 (alias) 지정하기 (항상 해주세요!) 1import numpy as np 1np &lt;module 'numpy' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'&gt; 3. ndarray 생성하기 – \"np.array([…])\" 1arr = np.array([1,2,3,4], dtype=int) 1arr # 주의: list와 다름 array([1, 2, 3, 4]) 1[1, 2, 3, 4] # list [1, 2, 3, 4] 1type(arr) numpy.ndarray 3-1. list로 부터 생성하기 – “np.array(list_name)” 1mylist1 = [1, 2, 3, 4] 12mylist2 = [[1, 2, 3, 4], [5, 6, 7, 8]] 1arr1 = np.array(mylist1) 1arr1 array([1, 2, 3, 4]) 1arr2 = np.array(mylist2) 1arr2 array([[1, 2, 3, 4], [5, 6, 7, 8]]) 3-2. shape확인하기 – “array_name .shape” 1arr1.shape (4,) 1arr2.shape (2, 4) 4. array에서의 data type array에서는 list와 다르게 1개의 단일 데이터 타입 만 허용 된다 4-1. list에서의 data type 1mylist = [1, 3.14, '사과', '1234'] 1mylist [1, 3.14, '사과', '1234'] 1mylist[0] 1 1mylist[2] '사과' 4-2. array에서의 data type case 1. int와 float타입이 혼재된 경우 int와 float타입이 혼재된 경우 int(정수)가 float(실수)로 바꿔진다 1arr = np.array([1, 2, 3, 3.14]) 1arr # 정수가 실수로 바꿔진다 array([1. , 2. , 3. , 3.14]) ​ case 2. int와 float 타입이 혼재되었으나, dtype을 지정한 경우 int와 float 타입이 혼재되었으나, dtype가 int로 지정된 경우, float의 앞에 정수 부분만 보류된다 1arr = np.array([1, 2, 3, 3.14], dtype = int) 1arr array([1, 2, 3, 3]) case 3. int / float 와 str 타입이 혼재된 경우 int / float 와 float타입이 혼재된 경우 int(정수)가 str(문자열)로 바꿔진다 1arr = np.array([1, 3.14, '사과', '1234']) 1arr array(['1', '3.14', '사과', '1234'], dtype='&lt;U32') 1arr[0] + arr[1] #str로 되어버려서 숫자의 사칙 연산이 안됨 '13.14' case 4. int와 str 타입이 혼재되어 있고 dtype이 int로 지정한 경우 (1) 문자내용인 str이 존재한 경우 error 발생 1arr = np.array([1, 3.14, '사과', '1234', '5.8'], dtype = int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-50-88e75a912236&gt; in &lt;module&gt; ----&gt; 1 arr = np.array([1, 3.14, '사과', '1234', '5.8'], dtype = int) ValueError: invalid literal for int() with base 10: '사과' (2) 실수(float)내용인 str이 존재한 경우도 error발생 1arr = np.array([1, 3.14, '1234', '5.8'], dtype = int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-52-98017763e514&gt; in &lt;module&gt; ----&gt; 1 arr = np.array([1, 3.14, '1234', '5.8'], dtype = int) ValueError: invalid literal for int() with base 10: '5.8' (3) 정수(int)내용인 str만 존재한 경우 해당 str이 자동으로 int로 바꿔짐 1arr = np.array([1, 3.14, '1234'], dtype = int) 1arr array([ 1, 3, 1234]) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python 기초문법 - (6) Package","slug":"S-Python-base6","date":"2020-05-16T04:52:05.000Z","updated":"2020-06-11T17:10:50.910Z","comments":true,"path":"2020/05/16/S-Python-base6/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/16/S-Python-base6/","excerpt":"패키지(Package) 와 import","text":"패키지(Package) 와 import 목록 1. 패키지와 모듈 그리고 함수의 관계도 2. 모듈 import 하기 3. 패키지 에서 import하기 4. 별칭 (alias) 지어주기 5. 앞으로 자주 사용할 패키지, 모듈 미리보기 패키지(Package) 와 import 1. 패키지와 모듈 그리고 함수의 관계도 함수들이 뭉쳐진 하나의 .py파일 안에 이루어진 것을 모듈이라고 한다 여러 개의 모듈을 그룹화 하면 패키지가 된다 패키지는 종종 라이브러비라고도 불린다 123from IPython.display import Image# 출척: pythonstudy.xyzImage('http://pythonstudy.xyz/images/basics/python-package.png') 2. 모듈 import 하기 import 하는 방법 .py (파이썬 파일 확장자)로 된 파일을 우리는 모듈 이라고 한다, import 구문을 통해 해당 파일을 불러올 수 있다 1import pandas 위의 코드는 pandas라는 모듈을 우리가 불러오겠다라는 의미이다 3. 패키지 에서 import하기 패키지 안에서 하나의 모듈을 불러온다 1from pandas import DataFrame # pandas라는 패키지 안에서 DataFrame이라는 모듈을 불러온다 1DataFrame() # 모듈 DataFrame사용 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통째로 패키지나 모듈을 불러온다 1import pandas 1pandas.DataFrame() # DataFrame이라는 모듈을 사용하기 위해서는 .을 찍고 이어서 쓰면 됨 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 4. 별칭 (alias) 지어주기 pandas라는 패키지 이름이 너무 길기 때문에 우리는 약어로 줄여쓸 수 있다. 보통 pd를 보편적으로 많이 사용한다. 줄여서 별명을 지어줄 때는 as를 붙혀준다 1import pandas as pd 1pd.DataFrame() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 5. 앞으로 자주 사용할 패키지, 모듈 미리보기 1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns numpy: 과학계산을 위한 패키지 pandas: 데이터 분석을 할 때 가장 많이 쓰이는 패키지 matplotlib: 시각확를 위한 패키지 seaborn: 시각화를 위한 패키지 (matplotlib을 더 쉽게 사용할 수 있도록 도와주는 패키지) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (5) List Comprehension. 문자열","slug":"S-Python-base5","date":"2020-05-13T16:37:58.000Z","updated":"2020-06-11T17:10:41.561Z","comments":true,"path":"2020/05/14/S-Python-base5/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/14/S-Python-base5/","excerpt":"List Comprehension (List에 조건필터를 적용). 문자열을 가지고 노는 방법.","text":"List Comprehension (List에 조건필터를 적용). 문자열을 가지고 노는 방법. 목록 1. List Comprehension (파이썬 고유의 아름다운 문법) 1-1. list comprehension 조건필터 1-2. [STEP 1] list를 만들어야 하니 일단 꺾쇠[ ]를 씌운다 1-3. [STEP 2] 조건 필터를 걸어 준다 1-4. [응용 STEP] 변수 값을 가공할 수도 있다 2. 문자열(string)을 가지고 놀기 2-1. 문자의 길이 2-2. 문장 쪼개기 – “.split” 2-3. 대문자 / 소문자로 만들기 – “.upper” / “.lower” 2.4. ~로 시작하는, ~로 끝나는 – “.startswith” , “.endswith” 2-5. 바꾸기 – “.replace(‘바꿀 대상, 바꿔야할 값’)” 2-6. 불필요한 공백 제거하기 – “.strip” 1. List Comprehension (파이썬 고유의 아름다운 문법) for ~ in 구조를 기본적으로 가지고 있다 List Comprehension 이니까 당연히 List를 사용한다 [실제 사례 연구] mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 이라는 list를 만들어 주고 우리는 이 중 짝수만 출력하고 싶으면 아래와 같이 쓸 수 있다: 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 123for i in mylist: if i % 2 == 0: print(i) 2 4 6 8 10 그럼 mylist에서 짝수만 뽑아서 list로 만들어 주고 싶다면: 12345678mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]even = []for i in mylist: if i % 2 == 0: even.append(i)print(even) [2, 4, 6, 8, 10] 이렇게 for in 문으로 해줄 수 있다. 하지만, 우리는 list comprehension을 통해 더욱 쉽게 해결 할 수 있다!! 1-1. list comprehension 조건필터 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 아래 문법이 바로 list comprehension 이다. 한 줄로 해결해 버리는 것이 매력임! 1even = [i for i in mylist if i % 2 == 0] 1even [2, 4, 6, 8, 10] 1-2. [STEP 1] list를 만들어야 하니 일단 꺾쇠[ ]를 씌운다 꺾쇠 안에 반복문이 들어간다 반복문을 돌면서 return 된 i값을 list에 넣는 원리이기 때문에 for구분 앞에 i를 써준다 1even = [i for i in mylist] 1even [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1-3. [STEP 2] 조건 필터를 걸어 준다 [i for i in mylist (이곳에 조건문)] 1[i for i in mylist if i % 2 == 0] [2, 4, 6, 8, 10] 이것을 변수에 다시 할당해주면 끝! 1even = [i for i in mylist if i % 2 == 0] 1even [2, 4, 6, 8, 10] 1-4. [응용 STEP] 변수 값을 가공할 수도 있다 예를 들어: mylist의 모든 값에 +2를 하고 다시 even이라는 list에 저장하고 싶다면 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1even = [i+2 for i in mylist] 1even [3, 4, 5, 6, 7, 8, 9, 10, 11, 12] 2. 문자열(string)을 가지고 놀기 2-1. 문자의 길이 1a = 'banana' 1len(a) 6 1a = 'banana pen' 1len(a) # 공백도 count된다 10 1b = '한글' 1len(b) 2 1b = '한글 바나나' 1len(b) 6 2-2. 문장 쪼개기 – “.split” split은 문장을 특정 규칙에 의해 쪼개 주는 기능을 한다 명령어: 변수명.split(‘쪼개는 기준’) 쪼개는 기준이 설정되어 있지 않으면 그냥 '빈칸’으로 인식된다 1a = 'This is a pen' 1a.split(' ') ['This', 'is', 'a', 'pen'] 1a.split() ['This', 'is', 'a', 'pen'] 1b = 'This-is-a-pen' 1b.split('-') ['This', 'is', 'a', 'pen'] return된 값을 list형식으로 저장한다 1aa = a.split(' ') 1aa ['This', 'is', 'a', 'pen'] 1aa[0] 'This' 1aa[2] 'a' 1aa[0] + aa[2] 'Thisa' 1c = '한글은 어떻게 될까요?' 1c.split() ['한글은', '어떻게', '될까요?'] 2-3. 대문자 / 소문자로 만들기 – “.upper” / “.lower” 1a = 'My name is hyemin' 1a.upper() 'MY NAME IS HYEMIN' 1a.lower() 'my name is hyemin' 1b = '한글엔 대소문자가 없어요ㅠ' 1b.upper() '한글엔 대소문자가 없어요ㅠ' 1b.lower() '한글엔 대소문자가 없어요ㅠ' 2.4. ~로 시작하는, ~로 끝나는 – “.startswith” , “.endswith” 123a = '01-sample.png'b = '02-sample.jpg'c = '03-sample.pdf' 1a.startswith('01') True 1a.endswith('.jpg') False 1b.endswith('.jpg') True 조건(혹은 형식)에 맞는 파일을 추출하고 싶을 때: 1mylist = [a, b] 123for file in mylist: if file.endswith('jpg'): print(file) 02-sample.jpg 2-5. 바꾸기 – “.replace(‘바꿀 대상, 바꿔야할 값’)” [예] file형식을 바꾸고 싶다면: 1a = '01-sample.png' 1a.replace('.png', '.jpg') '01-sample.jpg' 이 때 a의 값이 변하지 않아. 다시 할당 해야 함 1a '01-sample.png' 1a_new = a.replace('.png', '.jpg') # 새로 지정 1a_new '01-sample.jpg' 1a = a.replace('.png', '.jpg') # 덮어쒸우기 1a '01-sample.jpg' 2-6. 불필요한 공백 제거하기 – “.strip” [예] 12a = ' 01-sample.png'b = '01-sample.png' 1a == b False strip은 양 끝 불필요한 공백을 제거해 줌. 1a.strip() '01-sample.png' 1a.strip() == b True document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (4) 비교/논리 연산자. 조건문. 반복문","slug":"S-Python-base4","date":"2020-05-13T08:25:46.000Z","updated":"2020-06-11T17:10:35.405Z","comments":true,"path":"2020/05/13/S-Python-base4/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/13/S-Python-base4/","excerpt":"비교연산자. 조건문. 논리연산자. 반복문","text":"비교연산자. 조건문. 논리연산자. 반복문 목록 1. 비교연산자 1-1. 대소비교 &gt;, &gt;=, &lt;, &lt;= 1-2. 같다 == 1-3. 같지 않다 != 2. 조건문 2-1. 개념 2-2. if 2-3. else 2-4. elif 2-5. 1이나 0은 참이나 거짓을 표현하기도 한다 3. 논리 연산자 (and, or) 3-1. and 3-2. or 4. 반복문 4-1. 반복문이란? 4-2. for 와 in을 활용하자! 4-3. 반복문에서 짝수만 출력하려면? (continue구문) 4-4. 조건을 충족시 순환에서 빠져나와보자! (break구문) 1. 비교연산자 비교 연산자는 주로 대소비교를 할 때 사용한다. 1-1. 대소비교 &gt;, &gt;=, &lt;, &lt;= 11 &gt; 2 False 110 &gt;= 10 True 19 &lt; 10 True 18 &lt;= 7 False 1-2. 같다 == 주의: = 는 대입연산자. == 는 비교연산자 중의 “같다” 숫자형 &amp; 문자형 모두 비교 가능 12 = 2 File \"&lt;ipython-input-6-a8e553549e25&gt;\", line 1 2 = 2 ^ SyntaxError: can't assign to literal 12 == 2 True 12 == 3 False 1\"나\" == \"나\" True 1-3. 같지 않다 != 숫자형 &amp; 문자형 모두 비교 가능 12 != 2 False 12 != 3 True 1\"나\" != \"너\" True 2. 조건문 2-1. 개념 주어진 조건이 참인 경우 그 다음 내가 규칙(로직)을 실행하는 개념이다 2-2. if if는 어떤 조건이 성립한다면 ~이라는 의미 if구문 끝에는 반드시 콜론( : )이 있어야 함 12if 5 &gt; 3: print('참') 참 if구문 뒤에 indent가 있는 명령어는 if조건이 성립하면 실행 indent가 없으면 if의 성립여부와 무관하여 무조건 실행 12345if 5 &gt; 3: print('참') print('참') print('끝') 참 참 끝 12345if 5 &lt; 3: print('참') print('참') print('끝') # 앞에 indent가 없으면 if의 성립여부와 무관하여 실행 끝 2-3. else else는 if 조견 후에 따라오면, if가 아닌 경우에 실행 됨 1234if 5 &lt; 3: print(\"성립한다\")else: print(\"성립하지 않은다\") 성립하지 않은다 else는 꼭 if랑 같이 써야함. 단독으로 실행할 수 없음 12else: print(\"성립하지 않은다\") File \"&lt;ipython-input-22-6c0f4debaa4b&gt;\", line 1 else: ^ SyntaxError: invalid syntax 2-4. elif elif구문은 3가지 이상 문기(조건)의 동작을 수행할 때 사용 123456if 3 &gt; 5: print('if 구문')elif 3 &lt; 4: print('elif 구문')else: print('이것도 저것도 아니다') elif 구문 그럼, elif구문이 참인 여러 구문을 나열 했을 때는 어떻게 될까? 12345678910if 3 &gt; 5: print('if 구문')elif 3 &lt; 4: print('elif 1 구문')elif 3 &lt; 5: print('elif 2 구문')elif 3 &lt; 6: print('elif 3 구문')else: print('이것도 저것도 아니다') elif 1 구문 elif구문이 참인 여러 구문을 나열 했을 때는 첫번째 참인 elif구문만 실행됨 2-5. 1이나 0은 참이나 거짓을 표현하기도 한다 1234if 1: print('참')else: print('거짓') 참 1234if 0: print('참')else: print('거짓') 거짓 3. 논리 연산자 (and, or) and나 or조건은 두 가지 이상 조건을 다룰 때 활용한다 3-1. and and 조건은 모두 만족할 때 참으로 인식한다 1True and True and True True 1True and False and True False 1234if (0 &lt; 1) and (0 &lt; 2): print('모두 참')else: print('거짓') 모두 참 1234if (0 &lt; 1) and (0 &gt; 2): print('모두 참')else: print('거짓') 거짓 3-2. or or조건은 조건 중 하나라도 만족할 때 참으로 인식한다 1True or False or False True 1False or False or False False 1234if (0 &lt; 1) or (0 &gt; 2): print('하나라도 참')else: print('모두 거짓') 하나라도 참 1234if (0 &gt; 1) or (0 &gt; 2): print('하나라도 참')else: print('모두 거짓') 모두 거짓 4. 반복문 4-1. 반복문이란? 일을 반복 처리 해준다는 것 대상은 반드시 list, dict, set등 집합이어야 한다 [예] 반복문 쓰지 않을 때: 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] mylist에 들어 닜는 모든 값들을 출력하려고 한다면? 123456print(mylist[0])print(mylist[1])print(mylist[2])print('...')print(mylist[8])print(mylist[9]) 1 2 3 ... 9 10 반복문은 노가다를 획기적으로 줄여주는 방법이다! 4-2. for 와 in을 활용하자! [기본 문법] for 지정한 변수명 in [꺼내올 집합]: 명령어 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 12for i in mylist: print(i) 1 2 3 4 5 6 7 8 9 10 4-3. 반복문에서 짝수만 출력하려면? (continue구문) 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 방법1: 123for i in mylist: if i % 2 == 0: print(i) 2 4 6 8 10 방법2: continue구문을 사용하면 조건이 충족할 때 아래 명령어를 SKIP하고 다시 다음 순환으로 넘어간다 1234for i in mylist: if i % 2 == 1: continue print(i) 2 4 6 8 10 4-4. 조건을 충족시 순환에서 빠져나와보자! (break구문) 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] i가 6 이상이면 STOP 1234for i in mylist: if i &gt;= 6: # i &gt; 6 이면 6까지 출력한다 break print(i) 1 2 3 4 5 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (3) 함수","slug":"S-Python-base3","date":"2020-05-13T07:16:31.000Z","updated":"2020-06-11T17:10:29.795Z","comments":true,"path":"2020/05/13/S-Python-base3/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/13/S-Python-base3/","excerpt":"함수의 기초","text":"함수의 기초 목록 1. 함수란 무엇일까? 2. 함수 정의: def (define) 3. 함수는 값을 return할 수 있고, 안해도 됨 4. parameter가 여러 개 있으면, 함수에 넘겨 줄 때 순서가 중요 함수 1. 함수란 무엇일까? 반복적으로 사용되는 부문을 묶어서, 재사용 가능하도록 만들어 주는 것 함수에는 **들어가는 놈 (input)**이 있고, **나오는 놈 (output 혹은 return)**이 있다. 전해진 로직(규칙)에 따라, input -&gt; output으로 효율적으로 바꿔주는 역할을 한다 [예시] 함수 없이 계산할 때 123a = 1b = 2c = 3 1(a + b) * c 9 123a = 2b = 2c = 3 1(a + b) * c 12 함수로 변경 후 12def func(a, b, c): return (a + b) * c 1func(1, 2, 3) 9 1func(2, 2, 3) 12 2. 함수 정의: def (define) 사용법: def 함수이름 (parameter1, parameter2, parameter3…): parameter는 함수로 부터 넘겨 받은 변수 또는 값이다 끝에 콜론 ( : ) 빼먹지 않음에 주의 해야함! 12def myfunc(var1): print(var1) # 실행 명령 1myfunc(\"안녕하세요\") 안녕하세요 3. 함수는 값을 return할 수 있고, 안해도 됨 리턴이 없는 경우 12def my_func(a, b): print(a, b) 1my_func(1,10) 1 10 리턴이 있는 경우 123def my_func(a, b): s = a + b return s 1my_func(2, 3) 5 리턴이 있는 경우는 변수에 값을 다시 할당 할 수 있음 1result = my_func(2,3) 1print(result) 5 1print(result + 10) 15 4. parameter가 여러 개 있으면, 함수에 넘겨 줄 때 순서가 중요 12def my_func(a, b, c): return (a + b) * c 123a = 10b = 20c = 3 1(a + b) * c 90 1my_func(a, b, c) 90 1my_func(c, b, a) # (c + b) * a = (3 + 20) * 10 230 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (2) 집합 형태의 데이터 타입","slug":"S-Python-base2","date":"2020-05-12T17:26:49.000Z","updated":"2020-06-11T17:10:22.797Z","comments":true,"path":"2020/05/13/S-Python-base2/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/13/S-Python-base2/","excerpt":"","text":"집합 형태의 데이터 타입 1. list (순서가 있는 집합) 1-1. [ ] 형테로 표현 1-2. 값 추가 – “.append( )” 1-3. 값 제거 – “.remove” / “.clear” 1-4. 인덱싱(Indexing) -&gt; 색인 1-5. 인덱스로 접근하여 값 바꾸기 1-6. 길이 파악하기 2. tuple (순서가 있는 집합, 읽기 전용) 2-1. ( ) 형태로 표현 2-2. 읽기 전용이라 “값 추가”, “값 제거”, “값 바꾸기” 모두 안됨 2-3. 길이 파악하기 3. set (순서 X, 중복 X) 3-1. set의 할당: set() 3-2. 값 추가 – \".add \" 3-3. 값 제거 – “.remove” / “.clear” 4. dict (사전형 집합, key와 value 쌍) 4-1. { } 형태로 표헌 4-2. 값 추가 (key와 value 모두 지정) 4-3. 값 바꾸기 4-4. 값 제거 – “.pop” / “.clear” 4-5. 길이 파악하기 짐합 형태의 데이터 타입 list (순서 O, 짐합) tuple (순서 X, 읽기 전용 집합) set (순서 X, 중복 X 집합) dict (key, value로 이루어진 사전형 집합) 1. list (순서가 있는 집합) 1-1. [ ] 형테로 표현 1mylist = [] 1mylist [] 1type(mylist) list 12mylist = [1,2,3,4,5]mylist [1, 2, 3, 4, 5] 12mylist2 = [5,4,3,2,1] # 순서가 있다mylist2 [5, 4, 3, 2, 1] 1-2. 값 추가 – “.append( )” 12mylist = []mylist [] 12mylist.append(1)mylist [1] 123mylist.append(2)mylist.append(3)mylist [1, 2, 3] .append 함수 안에 1 argument만 들어갈 수 있다 12mylist.append(4,5)mylist --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-22-6f00703728b8&gt; in &lt;module&gt; ----&gt; 1 mylist.append(4,5) 2 mylist TypeError: append() takes exactly one argument (2 given) 1-3. 값 제거 – “.remove” / “.clear” 부분 제거 – \".remove\" 1mylist [1, 2, 3] 12mylist.remove(1)mylist [2, 3] 전부 제거 – \".clear\" 1mylist.clear() 1mylist [] 같은 값이 여러 개 포함되어 있을 때의 제거 순서 앞에서 부터 순차적으로 제거 됨 12mylist = [1,2,3,1,2,3]mylist [1, 2, 3, 1, 2, 3] 12mylist.remove(1)mylist [2, 3, 1, 2, 3] 12mylist.remove(1)mylist [2, 3, 2, 3] 1-4. 인덱싱(Indexing) -&gt; 색인 인덱스는 0번 부터 시작한다 1mylist = [1,2,3,4] # 인덱스: 0번, 1번, 2번, 3번 1mylist[0] 1 1mylist[3] 4 1mylist[4] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-34-88b11041aa4f&gt; in &lt;module&gt; ----&gt; 1 mylist[4] IndexError: list index out of range 인덱스가 음수일 경우: 뒤에서 부터 n번째 1mylist[-1] 4 1-5. 인덱스로 접근하여 값 바꾸기 1mylist [1, 2, 3, 4] 1mylist[0] 1 1mylist[0] = 100 1mylist [100, 2, 3, 4] 1-6. 길이 파악하기 1mylist [100, 2, 3, 4] 1len(mylist) # length 4 2. tuple (순서가 있는 집합, 읽기 전용) 2-1. ( ) 형태로 표현 1mytuple = (1,2,3,4,5) 2-2. 읽기 전용이라 “값 추가”, “값 제거”, “값 바꾸기” 모두 안됨 1mytuple.append(1) # 읽기 전용이라 값을 추가할 수 없음 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-45-d0f55ea1e3f6&gt; in &lt;module&gt; ----&gt; 1 mytuple.append(1) # 읽기 전용이라 값을 추가할 수 없음 AttributeError: 'tuple' object has no attribute 'append' 1mytuple.remove(1) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-46-05a40423345b&gt; in &lt;module&gt; ----&gt; 1 mytuple.remove(1) AttributeError: 'tuple' object has no attribute 'remove' 1mytuple[0] = 100 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-48-4e527888818c&gt; in &lt;module&gt; ----&gt; 1 mytuple[0] = 100 TypeError: 'tuple' object does not support item assignment 2-3. 길이 파악하기 1mytuple (1, 2, 3, 4, 5) 1len(mytuple) 5 3. set (순서 X, 중복 X) 3-1. set의 할당: set() 12myset = set()myset set() 1type(myset) set 3-2. 값 추가 – \".add \" 1234myset.add(1)myset.add(2)myset.add(3)myset {1, 2, 3} 1234567myset.add(1) myset.add(2)myset.add(3)myset.add(1) # 중복된 값을 한번만 기록myset.add(2)myset.add(3)myset {1, 2, 3} 12myset.add(4)myset {1, 2, 3, 4} 3-3. 값 제거 – “.remove” / “.clear” 부분 제거 – \".remove\" 1myset {1, 2, 3, 4} 1myset.remove(3) 1myset {1, 2, 4} 전부 제거 – \".clear\" 1mylist.clear() 1mylist [] 4. dict (사전형 집합, key와 value 쌍) 4-1. { } 형태로 표헌 1mydict = dict() 1mydict {} 1type(mydict) dict 4-2. 값 추가 (key와 value 모두 지정) mydict [ \" key \" ] = value key는 문자형 (str) / 숫자형 (int &amp; float) 모두 가능 1mydict[\"apple\"] = 123 1mydict {'apple': 123} 1mydict[\"apple\"] 123 1mydict[0] = 2 1mydict {'apple': 123, 0: 2} 1mydict[0] 2 1mydict[3.14] = 1 1mydict {'apple': 123, 0: 2, 3.14: 1} 1mydict[3.14] 1 4-3. 값 바꾸기 새 값을 해당 key에 할당하기 1mydict[\"apple\"] = \"hello\" 1mydict {'apple': 'hello', 0: 2, 3.14: 1} 4-4. 값 제거 – “.pop” / “.clear” 부분 제거 – \".pop\" 1mydict.pop('apple') 'hello' 1mydict {0: 2, 3.14: 1} 1mydict.pop(0) 2 1mydict {3.14: 1} 전부 제거 – \".clear\" 1mydict.clear() 1mydict {} 4-5. 길이 파악하기 123mydict[\"apple\"] = 123mydict[0] = 2mydict[3.14] = 1 1mydict {'apple': 'hello', 0: 2, 3.14: 1} 1len(mydict) 3 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (1) 출력. 데이터 타입. 데이터의 응용","slug":"S-Python-base1","date":"2020-05-11T17:18:11.000Z","updated":"2020-06-25T09:03:20.087Z","comments":true,"path":"2020/05/12/S-Python-base1/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/12/S-Python-base1/","excerpt":"출력. 변수. 데이터 타입. 데이터의 응용. 데이터 타입의 변환.","text":"출력. 변수. 데이터 타입. 데이터의 응용. 데이터 타입의 변환. 목록 1. 출력 (print) print( ) 함수 2. 변수와 대입 2-1. 변수의 이름 【가능한 경우】 【불가한 경우】 2-2. 변수의 대입 2-3. 변수의 출력 3. 데이터 타입 3-1. int(정수) 3-2. float(실수) 3-3. str 혹은 object (문자열) 3-4. bool (참/거짓) 3-5. 아무것도 아닌 None타입도 있다 4. 데이터의 응용 4-1. 사칙 연산자 4-2. 문자열의 연결 5. 데이터 타입 변환 5-1. 문자열로 변환: “str( ) 함수” or “따움표” 5-2. 정수로 변환: \" int( ) 함수\" 5-3. 실수로 변환: “float( ) 함수” 1. 출력 (print) print( ) 함수 숫자를 출력할 때 따움표(’ ’ or \" \") 필요없음 문자를 출력할 때 따움표 필요 ’ ’ 와 \" \" 차이없음 ‘’’ ‘’’ 를 사용하면 출력시 “줄 바꿈” 형식이 보류될 수 있음 1print(1) 1 1print(1+2) 3 1print('안녕하세요') 안녕하세요 1print(\"반갑습니다\") 반갑습니다 1234print('''안녕하세요,반갑습니다.''') 안녕하세요, 반갑습니다. 2. 변수와 대입 2-1. 변수의 이름 【가능한 경우】 case 1. 알파벳 1a = 1 1A = 1 case 2. 알파벳 + 숫자 1a1 = 1 case 3. 알파벳 + 언더바(_) 1a_ = 1 case 4. 언더바(_) + 알파벳 1_a = 1 【불가한 경우】 case 1. 언더바(_)를 제외한 특수문자 1* = 1 File \"&lt;ipython-input-23-6d0163a9fd4c&gt;\", line 1 * = 1 ^ SyntaxError: invalid syntax case 2. 알파벳 + 언더바를 제외한 특수문자 1a$ = 1 File \"&lt;ipython-input-25-2501fc576aab&gt;\", line 1 a$ = 1 ^ SyntaxError: invalid syntax case 3. 변수의 이름 사이의 공백 1a b = 1 File \"&lt;ipython-input-26-2bab97d7970c&gt;\", line 1 a b = 1 ^ SyntaxError: invalid syntax 2-2. 변수의 대입 변수 값을 부여할 때 \"=\"를 사용한다 1a = 1 2-3. 변수의 출력 print() 구문 사이에 값을 직접 입력하면, 바로 값이 출력됨. 1print(123) # 숫자는 \"\" 필요없음 123 1print(\"text\") # 문자는 \"\" 필요함 text print()구분 사이에 변수 이름을 입력하면, 변수의 값이 출력됨. 12a = 123print(a) 123 12b = \"text\"print(b) text 3. 데이터 타입 데이터 type: 1. int(정수) 2. float(실수) 3. str(문자열) 4. bool(참/거짓) 3-1. int(정수) 1a = 1 1type(a) int 1print(a) 1 코딩에서 1은 참으로 취급, 0은 거짓으로 취급 다음 코딩으로 진단해보자: 1234if 1: print('1은 참으로 취급')else: print('1은 거짓부렁이') 1은 참으로 취급 1234if 0: print('0은 참으로 취급')else: print('0은 거짓부렁이') 0은 거짓부렁이 1234if 123: print('123은 참으로 취급')else: print('123은 거짓부렁이') 123은 참으로 취급 [0 이외의 정수 다 참으로 취급] 3-2. float(실수) 1a = 3.14 1type(a) float 1print(a) 3.14 3-3. str 혹은 object (문자열) 문자열은 반드시 ’ ’ 혹은 \" \" 로 묶어야 함 1word = '안녕하세요' 1type(word) str 1print(word) 안녕하세요 1word = \"안녕하세요\" 1type(word) str 1print(word) 안녕하세요 ’\" \"’ 를 사용하면 출력시 “줄 바꿈” 형식이 보류될 수 있음 1234print('''안녕하세요,반갑습니다.''') 안녕하세요, 반갑습니다. 3-4. bool (참/거짓) 참: True 거짓: False 1a = True 1a True 1type(a) bool 1b = False 1b False 1type(b) bool 11 == True True 10 == False True 1123 == True False 1 이외의 정수는 조건절에서 참으로 인식되지만, bool과 비교할 때 참이 아니다 3-5. 아무것도 아닌 None타입도 있다 Null값을 넣는다고도 한다. Null: Nullify (무효화하다) – 사전상 의미 Python에서는 None 입니다 1a = None 1print(a) None 1type(a) NoneType 조건문에 None이라면? 1234if None: print(\"None은 참으로 취급\")else: print(\"None은 거짓부렁이\") None은 거짓부렁이 4. 데이터의 응용 4-1. 사칙 연산자 연산자 의미 예 + 더하기 2 + 1 -&gt; 3 - 빼기 1 - 2 -&gt; -1 * 곱하기 1 * 2 -&gt; 2 / 나누기 1 / 2 -&gt; 0.5 // 몫 5 // 2 -&gt; 2 % 나머지 5 % 2 -&gt; 1 ** 멱 2**3 -&gt; 8 4-2. 문자열의 연결 여러 개 문자열을 \"+\"을 통해 연결할 수 있다 12345subject = \"나는 \"object = \"치킨을 \"verb = \"좋아한다\"print(subject + object + verb) 나는 치킨을 좋아한다 하지만 문자열(str)과 숫자(int &amp; float)는 직접 연결할 수 없다 1234567a = \"내가 \"b = \"친구랑 \"c = 12d = \"시에 \"e = \"보기로 했다\"print(a + b + c + d + e) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-82-34cd0f9ce519&gt; in &lt;module&gt; 5 e = \"보기로 했다\" 6 ----&gt; 7 print(a + b + c + d + e) TypeError: can only concatenate str (not \"int\") to str 이 때는 데이터 타입을 변환할 필요가 있다 5. 데이터 타입 변환 5-1. 문자열로 변환: “str( ) 함수” or “따움표” 1type(6) int 1type(str(6)) str 1type('6') str 1type(3.14) float 1type(str(3.14)) str 1type(\"3.14\") str 12345a = \"내가 \"b = \"친구랑 \"c = 12d = \"시에 \"e = \"보기로 했다\" 1print(a + b + str(c) + d + e) 내가 친구랑 12시에 보기로 했다 1print(a + b + '12' + d + e)a 내가 친구랑 12시에 보기로 했다 5-2. 정수로 변환: \" int( ) 함수\" \"str\" --&gt; “int”: str( ) 안 내용이 정수일 때만 가능 1type(int(\"2\")) int 12number1 = \"2\"number2 = \"3\" 1print(int(number1) + int(number2)) 5 1print(int(\"2.6\")) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-103-f4645c45f771&gt; in &lt;module&gt; ----&gt; 1 print(int(\"2.6\")) ValueError: invalid literal for int() with base 10: '2.6' \"float\" --&gt; “int”: 소수점 버림 1type(int(3.6)) int 1print(int(3.6)) 3 5-3. 실수로 변환: “float( ) 함수” \"str\" --&gt; “float”: str( ) 안 내용이 정수일 때만 가능 1type(float(\"3.14\")) float 1print(float(\"3.14\")) 3.14 \"int\" --&gt; “float”: 소수점 하나 추가 1type(float(178)) float 1print(float(178)) 178.0 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"利用Git Pages+Hexo搭建博客过程中的参考资料","slug":"Reference","date":"2020-05-07T17:16:53.000Z","updated":"2020-06-24T04:14:29.783Z","comments":true,"path":"2020/05/08/Reference/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/08/Reference/","excerpt":"","text":"博客搭建 bilibili — 超简单易懂的Git入门教程 bilibili — github+hexo搭建个人博客 bilibili — github博客搭建（二）：Markdown语法及hexo主题修改 Git Pages + Jekyll/Hexo搭建自己的博客(最全总结你想知道的都在这里了) 网页配置 &amp; 主题配置 Hexo Usage Documents Hexo Themes default — [Demo] tomotoes — [Demo] / [Documents] Butterfly — [Demo] / [Documents] (应用中) Git Pages + Jekyll/Hexo搭建自己的博客(最全总结你想知道的都在这里了) Hexo主题升级方法（实用！） Markdown渲染 bilibili — github博客搭建（二）：Markdown语法及hexo主题修改 [字体修改方法(17:30)] Markdown在Hexo中的使用实例 [分割线，空行插入方法] Markdown渲染插件 hexo-renderer-markdown-it 插件 快速配置 hexo-renderer-markdown-it [Documents] hexo-renderer-markdown-it-plus （应用中） hexo-renderer-markdown 插入本地图片 markdown插入本地图片小技巧 typora + hexo博客中插入图片（应用中） 其他 记录网站访问量: 不蒜子 hexo博客解决不蒜子统计无法显示问题 设置博客评论： Gitalk申请页面 在个人博客里添加评论系统–Gitalk hexo 使用 gitalk 评论组件的几个注意点 多语言版本: Hexo 巧用 abbrlink 插件实现文章多语言版本 (既然没人帮我，那就)自己弄了个 Hexo 多语言 index 生成插件 更改tag大小写后出现404页面 Hexo 部署到 Github Pages 文件夹大小写问题 更改博客 Front Page 的默认配置 hexo博客Front-matter模板配置 Git &amp; Github bilibili — 【教程】学会Git玩转Github【全】 bilibili — 超简单易懂的Git入门教程 Git与Github的连接与使用 Git和GitHub使用教程 Jupyter Notebook bilibili — python数据分析神器Jupyter notebook快速入门 bilibili —【冷门教学】记笔记神器-jupyter notebook 第二弹 史上最详细、最完全的jupyter notebook使用教程，Python使用者必备！——ipython系列之三 机器学习新手必看：Jupyter Notebook入门指南 Jupyter notebook简介及嵌入Hexo博客中 用 Hexo 搭建个人博客-02：进阶试验（包括添加Jupyter Notebook支持的方法） 如何在你的Jupyter Notebook中使用R语言？ Markdown &amp; Typora bilibili — 二十分钟精通排版神器Markdown Typora官网 [Documents] Typora中下载并安装主题 bilibili — Typora 编辑器 —— 书写即为美学 bilibili — 【软件教程】如何用Typora记笔记？ | 附带Markdown基础教程 Typora设置（中文字体、颜色、行距、内边距等） Markdown中插入本地图片 markdown插入本地图片小技巧 typora + hexo博客中插入图片 HTML 表格样式 好看的table css样式 CSS 列表样式 HTML基础知识 table中 th, td, tr CSS如何设置html table表格边框样式 CSS如何设置表格中的字体大小 CSS padding 属性 [html/css] margin 속성 자세히 알아보기 漂亮的CSS表格样式 在此感谢所有提供了宝贵学习资料的原po主们~ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://hyemin-kim.github.io/tags/Hexo/"},{"name":"Typora","slug":"Typora","permalink":"https://hyemin-kim.github.io/tags/Typora/"},{"name":"Git","slug":"Git","permalink":"https://hyemin-kim.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://hyemin-kim.github.io/tags/Github/"},{"name":"Jupyter notebook","slug":"Jupyter-notebook","permalink":"https://hyemin-kim.github.io/tags/Jupyter-notebook/"}]},{"title":"在Hexo博文中添加本地图片的方法（基于Typora编辑器）","slug":"Hexo-Insert-local-images","date":"2020-05-06T12:20:48.531Z","updated":"2020-05-22T07:31:34.789Z","comments":true,"path":"2020/05/06/Hexo-Insert-local-images/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/06/Hexo-Insert-local-images/","excerpt":"当我们想在markdown文档中添加网络图片时，可以使用命令!['图片名称'](图片网络地址)进行实现，然而这条命令却不适用于添加本地图片。本文将介绍在使用Typora编辑器编辑Hexo博文时，向markdown文档中添加本地图片的方法。快来看看吧","text":"当我们想在markdown文档中添加网络图片时，可以使用命令!['图片名称'](图片网络地址)进行实现，然而这条命令却不适用于添加本地图片。本文将介绍在使用Typora编辑器编辑Hexo博文时，向markdown文档中添加本地图片的方法。快来看看吧 【编写博客前】— 进行配置 【编写博客时】— 图片导入方法 【编写博客后】— 图片存档结果 【编写博客前】— 进行配置 建立 资源文件夹(Asset Floder)，用来保存添加到博文中的本地图片 在本地Hexo根目录下的source文件夹中创建一个名为 images 的文件夹 在Typora中设置图片的相对路径 打开Typora的文件 &gt; 偏好设置 &gt; 图像，进行如下设置： 此设置会使source/images文件夹下新增一个与所编辑的markdown文档同名的文件夹，文档中所添加的 本地图片 都将存档于此（即拥有了如下路径：'hexo根目录'/source/images/'md文档名'/'图片名称'）)。 撰写markdown文档时配置 图片根目录 ，使其能够同步到hexo博客中去 撰写博文时，先点击Typora菜单栏中的格式 &gt; 图像 &gt; 设置图片根目录 , 将根目录配置为'hexo根目录'/source。然后再撰写博文。【注：每篇需要添加本地图片的博文都要先进行此步骤】 【编写博客时】— 图片导入方法 直接拖拽 将原本存放于其他本地文件夹中的图片直接拖拽到文档中的相应位置中去 此时图片会被自动存档至生成的同名文件夹'hexo根目录'/source/images/'md文档名'中 文档中图片地址的代码会显示成 自动生成的相对路径，即/images/'md文档名'/'图片名称' 利用相对路径调取 当利用 方法1 插入了至少一张图片时（即已生成同名文件夹时），便可以把接下来要插入的图片复制到此同名文件夹中，在文档中利用相对路径 调取图片： 所使用的命令是：![图片显示名称](/images/'md文档名'/'图片名称') 这里的图片显示名称不必与文件夹中保存的图片名称保持一致，'图片名称'中要记得包含图片格式（例如：tupian.jpg 或 picture.png 等） 【注意】当还没有利用 方法1 插入过图片时（即同名文件夹尚未生成时），不可以自己创建同名文件夹保存图片。亲测不好使！！（.md文档中可以显示，但是hexo博文中无法显示） 【编写博客后】— 图片存档结果 在利用上述方法完成了含有本地图片的markdown博文后，我们的资源文件夹'hexo根目录'/source/images/内最终会显示成什么样子呢？ 每一篇配置了图片根目录的博文（即【编写博客前】的第3步），都会在'hexo根目录'/source/images/文件夹中有一个与文档名称同名的文件夹'hexo根目录'/source/images/'md文档名' 该文件夹中会保存博文编写中曾经添加的所有本地图片 所有的含义是：即使编辑过程中某些本地图片在添加后又被删除了，它们也仍然会保留在文件夹中，即该文件夹会备份你在博文中添加的 所有本地图片历史 本地图片的含义是：这里只会保存插入的本地图片，而不会保存插入的网络图片。尽管在【编写博客前】的第2步配置中，我们也同样勾选了对网络位置的图片应用上述规则。（请原谅我并不知道其中的缘由。。） 就此，在Typora编辑器中编写Hexo博文时，向markdown文档中添加本地图片的方法就介绍完毕啦！快去应用到你的博文中去吧~ 本文参考了yinyoupoet的typora + hexo博客中插入图片 更多关于Typora中插入图片的内容可以参考Typora的官方说明 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://hyemin-kim.github.io/tags/Hexo/"},{"name":"Typora","slug":"Typora","permalink":"https://hyemin-kim.github.io/tags/Typora/"}]},{"title":"Markdown 常用语法（持续更新）","slug":"Markdown-Syntax","date":"2020-05-03T16:40:07.372Z","updated":"2020-05-22T16:16:06.234Z","comments":true,"path":"2020/05/04/Markdown-Syntax/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/04/Markdown-Syntax/","excerpt":"","text":"Markdown 常用语法 标题 一级标题： “#” + 空格 + “一级标题” 二级标题： “##” + 空格 + “二级标题” 三级标题： “###” + 空格 + “三级标题” …… 以此类推 【最多到6级】 换行 “内容” 末尾 + 2个空格 + Enter 斜体 方法一：“内容”前后加1个 * 号（无空格） 方法二：“内容”前后加1个下划线（无空格） *“内容” * ——&gt; “内容” _ “内容” _ ——&gt; 内容 加粗 方法一：“内容”前后加2个 * 号（无空格） 方法二：“内容”前后加2个下划线（无空格） ** “内容” ** ——&gt; \"内容\" __ “内容” __ ——&gt; “内容” 斜体加粗 “内容”前后加 3 个 * 号 （无空格） “内容” 删除线 ”内容”前后加 2 个波浪线（~） ~~ “内容” ~~ ——&gt; “内容” 高亮 “内容”前后加 2 个 = 号 == “内容” == ——&gt; “内容” 字体，颜色，字号 使用 font 标签 1&lt;font face='Microsift Yahei' color='red' size='6'&gt; 字体，颜色和字号 &lt;/font&gt; 字体，颜色和字号 上标 &amp; 下标 上标：“内容”前后加 1 个 ^ 号 下标：“内容”前后加 1 个 ~ 号 我是 ^ 上标 ^ ——&gt; 我是上标 我是 ~ 下标 ~ ——&gt; 我是下标 引用 “内容”前加 &gt; 号 “内容” 引用号可叠用，&gt;号越多，级数越低 例如：可以使用&gt;, &gt;&gt;, &gt;&gt;&gt; 的形式 一级引用 二级引用 三级引用 文字内容对齐设置 1. 使用div标签： 1&lt;div style=\"text-align: right\"&gt;your-text-here&lt;/div&gt; 居左 居中 居右 2. 使用p标签：(在Jupyter Notebook中不适用) 居中：&lt;center&gt; 内容 &lt;/center&gt; 居左/居右：&lt;p align='left'&gt; 内容 &lt;/p&gt; 居左 居中 居右 插入链接 ​ 中括号内输入“显示的文字”，紧接着小括号内输入“网址链接” ​ 【注意：网站地址需要 http 开头，最好直接复制】 点我进入百度 插入图片 ​ 感叹号 + 中括号内输入“显示的文字”，紧接着小括号内输入“图片链接” ​ 【注意：图片链接非网页的网址栏链接，而是右键“复制图片地址”得到的链接 (Chrome)】 调整图片大小： 1&lt;img src=\"链接\" width=\"宽度(数字or百分比)\" height=\"高度\" alt=\"图片名称\" align=center/left/right&gt; 列表 （1） 有序列表 ​ （序号1+点+空格）+内容+回车 ​ （序号2+点+空格）+内容+回车 ​ （序号3+点+空格）+内容+回车 第一行 第二行 第三行 ​ 【注意】：系统会默认调整有序列表的序列数。即，即使你误输入成了1.，2.，4.，系统也会自动更正为 1.，2.，3. 第一点 第二点 第四点 （2）无序列表 ​ 使用“ + ”+空格+内容 ​ ​ 或者“ - ”+空格+内容 ​ ​ 或者“ * ”+空格+内容 ​ 下一级：前面加 tab 第一章 第二章 第三章 第一节 （3）任务列表 ​ 短横线 + 1 个空格 + 中括号（括号中间带 1 个空格） + 1 个空格 + “内容” [x] 学习python [ ] 学习SQL 添加表格 竖线作为列分界线，换行竖线中间输入短横线作为行分界线 1 2 3 a b c d e f 代码 三个 ` 号，再输入所使用的编程语言 1print(\"Python\") # python 1install.packages(\"ggplot2\") # R语言 插入目录 [Only for Typora] 中括号内输入toc In Hexo: @[toc] (在使用hexo-renderer-markdown-it-plus插件时) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"}]}],"categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"},{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"앙상블","slug":"앙상블","permalink":"https://hyemin-kim.github.io/tags/%EC%95%99%EC%83%81%EB%B8%94/"},{"name":"회귀","slug":"회귀","permalink":"https://hyemin-kim.github.io/tags/%ED%9A%8C%EA%B7%80/"},{"name":"분류","slug":"분류","permalink":"https://hyemin-kim.github.io/tags/%EB%B6%84%EB%A5%98/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Seaborn","slug":"Seaborn","permalink":"https://hyemin-kim.github.io/tags/Seaborn/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"사각화","slug":"사각화","permalink":"https://hyemin-kim.github.io/tags/%EC%82%AC%EA%B0%81%ED%99%94/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"},{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://hyemin-kim.github.io/tags/Hexo/"},{"name":"Typora","slug":"Typora","permalink":"https://hyemin-kim.github.io/tags/Typora/"},{"name":"Git","slug":"Git","permalink":"https://hyemin-kim.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://hyemin-kim.github.io/tags/Github/"},{"name":"Jupyter notebook","slug":"Jupyter-notebook","permalink":"https://hyemin-kim.github.io/tags/Jupyter-notebook/"}]}