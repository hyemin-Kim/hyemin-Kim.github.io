{"meta":{"title":"Hyemin Kim","subtitle":"김혜민 / 金慧敏","description":"","author":"Hyemin Kim","url":"https://hyemin-kim.github.io","root":"/"},"pages":[{"title":"","date":"2020-05-04T18:01:24.474Z","updated":"2020-05-04T18:01:24.474Z","comments":false,"path":"about/index.html","permalink":"https://hyemin-kim.github.io/about/index.html","excerpt":"","text":"Hello document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"","date":"2020-05-20T10:31:42.690Z","updated":"2020-05-04T13:34:00.910Z","comments":false,"path":"categories/index - default.html","permalink":"https://hyemin-kim.github.io/categories/index%20-%20default.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"Links","date":"2020-05-20T08:53:04.000Z","updated":"2020-05-21T11:40:00.304Z","comments":false,"path":"link/index.html","permalink":"https://hyemin-kim.github.io/link/index.html","excerpt":"","text":"Some Useful Links Github Hexo Themes Hexo Usage Hexo Plugins document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"Categories","date":"2020-04-30T15:00:00.000Z","updated":"2020-05-21T11:27:57.020Z","comments":false,"path":"categories/index.html","permalink":"https://hyemin-kim.github.io/categories/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"Tag Cloud","date":"2020-04-30T15:00:00.000Z","updated":"2020-05-21T14:01:11.233Z","comments":false,"path":"tags/index.html","permalink":"https://hyemin-kim.github.io/tags/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"tagcloud","date":"2020-05-08T05:30:56.000Z","updated":"2020-05-08T05:34:14.280Z","comments":false,"path":"tagcloud/index.html","permalink":"https://hyemin-kim.github.io/tagcloud/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"","date":"2020-05-20T08:48:36.782Z","updated":"2020-05-04T13:34:13.986Z","comments":false,"path":"tags/index - default.html","permalink":"https://hyemin-kim.github.io/tags/index%20-%20default.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"}],"posts":[{"title":"【실습】 Python >> Text Mining -- 감성 분류 분석 (호텔 리뷰 데이터)","slug":"E-Python-TextMining-2","date":"2020-08-29T14:01:54.000Z","updated":"2020-08-29T15:07:50.847Z","comments":true,"path":"2020/08/29/E-Python-TextMining-2/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/29/E-Python-TextMining-2/","excerpt":"","text":"【Text Mining 실습】 – 호텔 리뷰 데이터: 감성 분류 &amp; 긍정/부정 키워드 분석 0. 개요 1. Library &amp; Data Import 2. 데이터셋 살펴보기 3. 한국어 텍스트 데이터 전처리 3-0. konlpy 설치 3-1. 정규 표현식 적용 3-2. 한국어 형태소 분석 - 명사 단위 3-3. 불용어 사전 3-4. Word Count 3-5. TF-IDF 적용 4. 감성 분류 – Logistic Regression 4-1. 데이터셋 생성 4-2. Training set / Test set 나누기 4-3. 모델 학습 4-4. 샘플링 재조정 4-5. 모델 재학습 5. 긍정 / 부정 키워드 분석 0. 개요 제주 호텔의 리뷰 데이터(평가 점수 + 평가 내용)을 활용해 다음 2가지 분석을 진행합니다: 리뷰속에 담긴 사람의 긍정 / 부정 감성을 파악하여 분류할 수 있는 감성 분류 예측 모델을 만든다 만든 모델을 활용해 긍정 / 부정 키워드를 출력해, 이용객들이 느낀 제주 호텔의 장,단점을 파악한다 1. Library &amp; Data Import &gt;&gt; 사용할 Library 123456789%matplotlib inlineimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport warningswarnings.filterwarnings('ignore') &gt;&gt; 사용할 데이터셋 Tripadvisor 여행사이트에서 \"제주 호텔\"로 검색해서 나온 리뷰들을 활용합니다. (평점 &amp; 평가 내용 포함) 1df = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/tripadviser_review.csv\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating text 0 4 여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다. 위치선정 또한 적당한 ... 1 4 2일 이상 연박시 침대, 이불, 베게등 침구류 교체 및 어메니티 보강이 필요해 보입... 2 4 지인에소개로온 호텔 깨끗하고 좋은거같아요 처음에는 없는게 많아 많이 당황했는데 ... 3 5 방에 딱 들어서자마자 눈이 휘둥그레질정도로 이렇게 넓은 호텔 처음 와본 것 같아요!... 4 5 저녁에 맥주한잔 하는게 좋아서 렌트 안하고 뚜벅이 하기로 했는데 호텔 바로 앞에 버... &gt;&gt; Feature Description rating: 이용자 리뷰의 평가 점수 (1~5) text: 이용자 리뷰 평가 내용 2. 데이터셋 살펴보기 12# dimensiondf.shape (1001, 2) 12# 결측치df.isnull().sum() rating 0 text 0 dtype: int64 12# informationdf.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 1001 entries, 0 to 1000 Data columns (total 2 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 rating 1001 non-null int64 1 text 1001 non-null object dtypes: int64(1), object(1) memory usage: 15.8+ KB 123# text 변수 확인df['text'][0] '여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다. 위치선정 또한 적당한 편이었고 청소나 청결상태도 좋았습니다.' 1df['text'][100] '올 봄에 벚꽃기간에 방문, 협재를 바라보는 바다뷰가 좋고 대로변이라 렌트해서 가기도 좋음. 조식은 이용안했는데 근처 옹포밥집까지 아침 산책겸 걸어가서 하고옴. 루프탑 수영장과 바가 있었는데 내가 갔을때는 밤에 비바람이 너무 불어서 이용못하고옴 ㅠㅠ 단점으로는 모 유명 여행블로거 리뷰처럼 화장실 물떄가... 그거빼곤 다 만족' “text” 내용을 확인해보면, 소량의 \"특수 문자\"와 \"모음\"이 존재하는 경우가 있습니다. 이들은 Text Mining을 적용할 의미가 없기 때문에 정규표현식을 이용해서 제거해보도록 할게요. 3. 한국어 텍스트 데이터 전처리 기계가 텍스트 형식으로 되어 있는 리뷰 데이터를 이해하려면, 텍스트 데이터를 단어 단위로 분리하는 전처리 괴정이 필요합니다. 여기서 분리된 단어들은 Bag of Words로 Count 기반으로 나타날 수도 있고, TF-IDF를 통해서 점수로 나타날 수도 있습니다. 먼저 리뷰의 평가 내용을 단어화해서 형태소를 추출하고, 그 다음 Bag of Words를 생성하여 TF-IDF 변환을 진행하겠습니다. 3-0. konlpy 설치 영문이 아닌 한글을 처리해야 하기 때문에 \"konlpy\"이라는 library를 사용합니다. 참고 자료: 파이썬 한글 형태소 분석기 KoNLPy 설치방법 및 에러해결 KoNLPy 홈메이지 – 설치하기 [Anaconda에서 KoNLPy 설치하기] 삽질은 이제 그만~ 1!pip install konlpy==0.5.2 jpype1 Jpype1-py3 Requirement already satisfied: konlpy==0.5.2 in d:\\anaconda\\lib\\site-packages (0.5.2) Requirement already satisfied: jpype1 in d:\\anaconda\\lib\\site-packages (1.0.2) Requirement already satisfied: Jpype1-py3 in d:\\anaconda\\lib\\site-packages (0.5.5.4) Requirement already satisfied: tweepy&gt;=3.7.0 in d:\\anaconda\\lib\\site-packages (from konlpy==0.5.2) (3.9.0) Requirement already satisfied: lxml&gt;=4.1.0 in d:\\anaconda\\lib\\site-packages (from konlpy==0.5.2) (4.5.0) Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from konlpy==0.5.2) (0.4.3) Requirement already satisfied: numpy&gt;=1.6 in d:\\anaconda\\lib\\site-packages (from konlpy==0.5.2) (1.18.1) Requirement already satisfied: beautifulsoup4==4.6.0 in d:\\anaconda\\lib\\site-packages (from konlpy==0.5.2) (4.6.0) Requirement already satisfied: typing-extensions; python_version &lt; \"3.8\" in d:\\anaconda\\lib\\site-packages (from jpype1) (3.7.4.1) Requirement already satisfied: requests[socks]&gt;=2.11.1 in d:\\anaconda\\lib\\site-packages (from tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (2.23.0) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in d:\\anaconda\\lib\\site-packages (from tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (1.3.0) Requirement already satisfied: six&gt;=1.10.0 in d:\\anaconda\\lib\\site-packages (from tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (1.14.0) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (2020.6.20) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (1.25.8) Requirement already satisfied: idna&lt;3,&gt;=2.5 in d:\\anaconda\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (2.9) Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6; extra == \"socks\" in d:\\anaconda\\lib\\site-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (1.7.1) Requirement already satisfied: oauthlib&gt;=3.0.0 in d:\\anaconda\\lib\\site-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy&gt;=3.7.0-&gt;konlpy==0.5.2) (3.1.0) 3-1. 정규 표현식 적용 12345678# 정규 표현식 함수 정의import redef apply_regular_expression(text): hangul = re.compile('[^ ㄱ-ㅣ 가-힣]') # 한글 추출 규칙: 띄어 쓰기(1 개)를 포함한 한글 result = hangul.sub('', text) # 위에 설정한 \"hangul\"규칙을 \"text\"에 적용(.sub)시킴 return result 만들어 놓은 정규 표현식을 \"text\"의 첫 행에 적용해서 결과 한번 확인해볼게요. 1df['text'][0] '여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다. 위치선정 또한 적당한 편이었고 청소나 청결상태도 좋았습니다.' 1apply_regular_expression(df['text'][0]) '여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다 위치선정 또한 적당한 편이었고 청소나 청결상태도 좋았습니다' 정규 표현식을 적용한 후 특수 문자가 잘 제거된 것을 확인할 수 있습니다. 3-2. 한국어 형태소 분석 - 명사 단위 &gt;&gt; 명사 형태소 추출 참고 자료: konlpy.tag 패키지 Documentation 12from konlpy.tag import Oktfrom collections import Counter 명사 형태소 추출 함수 Okt() 를 이용하여 정규표현식을 적용한 “text” 첫 행 내용의 형태소를 추출해 보겠습니다. 1apply_regular_expression(df['text'][0]) '여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다 위치선정 또한 적당한 편이었고 청소나 청결상태도 좋았습니다' 123okt = Okt() # 명사 형태소 추출 함수nouns = okt.nouns(apply_regular_expression(df['text'][0]))nouns ['여행', '집중', '휴식', '제공', '호텔', '위치', '선정', '또한', '청소', '청결', '상태'] 이제 이를 전체 말뭉치(corpus)에 적용해서 명사 형태소를 추출해볼게요. 123# 말뭉치 생성corpus = \"\".join(df['text'].tolist())corpus [메모리 부족으로 부분만 보여줌] '여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다. 위치선정 또한 적당한 편이었고 청소나 청결상태도 좋았습니다.2일 이상 연박시 침대, 이불, 베게등 침구류 교체 및 어메니티 보강이 필요해 보입니다. 베스트 웨스턴 회원의 경우 객실 뷰와 층수 요청에 적극적으로 반영해 주시길 바랍니다.지인에소개로온 호텔 깨끗하고 좋은거같아요 처음에는 없는게 많아 많이 당황했는데 알고오시면 좋을거같아요 (세면도구와 잠옷은필수로챙기셔야해용) 그것만챙겨오시면 잘쉬었다가실수있답니당방에 딱 들어서자마자 눈이 휘둥그레질정도로 이렇게 넓은 호텔 처음 와본 것 같아요!! 다음에도 제주도 오면 꼭 여기서 지낼겁니다ㅎㅎ 1박만 머문다는게 너무 아쉽네요ㅠㅠ저녁에 맥주한잔 하는게 좋아서 렌트 안하고 뚜벅이 하기로 했는데 호텔 바로 앞에 버스정류이 있어서 너무 좋았습니다. 12시에 도착해서 가방 맡기려 했는데 일찍 정비된방이 있다며 바로 입실하고 룸도 업그레이드 해주셔서 직원분이 친절해 정말 좋았어요^^바다전망이라해서 기대했는데 영아니네요.. 전일 함덕대명콘도에서 1박했는데 그곳이 실내 분위기랑 바다전망이 훨 좋아요..손님이 없는 날이라고 가장 바다가 이쁘게 보이는 방으로 배치해 주셨다. 불편함에 대해 바로 대응 써비스 해주었고 조식도 사소한 부분까지 신경써서 아주 맛있었다. 특급 호텔은 아니지만 트랜디하고 즐거운 다양함에 대해 고민한 흔적이 였보인다. 여름에 꼭와서 수영장을 사용해 보고 싶다 ~ !엄마와 둘이 여행왔다가 가격대비 좋다고 하여 다녀왔어요 ㅎㅎ 듣던대로 깔끔했고 위치도 너무 좋았어요 주위 마트 식당들 동문시장도 가까워서 좋았고 앞에 바다가 있어서 더 좋았습니다 ㅎㅎ 또 방문의사 있어요 ~딸 둘과의 4일동안의 제주여행줌 2박 숙소로 정해진 제주 휘슬락 호텔~ 처음엔 공항과 가까운 곳으로만 생각했으나 시설도 넘 깨끗하고 직원분들도 모두 친절모드로 제주여행의 마지막을 넘넘 좋게 마무리하고 돌아가네요~~^^ 테라스에서 보이는 전경도 넘 멋지네요♡ 인근 동문재래시장도 가까워 야시장 이용도하고 너무너무 잘다녀왔어요. 다음에 또 이용할께요.제주여행 2일차!!! 호텔 휘슬락에 체크인 ㄱㄱㄱ. 뷰 기가막힙니다... 깨끗하고요~~ 주변에 갈데 많습니다. 여친과 잊지못할 추억 만들어봅니다^^ 좋은 가성비에 분위기 나쁘지않네요 추천 드립니다. 후회없으실듯!!!예전에 그랜드 호텔일 때 저희 아이 돌잔치를 여기 삼다정에서 했었더랬죠. 제주도에서는 아주 전통있는 호텔입니다. 그 후로 메종 글래드로 업그레이드 되었는데, 위치, 시설, 서비스에 비해 매우 합리적인 가격대의 만족스러운 호텔입니다. 그래서 저희는 명절에 제주도 내려오면 늘 글래드에 숙박해요. 특히 1층에 아티제와 백미당이 있어서, 여기 커피와 베이커리를 좋아하는 저희 가족에게는 플러스예요.지금까지 제주여행을 다니면서 여러호텔을 이용해보았지만, 메종 글래드에서 가장 만족스러웠습니다. 우선 공항의 접근성과 쇼핑의 편리함 그리고 조식의만족도가 최고이며 무엇보다 직원분들의 친절함이 기억에 남습니다. 앞으로 우리가족은 제주에 갈땐 메종을 찾기로했답니다.엄마랑 첫 제주도 여행인데 침구가 너무 좋았고, 직원분들도 친절하셔서 편안하게 쉬고 왔습니다. 교통도 편해서 짧은 여행이었지만 알차게 볼 수 있었도요. 3층에서 이틀 묵었었는데 정원 같은 곳이 바로 보여서 이뻤어요. 거기 돌아다니니까 수영장도 2개 있었는데 겨울이라 못써서 아쉬웠습니다 ㅠㅠ 여름에 꼭 여기 오려구요!! ㅎㅎㅎ 추천합니다~~친구가 제주도에 놀러와서 투숙을 하였는데 객실이 깔끔하고 뷰도 좋았어요. 야외 수영장이 보이는 방향이었는데 야간에는 조명을 켜서 너무 예쁘더라구요. 체크인하러 가는 그 순간조차도 벨맨에게 대접을 받았습니다. 왠만하면 실명을 거론하지 않는데 프론트에 문J.. 이름이 기억이 안나지만 체크인이 너무 친절해서 기분이 좋았습니다. 웃는 모습이 너무 선하고 밝아서 여행 첫날부터 스타트가 좋았네요. 다음에 투숙을 할 경우가 생긴다면 또 다시 이용할거에요~!!차를 좋아하는 아이들에게는 최고의 선물~~ 카운터에서 친절하게 안내해주셔서 편하게 이용하고 왔어요~~ 삼다정 디너 최고입니다. 기회가 되면 여름에 또 오고 싶네요~~직원분들은 눈만 마주쳐도 도와주려고 할 정도로 엄청 친절. 미니바 무료도 굿. 시설은 최근 지어진거라 당연 청결. 주변에 관광지도 가까운곳이 많음. 제주여행숙고소 강추~~ 내가 숙은 위치에서 찍은 야경뷰조식조타하여 일부러 저녁 많이 안 먹고 일찍 일어나서 동네 한바퀴 돌아주고 씻고 나서 2층가서 먹방 했네요. 신라호텔보다 퀄리티 좋음신제주에 위치한 매우 깨끗한 호텔입니다. 특히 조식을 추천 드립니다. 구제주에 오래된 호텔에 비할 수 없는 기분 좋은 호텔이였습니다.모녀 여행 중 제주시 1박을 위해 선택한 호텔입니다. 우선 공항에서 가깝고 오픈한 지 얼만 안 된 것 같아 예약했습니다. 호텔은 대로변에 있어 접근성이 좋고 (호텔은 5~10분거리), 더군다나 공항까지 셔틀버스 운행합니다. 데스크 직원분들 매우 친절하시고 주차안내분도 친절하셔서 첫 인상이 좋았습니다. 룸은 트윈으로 했는데 생각보다 큰 방에 퀸 사이즈가 2개여서 ㅋㅋㅋㅋ 대만족이었습니다. 스타일러가 있어서 여행 중 입었던 옷 다 돌렸습니다. 조식은 가짓수가 많지는 않으나 있어야 될 것은 다 있는 느낌? 근데 화장실이 조명이 너무 어둡고 내부인테리어도 어두워서 ㅋㅋㅋ 그 외의 호텔 분위기와 매우 이질적입니다. (이건 개인적인 취향인 것 같네요) 어메니티도 구비되어 있는데 향이 독특합니다. ㅋㅋㅋ 실망한 부분은 여행 시 산 과일을 먹으려고 나이프와 포크 부탁했는데 서비스가 안되더라고요..그리고 차와 커피 준비된 부분이 빈약합니다. (어느 부분은 특급호텔 표방인 것 같고 어떤 부분은 모텔인 것 같은 ) 하지만 결론적으로 가성비 훌륭, 접근성 훌륭, 청결도 훌륭해서 엄마와 함께 쾌적한 시간을 보냈습니다. 감사합니다.슈페리어킹룸에 하루 숙박한 후기입니다. 제주여행의 마지막날 숙박했는데요 지은지 얼마 안 된 느낌의 새 건물 이었습니다. 건물 안 인테리어는 약간 유럽 스타일이었구요 그림이나 조각들이 생각보다 많아서 놀랐어요 복도랑 객실도 그림이 전시되어 있고 전부 카펫으로 되어 있었습니다. 객실은 비슷한 등급의 다른 호텔들보다 큰 편이었고 침대는 두 명이서 자기에 충분할 정도로 정말 컸습니다. 비가 오는 날이라 비를 조금 맞았는데 객실 내에 LG 스타일러가 있어서 외투를 돌렸더니 뽀송뽀송해져서 완전 만족 합니다!! 진짜 스타일러 강추!!!! 그리고 무료셔틀 이용했는데 공항까지 한 7분 정도 걸렸습니당! 셔틀은 운행하는 시간이 정해져 있는데 미리 예약 하셔야 이용 하실 수 있어요~~ 다음에 제주도 온다면 또 이용하고 싶은 호텔이네요~^^시티뷰이지만 오름도 볼 수 있고 무엇보다도 교통이 훌륭하였다 다만 바로 도로가인 관계로 밤에 차량 소리가 다소 신경쓰였다급하게 방문했는데 방도 깔끔하고 직원분들 모두 친절하셔서 좋았습니다~ 1층 편의점도 있어서 좋았어요~ 칫솔은 챙겨야합니다 ㅎㅎ 재방문 의사 있습니다동계훈련을 신제주로 오게 되었는데̄̈, 훈련 하는동안 라마다호텔에서 편하게 잘 쉬었다̆̎ 갑니다̆̎! 가족과 연인과 함께 와도 좋을 것 같아요̆̈! 조식도 괜찮고 전체적으로 깔끔하고 편리하게 되어있네요̆̈ ◡̈⋆ 사진이 너무 많아 첨부하진 못했지만, 엘리베이터 가는̆̈ 곳 쪽에 빔으로 실시간 비행기 시간을 알려줘서 너무 편하고 신기했어요̆̈! 12# 정규 표현식 적용apply_regular_expression(corpus) [메모리 부족으로 부분만 보여줌] '여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다 위치선정 또한 적당한 편이었고 청소나 청결상태도 좋았습니다일 이상 연박시 침대 이불 베게등 침구류 교체 및 어메니티 보강이 필요해 보입니다 베스트 웨스턴 회원의 경우 객실 뷰와 층수 요청에 적극적으로 반영해 주시길 바랍니다지인에소개로온 호텔 깨끗하고 좋은거같아요 처음에는 없는게 많아 많이 당황했는데 알고오시면 좋을거같아요 세면도구와 잠옷은필수로챙기셔야해용 그것만챙겨오시면 잘쉬었다가실수있답니당방에 딱 들어서자마자 눈이 휘둥그레질정도로 이렇게 넓은 호텔 처음 와본 것 같아요 다음에도 제주도 오면 꼭 여기서 지낼겁니다ㅎㅎ 박만 머문다는게 너무 아쉽네요ㅠㅠ저녁에 맥주한잔 하는게 좋아서 렌트 안하고 뚜벅이 하기로 했는데 호텔 바로 앞에 버스정류이 있어서 너무 좋았습니다 시에 도착해서 가방 맡기려 했는데 일찍 정비된방이 있다며 바로 입실하고 룸도 업그레이드 해주셔서 직원분이 친절해 정말 좋았어요바다전망이라해서 기대했는데 영아니네요 전일 함덕대명콘도에서 박했는데 그곳이 실내 분위기랑 바다전망이 훨 좋아요손님이 없는 날이라고 가장 바다가 이쁘게 보이는 방으로 배치해 주셨다 불편함에 대해 바로 대응 써비스 해주었고 조식도 사소한 부분까지 신경써서 아주 맛있었다 특급 호텔은 아니지만 트랜디하고 즐거운 다양함에 대해 고민한 흔적이 였보인다 여름에 꼭와서 수영장을 사용해 보고 싶다 엄마와 둘이 여행왔다가 가격대비 좋다고 하여 다녀왔어요 ㅎㅎ 듣던대로 깔끔했고 위치도 너무 좋았어요 주위 마트 식당들 동문시장도 가까워서 좋았고 앞에 바다가 있어서 더 좋았습니다 ㅎㅎ 또 방문의사 있어요 딸 둘과의 일동안의 제주여행줌 박 숙소로 정해진 제주 휘슬락 호텔 처음엔 공항과 가까운 곳으로만 생각했으나 시설도 넘 깨끗하고 직원분들도 모두 친절모드로 제주여행의 마지막을 넘넘 좋게 마무리하고 돌아가네요 테라스에서 보이는 전경도 넘 멋지네요 인근 동문재래시장도 가까워 야시장 이용도하고 너무너무 잘다녀왔어요 다음에 또 이용할께요제주여행 일차 호텔 휘슬락에 체크인 ㄱㄱㄱ 뷰 기가막힙니다 깨끗하고요 주변에 갈데 많습니다 여친과 잊지못할 추억 만들어봅니다 좋은 가성비에 분위기 나쁘지않네요 추천 드립니다 후회없으실듯예전에 그랜드 호텔일 때 저희 아이 돌잔치를 여기 삼다정에서 했었더랬죠 제주도에서는 아주 전통있는 호텔입니다 그 후로 메종 글래드로 업그레이드 되었는데 위치 시설 서비스에 비해 매우 합리적인 가격대의 만족스러운 호텔입니다 그래서 저희는 명절에 제주도 내려오면 늘 글래드에 숙박해요 특히 층에 아티제와 백미당이 있어서 여기 커피와 베이커리를 좋아하는 저희 가족에게는 플러스예요지금까지 제주여행을 다니면서 여러호텔을 이용해보았지만 메종 글래드에서 가장 만족스러웠습니다 우선 공항의 접근성과 쇼핑의 편리함 그리고 조식의만족도가 최고이며 무엇보다 직원분들의 친절함이 기억에 남습니다 앞으로 우리가족은 제주에 갈땐 메종을 찾기로했답니다엄마랑 첫 제주도 여행인데 침구가 너무 좋았고 직원분들도 친절하셔서 편안하게 쉬고 왔습니다 교통도 편해서 짧은 여행이었지만 알차게 볼 수 있었도요 층에서 이틀 묵었었는데 정원 같은 곳이 바로 보여서 이뻤어요 거기 돌아다니니까 수영장도 개 있었는데 겨울이라 못써서 아쉬웠습니다 ㅠㅠ 여름에 꼭 여기 오려구요 ㅎㅎㅎ 추천합니다친구가 제주도에 놀러와서 투숙을 하였는데 객실이 깔끔하고 뷰도 좋았어요 야외 수영장이 보이는 방향이었는데 야간에는 조명을 켜서 너무 예쁘더라구요 체크인하러 가는 그 순간조차도 벨맨에게 대접을 받았습니다 왠만하면 실명을 거론하지 않는데 프론트에 문 이름이 기억이 안나지만 체크인이 너무 친절해서 기분이 좋았습니다 웃는 모습이 너무 선하고 밝아서 여행 첫날부터 스타트가 좋았네요 다음에 투숙을 할 경우가 생긴다면 또 다시 이용할거에요차를 좋아하는 아이들에게는 최고의 선물 카운터에서 친절하게 안내해주셔서 편하게 이용하고 왔어요 삼다정 디너 최고입니다 기회가 되면 여름에 또 오고 싶네요직원분들은 눈만 마주쳐도 도와주려고 할 정도로 엄청 친절 미니바 무료도 굿 시설은 최근 지어진거라 당연 청결 주변에 관광지도 가까운곳이 많음 제주여행숙고소 강추 내가 숙은 위치에서 찍은 야경뷰조식조타하여 일부러 저녁 많이 안 먹고 일찍 일어나서 동네 한바퀴 돌아주고 씻고 나서 층가서 먹방 했네요 신라호텔보다 퀄리티 좋음신제주에 위치한 매우 깨끗한 호텔입니다 특히 조식을 추천 드립니다 구제주에 오래된 호텔에 비할 수 없는 기분 좋은 호텔이였습니다모녀 여행 중 제주시 박을 위해 선택한 호텔입니다 우선 공항에서 가깝고 오픈한 지 얼만 안 된 것 같아 예약했습니다 호텔은 대로변에 있어 접근성이 좋고 호텔은 분거리 더군다나 공항까지 셔틀버스 운행합니다 데스크 직원분들 매우 친절하시고 주차안내분도 친절하셔서 첫 인상이 좋았습니다 룸은 트윈으로 했는데 생각보다 큰 방에 퀸 사이즈가 개여서 ㅋㅋㅋㅋ 대만족이었습니다 스타일러가 있어서 여행 중 입었던 옷 다 돌렸습니다 조식은 가짓수가 많지는 않으나 있어야 될 것은 다 있는 느낌 근데 화장실이 조명이 너무 어둡고 내부인테리어도 어두워서 ㅋㅋㅋ 그 외의 호텔 분위기와 매우 이질적입니다 이건 개인적인 취향인 것 같네요 어메니티도 구비되어 있는데 향이 독특합니다 ㅋㅋㅋ 실망한 부분은 여행 시 산 과일을 먹으려고 나이프와 포크 부탁했는데 서비스가 안되더라고요그리고 차와 커피 준비된 부분이 빈약합니다 어느 부분은 특급호텔 표방인 것 같고 어떤 부분은 모텔인 것 같은 하지만 결론적으로 가성비 훌륭 접근성 훌륭 청결도 훌륭해서 엄마와 함께 쾌적한 시간을 보냈습니다 감사합니다슈페리어킹룸에 하루 숙박한 후기입니다 제주여행의 마지막날 숙박했는데요 지은지 얼마 안 된 느낌의 새 건물 이었습니다 건물 안 인테리어는 약간 유럽 스타일이었구요 그림이나 조각들이 생각보다 많아서 놀랐어요 복도랑 객실도 그림이 전시되어 있고 전부 카펫으로 되어 있었습니다 객실은 비슷한 등급의 다른 호텔들보다 큰 편이었고 침대는 두 명이서 자기에 충분할 정도로 정말 컸습니다 비가 오는 날이라 비를 조금 맞았는데 객실 내에 스타일러가 있어서 외투를 돌렸더니 뽀송뽀송해져서 완전 만족 합니다 진짜 스타일러 강추 그리고 무료셔틀 이용했는데 공항까지 한 분 정도 걸렸습니당 셔틀은 운행하는 시간이 정해져 있는데 미리 예약 하셔야 이용 하실 수 있어요 다음에 제주도 온다면 또 이용하고 싶은 호텔이네요시티뷰이지만 오름도 볼 수 있고 무엇보다도 교통이 훌륭하였다 다만 바로 도로가인 관계로 밤에 차량 소리가 다소 신경쓰였다급하게 방문했는데 방도 깔끔하고 직원분들 모두 친절하셔서 좋았습니다 층 편의점도 있어서 좋았어요 칫솔은 챙겨야합니다 ㅎㅎ 재방문 의사 있습니다동계훈련을 신제주로 오게 되었는데 훈련 하는동안 라마다호텔에서 편하게 잘 쉬었다 갑니다 가족과 연인과 함께 와도 좋을 것 같아요 조식도 괜찮고 전체적으로 깔끔하고 편리하게 되어있네요 사진이 너무 많아 첨부하진 못했지만 엘리베이터 가는 곳 쪽에 빔으로 실시간 비행기 시간을 알려줘서 너무 편하고 신기했어요 123# 전체 말뭉치(corpus)에서 명사 형태소 추출nouns = okt.nouns(apply_regular_expression(corpus))print(nouns) ['여행', '집중', '휴식', '제공', '호텔', '위치', '선정', '또한', '청소', '청결', '상태', '일', '이상', '연', '침대', '이불', '등', '침구', '류', '교체', '및', '어메니티', '보강', '베스트', '웨스턴', '회원', '경우', '객실', '뷰', '층수', '요청', '적극', '반영', '지인', '소개', '온', '호텔', '거', '처음', '당황', '세면', '도구', '잠옷', '필수', '그것', '방', '눈', '정도', '호텔', '처음', '것', '다음', '제주도', '꼭', '여기', '박만', '저녁', '맥주', '한잔', '렌트', '안', '뚜벅', '호텔', '바로', '앞', '버스', '정류', '시', '도착', '가방', '일찍', '정비', '방이', '바로', '입실', '룸', '업그레이드', '직원', '정말', '바다', '전망', '영', '전일', '함덕', '대명', '콘도', '곳', '실내', '분위기', '바다', '전망', '훨', '손님', '날', '가장', '바다', '방', '배치', '대해', '바로', '대응', '써비스', '조식', '부분', '신경', '아주', '특급', '호텔', '트랜디', '대해', '고민', '흔적', '여름', '꼭', '수영장', '사용', '보고', '엄마', '둘', '여행', '가격', '대비', '위치', '주위', '마트', '식당', '시장', '앞', '바다', '더', '또', '방문', '의사', '딸', '둘', '동안', '제주', '여행', '줌', '박', '숙소', '정해진', '제주', '휘슬', '락', '호텔', '처음', '공항', '곳', '생각', '시설', '직원', '모두', '친절', '모드', '여행', '마지막', '마무리', '테라스', '전경', '인근', '재래시장', '야시장', '이용도', '다음', '또', '이용', '제주', '여행', '일차', '호텔', '휘슬락', '체크', '뷰', '기', '주변', '여친', '추억', '가성', '비', '분위기', '추천', '후회', '예전', '그랜드', '호텔', '일', '때', '저희', '아이', '돌잔치', '여기', '다정', '했었더랬', '제주도', '아주', '전통', '호텔', '그', '후', '메종', '글래드', '업그레이드', '위치', '시설', '서비스', '매우', '합리', '가격', '대의', '호텔', '저희', '명절', '제주도', '늘', '글래드', '숙박', '층', '아티', '제', '백미', '여기', '커피', '베이커리', '저희', '가족', '플러스', '지금', '여행', '호텔', '이용', '메종', '글래드', '가장', '우선', '공항', '접근성', '쇼핑', '조식', '만족도', '최고', '무엇', '직원', '기억', '앞', '우리', '가족', '제주', '땐', '메종', '찾기', '엄마', '첫', '제주도', '여행', '침구', '직원', '쉬', '교통', '여행', '볼', '수', '도', '층', '이틀', '정원', '곳', '바로', '보', '거기', '수영장', '개', '겨울', '여름', '꼭', '여기', '추천', '친구', '제주도', '놀러와', '투숙', '객실', '뷰', '야외', '수영장', '방향', '야간', '조명', '체크', '그', '순간', '맨', '대접', '실명', '거론', '프론트', '문', '이름', '기억', '안나', '체크', '기분', '모습', '여행', '첫날', '스타트', '다음', '투숙', '경우', '또', '다시', '이용', '차', '아이', '최고', '선물', '카운터', '안내', '이용', '다정', '디너', '최고', '기회', '여름', '또', '직원', '눈', '정도', '친절', '미니바', '무료', '굿', '시설', '최근', '연', '청결', '주변', '관광지', '곳', '제주', '여행', '숙고', '소', '강추', '내', '숙', '위치', '야경', '뷰', '조식', '일부러', '저녁', '안', '일찍', '일어나서', '동네', '바퀴', '층', '먹방', '신라', '호텔', '퀄리티', '제주', '위치', '매우', '호텔', '조식', '추천', '제주', '호텔', '비', '수', '기분', '호텔', '모녀', '여행', '중', '제주시', '박', '위해', '선택', '호텔', '우선', '공항', '오픈', '얼', '안', '것', '예약', '호텔', '대로', '변', '접근성', '호텔', '분', '거리', '더군다나', '공항', '셔틀버스', '운행', '데스크', '직원', '매우', '차안', '분도', '첫', '인상', '룸', '트윈', '생각', '방', '퀸', '사이즈', '개', '만족', '스타', '여행', '중', '옷', '조식', '가짓수', '것', '느낌', '화장실', '조명', '내부', '인테리어', '그', '외', '호텔', '분위기', '매우', '질적', '이건', '개인', '취향', '것', '어메니티', '구비', '향', '부분', '여행', '시', '산', '과일', '나이프', '포크', '부탁', '서비스', '차', '커피', '준비', '부분', '부분', '특급', '호텔', '표방', '것', '부분', '모텔', '것', '결론', '가성', '비', '훌륭', '접근성', '훌륭', '청결', '엄마', '시간', '슈', '페리', '킹룸', '하루', '숙박', '후기', '여행', '마지막', '날', '숙박', '지은지', '얼마', '안', '느낌', '새', '건물', '건물', '안', '인테리어', '약간', '유럽', '스타일', '그림', '조각', '생각', '복도', '객실', '그림', '전시', '전부', '카펫', '객실', '등급', '다른', '호텔', '침대', '두', '명', '이서', '자기', '정도', '정말', '비', '날', '비', '조금', '객실', '내', '스타', '외투', '완전', '만족', '진짜', '스타', '강추', '무료', '셔틀', '이용', '공항', '분', '정도', '습', '셔틀', '운행', '시간', '미리', '예약', '이용', '수', '다음', '제주도', '또', '이용', '호텔', '시티', '뷰', '오름', '볼', '수', '무엇', '교통', '다만', '바로', '도로', '가인', '관계', '밤', '차량', '소리', '다소', '신경', '방문', '방도', '직원', '모두', '층', '편의점', '칫솔', '재', '방문', '의사', '동계', '훈련', '제주', '훈련', '동안', '라마', '호텔', '가족', '연인', '것', '조식', '전체', '사진', '첨부', '엘리베이터', '곳', '쪽', '빔', '실시간', '비행기', '시간', '공항', '택시', '미만', '택시', '비', '이동', '가능', '침구', '및', '룸', '상태', '최상', '욕실', '슬리퍼', '위생', '상태', '염려', '카펫', '염려', '설날', '조식', '떡국', '당황', '함', '떡국', '공항', '려고', '현장', '결재', '황스', '려운', '중국', '만두', '종류', '별로', '구만', '현장', '결재', '조식', '일', '메뉴', '답변', '첫', '도착', '제일', '첫', '주차', '걱정', '요', '할아버지', '안심', '객실', '컨디션', '최고', '조식', '문어', '처리', '최고', '닺', '회사', '출장', '차', '시설', '직원', '서울', '때', '이용', '다음', '또', '프론트', '방도', '간혹', '이벤트', '업그레이드', '해주시', '수영장', '및', '부대', '시설', '최고', '항상', '제주도', '때', '롯데', '롯데', '시티', '호텔', '제주', '비지니스', '호텔', '가족', '여행객', '손색', '객실', '욕조', '겸비', '사계절', '수풀', '무료', '이용', '층', '야외', '수영장', '중문', '표선등', '원거리', '여행지', '복귀', '후', '밤', '시', '수영장', '이용', '또한', '시내', '유명', '식당', '등', '방문', '아주', '일단', '공항', '분', '정도', '위치', '주차장', '지하', '층', '공간', '주차', '수', '체크', '때', '직원', '응대', '기분', '체크', '수', '다른', '문의사항', '신지', '감동', '습', '객실', '역시', '롯데', '생각', '정도', '풀', '장도', '이용', '수', '더', '옆', '락타', '룸', '샤워', '마련', '코인', '세탁실', '정말', '이용', '오션', '뷰', '멀리', '바다', '야경', '남자친구', '첫', '여행', '덕분', '여행', '습', '다음', '제주', '꼭', '방문', '이번', '제주도', '여행', '때', '롯데', '시티', '제주', '박', '숙박', '체크', '때', '프런트', '직원', '객실', '배정', '공항', '비행기', '이착륙', '객실', '객실', '클리닝', '인테리어', '호텔', '숙박', '근무', '청소', '아주머니', '인사', '기분', '다음', '번', '재', '방문', '코로나', '사태', '투숙', '직원', '투숙', '다만', '객', '실내', '노화', '곳', '보', '벽지', '주름', '지고', '욕실', '타일', '가구', '코너', '곳곳이', '주변', '중국', '관광객', '항상', '곳', '위치', '인지', '사람', '늘', '북적', '감', '전반', '객실', '관리', '상태', '및', '청소', '상태', '편이', '직원', '피드백', '역시', '편입', '니', '도시', '내부', '관광', '특화', '지역', '위치', '전반', '근처', '카페', '및', '식당', '가기', '전반', '호텔', '및', '위치', '제주', '고유', '특색', '것', '하루', '이틀', '제주', '도시', '스테이', '시', '선택', '제주', '선택', '스테이', '위치', '뭐', '매우', '신라', '스테이', '가도', '느낌', '더', '것', '후기', '스타벅스', '가장', '번화가', '전', '아침', '청소', '소리', '커서', '방음', '공항', '시설', '또한', '프론트', '직원', '주변', '먹거리', '단점', '라면', '주차장', '것', '오심', '이중', '주차', '역시', '미리', '미리', '예약', '꼭', '트윈', '항상', '혼자', '침대', '개', '방음', '겐찮은듯', '조식', '다그', '도일', '층', '커피', '함', '께빵', '돈', '중국인', '관광객', '괘', '공항', '무료', '셔틀', '타고', '호텔', '객실', '눈앞', '바다', '다른', '관광지', '가지', '힐링', '호텔', '시설', '부분', '객실', '휴식', '테라스', '바로', '바다', '바다', '식당', '조식', '시간', '룸', '욕실', '물', '듯', '물', '어메니티', '조금', '조식', '수영장', '피트니스', '패키지', '이용', '쉬', '위치', '전망', '가족', '공간', '화장실', '공간', '미닫이', '조금', '로비', '비롯', '모든', '직원', '수영장', '비롯', '각종', '부대', '시설', '온', '물건', '아침식사', '때', '바다', '뷰', '밥맛', '더', '로비', '피아노', '연주', '아이', '층', '침대', '아주', '방도', '직원', '수영장', '이용', '시내', '로비', '피아노', '연주', '여행', '습', '다룸', '타입', '기억', '안나', '패밀리', '실', '거실', '침대', '방', '한실', '방', '침대', '생각', '바다', '뷰', '시장', '서부', '수산시장', '새벽', '경매', '구경', '조식', '추가', '아침', '어차피', '현재', '호텔', '묵고', '인터넷', '예약', '때', '뷰', '지정', '수', '지정', '안해', '오션', '뷰', '프런터', '문의', '온', '영화', '하', '문의', '시스템', '티브이', '채널', '몇개', '콘센트', '플러그', '몇개', '와이프', '폰', '충전', '것', '것', '충전', '결정', '낼', '아침', '콜', '택시', '달라', '것', '지금', '낼', '아침', '다시', '처음', '경험', '호텔', '문의', '것', '방이', '거', '전', '혀', '장점', '인생', '최악', '호텔', '전통', '시장', '및', '시내', '중심', '주변', '관광', '바닷가', '위치', '전망', '호텔', '비교', '시설', '직원', '편임', '제주', '공항', '박', '방도', '직원', '친절', '방이', '다음', '한번', '더', '예정', '여름', '휴가', '때', '가족', '코너', '스위트룸', '공항', '근처', '시장', '오션', '뷰', '유리창', '코너', '스', '위트', '캠핑', '패키지', '캠핑', '테이블', '세트', '텐트', '아이', '것', '저희', '침대', '방', '에어컨', '구비', '작은방', '에어컨', '거실', '텐트', '매트', '더', '조식', '바다', '뷰', '자리', '조식', '조금', '일찍', '것', '저희', '때', '옆', '탑동', '공원', '쪽', '프리', '마켓', '공연', '매일', '저녁', '이틀', '동안', '구경', '시장', '식사', '쇼핑', '등', '이', '호텔', '이용', '관덕정', '정문', '앞', '위치', '시장', '도보', '분', '소요', '호텔', '편', '해장국', '집', '이용', '수', '가격', '대비', '시설', '직원', '공항', '시장', '시설', '좀', '동문', '시장', '서문시장', '도보', '분', '거리', '공항', '제주', '목관', '맞은편', '위치', '슬슬', '해', '우선', '호텔', '위치', '공항', '방도', '업그레이드', '별관', '본관', '관덕정', '바로', '맞은편', '앞', '위치', '동문', '시장', '갈수', '건물', '조금', '안', '최신', '시설', '그린', '환경', '때문', '욕실', '어메니티', '별도', '준비', '조식', '갠', '공항', '분', '정도', '대중교통', '이동', '곳', '근처', '시장', '등', '재래시장', '회', '구매', '호텔', '심플', '직원', '매우', '욕실', '비품', '별도', '구매', '트윈침대', '스탠다드', '트윈', '층', '높이', '욕조', '점', '한라산', '욕조', '노곤', '노곤', '몸', '시장', '버스', '터미널', '직원', '온돌룸', '공항', '저녁', '차', '렌트', '가기', '단점', '세면대', '물이', '것', '치약', '칫솔', '제공', '것임', '생수', '병', '무료', '제공', '다음', '재', '방문', '의사', '공항', '환승', '곧바로', '수', '동광양', '정류장', '호텔', '번화가', '시청', '근처', '객실', '비지니스', '작', '객실', '욕조', '몸', '수', '운', '바다', '객실', '투숙', '여기', '바다', '줄', '터', '시청', '근처', '위치', '교통', '이용', '뷰', '객실', '스텝', '다시', '이용', '곳', '위치', '시설', '주차장', '조금', '협소하', '세면', '도구', '칫솔', '정말', '세면', '도구', '칫솔', '치약', '샤워', '때', '거품', '타월', '화장', '대가', '호텔', '거울', '호텔', '화장', '곳', '객실', '쇼파', '최고', '조합', '조식', '금액', '대비', '아주', '호텔', '내', '주차공간', '바로', '옆', '공터', '태풍', '숙박', '직원', '룸', '컨디션', '지하', '주차장', '공간', '개층', '조금', '약간', '점', '라면', '호텔', '주변', '놀', '거리', '거리', '마지막', '날', '오후', '한시', '비행기', '공항', '근처', '호텔', '사진', '보고', '예약', '결론', '가성', '비', '짱', '가격', '공항', '시장', '주차', '무엇', '사우나', '부모님', '할머니', '모시', '제주도', '계획', '박', '일로', '시간', '좀', '빠듯해', '숙소', '어디', '정', '고민', '리뷰', '보고', '이', '호텔', '선택', '우선', '공항', '길가', '자리', '찾기', '차', '주차', '골목길', '점', '조금', '숙소', '때', '생각', '뷰', '비행기', '이륙', '착륙', '모습', '보이', '그냥', '일반', '시내', '모습', '대욕', '헬스장', '등', '부대', '시설', '무료', '가격', '대비', '저희', '부모님', '할머니', '다시', '제주도', '가면', '숙소', '고려', '생각', '정도', '위치', '공항', '주위', '편의점', '식당', '등', '다음', '기회', '다시', '선택', '수', '정도', '위치', '공항', '렌터카', '분', '정도', '거리', '주차장', '건물', '입구', '반대쪽', '차량', '주차', '위치', '한정', '단체', '손님', '이용', '것', '체크', '시', '층', '인', '더블', '침대', '침대', '제외', '여유', '공간', '전망', '길', '반대편', '다른', '호텔', '건물', '한라산', '보이', '도심', '임', '불구', '방', '소음', '거의', '주변', '식당', '점', '세명', '트리플', '룸', '도착', '때', '로비', '중국인', '완전', '단점', '숙박', '전날', '저녁', '예약', '방이', '남아', '예약', '지은지', '별로', '듯', '투숙', '자체', '계획', '가지', '게', '지인', '그것', '바로', '당일', '날', '정보', '이틀', '잔', '거', '조식', '아이', '간', '거', '아침', '그냥', '햇반', '지인', '장조림', '아이', '전자', '레인지', '식당', '가야', '직원', '부탁', '달라', '함', '뭐', '주변', '별로', '주차', '헬', '지하', '주차장', '중', '가격', '인지', '중국인', '또', '세미나', '걸', '온', '한국인', '말', '그대로', '잠', '근처', '나름', '제주', '번화가', '유명', '제과점', '공항', '버스', '정거장', '택시', '비지니스', '출장', '차', '현재', '박', '투숙', '모기', '제', '만해', '마리', '가량', '방안', '에프킬라', '비치', '계속', '뿌리', '잡고', '방안', '찬장', '화장실', '천장', '곳곳', '모기', '호텔', '측은', '벌레', '관리', '별도', '신경', '제주', '공항', '기본', '요금', '거리', '도로', '수', '호텔', '주차장', '호텔', '앞', '도로', '건너편', '체크', '때', '차', '번호', '무료', '주차', '수', '객실', '아주', '청소', '조식', '샐러드', '음식', '구성', '전복죽', '정말', '직원', '우선', '정말', '저번', '때', '핸드폰', '충전기', '대응', '제주', '월', '지금', '방문', '부모님', '강', '비지니스', '출장', '공항', '교통', '다소', '불편', '피트니스', '센터', '공사', '숙면', '침대', '다소', '가성', '비', '갑', '조식', '무난', '직원', '삶', '노력', '지불', '비용', '더', '것', '그', '수', '몇', '경험', '스위트룸', '경험', '공간', '로맨틱', '분위기', '독립', '북유럽', '욕조', '욕실', '룸', '통', '유리', '커튼', '바깥', '여', '묘', '느낌', '제일', '공간', '또', '다른', '공간', '설치', '모던', '유럽', '의', '세면대', '입', '샤워', '룸', '비데', '공간', '효율', '쇼파', '폭', '침대', '볼', '수', '인치', '삼성', '다음', '날', '눈', '제주', '만끽', '수', '편안함', '제공', '호텔', '다음', '제주', '여정', '꼭', '예정', '일단', '시설', '직원', '모두', '조식', '퀄리티', '저희', '둘', '바닥', '카펫', '좀', '비지니스', '목적', '커플', '끼리', '제주', '공항', '쭉', '직진', '운전', '숙소', '주차장', '협소하', '인근', '공영', '주차장', '곳', '주차', '소음', '옆', '애기', '투숙', '객', '소음', '무선인터넷', '근처', '편의점', '것', '추가', '구매', '제주도', '가족', '여행', '갑자기', '서전', '날', '항공', '예약', '급', '숙소', '정', '다가', '첫날', '저녁', '비행기', '도착', '공항', '곳', '가급', '결제', '알', '우리', '가족', '자기', '은방', '예약', '해', '상황', '우리', '상황', '아시', '룸', '업', '고트', '침대', '생각', '지도', '호텔', '직원', '세심', '함', '호텔', '화장실', '생각', '것', '맘', '아침', '공시', '애', '시작', '계속', '추억', '비행기', '비행기', '잠', '생각', '공항', '이벤트', '맥주잔', '무료', '쿠폰', '일도', '화장실', '공항', '근처', '비행기', '시간', '정말', '급', '호텔', '직원', '호텔', '전체', '분위기', '급', '객실', '크기', '룸서비스', '직원', '서비스', '정신', '모두', '추억', '공항', '비행기', '시간', '이동', '아주', '시설', '성', '평가', '생각', '점', '호텔', '편의', '시설', '점', '요즘', '호텔', '숙박', '여러', '편의', '시설', '가지', '이', '호텔', '시설', '직언', '분', '개인', '스탠다드', '패밀리', '더', '블룸', '예약', '도착', '변기', '물질', '그대로', '얘기', '직원', '수건', '환불', '월일', '오션', '뷰', '방향', '패밀리', '트윈', '이용', '함', '숙박', '료', '공항', '거리', '숙소', '공간', '것', '커튼', '푸른', '바다', '바로', '눈앞', '창', '파도', '소리', '철썩', '거리', '공간', '아침', '해', '풍경', '밖', '방안', '바로', '옆', '생선회', '식당', '바다', '추억', '기억', '장소', '생각', '놀이', '공원', '때문', '걱정', '디너', '메뉴', '가격', '맛', '양도', '돼지', '전골', '매운탕', '밖', '여기', '다만', '조식', '형편', '제주', '시내', '브런치', '카페', '거기', '요가', '성비', '정말', '호텔', '위치', '시설', '호텔', '뒤쪽', '가면', '맛집', '쭈욱', '식사', '앞', '바다', '뷰', '수영장', '작', '정도', '객실', '객실', '직원', '위치', '등', '가성', '비', '갑인', '호텔', '주차장', '이', '렌트', '호텔', '뒤쪽', '제주', '드타', '운', '지역', '먹거리', '쇼핑', '등', '안', '방파제', '의', '횟집', '타운', '은', '해산물', '제주', '가장', '규모', '재래시장', '시장', '가까이', '바다', '전망', '호텔', '가격', '대비', '매우', '곳', '인근', '회', '센터', '회', '객실', '바다', '맛', '공항', '도', '재', '방문', '의사', '제주시', '인근', '위치', '오션', '뷰', '룸', '경우', '탁', '전망', '수', '아침', '조식', '꼭', '메뉴', '어르신', '수', '구성', '공항', '곳', '추천', '시설', '뷰', '아주', '가격', '대비', '오션', '뷰', '화장실', '깨끗', '생각', '조식', '주차', '밤', '자리', '직원', '대신', '단점', '수영장', '작고', '시', '수영', '수', '아쉬움', '체크', '인도', '무엇', '방이', '커서', '침대', '개', '인', '가족', '야외', '수영장', '물', '소독약', '덜', '건', '조금', '아이', '스비', '휴가', '힐링', '위해', '홀로', '제주도', '구경', '한라산', '등정후', '칼', '호텔', '하루', '숙박', '여행', '마지막', '날', '호텔', '수영장', '헬스장', '이용', '계획', '서울', '부터', '준비', '아침', '조식', '혹시', '것', '확인', '차', '전화', '통해', '휘트니', '스', '전화', '헬스장', '운동복', '혹시', '수영모', '등', '제', '수영모', '고오', '바람', '다시', '전화', '혹시', '수영모', '대여', '구매', '여직원', '분', '무시', '말투', '제', '원래', '회원', '제로', '운영', '곳', '일반인', '입장', '그', '회원', '모두', '수영모', '투숙', '객', '이용', '일반인', '원래', '입장', '투숙', '객', '선심', '서비스', '말투', '필요', '말', '순간', '무시', '기분', '바로', '전화', '원래', '여기', '기전', '회원', '제', '투숙', '객', '추가', '비용', '이용', '이용', '대뜸', '말', '일반인', '투숙', '객', '무시', '매우', '화가', '바로', '칼', '호텔', '고객', '소리', '컴', '플레인', '더', '이상', '시경', '바로', '체크', '아웃', '서울', '신라', '호텔', '하야', '트', '메리어트', '등', '특급', '호텔', '여럿', '이용', '회원', '여', '일반', '투숙', '객', '무시', '칼', '호텔', '급', '이어도', '가격', '이용', '직원', '수준', '가격', '수준', '이군', '매우', '실망', '하루', '종일', '준', '급', '호텔', '서비스', '리셉션', '컨시어', '태도', '룸', '컨디션', '정말', '최악', '체크', '고객', '체크', '시', '리셉션', '것', '룸', '안', '것', '무료', '유료', '사고', '칠', '학생', '걱정', '선생님', '헬스장', '어딘', '사우나', '이용', '수', '것', '기본', '살', '사항', '고객', '무슨', '거지', '입', '룸', '리빙룸', '방도', '하나요', '트윈룸', '두', '개', '방', '무려', '게재', '사진', '실물', '방', '차이', '실화', '파우더', '룸', '벽', '곰팡이', '자국', '작동', '골드스타', '냉장고', '방', '무려', '로', '예약', '컨디션', '절대', '예약', '전반', '직원', '태도', '조식', '레스토랑', '직원', '왜', '자꾸', '정색', '합', '커피', '수', '정색', '왜', '합', '물', '바닥', '살짝', '서버', '분', '휙', '데리', '가신', '다른', '서버', '뭐', '나머지', '물기', '손님', '직접', '해', '체계', '룰', '엉망', '손님', '응대', '급', '요즘', '소규모', '호텔', '태도', '안', '다시', '일', '예약', '저', '속', '분', '시기', '마음', '위치', '것', '가격', '리트', '것', '이름', '급', '걸', '서비스', '도', '여행', '출장', '번', '기본', '안', '공항', '거리', '객실', '생각', '주위', '마지막', '날', '방이', '라그', '마음', '조식', '기대', '실내수영장', '수영', '정도', '수온', '마음', '하루', '가기', '거', '스', '위트', '비수', '상대', '가격', '객실', '약간', '노후', '조식', '위치', '공항', '아주', '멀리', '정가', '무리', '할인', '행사', '정도', '가능', '참고', '누', '조식', '포함', '마일리지', '대한항공', '마일리지', '스위트룸', '하룻밤', '확실', '연식', '요즘', '호텔', '시설', '느낌', '임', '스위트룸', '요즘', '고급', '호텔', '일반', '룸', '급', '호텔', '서비스', '음식', '원가', '조금', '할인', '특', '때', '추천', '함', '오션', '뷰', '층', '숙박', '함덕', '서우', '해수욕장', '한눈', '창문', '창문', '이상', '뷰', '겨울철', '통', '유리', '때문', '온도', '리기', '위해', '난', '방기', '동시', '온', '방식', '대략', '도정', '숙소', '화장실', '샤워', '부스', '다소', '방음', '옆방', '티비', '소리', '취침', '위해', '옆방', '티비', '소리', '티비', '후', '수', '초등학생', '아이', '박', '일', '청소', '상태', '양호', '위치', '전반', '다만', '조식', '가짓수', '첫날', '일찍', '도착', '근처', '한식당', '아침', '가격', '맛', '양도', '호텔', '조식', '별로', '근처', '한식당', '아침', '것', '차라리', '호텔', '조식', '시설', '무엇', '바다', '뷰', '정말', '최고', '이', '호텔', '반드시', '꼭', '바다', '객실', '다만', '방', '은', '조금', '편이', '옆방', '거리', '소리', '문', '쾅', '좀', '크게', '층', '씨유', '편의점', '주변', '델문', '카페나', '맛집', '함덕', '해수욕장', '바로', '앞', '위치', '해수욕', '최적', '위치', '객실', '디럭스', '시티', '뷰', '오션', '뷰', '디럭스', '시티', '뷰', '발코니', '오션', '뷰', '함덕', '바다', '보', '룸', '편이', '직원', '최적', '위치', '객실', '전망', '모로', '추천', '층', '오션', '뷰', '트윈룸입니', '선착순', '업그레이드', '오션', '뷰', '객실', '상태', '어메니티', '청결', '모두', '무엇', '뷰', '예술', '직원', '응대', '기분', '호텔', '로비', '샤워', '시설', '물놀이', '후', '모래', '층', '부대', '시설', '카페', '레스토랑', '음식', '편의점', '가족', '친구', '커플', '여행', '모두', '추천', '피크', '시즌', '살짝', '간', '월', '주', '호텔', '주변', '날씨', '적', '선선', '물놀이', '수온', '위치', '직원', '근래', '리뷰', '보고', '걱정', '괜', '걱정', '건물', '자체', '느낌', '청소', '상태', '침대', '상태', '주차', '편리', '갈수', '맛집', '코르', '사태', '비수', '기지', '가성', '비', '년', '때', '다시', '방문', '객실', '상태', '커튼', '곰팡이', '교체', '요청', '방', '우리', '뷰', '사양', '적', '호텔', '주체', '개', '셀', '교회', '절반', '정도', '인수', '듯', '보임', '방', '더', '아트', '스테이', '셀', '이름', '우리', '더', '아트', '스테이', '것', '추정', '방', '이용', '곳', '최악', '시설', '직원', '프로', '페셔', '인력', '호텔', '이어도', '매트', '처음', '봄', '매트리스', '그냥', '나무', '판', '허리', '줄', '안감', '안감', '객실', '무난', '함덕', '해변', '워낙', '가시', '함덕', '쪽', '호텔', '가격', '대비', '이용', '제주도', '처음', '방문', '다른', '곳', '비교', '주말', '임', '고려', '한국', '다른', '지역', '가성', '비', '바다', '바로', '옆', '층', '시간', '운영', '편의점', '주변', '맛집', '식사', '이용', '수', '곳', '봄', '벚꽃', '기간', '방문', '협재', '바다', '뷰', '대로', '변', '렌트', '가기', '조식', '이용', '근처', '옹포', '밥집', '아침', '산책', '겸', '옴', '루프', '탑', '수영장', '바', '내', '때', '밤', '비바람', '불어', '이용', '못', '옴', '단점', '모', '유명', '여행', '블로거', '리뷰', '화장실', '물떄', '그거', '만족', '월', '제주도', '탓', '수풀', '수영장', '위주', '제주', '풀이', '호텔', '고민', '가성', '비', '호텔', '완전', '온수', '미온수', '아이', '다소', '미온', '수풀', '바로', '옆', '자쿠지', '운영', '잠깐', '수', '수준', '미온수', '수영장', '자체', '인피니트', '수영장', '환상', '바다', '수', '수영장', '하나', '추천', '함', '그', '외', '스페', '제주', '식당', '인생', '치킨', '빠에야', '수', '음협', '재', '바다', '뷰', '매우', '스파', '룸', '층', '뷰', '호텔', '구조', '스파룸', '모두', '층', '루프', '탑', '수영장', '더', '곳', '루프', '탑', '이용', '시간', '시간', '시간', '기억', '안나', '수영장', '자쿠', '이용', '맥주', '무료', '이용권', '저녁', '테이블', '맥주', '바람', '수', '밤', '바다', '룸', '기본', '어메니티', '박', '하니', '것', '계속', '줌', '방', '청소', '시', '사이', '거', '시트', '교체', '정리', '삼다수', '병과', '네스프레소', '캡슐', '개', '계속', '짐', '스파', '욕조', '생각', '커서', '여자', '분', '피로', '스페인', '제주', '영업', '종료', '룸서비스', '이용', '조식', '조식', '이용', '안해', '호텔', '바로', '앞', '과', '협재', '버거', '호텔', '오른쪽', '횟집', '마담', '나탈리', '마담', '나탈리', '음악', '계속', '호텔', '전체', '규모', '호텔', '필터', '링', '해변', '실외수영장', '조식', '검색', '호텔', '중', '전', '객실', '협재', '해변', '뷰', '옥상', '수영장', '룸서비스', '선택', '결과', '만족', '대형', '호텔', '가격', '방', '객실', '만큼', '수영장', '룸서비스', '등', '사람', '번잡', '주차장', '바로', '앞', '미니바', '개수대', '바로', '옆', '분', '거리', '내', '유명', '식당', '것', '움', '돈', '대형', '호텔', '가면', '룸', '작고', '수영장', '식당', '주차장', '사람', '여기', '룸서비스', '음식', '맛', '양도', '조식', '선택', '안해', '룸서비스', '맛', '볼', '때', '듯', '호텔', '모든', '곳', '것', '때', '호텔', '인근', '아침', '시', '분', '이전', '아무', '것', '리지', '룸', '서비스', '음식', '만', '매일', '매우', '제한', '선택', '시설', '더', '날', '시간', '살', '객실', '바다', '경치', '이웃', '섬', '환상', '일몰', '실제', '더', '리조트', '임', '홍보', '가격', '시설', '맥', '상통', '호텔', '화산', '바위', '해변', '자리', '정상', '호텔', '사용', '그림', '지금', '날', '사진', '제주', '여행', '기점', '버스', '터미널', '옆', '이동', '아주', '위치', '스템', '적극', '응대', '친절', '편안함', '제공', '시설', '또한', '관리', '잠자리', '계', '공간', '제공', '기타', '편의', '시설', '부족함', '제공', '제주', '곳', '알', '후', '곳', '이용', '찾기', '위치', '길이', '밤', '거리', '다행', '리셉션', '근무', '직원', '중국어', '영어', '줄', '도움', '것', '해결', '리셉션', '직원', '택시', '목적지', '수', '밤', '해피', '워', '무료', '음료', '맥주', '사이다', '과일', '주스', '포함', '빵', '달걀', '치즈', '아침', '식사', '직접', '준비', '것', '방이', '실내', '히터', '작동', '수건', '다소', '엘리베이터', '층', '짐', '가야', '전체', '제주도', '처음', '라면', '예', '버스', '투어', '추천', '제주도', '호스텔', '위치', '대중교통', '타고', '어디', '수', '공항', '잠깐', '택시', '원', '미만', '직원', '매우', '질문', '답', '객실', '매우', '손님', '예', '투어', '할인', '상품', '번', '모두', '제주도', '다시', '이', '호스텔', '다시', '묵', '것', '제주도', '혼자', '여행', '마지막', '날', '접근성', '과거', '경험', '게스트하우스', '비교', '그냥', '잠', '자고', '오기', '곳', '경험', '일이', '지금', '발전', '예상', '점', '공항', '가까이', '친구', '방', '뭐', '곳', '아침', '토스터', '잼', '화장실', '개', '욕실', '겸', '화장실', '개', '꽤', '시', '이후', '전체', '소등', '불키', '조용조', '용', '얘기', '방키', '고여', '숙소', '남자', '숙소', '입구', '달라', '안전', '공항', '정말', '차로', '분', '이내', '도착', '것', '전반', '서비스', '겨울', '루프', '탑', '수영장', '이용', '수', '루프', '탑', '이용', '추가', '금액', '저녁', '뷔페', '아침', '조식', '조식', '이용', '식당', '방', '오션', '뷰', '꽤', '다음', '이용', '것', '전반', '여느', '호텔', '아침', '바다', '뷰', '예술', '공항', '호텔', '앞', '롯데리아', '양', '옆', '편의점', '야외', '주차장', '다만', '제', '방만', '건', '샤워', '기', '고정', '계속', '기본', '적', '무궁화', '개', '호텔', '가성', '비', '욕실', '및', '실내', '공간', '주차장', '야외', '편', '여름', '루프', '탑', '수영장', '이용', '함', '층', '뷔페', '식당', '루프', '탑', '바', '수영장', '사용', '곳', '다만', '조명', '전체', '눈', '좀', '제주', '시내', '볼', '숙박', '호텔', '여름', '휴가', '철', '수기', '가격', '수기', '이름', '수준', '상황', '선택', '호텔', '호텔', '할인', '사이트', '직접', '호텔', '홈페이지', '예약', '더', '시내', '공항', '일', '마치', '바로', '수', '위치', '선택', '가격', '무척', '시설', '주변', '주차공간', '여유', '전기차', '렌트', '길', '건너', '롯데리아', '급속', '충전', '소가', '더', '다른', '후기', '주변', '별', '것', '편의점', '두', '곳', '조금', '카페', '뿐', '호텔', '뒤', '유치원', '주택가', '곳', '요', '차량', '가지', '분', '선택', '것', '직원', '시설', '부정', '점', '라면', '객실', '내부', '전기', '플러그', '책상', '위', '것', '두', '개', '욕실', '전기', '면도', '기용', '개', '전부', '뷰', '층', '창문', '밖', '주택가', '가까이', '사람', '끼리', '서로', '눈', '수도', '거리', '차량', '가지', '이동', '공항', '시내', '가성', '비', '호텔', '추천', '수', '것', '용', '두엄', '곳', '위치', '엘배', '주차공간', '약간', '룸', '사물함', '침대', '파우더', '룸', '화장', '살', '욕실', '분리', '복도', '끝', '층', '공용', '휴게', '공간', '하나', '층', '음삭', '넉', '수', '공간', '침구', '편이', '침댜', '커튼', '옆', '사람', '마주', '조식', '샌드위치', '직접', '구조', '맛', '커피', '쥬스', '제공', '용두암', '숙소', '날씨', '한라산', '볼', '수', '저녁', '밤', '공항', '종', '달리', '대안', '수', '듯', '무난', '숙소', '공항', '접근성', '시설', '상대', '더', '추천', '월', '곳', '박', '기회', '방금', '도착', '곧', '제주', '시내', '매우', '곳', '제조', '국제', '공항', '택시', '분', '안', '건물', '테라스', '전망', '볼', '수', '바다', '매우', '언덕', '분', '정도', '도착', '아침', '식사', '맛', '다만', '객실', '창문', '마치', '요새', '느낌', '원래', '의도', '수도', '건물', '위', '휴식', '공간', '인터넷', '전반', '매우', '또한', '주인', '피터', '매우', '도', '정말', '집', '편안함', '수', '여기', '동안', '정말', '꼭', '다시', '미르', '게스트하우스', '특징', '건물', '건축', '양식', '주인', '피터', '성격', '그대로', '건물', '디자인', '제주도', '상징', '근처', '용두암', '화강암', '영감', '저', '중앙', '뜰', '해먹', '네', '개', '벽', '하늘', '것', '아침', '식사', '샌드위치', '또한', '피터', '이야기', '것', '그', '매우', '환대', '영어', '방', '다소', '시', '전', '샤워', '마치', '불', '노력', '완전', '주차장', '주차', '타워', '바로', '앞', '거리', '중심부', '어디', '갈수', '앞', '애용', '요즘', '코로나', '시국', '셀프', '체크', '점도', '아주', '일단', '위치', '정말', '곳', '주변', '곳도', '공항', '근처', '그다음', '아침', '비행기', '분도', '택시', '전체', '객', '실내', '청소기', '세탁기', '식기구', '마련', '이용', '풀', '점', '하나', '공항', '도', '번화가', '교통', '먹거리', '문제', '무엇', '저희', '단기', '장기', '달', '살기', '얼마', '건', '공항', '약', '도', '채', '거리', '아침', '비행기', '타고', '가야', '상황', '부담', '주차', '걱정', '건물', '내', '기계', '주차장', '바로', '앞', '주차장', '주차', '시내', '위치', '편의점', '음식점', '이용', '아주', '객실', '내', '건', '모두', '곳', '동안', '개인', '곳', '옥상', '앞', '바다', '뒤', '산이', '이', '전망', '정말', '여름', '한참', '생각', '절로', '곳', '하루', '잠시', '분', '최적화', '지은지', '얼마', '햇', '용', '청소기', '세탁기', '구비', '층', '조기', '벽', '가로', '창밖', '조기', '벽', '화장실', '페인트', '군데군데', '세면대', '곰팡이', '전체', '곰팡이', '냄새', '공항', '근처', '이마트', '마트', '식당가', '입지', '로비', '방', '좀', '별로', '트윈룸', '더블', '싱글', '더블', '둘', '퀸', '더블', '사이즈', '임', '더', '블룸', '침대', '중국', '정말', '로비', '중국사람', '취향', '듯', '카지노', '때문', '인지도', '공항', '매우', '시설', '또한', '건너편', '라마', '비', '호텔', '조금', '작', '가격', '대비', '단', '물', '수압', '조금', '공항', '제주도', '기분', '바다', '숙소', '좀', '웅장', '방', '다음', '묵', '의사', '더', '블룸', '트윈침대', '개', '준', '것', '오히려', '시설', '옛날', '호텔', '날', '화장실', '냄새', '좀', '별로', '카지노', '외국인', '전용', '어차피', '해당', '사항', '도착', '공항', '근처', '숙소', '예약', '저', '프론트', '가격', '대비', '룸', '침대', '룸', '조금', '침구', '저', '오션', '뷰', '바다', '앞', '이용', '바로', '앞', '이마트', '옆', '편의점', '맥주', '사기', '주차', '또한', '저', '매우', '만족', '성비', '패키지', '정말', '박', '다음', '좀', '오션', '뷰', '커플', '끼리', '오기', '최고', '듯', '패키지', '박일동', '안', '힐링', '기분', '제주도', '최애', '호텔', '전망', '최고', '최고', '골프', '오션', '뷰', '최고', '정말', '직원', '내부', '맘', '커플', '끼리', '여행', '곳', '골프', '패키지', '오니', '방이', '예약', '저렴', '저렴', '오션', '뷰', '최고', '듯', '제주도', '때', '예약', '제', '최애', '숙소', '커플', '끼리', '가기', '곳', '것', '오션', '뷰', '최고', '습', '골프', '곳', '것', '제주도', '다음', '또', '여기', '숙박', '호텔', '디자인', '인상', '면', '목표', '달성', '호텔', '일종', '힙', '스터', '모던', '분위기', '프론트', '오피스', '직원', '도움', '주차', '공간', '대리', '주차', '서비스', '이용', '가능', '옥상', '바', '휴식', '취하', '기', '곳', '위치', '환상', '상점', '식당', '공항', '문제', '방', '디자이너', '현대', '주의', '테마', '멀리', '것', '가장', '눈', '문제', '샤워', '커튼', '것', '우리', '샤워', '때', '싱크대', '지역', '절반', '실제', '또한', '세면', '도구', '공간', '반', '것', '의미', '싱크대', '영역', '수도꼭지', '싱크대', '확장', '역류', '발생', '다른', '문제', '손님', '호텔', '운영', '관련', '예', '욕조', '벽', '사이', '간격', '하우스', '키핑', '그', '지역', '은색', '청소', '합', '또한', '호텔', '바닥재', '베이지', '색', '다다미', '선택', '얼룩', '더', '어', '두운', '카펫', '바닥', '더', '작동', '나', '호텔', '마음', '더', '만들기', '위해', '요소', '개선', '글쎄', '차', '사용', '때', '전화', '번호', '화장품', '회사', '것', '몇', '번의', '시도', '끝', '도로', '목적지', '설정', '전화', '번호', '다른', '참조', '사용', '결정', '그', '길', '가장', '건물', '므', '수', '호텔', '새', '방이', '아침', '식사', '직원', '호텔', '건물', '내', '기계', '주차', '공간', '호텔', '옆', '개방', '주차장', '투숙', '객', '개방', '주차장', '주차', '화장실', '칫솔', '위치', '신라', '면세점', '약', '삼', '공항', '다시', '제주', '도착', '것', '장소', '무료', '주차', '대행', '꽤', '공항', '매우', '샤워', '공간', '욕조', '비데', '나', '방이', '미국', '호텔', '표준', '평균', '크기', '말', '모든', '것', '그', '각각', '더블', '침대', '얼굴', '마스크', '방', '식사', '표시', '책상', '직원', '최소한', '영어', '구사', '일부', '직원', '다른', '사람', '나', '관광객', '호텔', '사용', '것', '것', '언급', '것', '엽서', '프론트', '데스크', '스탬프', '그것', '거부', '우체국', '가라', '말', '침구', '어메니티', '조식', '모두', '가격', '대비', '가성', '최고', '조식', '후회', '루프', '탑', '이', '통', '유리', '전망', '뷰', '호텔', '가격', '편이', '구', '주차장', '제주', '시내', '호텔', '주차장', '곳', '본적', '발렛', '무료', '조식', '무엇', '침구', '꿀잠', '강추', '주차장', '발렛', '써비스', '번', '감동', '굿굿', '패밀리', '룸', '예약', '운', '스위트', '업그레이드', '더블', '개', '전망', '티비', '두', '대입', '니', '거실', '방', '분리', '가족', '어른', '밤', '시간', '조식', '죽', '종류', '양식', '음식', '어르신', '입맛', '다만', '욕실', '샤워', '부스', '분리', '전체', '호텔', '금액', '모텔', '가격', '생각', '객실', '선택', '생각', '직원', '또한', '가격', '객실', '침구', '류', '추천', '조식', '사람', '전복죽', '제주', '지인', '추천', '간', '호텔', '그', '전', '호텔', '알', '보고', '여러', '호텔', '가격', '예약', '좀', '걱정', '헸더랬습니', '보고', '호텔', '저리', '가라', '정도', '위치', '제주', '시내', '관광', '방도', '수압', '조식', '뷔페', '지수', '요', '추천', '제주', '공항', '분', '거리', '더원', '호텔', '지은지', '년', '룸', '컨디션', '호텔', '옥상', '하늘정원', '제주', '도착', '최상', '선택', '직원', '청소', '상태', '단점', '주차', '좀', '비지니스', '다음', '이용', '생각', '박일', '때문', '제주도', '위치', '직원', '모두', '대해', '침구', '카피', '드라이어', '등', '숙소', '시설', '위치', '노', '오거리', '근처', '도청', '제주', '인근', '출장', '오시', '분', '추천', '제주도', '엠버', '호텔', '센트럴', '대박', '숙소', '직원', '호텔', '다음', '제주도', '방문', '시', '또', '추천', '다음', '또', '옆', '진짜', '해장국', '집도', '아주', '마음', '여행', '도움', '직원', '위치', '제주', '시외', '버스', '터미널', '도보', '분', '거리', '대중', '교통', '버스', '접근', '여행', '수', '그', '무슬림', '위해', '곳', '해변', '법', '한라산', '하이킹', '법', '현지', '시장', '법', '등', '정보', '제공', '나', '다시', '여기', '것', '외국인', '친구', '한국', '방문', '기간', '마켓', '물품', '주문', '배달', '게스트하우스', '주인', '이메일', '주인', '마음', '주문', '하라', '허락', '상황', '마켓', '수령', '전화', '번호', '꼭', '핸드폰', '번호', '입력', '게스트하우스', '전화', '해', '가용', '핸드폰', '번호', '문의', '제', '번호', '입력', '해도', '실제', '수령', '게스트', '하우스', '번호', '더', '생각', '전화', '계속', '추궁', '누가', '언제', '이름', '뭐', '확인', '수령', '핸드폰', '번호', '달라', '하니', '개인정보', '개념', '직원', '반응', '어이', '글', '정신', '교육', '좀', '장난', '것', '내용', '대충', '아래', '직원', '왈', '저희', '물건', '대신', '못', '나', '사장', '이야기', '직원', '동안', '주문', '나', '거', '수령', '핸드폰', '번호', '필요', '폰', '번호', '하나', '유선', '전화', '입력', '직원', '저', '마켓', '유선', '번호', '나', '저', '지금', '마켓', '보고', '못', '직원', '개인정보', '나', '식', '실랑이', '직원', '걸', '알', '주인', '언제', '오냐', '제대로', '정말', '손님', '태도', '터미널', '바로', '옆', '위치', '정말', '터미널', '바로', '옆', '버스', '이용', '또한', '예전', '여관', '리', '모델', '듯', '개별', '욕실', '가격', '이용', '조식', '시간', '초코파이', '간단', '음료', '비닐', '팩', '한라산', '때', '요긴', '간식', '버스', '여행자', '추천', '침대', '조금', '주차장', '객수', '주차장', '협소', '호텔', '답', '뷰', '난타', '공연', '보기', '위해', '이틀', '호텔', '저녁', '비행기', '렌트', '도착', '저녁', '시', '룸서비스', '시', '반', '리셉션', '전화', '후라이드', '치킨', '수', '침대', '욕조', '산', '조식', '식당', '메뉴', '전복', '해물뚝배기', '갈비', '난타', '공연', '투숙', '객', '할인', '가까이', '제주', '가면', '항상', '숙소', '나보', '호텔', '난타', '난타', '공연', '볼', '수', '곳', '시간', '난타', '공연', '보지', '못', '아쉬움', '호텔', '난타', '한라산', '돌', '문화', '공원', '사려', '숩길', '절물', '휴양림', '등', '공항', '편이', '주변', '호텔', '난타', '공연장', '외', '편입', '니', '침대', '층', '편의점', '물품', '구매', '객실', '치약', '칫솔', '것', '약간', '점', '난타', '상설', '공연장', '호텔', '객실', '비즈니스', '호텔', '급', '다만', '시내', '택시', '안', '때', '객실', '조식', '난타', '공연', '시간', '산', '중턱', '인지', '밤', '공기', '위치', '규모', '호텔', '별로', '애월', '비교', '규모', '호텔', '로서', '푸른', '바다', '바로', '앞', '저녁', '석양', '무렵', '직원', '직원', '편입', '니', '룸', '바다', '전망', '욕실', '방', '전체', '비릿', '냄새', '나', '단점', '조식', '전체', '가성', '비', '기타', '바다', '눈', '보이', '사시', '사철', '수영', '루프', '탑', '수영장', '아주', '다시', '가격', '할인', '가도', '밤', '디제이', '모로', '수준', '그닥', '실내', '환기', '팬', '및', '에어컨', '소음', '침대', '객실', '외부', '유리창', '사이', '스파', '객실', '이', '스파', '위쪽', '상시', '작동', '팬', '현관', '룸키', '마스터', '전원', '저속', '작동', '화장실', '팬', '작동', '고속', '작동', '시스템', '일단', '룸', '키', '이', '스파', '위쪽', '팬', '끌', '수', '스위치', '저', '이', '팬', '소음', '수면', '방해', '정도', '매우', '관리직', '환기', '팬', '원선', '분리', '직원', '분', '말씀', '전', '컴', '플레인', '적', '또', '천정', '삼성', '시스템', '에어컨', '설치', '설치', '문제', '종', '문제', '소음', '저', '경우', '밤', '에어컨', '수', '정도', '날씨', '사용', '분', '문제', '수준', '소음', '여름', '투숙', '분', '고민', '듯', '관리', '직원', '분', '에어컨', '소음', '방법', '숙박', '포기', '다른', '호텔', '가신', '고객', '말씀', '객실', '내부', '청결', '및', '하우스', '키핑', '문제', '제', '경우', '객실', '청소', '실제', '담당', '분', '테', '이', '정도', '가격', '호텔', '수준', '응대', '관련', '그', '분과', '대화', '더', '나누기', '프런트', '관련', '컴', '플레인', '프런트', '해결', '려고', '노력', '것', '다만', '호텔', '직원', '서비스', '마인드', '교육', '하우스', '키핑', '제대로', '느낌', '가족', '국적', '분위기', '애월', '호텔', '밑', '여자', '정', '황상', '입금', '지인', '강아지', '데리', '적반하장', '화', '우리', '가족', '한텐', '친절', '저런', '바로', '글', '보시', '가족', '여행', '중', '우리', '관광', '간', '사이', '호텔', '직원', '무단', '허락', '객실', '난입', '온', '방', '우선', '이', '팩트', '이유', '메이드', '청소', '중', '애완', '용품', '것', '우리', '허락', '객실', '내부', '물건', '사진', '몰래', '직원', '단체', '방', '유포', '호텔', '총지배인', '및', '직원', '사실', '확인', '차', '명', '이서', '그것', '확인', '우리', '객실', '무단', '것', '관광', '총지배인', '사람', '우리', '말', '자기', '객실', '직접', '물건', '확인', '벌금', '내', '것', '정말', '말', '정도', '실물', '강아지', '것', '그로', '민원', '것', '하물며', '및', '증거', '추정', '물건', '호텔', '관계자', '명', '무단', '객실', '출입', '가요', '이', '대한민국', '호텔', '수', '일일', '물건', '추정', '컨데', '강아지', '스위트룸', '박', '더', '내', '객실', '뒤', '컴', '플레인', '및', '것', '내', '직원', '우리', '객실', '무단', '출입', '것', '하니', '박치', '돈', '경찰', '객실', '수색', '계속', '확인', '협박', '및', '강압', '말로', '우리', '모욕감', '조성', '그', '누가', '부모님', '가족', '쉬', '공간', '직원', '수색', '동의', '하나요', '혹', '나', '그', '안', '호텔', '규율', '담배', '고기', '흔적', '해도', '그', '누구', '우리', '허락', '우리', '점유', '객실', '가격', '컨디션', '서비스', '위치', '등', '제주', '행시', '제주시', '무조건', '곳', '다시', '묵', '예정', '나', '홀로', '커플', '가족', '년', '월', '일', '일', '남자친구', '제주도', '늘송', '파크텔', '이틀', '전체', '곳', '여행', '위해', '숙박', '장소', '위치', '정말', '문제', '늘송', '파크텔', '위치', '아주', '제주', '국제', '공항', '곳', '위치', '데', '공항', '숙소', '무료', '차편', '제공', '늘송', '파크텔', '주인', '미스터', '박', '우리', '공항', '호텔', '객실', '주호', '은', '아주', '객실', '티브이', '와이파이', '컴퓨터', '미니', '소독기', '식수', '음', '에어', '컨디션', '등', '비치', '아주', '게다가', '객실', '화장실', '정말', '이', '리뷰', '제주도', '방문', '다른', '여행객', '숙소', '선택', '도움', '호텔', '대한', '저희', '첫인상', '매우', '것', '직원', '마찬가지', '이', '호텔', '뭐', '고요', '방과', '침대', '시트', '방', '공기', '청정기', '무료', '와이파이', '티비', '채널', '인물', '채널', '포함', '충격', '도움', '직원', '변기', '커버', '아침', '당신', '이', '변기', '커버', '거', '이', '호텔', '바로', '편', '돼지', '전복죽', '패밀리', '레스토랑', '가격', '식당', '수', '거리', '한국', '음식점', '이건', '패스트푸드', '점', '이건', '공항', '대략', '분', '거리', '조언', '제주도', '차', '말레이시아인', '라면', '꼭', '국제', '면허증', '신청', '수건', '직접', '제공', '수건', '몇', '장', '안', '방', '시설', '방', '인치', '평면', '컴퓨터', '공기', '청정기', '미니', '냉장고', '정수기', '마련', '공항', '차', '타고', '약', '분', '정도', '여러', '레스토랑', '편의점', '인근', '직원', '영어', '아주', '저희', '전체', '불만', '제주', '공항', '고분', '내외', '거리', '편의점', '맥도날드', '근처', '식당', '돼지', '바비큐', '바로', '길', '건너', '시간', '코인', '세탁소', '가까이', '방', '무료', '무선', '인터넷', '사용', '가능', '화장실', '마지막', '주인', '무척', '시간', '코인', '세탁소', '저희', '분', '인도네시아어', '무척', '해', '더', '이상', '것', '정도', '숙소', '제주도', '매우', '추천', '호텔', '최근', '것', '인테리어', '주인', '온돌', '난방', '객실', '내', '와이파이', '무료', '방', '어제', '관광', '호텔', '위치', '수', '숙소', '바다', '전망', '객실', '배정', '전망', '매우', '욕실', '매우', '듯', '느낌', '테라스', '곳', '청결', '부분', '신경', '필요', '베란다', '환경', '좀', '바닷가', '근처', '날', '벌레', '수', '환경', '일', '듯', '층', '투숙', '테라스', '날', '벌레', '나', '바퀴벌레', '류', '에어컨', '실외', '기', '창문', '여', '부위', '방쪽', '창문', '열기', '청소', '좀', '더', '신경', '듯', '샴푸', '바디크렌저', '용기', '표기', '브랜드', '제품', '최저', '가품', '놨더군', '군더더기', '숙소', '다음', '날', '성산일출봉', '우도', '계획', '박', '만원', '가격', '대비', '굿', '주차장', '바다', '앞', '고요', '주변', '것', '숙박', '계획', '라면', '곳', '생각', '애초', '성산', '근처', '숙소', '생각', '때문', '별', '고민', '선택', '숙소', '성산', '숙소', '건', '용눈이오름', '성산일출봉', '돌', '문화', '공원', '등등', '애월', '서귀포', '번잡', '함', '피해', '제주', '숙소', '자체', '아주', '창', '우도', '눈앞', '가득', '광경', '분위기', '호텔', '공항', '가격', '대비', '가성', '비', '최고', '설비', '사장', '한라', '수목원', '차로', '오전', '드라이브', '다음', '제주도', '가면', '또', '호텔', '방이', '위치', '호텔', '리셉션', '직원', '분', '다음', '번', '꼭', '갤러리', '호텔', '비', '가야', '호텔', '방이', '스태프', '동네', '식당', '술집', '다음', '번', '이', '호텔', '제주', '시내', '비지니스', '호텔', '이용', '접근성', '가성', '비도', '강력', '추천', '제주도', '출장', '갑작스레', '예약', '호텔', '위치', '사진', '매우', '만족', '직원', '매우', '가격', '대비', '룸', '컨디션', '굿굿굿', '업무', '차', '여행', '해도', '곳', '다시', '방문', '예정', '서귀포', '미도', '호스텔', '이사', '여행', '시작', '중앙', '로터리', '버스', '정류장', '번', '버스', '타고', '제주', '시외', '버스', '터미널', '다음', '번', '버스', '타고', '버스', '정류장', '버스', '번호', '거의', '오지', '그', '당시', '우리', '시간', '우리', '숙소', '방법', '혼동', '동안', '소녀', '우리', '어디', '것', '택시', '요금', '확인', '데', '도움', '앱', '원', '지불', '다음', '택시', '실제', '비용', '원', '메', '앞', '도착', '어쨌든', '우리', '카드', '택시', '요금', '지불', '매우', '내', '검토', '다음', '시작', '첫인상', '환영', '길림', '펜션', '여행', '동안', '내', '최고', '숙박', '시설', '주인', '인', '강', '정말', '그', '우리', '짐', '버스', '노선', '숙소', '숙소', '설명', '우리', '길', '때', '위치', '공유', '위해', '추가', '언제', '도움', '요청', '수', '그', '택시', '운전사', '나', '버스', '운전사', '주어', '방법', '경우', '도움', '명함', '우리', '쉐어', '하우스', '모든', '것', '주방', '세탁기', '헤어', '드라이어', '비누', '샴푸', '컨디셔너', '온수', '빵', '계란', '커피', '머신', '매일', '수건', '우리', '사용', '수', '모든', '주방', '도구', '숙박', '시설', '정말', '사진', '자료', '완전', '깨끗', '가격', '사장', '친절', '다시', '또오', '공항', '깝', '바다', '는걸', '어서', '정도', '가격', '완전', '깨끗', '압력밥솥', '전자레인지', '토스트', '기', '커피포트', '기', '기본', '조미료', '완비', '아두', '아주', '맘', '마음', '듬그', '우리', '위해', '모든', '것', '설명', '해주시', '호의', '정보', '섬', '스파이크', '를', '영어', '냉장고', '정리', '시', '펜션', '은', '계란', '빵', '오렌지', '주스', '추가', '분', '정도', '수', '레스토랑', '수', '일간', '나', '게스트', '하우스', '경험', '우선', '버스', '통해', '공항', '접근', '수', '나', '게스트', '하우스', '바로', '앞', '버스', '정류장', '현지', '버스', '타고', '제주', '여행', '교통', '걱정', '필요', '둘째', '주변', '마을', '가장', '레스토랑', '운', '돼지', '마지막', '방', '라운지', '주방', '공간', '또한', '미소', '인사말', '이', '곳', '추천', '이', '호스텔', '몇', '가지', '사항', '주인', '매우', '그', '지역', '대해', '압니', '제', '특정', '음식', '레스토랑', '영업', '확인', '전화', '지도', '나', '수', '라운지', '룸', '무료', '아침', '식사', '제공', '재료', '제공', '공항', '장소', '시외', '버스', '정류장', '위치', '레스토랑', '바', '한라산', '분', '거리', '호스텔', '객실', '건', '에어컨', '샴푸', '및', '바디', '워', '시가', '욕실', '방', '명', '투숙', '사물함', '약간', '가방', '전체', '귀중', '품', '수', '전체', '크기', '수건', '손', '수건', '제공', '꼭', '다시', '이용', '첫', '제주도', '여행', '동안', '전혀', '불평', '것', '방', '세면', '도구', '포함', '화장실', '매일', '새', '타월', '제공', '무제한', '토스트', '계란', '우유', '커피', '주스', '아침식사', '조리', '가능', '시간', '요리', '가능', '점심', '식사', '저녁', '식사', '차', '밤새', '무료', '주차장', '제공', '시청', '편의', '위치', '바', '술집', '지구', '인근', '식당', '리셉션', '직원', '모든', '도움', '심지어', '영어', '차', '한국어', '입력', '것', '도', '전체', '꼭', '추천', '우리', '꼭', '다시', '묵', '것', '제주', '섬', '발견', '위해', '박', '거기', '이', '게스트', '하우스', '도시', '번화가', '부분', '위치', '섬', '거의', '모든', '명소', '버스', '거기', '출발', '섬', '남쪽', '동쪽', '서쪽', '때', '대략', '시간', '계산', '수', '게스트하우스', '사람', '정말', '섬', '모든', '곳', '도달', '가장', '방법', '항상', '알', '게스트하우스', '수도', '모든', '것', '제공', '샴푸', '헤어', '드라이어', '수건', '등', '나', '추천', '제주', '시청', '근처', '교통', '버스', '여행', '선택', '시내', '위치', '저녁', '단점', '주인', '때문', '문제', '무', '계획', '숙소', '잡고', '자마자', '롱보드', '보고', '사람', '분위기', '여기저기', '푹', '쉬', '전체', '심플', '분위기', '선택', '초이스', '힙', '음악', '핫도그', '술', '무엇', '층', '바', '음악', '혼자', '운', '공짜', '술', '수', '굳럭', '택시', '타고', '제주도', '구나', '도로', '편', '힙', '로고', '층', '라운지', '저', '엔돌핀', '층', '음악', '소리', '겁', '겁', '체크', '바', '장님', '매니저', '노래', '크게', '맥주', '칵테일', '잔', '로컬', '외국인', '분도', '자주', '오시', '신축', '방', '운', '제', '방', '테라스', '밤', '아침', '어메이징', '뷰', '선사', '가격', '걸', '제공', '조식', '근처', '러닝', '힐링', '서귀포', '쪽', '공항', '우연찮', '머', '곳', '발견', '또', '사장', '층', '바', '페로', '운영', '그', '위로', '호스텔', '객실', '바', '카페', '객실', '모두', '전망', '나', '맨', '층', '조식', '실', '도심', '풍경', '엄지', '척', '직원', '다음', '제주', '무조건', '다시', '거', '숙소', '서비스', '덕분', '가요', '아래층', '분위기', '가격', '라운지', '밤', '혼자', '맥주', '마시기', '진짜', '굿', '진짜', '다른', '완전', '추천', '조식', '뷰', '아주', '산지천', '한라산', '항', '보', '도미', '토리', '객실', '뷰', '최고', '공항', '근처', '숙소', '그냥', '여기', '저', '도미', '토리', '매트리스', '꿀잠', '호스트', '층', '새벽', '시', '한참', '수다', '다음', '제주', '다시', '또', '정나무', '포인트', '인테리어', '방', '분위기', '사장', '감각', '듯', '다른', '비지니스', '호텔', '호텔', '방', '새', '다음', '번', '생기', '또', '곳', '사장', '정원', '웨딩', '스냅', '차', '제주', '방문', '평점', '정원', '카페', '느낌', '곳', '방문', '주인', '이상', '시설', '서비스', '갈수록', '흥', '일부러', '분위기', '외국인', '사장', '무엇', '합리', '가격', '숙박', '레스토랑', '때문', '곳애월항', '근처', '곳', '전체', '룸', '컨디션', '실내', '집', '기류', '정원', '느낌', '산책로', '걷기', '뒤쪽', '연못', '객실', '아침', '조식', '날수', '사장', '내외', '기분', '곳', '주차', '하층', '하층', '엘리베이터', '식당', '편의점', '근처', '가격', '이용', '공차', '근처', '유리', '식당', '세븐', '편의점', '공항', '분', '거리', '위치', '이동', '투숙', '장점', '가격', '그', '가격', '것', '감안', '때', '전혀', '실망', '객실', '욕실', '도로', '변', '소음', '걱정', '도로', '통행량', '투숙', '단점', '이틀', '투숙', '때문', '체크아웃', '때', '정비', '말', '달라', '요청', '이튿날', '외출', '정비', '해', '정비', '것', '소통', '것', '원래', '숙박', '시설', '금연', '기본', '처음', '배정', '객실', '담배', '냄새', '직원', '바로', '방', '변경', '제발', '숙박', '곳', '금연', '흡연', '항상', '술', '짓', '사람', '담배', '짓', '사람', '나', '어이', '평', '가격', '대비', '우리', '일요일', '오후', '체크', '수요일', '우리', '방', '개', '해', '담배', '냄새', '연기', '우리', '방', '수', '우리', '방', '욕실', '거울', '세면대', '샤워', '화장실', '마치', '천', '전체', '호텔', '잠시', '것', '이', '것', '다른', '영어', '거의', '우리', '애플리케이션', '사용', '수', '이', '욕실', '및', '전반', '아주', '허름합니', '등급', '것', '제주도', '패키지', '여행', '중', '호텔', '박', '스위트룸', '인', '실', '사용', '스위트룸', '거실', '화장실', '침대', '개', '방이', '하나', '별로', '예상', '생각', '것', '숙소', '다만', '점', '호텔', '제공', '이불', '거', '조식', '서비스', '이용', '한식', '제공', '반찬', '가지', '정도', '국도', '맛', '제주', '번', '시내', '주변', '식당', '까페', '술집', '나이트', '등', '거의', '유흥', '거리', '해도', '과언', '가족', '휴가', '숙박', '침대', '드하', '가장', '충격', '바퀴벌레', '벌레', '신경안', '쓰시', '분', '처음', '저', '진짜', '충격', '처음', '어머니', '화장실', '그때', '방', '마리', '더', '발견', '화가', '안내', '데스크', '연락', '원래', '바퀴벌레', '지네', '등등', '답변', '방이', '방도', '못', '수건', '요', '진짜', '어이', '짐', '마리', '집', '순식간', '짐', '정리', '테이블', '신경', '잠도', '못', '숙소', '날', '최악', '호텔', '절대', '직원', '대처', '불만', '지인', '년전', '추천', '제주도', '여행', '첫날', '숙소', '롤', '곳', '위치', '좀', '외지', '객실', '상태', '좀', '미흡', '조식', '정말', '별로', '소음', '호텔', '대처', '서비스', '모텔', '디럭스', '박', '숙박', '천장', '물', '소리', '새벽', '내내', '데스크', '문의', '새벽', '시', '호텔', '우린', '컴', '플레인', '적', '내일', '시설', '팀', '확인', '함', '다음', '날', '시설', '팀', '확인', '것', '그', '다음', '날', '방', '숙박', '나', '소음', '그로', '일', '내내', '새벽', '시', '소음', '녹음', '불구', '디럭스', '풀북', '나', '디럭스', '숙박', '거르세', '제발', '트립어드', '바이', '저가', '업뎃', '녹음', '기능', '추가', '수', '평생', '간직', '후', '소음', '업뎃', '것임', '정말', '이', '호텔', '모텔', '아스', '크림', '숟가락', '좀', '달라', '하니', '데스크', '권한', '함', '조식', '운영', '중인', '호텔', '말', '끝', '모텔', '것', '서비스', '걸', '그동안', '호텔', '중', '정말', '오기', '베스트', '최악', '호텔', '본관', '층', '객실', '바로', '앞', '바다', '뷰', '객실', '객', '실내', '에어컨', '제습기', '빨래', '건조기', '사이즈', '주방', '사용', '함', '로비', '물', '맥주', '판매', '공', '호텔', '입구', '편의점', '그', '곳', '구매', '추천', '함', '공항', '대략', '분', '정도', '소요', '위치', '공항', '편', '다만', '호텔', '시설', '관리', '면', '약간', '보임', '방충', '망', '구멍', '곳도', '벽돌', '군데군데', '곳', '보임', '전체', '호텔', '우리', '방만', '이불', '구멍', '하나', '분', '거리', '해변', '맛집', '자리', '제주', '때', '묵고', '매번', '불만', '추천', '룸', '레스토랑', '직원', '함덕', '해변', '분', '주변', '맛집', '꽤', '공항', '승용차', '약', '분', '차', '시간', '공항', '버스', '함덕', '해변', '바로', '앞', '만원', '슈페리어트윈룸', '인', '사용', '시', '객실', '아주', '다만', '객', '실수', '주차장', '조금', '협소', '것', '라마', '환경', '바다', '접근성', '용이', '조식', '단점', '주변', '함덕', '해수욕장', '밤새', '아주', '분', '정도', '위치', '제', '땐', '사람', '이용', '곳', '청소', '샴푸', '린스', '바디', '워시', '치약', '폼클렌징', '빨래', '무료', '이구', '여자', '방', '드라이기', '뿐', '빗', '화장', '솜', '면봉', '근처', '시장', '공항', '버스', '수', '마스코트', '락심이', '정말', '밖', '안', '구분', '위생', '분', '주의', '것', '조식', '계란', '식빵', '밥', '미역국', '씨리얼', '우유', '쥬스', '시장', '가까이', '수', '관덕정', '도미', '토리', '층', '곳', '화장실', '겸용', '하나라', '좀', '사람', '거실', '서로', '정보', '공유', '제주도', '때', '종종', '게', '위치', '쪽', '곳', '좀더', '조식', '주인', '가끔', '저녁', '파티', '은', '여행', '때', '가격', '다소', '편이', '제주', '시내', '공항', '근처', '아침', '비행기', '분', '것', '곳', '건물', '개조', '해도', '시설', '다소', '낙후', '것', '감안', '듯', '시내', '게스트하우스', '가게', '곳', '가격', '좀', '대신', '건물', '편이', '제', '방', '창문', '모기', '화장실', '약간', '낙후', '느낌', '주인', '리', '모델링', '페인트', '칠이', '느낌', '아침', '조식', '메뉴', '게스트하우스', '일반', '메뉴', '준비', '분위기', '화기', '애애', '거실', '담소', '친구', '뷰', '눈', '펑펑', '무리', '방도', '쉬', '다음', '가족', '엠버', '리조트', '번창', '날씨', '호텔', '곳', '바베큐', '파티', '나중', '설', '매장', '오픈', '친구', '제주', '여행', '카라반', '숙박', '꼭', '여기', '리뷰', '보고', '선택', '곳', '선택', '직원', '객실', '청소', '리조트', '프론트', '스낵코너', '종류', '맥주', '캔', '스낵', '구매', '가족', '곳', '다음', '날', '한라산', '등반', '계획', '결정', '엠버', '리조트', '생각', '외로', '경치', '두', '말', '객실', '청결', '도시', '음속', '곳', '사진', '업데이트', '안', '것', '실제', '방문', '때', '사진', '기대', '이상', '외부', '느낌', '내부', '인테리어', '신경', '리', '클라이너', '소파', '커피', '머신', '세심', '부분', '조경이', '랄', '여러가지', '공', '한라산', '쪽', '시내', '좀', '난방', '물', '힐링', '조식', '가격', '숙소', '자주', '방문', '제주', '이번', '함덕', '숙박', '예약', '가격', '파셜', '오션', '뷰', '제공', '예약', '서드', '파티', '것', '테라스', '것', '내', '것', '일단', '룸', '체인지', '다른', '방', '이', '객실', '도대체', '무엇', '침대', '매우', '싸구려', '침대', '티나', '거림', '세면대', '화장실', '아예', '분리', '동선', '호텔', '생전', '처음', '다른', '분', '말씀', '곰팡이', '문제', '객실', '억지로', '것', '것', '욱여넣', '느낌', '나름', '전망', '편이', '화장실', '고작', '욕조', '하나', '수', '수준', '문', '마저', '장난', '매우', '두', '번', '다시', '모로', '최악', '호텔', '중', '하나', '코너', '바다', '뷰', '를', '묵', '바다', '손톱', '보', '네', '원래', '함덕', '앞', '호텔', '이용', '여기', '이번', '여기', '호텔', '묵엇', '습', '다가', '자마자', '식당', '수도관', '파열', '레스토랑', '천장', '맥주', '무한리필', '조식', '도시락', '대체', '예정', '함', '방', '화장실', '곰', '짐', '세면대', '물', '샴푸', '코딱지', '거', '줌', '콘센트', '구멍', '개', '라서', '명', '보조', '배터리', '잠', '침대', '머리', '콘센트', '구멍', '개', '방', '구비', '슬리퍼', '누가', '어도', '번은', '슬리퍼', '명', '방', '물', '병', '수건', '장만', '줌', '아침', '시', '조식', '카운터', '직원', '도시락', '얼른', '우도', '려고', '직원', '옴', '객실', '점검', '안내', '팻말', '보고', '객실', '커녕', '천장', '레스토랑', '쪽', '담배', '냄새', '오지', '풍기면', '옴', '조식', '달라', '도시락', '고함', '그때', '시간', '시', '조식', '시', '업체', '지금', '직원', '고함', '됏다', '옴', '승', '뭐', '호텔', '방', '상태', '답', '최선', '그', '금액', '대의', '호텔', '비치', '자기', '숙소', '걸', '금액', '때로는', '함덕', '바다', '살짝', '때', '기분', '정도', '해변', '메인', '해변', '위치', '방', '크기', '인테리어', '가격', '생각', '가성', '비', '편이', '생각', '저', '제일', '작은방', '바다', '측면', '뷰', '이', '방', '구조', '세면대', '샤워실', '동선', '좀', '시설', '위치', '바닷가', '근처', '산책', '맥', '파이', '근처', '더욱', '버스', '접근성', '택시', '주로', '이용', '함', '요새', '중국', '관광객', '위치', '자체', '시장', '마트', '편', '다만', '앞', '놀이기구', '문', '전', '편이', '전망', '앞쪽', '다른', '호텔', '볼', '건', '방', '넓이', '상태', '무난', '편이', '일회용품', '점', '꼭대기', '층', '바', '체크', '인시', '생맥주', '쿠폰', '주니', '한잔', '모텔', '리', '모델링', '것', '예전', '흔적', '부분', '전반', '관리', '침대', '시트', '등', '제주', '도착', '때', '가성', '비', '아주', '주변', '제주', '등', '유명', '맛집', '탑층', '바', '오픈', '생맥주', '잔', '무료', '쿠폰', '주니', '호감', '급상승', '주변', '소음', '가격', '생각', '시설', '움', '점', '얘기', '처리', '바닷가', '조금', '보', '공항', '근처', '하루', '예약', '세면', '때', '일회용품', '객실', '택시', '공항', '분', '정도', '소요', '곳', '그것', '시간', '이', '리조트', '해변', '바로', '옆', '때문', '전망', '제공', '클린', '룸', '침대', '리조트', '승무원', '매우', '내', '다시', '제주', '방문', '리조트', '다시', '것', '제주도', '위치', '바로', '해변', '근처', '룸', '뷰', '화', '해변', '자체', '곳', '우리', '가족', '갈수', '근처', '카페', '해녀', '박물관', '근처', '성산일출봉', '분', '정도', '이', '근처', '여행', '분', '추천', '제주도', '출장', '때문', '방문', '다음', '휴가', '때', '다시', '방문', '숙소', '바다', '바로', '앞', '조식', '프라이', '베이컨', '샐러드', '빵', '등', '수', '청소', '상태', '직원', '때문', '더', '만족', '수', '룸', '카페', '바다', '뷰', '때문', '단점', '태교여행', '박', '리조트', '바다', '바로', '앞', '위치', '조식', '달걀프라이', '베이컨', '샐러드', '직접', '준비', '토스트', '버터', '씨리얼', '황도', '오렌지', '주스', '마련', '수', '직원', '모두', '리조트', '내', '카페', '카페', '역시', '바다', '경치', '객실', '침대', '바다', '정말', '제대로', '힐링', '여행', '룸', '컨디션', '제주도', '동쪽', '여행', '준비', '리조트', '무조건', '또', '잠', '자고', '오자', '가성', '비', '일', '듯', '박일', '여행', '하루', '더', '체류', '바람', '것', '간', '곳', '공간', '아침', '식사', '때', '한국인', '저희', '가족', '금은', '중국', '관광객', '듯', '가격', '공항', '근처', '하루', '추천', '공항', '택시', '비', '원', '정도', '제주', '공항', '저녁', '도착', '근처', '잡고', '거리', '포', '시즌', '호텔', '추천', '다만', '방', '집', '비행기', '시간', '아침', '새벽', '때', '라면', '제주', '공항', '근처', '숙소', '이', '곳', '공항', '인근', '중', '저가', '호텔', '하나', '숙소', '다소', '비', '시설', '편입', '니', '시내', '위치', '인근', '지역', '관광', '그것', '위치', '예산', '호텔', '어디', '수', '제과점', '신라', '면세점', '약', '거리', '도로', '건너편', '아이', '위', '놀이터', '뒷문', '사용', '그것', '제', '딸', '즐거움', '방', '욕실', '크기', '매트리스', '나', '만', '직원', '도움', '제주', '공항', '도심', '한가운데', '접근성', '건물', '년대', '시간', '건물', '외형', '및', '내부', '건물', '로비', '쾌쾌', '아침', '조식', '가격', '그', '가격', '밥', '전체', '거두', '절미', '숙박', '료', '생각', '아주', '호텔', '혹시', '가격', '망각', '수준', '그것', '고객', '도둑', '심보', '그냥', '도심', '아주', '시설', '가격', '숙박시설', '보시', '아침', '조식', '뷔페', '방도', '몇', '개', '방', '리', '모델링', '덜', '길가', '신호등', '길가', '위치', '택시', '잡기', '호텔', '나', '운', '발코니', '방이', '나', '행복', '해', '물', '필요', '각', '객실', '용기', '수건', '호텔', '또한', '욕실', '발매', '안', '아침', '식사', '보통', '수준', '호텔', '중국', '단체', '관광객', '위', '건물', '여행지', '라스베가스', '스트립', '호텔', '이', '곳', '년', '가지', '방', '침대', '시트', '손님', '머리카락', '여행객', '위해', '모기', '살', '수', '푸드', '바베큐', '침대', '위치', '도시', '중심부', '멀리', '친구', '여기', '제주도', '최고', '호텔', '가격', '대비', '가치', '위치', '중심', '시설', '방', '매우', '와이파이', '나', '이', '호텔', '최고', '관광지', '잠', '것', '뿐', '급', '럭셔리', '호텔', '공항', '호텔', '버스', '노선', '뿐', '근처', '식당', '또한', '시장', '왕복', '방', '방음', '화장실', '냄새', '냉', '방도', '개인', '조절', '수', '본인', '키', '다음', '번', '제주도', '방문', '또', '연말', '매년', '제주', '그때', '이용', '곳', '주변', '객실', '소음', '서비스', '친절', '청결', '모두', '곳', '제주도', '곳', '곳도', '여기', '곳', '찾기', '제주', '숙소', '중', '가장', '규모', '작', '곰팡이', '하나', '침구', '잠', '진짜', '푹', '재', '방문', '의사', '프로', '참고', '공항', '택시', '분', '정도', '거리', '저', '친구', '모두', '정말', '다음', '조식', '또한', '저기', '위치', '수건', '청소', '정말', '바다', '전망', '확', '추천', '조식', '포함', '공항', '근처', '도', '가격', '합리', '이불', '매트리스', '커버', '사용', '맘', '조식', '심플', '종류', '별로', '제공', '맘', '주차공간', '다소', '이', '가격', '대비', '만족', '출장', '때문', '제주도', '가성', '비', '전체', '난방', '방이', '아주', '또한', '옆', '편의점', '더', '제주', '출장', '때문', '주로', '모텔', '숙박', '가격', '스테이', '호텔', '예약', '시설', '직원', '서비스', '마인드', '조식', '무료', '이용', '사진', '보이', '방', '꽤', '봄철', '에어컨', '창문', '청결', '아주', '로비', '직원', '매우', '도움', '승강기', '객실', '바닥', '짐', '실', '수', '다시', '여기', '머', '무르', '방', '겨울', '에어컨', '창문', '해', '예약', '사이트', '사진', '물고기', '눈', '렌즈', '것', '오해', '소지', '다시', '여기', '롭', '여행자', '호텔', '로비', '스태프', '현대', '환경', '우리', '묵', '수', '곳', '레스토랑', '서비스', '이', '호텔', '근처', '시장', '액세스', '수', '우리', '제주', '여행', '때', '우리', '몇', '밤', '여기', '우리', '렌트카', '탐색', '장치', '찾기', '매우', '공항', '약', '분', '우리', '아파트', '발코니', '바다', '거실', '주방', '기본', '요리', '도구', '아파트', '지시', '사항', '영어', '모든', '고문', '밖', '동시', '발코니', '문', '개', '것', '대한', '번역', '앱', '사용', '또한', '아파트', '거실', '패널', '장소', '조명', '제어', '리모콘', '셀프', '세탁', '시설', '공항', '것', '차로', '분', '거리', '시간', '코인', '세탁소', '제주', '때', '가치', '기반', '므', '다시', '예약', '방', '나', '그', '지역', '새', '개발', '생각', '그것', '매우', '바다', '발코니', '전망', '수', '직원', '별로', '우리', '에어', '컨디셔너', '문제', '관해', '그', '말', '우리', '통제', '이해', '수', '다음', '날', '그', '우리', '제어판', '더', '광고', '영어', '녹음', '우리', '공항', '오전', '시', '택시', '요청', '비록', '문제', '직원', '우리', '위해', '또', '다른', '택시', '우리', '택시', '확신', '우리', '그', '대화', '나누기', '그', '아주', '사람', '다음', '번', '거기', '것', '공항', '분', '거리', '교통', '정체', '달러', '때문', '매우', '합리', '요금', '시설', '그냥', '일반', '모텔', '분명', '실내', '흡연', '금지', '객실', '담배', '쩐내', '저', '그', '이상', '그', '이하', '동의', '입구', '위치', '리', '모델링', '완료', '호텔', '객실', '위치', '직원', '환대', '혼자', '개', '침대', '방이', '부담', '내', '이용', '방', '층', '프린세스', '코스', '방', '이벤트', '성의', '방이', '층', '프린세스', '룸', '바다', '방도', '편이', '욕조', '복도', '끝', '스모', '킹', '라운지', '엘리베이터', '개', '조식', '만원', '가격', '대비', '공항', '버스', '택시', '바로', '가면', '분도', '택시', '번화가', '위치', '쇼핑', '거나', '커피', '술', '한잔', '호텔', '상태', '서비스', '마음', '적극', '추천', '다음', '예정', '공항', '먹거리', '곳', '완전', '중심', '스카이', '파크', '객실', '비지니스', '호텔', '생각', '잠', '바오', '젠', '거리', '일정', '예약', '주차장', '될껀', '하층', '세탁실', '여행', '곳', '또', '비행기', '바람', '예약', '공항', '평이', '예약', '정말', '시설', '거여', '직원', '수', '발', '묶여서', '당황', '주변', '식당', '추천', '감동', '추천', '요가', '방', '이용', '객실', '침대', '개', '좀', '듯', '느낌', '생각', '안', '화장실', '문', '안쪽', '변기', '샤워', '대가', '유리', '각각', '문', '수건', '총', '장', '냉장고', '와이파이', '호텔', '박', '묵', '공항', '버스', '타고', '정류장', '만', '이', '호텔', '수', '근처', '위치', '쇼핑', '식사', '공간', '마켓', '호텔', '직원', '만날', '수', '엘리베이터', '만', '그', '우리', '체크', '인', '아침식사', '제공', '객실', '및', '시설', '아주', '욕실', '문', '별도', '화장실', '및', '샤워실', '아침', '식사', '표준', '및', '커피', '차', '선택', '수', '의', '시스템', '공항', '버스', '안', '버스', '역', '최상', '위치', '쇼핑', '근처', '레스토랑', '버스', '정류장', '공항', '고분', '정거장', '만', '해당', '편안함', '그', '만', '아침', '식사', '기본', '단점', '화장실', '문', '방', '온도', '조절', '방법', '알', '호텔', '위치', '모든', '곳', '히터', '의', '온도', '이', '변경', '밤', '잠', '게', '저', '저', '창', '열기', '권한', '또한', '욕실', '문', '사진', '해당', '것', '가격', '숙소', '무엇', '주인', '감동', '무료', '아침밥', '준비', '배', '불리', '다시', '리조트', '해안', '모두', '아이', '씨', '가치', '강력', '추천', '한가지', '단점', '독서', '용', '램프', '극복', '오아시스', '곳', '수', '정원', '소리', '체재', '회의', '약', '분', '도보', '근처', '국제', '컨벤션', '센터', '근처', '대포', '주상절리', '절벽', '연', '폭포', '제주', '미지', '식물원', '및', '드라이브', '거리', '사찰', '우리', '개', '아파트', '명', '일', '합리', '주방', '시설', '그릇', '밥솥', '가스레인지', '매우', '합리', '가격', '요리', '수', '가족', '여행', '한국', '음식', '아침', '식사', '제공', '몇', '가지', '메뉴', '역상', '컨시어', '아주', '사람', '영어', '아주', '협조', '체크', '때', '밤', '약', '사용', '수', '이', '곳', '공원', '거리', '가득', '해당', '수도', '리셉션', '시간', '사용', '서귀포', '분', '거리', '레스토랑', '쇼핑', '센터', '등', '차', '여행', '제주', '그룹', '경우', '사람', '이', '곳', '강력', '추천', '아파트', '호텔', '회의', '아이', '씨', '또한', '가족', '휴가', '더', '수', '주위', '저', '그냥', '이', '날', '추천', '곳', '묵고', '숙박시설', '제주', '컨퍼런스', '센터', '아침', '식사', '제공', '그', '영어', '매우', '도움', '심지어', '관리', '공항', '택시', '투어', '시간', '환상', '객실', '무선', '인터넷', '바다', '전망', '수', '분', '정도', '위치', '얼마', '전체', '매우', '온수', '난방', '다만', '조식', '편이', '것', '함덕', '해수욕장', '바로', '앞', '위치', '신축', '건물', '개보', '수로', '방', '컨디션', '제주', '날씨', '때', '해수욕장', '함덕', '협재금능', '순위', '칠', '만큼', '에메랄드', '색', '신관', '클린룸', '구관', '씨뷰', '군데', '숙박', '신관', '대신', '조식', '굿앤굿', '스마트', '이용', '구관', '씨뷰', '제일', '패밀리', '룸', '바다', '뷰', '대신', '노후', '시설', '좀', '함덕', '해변', '제일', '장점', '우선', '프론트', '직원', '모두', '원래', '패밀리', '룸', '예약', '오션', '뷰', '럭셔리', '룸', '추가', '기존', '금액', '오만원', '남짓', '더', '후회', '체크', '시간', '조금', '일찍', '정리', '짐', '수', '체크', '박', '일로', '스위트', '취사', '가능', '투숙', '체크', '아웃', '직원', '함덕', '해수욕장', '매우', '근처', '만', '곳', '모던', '관리', '사우나', '투숙', '객', '유료', '가족', '여행', '숙박', '취사', '구관', '함덕', '해수욕장', '뷰', '볼', '수', '내부시', '별로', '업무', '출장', '공항', '사거리', '위치', '굿', '신축', '건물', '듯', '냄새', '전혀', '쾌적', '더블', '침대', '싱글', '침대', '스타일', '객실', '욕실', '로비', '식사', '메뉴', '카페', '가격', '박', '당', '약', '직원', '영어', '섬', '제주도', '허용', '범위', '및', '가격', '값', '것', '침대', '화장실', '이', '크기', '수건', '포기', '해', '도착', '때', '리셉션', '아무', '자고', '방', '직원', '카운터', '뒤', '저', '절전', '겨울', '생각', '위치', '어디', '드라이브', '음식', '때문', '주변', '주의', '점', '호텔', '하룻밤', '방', '곳', '꽤', '화장실', '제외', '제주', '시', '중심부', '쇼핑', '지역', '주차', '공간', '다소', '제한', '직원', '전문', '곳', '편의점', '근처', '시장', '바로', '앞', '자', '먹거리', '식사', '저녁', '시간', '수', '장점', '호텔', '사용', '가구', '부모님', '데리', '여행', '때', '법', '분위기', '사용', '물건', '것', '애저', '꼭', '번', '보시', '추천', '직원', '층', '갤러리', '옆', '터', '차', '한잔', '여유', '즐', '기기', '아침식사', '시장', '아침식사', '수', '전', '트리플', '룸', '가격', '대비', '정말', '트윈룸', '다른', '리뷰', '글', '보고', '전혀', '뷰', '건', '만원', '트리플', '룸', '뷰', '순', '겨울', '방도', '끈', '단점', '굳이', '조식', '점', '방과', '달리', '화장실', '춥다', '거', '다른', '점', '위치', '재', '방문', '의사', '더블', '침대', '객실', '예약', '객실', '매우', '침대', '옷장', '공간', '침실', '사이', '칸막이', '음', '방', '매우', '건물', '마모', '흔적', '유지', '나', '칸막이', '쪽', '모든', '방', '통해', '연결', '발코니', '층', '방', '배치', '공기', '리', '도록', '슬라이더', '도어', '열', '때', '날씨', '스크린', '도어', '슬라이더', '도어', '불편', '함', '안전', '아마', '관리인', '주인', '프론트', '여성', '매우', '수용', '그', '여름', '동안', '단지', '통상', '작용', '것', '인', '에어', '컨디셔너', '통제', '나', '제공', '욕실', '욕조', '샤워', '커튼', '샤워', '때', '욕실', '절반', '그것', '이외', '그것', '호텔', '제주', '한가운데', '전략', '위치', '나', '체재', '지하', '쇼핑', '센터', '출구', '의', '뒤', '로부터', '약간', '단계', '이', '지역', '쇼핑', '및', '레스토랑', '호텔', '아침', '식사', '제공', '선택', '폭', '또한', '호텔', '몇', '걸음', '곳', '버스', '정류장', '도시', '루프', '투어', '이용', '수', '지하철', '쇼핑몰', '도시', '내의', '대부분', '지역', '연결', '시간', '후회', '우리', '공항', '시장', '곳', '뭔가', '것', '선택', '그것', '호텔', '관리', '직원', '동문', '시장', '길', '건너편', '지하', '상가', '입구', '약', '방', '우리', '위', '베개', '여분', '점', '것', '관', '문제', '곳', '식당', '스타', '벅스', '길', '간다', '날', '밤', '우리', '저녁', '바다', '쪽', '곧장', '한국어', '바베큐', '서양인', '준비', '직원', '우리', '또한', '버스', '정류장', '제주시', '관광', '버스', '타고', '일일', '패스', '사용', '주변', '우리', '제주', '숙박', '호텔', '숙박', '시장', '가로', '사진', '위치', '돼지', '거리', '동문', '마켓', '신문사', '상대', '지하', '상가', '방과', '욕실', '가격', '고려', '그', '매일', '제공', '무료', '광천수', '제공', '우리', '박', '전통', '객실', '두번째', '방문', '함', '최근', '리', '모델링', '별관', '얼마', '새', '집', '인테리어', '구석구석', '신경', '흔적', '빨래', '건조대', '구비', '가성', '비', '최고', '협재해수욕장', '한림', '공원', '매우', '위치', '매우', '난방', '살짝', '방', '개', '내부', '매우', '그냥', '가성', '비', '정도', '위치', '협재', '해변', '도보', '분', '거리', '위치', '매우', '수영장', '여름', '제주도', '이만', '위치', '이정', '시설', '가격', '경쟁력', '숙소', '거의', '것', '재', '방문', '의사', '새벽', '시', '새벽', '시', '공사', '시작', '사전', '통보', '객실', '바닥', '청소', '상태', '불량', '맨발', '무척', '화장실', '핸드', '워시', '물', '서비스', '모텔', '체크', '인과', '체크', '아웃', '아주', '그냥', '통과', '예약', '접수', '및', '증거', '를', '볼', '수', '체크', '아웃', '룸', '키', '카운터', '이', '전송', '수', '이', '호텔', '전망', '협재', '해변', '곳', '위치', '호텔', '약', '분', '정도', '이', '협재', '해변', '두번째', '방문', '함', '최근', '리', '모델링', '별관', '얼마', '새', '집', '인테리어', '구석구석', '신경', '흔적', '빨래', '건조대', '구비', '가성', '비', '최고', '협재해수욕장', '한림', '공원', '매우', '위치', '매우', '난방', '살짝', '방', '개', '내부', '매우', '그냥', '가성', '비', '정도', '위치', '협재', '해변', '도보', '분', '거리', '위치', '매우', '수영장', '여름', '제주도', '이만', '위치', '이정', '시설', '가격', '경쟁력', '숙소', '거의', '것', '재', '방문', '의사', '새벽', '시', '새벽', '시', '공사', '시작', '사전', '통보', '객실', '바닥', '청소', '상태', '불량', '맨발', '무척', '화장실', '핸드', '워시', '물', '서비스', '모텔', '체크', '인과', '체크', '아웃', '아주', '그냥', '통과', '예약', '접수', '및', '증거', '를', '볼', '수', '체크', '아웃', '룸', '키', '카운터', '이', '전송', '수', '이', '호텔', '전망', '협재', '해변', '곳', '위치', '호텔', '약', '분', '정도', '이', '협재', '해변', '집', '듯', '위치', '객실', '및', '수영장', '등', '시설', '모두', '다만', '일', '직원', '분', '수가', '소로', '중국인', '투숙', '객', '분', '국', '제주', '중심', '지역', '노', '오거리', '차로', '정도', '중산', '지역', '때문', '아주', '경관', '년', '신축', '호텔', '리조트', '시설', '매우', '저', '호텔', '객실', '투숙', '객실', '일단', '좀', '비니', '지스', '호텔', '욕실', '정도', '욕조', '하나', '법', '생수', '병', '회용', '슬리퍼', '개', '무료', '제공', '회용', '칫솔', '치약', '세면', '용품', '제공', '침대', '느낌', '매우', '주변', '것', '때문', '정말', '호텔', '대부분', '비치', '구둣주걱', '구두', '천이', '조금', '의아', '실내', '수영장', '작고', '사우나', '샤워', '시설', '탕', '리조트', '무료', '조식', '뷔페', '우리', '주', '건물', '별개', '가족', '스위트', '아주', '아주', '아주', '주방', '거실', '분리', '욕실', '및', '침실', '마리', '고양이', '만', '별도', '주차', '수', '스위트', '룸', '수영장', '박', '동안', '아무', '날', '밤', '방', '청소', '마치', '해외', '기분', '정도', '여유', '새', '귀', '정원', '꽃', '새소리', '깨', '처음', '요', '객실', '스파', '인테리어', '하나', '하나', '세심', '신경', '흔적', '우리나라', '보기', '리조트', '감히', '말', '조식', '뷰', '서비스', '모두', '모두', '관광지', '사람', '북적', '제대로', '해외', '온', '기분', '매년', '곳', '요즘', '좀', '모습', '곳곳', '아침식사', '꽤', '편입', '니', '스탭들', '매우', '식구', '인테리어', '무척', '다만', '전', '부대', '시설', '축소', '저녁', '곳', '수영장', '아이', '외', '것', '실내', '월풀', '분', '바닷가', '해변', '벤치', '아침', '출장', '나중', '가족', '다시', '한번', '여름', '멀리', '바다', '야외', '풀', '가족', '시간', '제주', '전통', '형태', '지중해', '양식', '듯', '움', '내내', '조식', '제공', '뷔페', '아이', '어른', '저', '아내', '무척', '말', '그대로', '전형', '게스트하우스', '문제', '방이', '한겨울', '이불', '개', '계속', '잠', '가격', '혼자', '여행', '사람', '난방', '방음', '처음', '때', '외국인', '분위기', '금방', '수', '저녁', '외국', '온', '분', '맥주', '이야기', '수', '인상', '대표', '메이', '싱가폴', '오신', '미스터', '장', '모두', '기억', '사업', '정상', '방문', '제주', '여행', '기억', '호스텔', '코리아', '감사', '저', '이마트', '앞', '곳', '시장', '앞', '쪽', '두', '군데', '자', '분', '두', '군데', '관리', '첫날', '저녁', '이마트', '편', '키크', '여자', '맞이', '밤', '라운지', '맥주', '사', '주시', '여행', '오신', '분', '모두', '둘째', '날', '아침', '일보', '낮', '동문', '시장', '쪽', '호스텔', '코리아', '발견', '요시', '지점', '이', '일', '어제', '밤', '분', '또', '거기', '일', '이름', '타샤', '나', '타샤', '것', '망치', '작업', '모습', '기억', '제주도', '여자', '뭐', '성격', '분신', '술', '직원', '다시', '감사', '여관', '펜션', '가격', '시설', '이용', '수', '공항', '거리', '기본', '요금', '정도', '나오니', '저', '최적', '숙박', '장소', '호스텔', '코리아', '화이팅', '다음', '여행', '일정', '방문', '방도', '청소', '관리', '다만', '화장실', '휴지', '요금', '부과', '수건', '주지', '점', '유의', '그', '점', '직원', '아주', '직원', '아침', '식사', '식당', '직접', '운전', '우리', '주기도', '위치', '중심', '다음', '숙박', '생각', '월', '중순', '제', '호스텔', '중', '최악', '에어컨', '때문', '밤', '잠', '수가', '방이', '아주', '후텁', '근해', '방충', '망', '구멍', '송송', '또', '구멍', '해도', '창문', '꽉', '모기', '방', '데', '문제', '밤', '시간', '절반', '정도', '모기', '시간', '마리', '건', '일도', '뿐', '아주', '레스토랑', '술집', '창문', '바로', '밑', '새벽', '시', '영업', '아주', '밤', '접수', '처', '직원', '호스텔', '자체', '객실', '욕실', '겨울', '다시', '수도', '것', '여름', '절대', '가지', '제주시', '부띠', '호텔', '모던', '인테리어', '전체', '어두운편', '자동', '물', '변기', '수압', '인상', '가격', '대비', '시설', '주변', '바다', '가까이', '다만', '바다', '보이', '무난', '호텔', '꽤', '동남', '아시아', '매우', '마을', '측면', '자리', '잡고', '매우', '거리', '레스토랑', '편의점', '인접', '해', '가을', '매우', '바람', '시내', '외곽', '위치', '환경', '서비스', '객실', '정말', '호텔', '결정', '전', '활동', '생각', '어쩌면', '저', '느낌', '다음', '방문', '것', '시도', '최근', '오픈', '호텔', '가치', '슈퍼마켓', '미터', '버스', '정류장', '호텔', '아주', '디자인', '공간', '호텔', '이', '표준', '짐', '준', '안전', '금고', '및', '변경', '다른', '부주의', '직원', '관광지', '장소', '수', '하드', '곳', '찾기', '위해', '침대', '매트리스', '베개', '아주', '수', '만약', '그', '안', '힐링', '잠', '경관', '시간', '고양이', '알파카', '마리', '사람', '경험', '저희', '잠', '자서', '그', '점', '고려', '위치', '만약', '진짜', '관광', '잠', '도심', '안', '부부', '주인', '로그', '파크', '리조트', '시골', '주말', '수', '환상', '장소', '로그', '파크', '정말', '지역', '평화로', '웠', '산', '전망', '직원', '도움', '이', '곳', '지역', '그', '지역', '장소', '제주', '여행', '곳', '경우', '추천', '아이', '데리', '시간', '야생', '동물', '놀', '수', '우리', '첫', '우리', '오두막', '체크', '위해', '때', '우리', '개', '알파카', '로그', '파크', '위치', '애완', '동물', '농장', '우리', '아침', '산책', '위해', '일찍', '일어나서', '농부가', '돼지', '사슴', '염소', '닭', '먹이', '것', '아이', '그것', '것', '이', '장소', '다른', '사면', '매일', '밤', '캠프', '파이어', '를', '소유자', '사용', '수', '장비', '그', '구매', '위해', '메인', '통나무', '집', '음식', '물', '맥주', '구입', '수', '장소', '나', '주말', '동안', '친구', '그룹', '여기', '오기', '호텔', '찾기', '곳', '한라산', '자연', '국립', '공원', '근처', '계획', '사람', '선택', '것', '새', '요리', '수', '주방', '때', '가격', '대비', '하우스', '제주', '꼭', '묵', '전용', '교통', '여행객', '우선', '가격', '대비', '복층', '사용', '층', '더블', '침대', '하나', '싱글', '침대', '하나', '층', '더블', '침대', '하나', '매일', '청소', '수건', '걸', '다만', '점', '화장실', '실리콘', '물때', '좀', '수압', '아침', '매우', '시간', '어', '때', '길', '매우', '어두우', '그거', '외', '친구', '최고', '장소', '말', '그대로', '수', '이', '곳', '공기', '우리', '당나귀', '꿩', '의', '잔디밭', '산책', '자기', '수용', '수', '주방', '일행', '이용', '근처', '편의점', '난방', '시설', '자신', '교통', '수단', '때', '필요', '바오', '젠', '거리', '바로', '가까이', '때문', '식사', '기도', '쇼핑', '매우', '예전', '시내', '좀', '호텔', '투숙', '꼭', '차', '가지', '식사', '만해', '음주운전', '부담', '항상', '시가지', '위치', '공항', '택시', '분안', '거리', '접근성', '음', '주위', '인프라', '곳', '가도', '걱정', '것', '숙소', '시설', '또한', '위생', '시설', '적극', '추천', '함바', '젠', '거리', '위치', '공항', '택시', '타고', '수', '거리', '반대', '호텔', '길', '건너', '신라', '스테이', '앞', '버스', '공항', '금방', '일반', '스탠다드', '룸', '이용', '방이', '청소', '해주시', '분도', '인사', '기분', '다만', '리셉션', '직원', '좀', '더', '것', '태도', '기분', '공항', '택시', '타고', '수', '부담', '거리', '위치', '더블베드', '싱글', '베드', '트윈룸', '이용', '생각', '명', '투숙', '전혀', '다음', '저녁', '비행', '제주도', '도착', '다시', '이용', '생각', '정도', '저희', '곳', '박', '일', '동안', '위치', '저희', '공항', '픽업', '서비스', '각각', '대략', '원', '정도', '로비', '안내', '데스크', '체크', '인과', '체크아웃', '위', '곳', '그', '체크', '때', '저희', '여권', '요구', '확인', '용지', '요구', '체크', '진행', '또한', '저희', '도착', '곳', '손님', '별로', '저희', '본래', '체크', '시간', '오후', '시', '전', '방', '수', '허락', '와이파이', '신호', '로비', '방', '무선', '인터넷', '컴퓨터', '로비', '안내', '데스크', '저희', '여행', '일정', '택시', '투어', '서비스', '제공', '중국말', '수', '운전기사', '원', '영어', '수', '운전기사', '원', '방', '아주', '벽', '텔레비전', '크기', '또한', '방', '수', '정도', '공간', '옷장', '옷', '걸이', '몇', '개', '소파', '오직', '두', '사람', '수', '방', '크기', '전혀', '정도', '각', '방', '미네랄', '워터', '주스', '배치', '이', '호텔', '위치', '아주', '카페', '선술집', '식당', '편의점', '옷', '가게', '화장품', '가게', '모두', '가까이', '때문', '요조', '용한', '지역', '게스트', '하우스', '공항', '버스', '터미널', '및', '도심', '곳', '합리', '아침', '식사', '제공', '객실', '장소', '일간', '만', '것', '우리', '체재', '여기', '게스트', '하우스', '한국인', '침대', '공항', '버스', '정류장', '정거장', '아침', '식사', '일찍', '트레킹', '주인', '또한', '공항', '영빈', '관', '도착', '모든', '방법', '대한', '세부', '정보', '여기', '한국', '택시', '기사', '포함', '프로', '위치', '공항', '쇼핑', '장소', '및', '레스토랑', '바오', '첸', '스트리트', '제주', '버스', '터미널', '영어', '말', '수', '직원', '공항', '아침', '택시', '도움', '곳', '클린', '룸', '직원', '매일', '방', '청소', '아침', '식사', '았습니', '단점', '버스', '터미널', '직진', '버스', '경로', '저', '호텔', '일', '밤', '가족', '위치', '근처', '명소', '거리', '분', '새', '호텔', '매우', '직원', '여행', '제주도', '중간', '위치', '접근성', '것', '예상', '예약', '한라산', '것', '굳이', '한라산', '근처', '숙소', '정', '필요', '것', '고층', '공실이', '배정', '숙소', '일반', '아파트', '구조', '밤', '시간', '바늘', '요청', '호텔', '바늘', '요청', '주기도', '이외', '점', '부대', '시설', '방', '개', '거실', '신청', '체크', '때', '욕조', '방개', '거실', '욕조', '아기', '주변', '것', '것', '골프', '조식', '별로', '일단', '관리', '느낌', '듭니', '위치', '설악산', '쪽', '이', '쪽', '관광', '분', '최적', '리조트', '분', '시간', '미리', '확인', '아침', '조식', '산책로', '창문', '도크', '발코니', '화장실', '수압', '아침', '산책로', '조식', '아주', '저녁', '디너', '한번', '가격', '반찬', '간이', '세지', '안', '편의점', '스파', '끼리', '연결', '통로', '시설', '아침', '산책로', '마음', '듭니', '가족', '가기', '것', '제주도', '출장', '차', '방문', '일단', '로비', '특급', '호텔', '공용', '업무', '도움', '제주', '관광', '책자', '비치', '커피한잔', '정보', '객실', '비치', '침구', '류', '가구', '더블', '침대', '싱글', '침대', '명', '다음', '날', '아침', '식사', '공항', '분', '정도', '전체', '만원', '가격', '이정', '시설', '서비스', '인용', '두', '침대', '더블', '침대', '더블', '싱글', '침대', '경우', '더', '전략', '위치', '편의점', '근처', '커피', '숍', '편의', '시설', '욕실', '채식', '및', '해산물', '옵션', '포함', '무료', '일일', '아침', '식사', '수프', '아주', '김치', '김치', '손님', '용', '주차장', '경우', '다리미', '제공', '호텔', '박', '이상', '렀으', '서비스', '일', '우리', '도착', '주인', '거기', '우리', '시', '호텔', '도착', '청소', '때문', '오후', '시', '방이', '준비', '것', '우리', '매우', '일찍', '체크', '요청', '그', '방', '마술', '원', '이용', '수', '청소', '때문', '사용', '수', '현금', '때문', '나중', '지불', '요청', '일', '호텔', '때', '우리', '로', '환영', '아침', '제발', '고객', '더', '인보이스', '요청', '후', '나중', '수령', '지시', '그', '일', '후', '우리', '그것', '우리', '리셉션', '분', '그', '준비', '비', '때', '우리', '우산', '요청', '그', '임대료', '원', '요구', '실례', '것', '리셉션', '종이컵', '지불', '무료', '호텔', '때', '그', '은', '만', '말', '다시', '번', '달러', '거의', '지출', '후', '안녕', '나', '노력', '효과', '우리', '한국', '일반', '것', '봉사', '거기', '돈', '나', '제주', '나', '지난', '밤', '동안', '공항', '근처', '가장', '보기', '호텔', '때문', '여기', '방', '저', '우리', '셋', '트윈', '룸', '예약', '더블', '침대', '개', '싱글', '침대', '개', '구성', '객실', '욕실', '매우', '그', '모든', '세면', '용품', '치약', '샤워', '젤', '샴푸', '수건', '등', '제공', '걱정', '필요', '그', '미니', '냉장고', '주전자', '가지', '주차', '호텔', '앞', '지하', '주차', '제공', '실수', '경우', '근처', '호텔', '주요', '도로', '인근', '도보', '분', '따라서', '택시', '문제', '또한', '호텔', '근처', '버스', '정류장', '공항', '택시', '분', '소요', '인근', '상점', '제주', '공항', '인근', '호텔', '분', '추천', '여기', '두', '번', '렀습니', '처음', '제주', '때', '싱가포르', '두', '번', '비행', '후', '택시', '분', '로', '매우', '호텔', '주소', '한국어', '표시', '운전', '기사', '의', '호텔', '주소', '입력', '를', '찾기', '두', '우리', '서울', '아침', '출발', '전날', '밤', '두', '번', '모두', '트윈', '룸', '더블', '침대', '싱글', '침대', '호', '방', '새', '크기', '모기', '이중창', '중', '유리창', '샤워', '욕실', '만', '주전자', '칫솔', '치약', '커피', '일본', '호텔', '달리', '침대', '위해', '우리', '개', '트윈', '방', '의', '그룹', '예비', '침대', '위안', '사용', '침대', '위', '나', '우리', '모두', '창문', '때문', '여기', '꽤', '포함', '아침', '식사', '대부분', '한국', '스타일', '우리', '지불', '가격', '위해', '불평', '것', '제주', '서귀포', '다음', '호텔', '인', '데이즈', '호텔', '더', '아침', '식사', '낮', '포함', '매일', '요리', '약간', '변화', '호텔', '위치', '편이', '레스토랑', '인근', '개', '이상', '슈퍼마켓', '인터', '시티', '버스', '인터체인지', '호텔', '매우', '도보', '서문', '시장', '동문', '시장', '버스', '장점', '공항', '단점', '청소', '한겨울', '모기', '방', '마리', '정도', '계속', '잠', '수가', '벽', '모기', '흔적', '침대', '냄새', '제주', '박일', '여행', '중', '하루', '중문', '하루', '오렌지', '트리', '숙박', '가격', '시설', '주변', '소음', '좀', '제', '그', '날', '알', '수', '만요', '간', '휴식', '처', '잠', '여행', '끝', '우리', '호텔', '박', '호텔', '위치', '더', '점', '침대', '매우', '베개', '작고', '방', '나이', '약간', '만', '나이', '우리', '화장실', '기능', '아침', '식사', '최소한', '의', '사무실', '대부분', '압력', '청소', '쿼리', '응답', '및', '예약', '안팎', '압력', '우리', '위치', '매력', '것', '제주도', '여행', '나', '하룻밤', '이', '호텔', '예', '투어', '통해', '예약', '패키지', '일부', '내', '나', '첫날', '여행', '후', '체크', '것', '도착', '때', '내', '예', '투어', '구입', '꾸러미', '벌써', '지불', '응접', '사람', '나', '지불', '노력', '어쨌든', '그것', '분류', '그', '남자', '그', '거기', '나', '그', '휴식', '줄', '것', '이', '호텔', '시가', '위치', '도심', '동문', '시장', '지하', '쇼핑몰', '단', '몇', '분', '거리', '호텔', '나이', '기본', '침대', '매우', '방', '약간', '연기', '냄새', '전반', '장소', '예산', '사람', '위해', '체류', '위해', '제주시', '역사', '시가지', '곳', '수', '편의점', '레스토랑', '카페', '술집', '쇼핑', '교회', '박물관', '등', '대부분', '거리', '작동', '내', '길', '바로', '호텔', '리셉션', '전화', '경우', '객실', '에어컨', '난방', '시설', '욕실', '물', '히터', '사용', '수', '무료', '아침식사', '커피', '커피숍', '판매', '위', '짐', '유물', '또한', '무료', '사용', '수', '분', '차로', '침대', '침구', '침구', '류', '나', '다음', '묵', '곳', '이', '섬', '다시', '방문', '기회', '경우', '다시', '묵', '것', '표준', '트윈', '표준', '트리플', '업그레이드', '방과', '욕실', '매우', '와이파이', '연결', '쇼핑', '거리', '근처', '내', '가까이', '말', '때', '말', '그대로', '근처', '블록', '곳', '나', '위치', '우리', '매우', '나', '매우', '그것', '무료', '아침', '식사', '당신', '편의점', '카페', '구석', '걱정', '필요', '그', '당신', '당일', '치기', '여행', '위', '교통', '편', '제공', '투어', '택시', '요금', '하루', '원', '전반', '경험', '매우', '매일', '밤', '수', '장점', '객실', '욕실', '버스', '정류장', '근처', '위치', '호텔', '가격', '무료', '무선', '인터넷', '단점', '수건', '레스토랑', '카페', '호텔', '직원', '영어', '구사', '하우스', '키핑', '기본', '요청', '출장', '직원', '안내', '이간', '직원', '맘', '낮', '때문', '정신', '저녁', '휴가', '온', '기분', '담', '가족', '는걸', '숙소', '예약', '걱정', '내부', '시설', '보고', '결정', '가격', '부대', '시설', '협재해변', '나름', '다음', '와이프', '협', '해변', '인근', '부동산', '문제', '제주', '갑자기', '가게', '혼자', '하루', '더', '제주', '리조트', '수기', '정상', '요금', '건물', '좀', '조명도', '복도', '느낌', '해변', '거리', '차로', '약', '분', '정도', '뒷마당', '수영장', '잔디밭', '잠시', '하늘', '보고', '시간', '내겐', '여름', '본격', '시작', '사람', '수', '온수', '가격', '대비', '곳', '뭐', '곳', '아주', '급', '고급', '호텔', '쉬', '때', '가족', '펜션', '콘도', '급', '방도', '하니', '가족', '단위', '실속', '만점', '숙소', '바퀴벌레', '마리', '낮', '물놀이', '땐', '밤', '쯤', '발코니', '마리', '문', '방안', '마리', '컵', '엎어두', '아침', '일찍', '체크아웃', '카운터', '계', '신분', '말', '달', '번', '방역', '주변', '산이', '대요', '호텔', '바퀴', '바퀴', '신분', '추천', '한림', '다소', '외곽', '위치', '제주', '정취', '베니키아', '더', '제주', '추천', '친철', '데스크', '직원', '조경이', '무척', '비지니스', '단체', '여행', '대형', '세미나', '실과', '체력', '실', '수영장', '등', '부대', '시설', '시간', '주의', '사항', '흡연', '분', '구내', '매점', '담배', '판매', '꼭', '구매', '후', '체크', '한림', '위치', '샴푸', '바디', '워시', '드라이기', '호텔', '드라이기', '숙소', '예약', '여행', '내내', '기분', '가격', '기대', '하나', '바닷가', '도', '뷰', '노을', '건', '정말', '직원', '신축', '건물', '객실', '마음', '층', '바다', '보이', '전망', '가격', '숙소', '주인', '분', '매우', '매우', '버스', '잔돈', '걱정', '문제', '해결', '룸', '컨디션', '매우', '방이', '온돌', '뜨근뜨근', '수', '뷰', '제주도', '진', '풍경', '수', '매우', '만족', '최근', '리', '모델링', '건', '건물', '조식', '천원', '가격', '사장', '것', '것', '다음', '방만', '쪽', '이용', '예정', '다애', '월', '바다', '바로', '앞', '오션', '뷰', '숙소', '예약', '아보', '예약', '위치', '바다', '루프', '탑', '풀', '빌라', '수풀', '역시', '맘', '이번', '제주', '여행', '숙소', '뷰', '제일', '우선', '예약', '뷰', '스파', '내부', '인테리어', '집', '분위기', '바다', '수풀', '최고', '다애', '월', '바다', '바로', '앞', '위치', '전망', '바다', '스파', '스위트', '수풀', '호텔', '완전', '럭셔리', '호텔', '제주', '워낙', '숙박시설', '고민', '지인', '통해', '숙박', '럭셔리', '게', '테', '차', '수', '바닷가', '앞', '호텔', '주변', '아침', '운동', '호텔', '앞', '카페', '멀리', '가지', '호텔', '주변', '수', '밥', '객실', '다시', '쉬', '직원', '호텔', '내', '특산', '품', '매장', '사장', '꼭', '단체', '관광객', '곳', '아침', '밤', '리조트', '소음', '방', '청결', '상태', '호텔', '분', '다른', '곳', '시설', '조금', '도로', '호텔', '직원', '새', '시설', '신분', '다른', '호텔', '이용', '호텔', '이', '호텔', '것', '박', '일', '제주', '오름', '투어', '일정', '박', '대중교통', '이용', '시', '분', '정도', '거리', '위치', '조금', '코스', '위치', '렌트', '코', '대중교통', '이용', '길', '탐방', '인', '게스트', '하우스', '이용', '시', '면', '가격', '대비', '괜', '가격', '대비', '관광지', '접근성', '단지', '주차장', '직원', '쉬', '지은지', '좀', '가격', '모텔', '시설', '거부', '감', '가족', '공항', '랜트카', '택시', '분', '정도', '주변', '편의점', '및', '맛집', '꽤', '여행', '시작', '장소', '모든', '객실', '오션', '뷰', '작', '맛', '주차', '시설', '자리', '건물', '편', '주차', '시설', '호텔', '내', '편의', '시설', '맛사지', '에스테', '사우나', '여행', '피로', '사우나', '방법', '꼭', '숙박', '특색', '가격', '시설', '장점', '출장', '건물', '외관', '복도', '카페트', '등', '방', '시설', '가격', '주변', '편의점', '빵집', '등', '해안', '도로', '산책', '수', '위치', '호텔', '분', '위치', '주위', '환경', '반대편', '이마트', '카페', '식당', '다만', '룸', '컨디션', '윗방', '화장실', '물', '소리', '계속', '숙면', '취할수', '가격', '한국', '온돌', '바닥', '방', '자', '이', '객실', '정말', '이', '곳', '기분', '카지노', '아주', '가까이', '가게', '길', '분', '정도', '위치', '아주', '점', '곳', '우리', '이', '호텔', '이서', '이틀', '밤', '우리', '단체', '관광', '대로', '위치', '가격', '추천', '것', '말', '대부분', '또', '유저', '말', '듯이', '아시아', '기준', '방', '화장실', '제대로', '사람', '방', '화장실', '것', '선호', '듯', '방이', '복도', '물', '방', '히터', '잠도', '수', '여기', '사람', '최악', '호텔', '그', '말', '이', '호텔', '제대로', '설명', '주지', '그', '사람', '침대', '이', '것', '우리', '것', '바로', '앞', '거리', '버스정류장', '함덕', '김녕해변', '뚜벅', '여행자', '렌트카', '여행자', '모두', '곳', '친구', '여행', '수도', '담소', '나누기', '곳', '인도', '인테리어', '사장', '매일', '청소', '덕분', '상태', '유지', '곳', '돌담', '제주', '집', '채', '정성', '집안', '방안', '마당', '음악', '향', '맞이', '공간', '소란', '월', '정리', '함덕', '사이', '자리', '복리', '인지', '더', '평화', '곳', '아침식사', '봄날', '다시', '부부', '기분', '시설', '또한', '리', '모델링', '내부', '인도', '스타일', '인테리어', '맘', '마스코트', '윈디', '기여', '웠', '또', '샨티', '샨티', '마지막여행', '밤', '게스트하우스', '시골', '집', '듯', '편안함', '하루', '숙소', '예약', '곳', '제', '사전', '검색', '간', '다른', '숙소', '다만', '네이버', '검색', '엔진', '찾기', '뿐', '그', '동네', '못', '것', '게스트하우스', '전체', '분위기', '그', '분위기', '사장', '미소', '시설', '조명', '향', '음', '모든', '것', '제', '일', '제주', '중', '가장', '밤', '조식', '상큼', '샐러드', '계란', '강력', '추천', '저', '음주', '가무', '힐링', '술', '숙면', '취하', '분위기', '것', '바다', '바로', '앞', '호텔', '뒷쪽', '길', '식당', '개', '마트', '까페', '펍등', '저녁', '산책', '거리', '올리브영', '매장', '맘스', '터치', '번가', '피자', '생', '돈까스', '등', '배달', '음식점', '바다', '앞', '잔디밭', '저녁', '산책', '기도', '정말', '방문', '건의', '사항', '객실', '전등', '형광등', '색', '스탠드', '구색', '불빛', '다소', '함덕', '해수욕장', '바로', '앞', '아이', '정말', '다시', '방문', '의사', '근처', '현재', '공사', '닭머르', '스위스', '마을', '돌', '문화', '박물관', '산굼부리', '에코랜드', '등', '화쪽', '해녀', '박물관', '호텔', '뒷쪽', '합리', '가격', '식당', '굳이', '맛집', '주택가', '사이', '덕림사', '사찰', '아주', '오션', '뷰', '방', '예약', '뷰', '수', '직원', '모두', '청결', '도도', '기기', '좀', '연식', '에어콘', '소리', '가족', '방문', '인', '방이', '인', '객실', '유럽', '설계', '것', '옛날', '건물', '시설', '전반', '유럽', '설계', '오히려', '호텔', '위치', '제주시', '꽤', '가야', '점', '객', '경치', '근처', '바닷가', '접근성', '오션', '뷰', '가장', '최적', '호텔', '바로', '앞', '함덕', '해수욕장', '요즘', '델문', '카페', '바로', '오분', '거리', '함덕', '해수욕장', '위치', '곳', '좀', '가성', '비', '비치', '뷰', '호텔', '밤', '어선', '불빛', '보이', '우리', '시', '다음', '날', '비행기', '이', '호텔', '예약', '이', '호텔', '제주', '국제', '공항', '분', '거리', '체크', '때', '영어', '이야기', '수', '그', '우리', '샤워', '우리', '드라이브', '일', '수기', '한국', '처음', '우리', '눈', '우리', '마음', '방', '전망', '층', '스타벅스', '보너스', '저', '제', '가족', '단위', '가운데', '하룻밤', '수준기', '우리', '방', '의', '바로', '위', '호텔', '화이트', '하우스', '표지판', '앞', '호텔', '위치', '이', '호텔', '도착', '키', '코드', '기본', '이', '호텔', '선택', '때문', '약', '분', '드라이브', '제주', '공항', '시', '출발', '다음', '날', '아침', '위', '스타벅스', '우리', '아침식사', '스낵', '처리', '또한', '레스토랑', '식당', '수', '서해안', '댐핑할', '호텔', '위치', '곳', '오른쪽', '이', '곳', '용두암', '록', '명소', '호텔', '오른쪽', '수', '비치', '호텔', '앞', '바위', '주차', '무료', '제공', '주차장', '드라이브', '입장', '대신', '길', '호텔', '뒤쪽', '고객', '해당', '그', '후', '짐', '가지', '엘리베이터', '로비', '통로', '엘리베이터', '타고', '층', '체크', '카운터', '어디', '예', '수준', '때문', '스타벅스', '로비', '수준기', '호텔', '직원', '호텔', '프런트', '직원', '그', '중국어', '중국', '은', '영어', '거의', '호텔', '방', '제', '첫', '호텔', '매우', '천장', '수직', '공간', '방', '과장', '수평', '침실', '화이트', '컬러', '인상', '문서', '및', '벽', '천장', '퀸', '사이즈', '침대', '개', '나무', '테이블', '소파', '앤티크', '나무', '의자', '화장', '의', '거울', '및', '헤어', '드라이기', '냉장고', '주전자', '쌍', '슬리퍼', '마련', '체크', '호실', '마지막', '밤', '호텔', '체크', '데스크', '바로', '옆', '방', '말', '그대로', '생각', '때문', '수', '기', '때문', '우리', '수', '우리', '그것', '이', '호텔', '예약', '물가', '풍경', '고', '우리', '모든', '벽', '파란색', '공사', '사진', '우리', '창', '스타벅스', '드라이브', '통해', '사람', '불안', '때문', '실제', '방', '커피', '수', '저녁', '나', '방', '담배', '냄새', '나', '것', '프런트', '데스크', '대해', '이', '호텔', '금연', '실', '그', '나', '이야기', '해', '창', '열', '수', '희망', '의', '진정', '창', '분사', '그', '냄새', '우리', '그', '연기', '냄새', '화장실', '것', '알', '문', '그', '화장실', '아주', '내부', '프론트', '데스크', '전화', '그', '사람', '다시', '볼', '수', '나', '자신', '말', '그대로', '문', '앞', '해', '문', '그', '위로', '어깨', '으쓱', '저', '말', '냄새', '나', '그', '우리', '위해', '팬', '것', '요청', '다른', '방', '이동', '수', '계산', '때문', '이전', '직원', '전체', '앞', '도착', '때', '이', '소리', '잠', '소형', '착암기', '직원', '저희', '통보', '것', '우리', '경고', '것', '공사', '현장', '시작', '작업', '항질', '염성', '탄식', '전반', '호텔', '시설', '위치', '우리', '바다', '가운데', '전망', '그냥', '벽', '통해', '층', '스타벅스', '매우', '우리', '방', '매우', '꽤', '공항', '옆', '위치', '호텔', '아침', '일찍', '비행기', '약간', '소음', '수', '모든', '약', '여러', '식사', '옵션', '몇', '가지', '단점', '것', '영어', '체크', '시', '도착', '때', '사막화', '사람', '명령', '수', '몇', '번', '나', '분', '아무', '것', '전화', '번호', '그', '후', '체크', '카운터', '하나', '나', '그', '소리', '방', '링잉', '직원', '및', '바로', '뒤', '이', '모든', '것', '좀', '어쨌든', '체크', '수', '게', '에어컨', '버튼', '모두', '한글', '빨간색', '파란색', '기호', '방', '문', '창', '다음', '온', '침대', '박스', '스프링', '매트리스', '의', '두', '밤', '매트', '로', '침대', '위', '패딩', '도움', '이해', '비판', '전형', '한국', '호텔', '한국', '호텔', '그냥', '조심', '경우', '언어', '통역', '문제', '수', '다시', '여기', '묵', '것', '요청', '위', '몇', '가지', '질문', '카드', '준비', '골프장', '온', '호텔', '주차', '내부', '시설', '제주', '도착', '자고', '사우나', '다음', '날', '시작', '애월', '협제', '새벽', '우동', '예약', '가기', '이번', '온', '호텔', '리조트', '숙소', '정', '리조트', '예약', '사용', '중', '최대', '명', '사용', '크기', '명', '사용', '공간', '여유', '주방', '시설', '화장실', '시설', '아주', '한라산', '애월', '해변', '한림', '공원', '등', '인기', '관광', '명소', '의', '접근성', '호텔', '건물', '사우나', '시설', '가족', '모두', '곳', '라며', '대가족', '명', '이상', '여행', '시', '추천', '만', '숙소', '생각', '친구', '번개', '골프', '투어', '위해', '호텔', '이용', '골프텔', '클럽', '하우스', '위치', '중간', '편의점', '수영장', '저희', '이용', '곳', '동인', '데', '방개', '침대', '화장실', '방', '거실', '레시', '회', '마늘', '치킨', '한라산', '소주', '아침', '클럽', '하우스', '가시', '조식', '세트', '예전', '타이거우즈', '방문', '타이거우즈', '세트', '외', '성게', '미역국', '우거지', '해장국', '등', '취향', '란딩', '여름', '다시', '한번', '보고', '협재금능', '해수욕장', '수', '방', '비양도', '를', '볼', '수', '뷰', '수영장', '수질', '관리', '느낌', '차', '호텔', '제공', '공항', '무료', '셔틀', '버스', '타고', '푹', '쉬', '친구', '도', '수', '아마', '가족', '끼리', '여름', '피', '겸', '오시', '것', '다만', '호텔', '층', '식당', '정말', '해', '조식', '별로', '리조트', '시설', '상태', '골프', '수', '숙박', '사우나', '물놀이', '시설', '이용', '가능', '금늘', '해수욕장', '가까이', '여름', '즐', '기기', '합당', '함', '공항', '셔틀', '운행', '함', '제주시', '도심', '중심', '공항', '정말', '건물', '리', '모델링', '숙박', '만원', '사람', '아침식사', '제공', '담', '꼭', '이용', '호텔', '객실', '심플', '사용', '직원', '조식', '주차장', '호텔', '맞은편', '무료', '주차장', '이용', '호텔', '앞', '안내', '표지판', '더', '참고', '인도', '온', '관광객', '공항', '근처', '예약', '직원', '예약', '명단', '누락', '당황', '빈', '방이', '하나', '찻길', '옆', '소리', '저', '잠', '제대로', '하루', '정도', '가격', '우리', '그룹', '여행', '때', '체크', '우리', '방', '층', '기본', '시설', '기본', '아침', '방', '꽤', '외부', '하루', '후', '침대', '겨울', '방', '때', '문제', '우리', '방과', '그', '밖', '모든', '것', '접수', '결석', '약간', '소음', '잠시', '후', '것', '이', '장소', '재료', '색상', '선택', '호텔', '수', '것', '다른', '것', '년대', '사무실', '호텔', '영화', '무작위', '디자인', '느낌', '품질', '관리', '스티커', '대부분', '벽', '천장', '패널', '부착', '음식', '설명', '포함', '아침', '식사', '뷔페', '실제', '빵', '계란', '수', '음', '의미', '물', '외', '것', '차', '커피', '스프', '영진', '작성', '통지', '첨부', '사진', '참조', '조식', '토스트', '수프', '계란', '튀김', '및', '기타', '몇', '가지', '당신', '무슬림', '단어', '그것', '향', '화살표', '렌트', '룸', '천장', '페인트', '고정', '필요', '나', '한국', '다른', '호텔', '다른', '곳', '그것', '보지', '인터넷', '그것', '일종', '것', '번', '약', '초', '이상', '작동', '번', '하나', '장치', '제한', '것', '보임', '제주도', '공공', '장소', '무료', '를', '제공', '모든', '동작', '이유', '상자', '체크', '가격', '정도', '시설', '난방', '시', '이전', '별도', '난방', '장치', '전달', '별도', '난방', '장치', '수', '편이', '호스텔', '가격', '제주', '전체', '가격', '생각', '가격', '가성', '비', '최강', '숙소', '아침', '식사', '식당', '몇', '때문', '아침', '바로', '앞', '편의점', '것', '언제', '수', '환경', '여행지', '거리', '약간', '주차', '약간', '호스텔', '가격', '다른', '서비스', '생각', '것', '정도', '서비스', '숙소', '퀄리티', '다른', '분', '무료', '조식', '조식', '일', '당', '천원', '저', '신청', '아침', '천원', '이상', '퀄리티', '제공', '때문', '조식', '근처', '식당', '가기', '분', '제공', '조식', '이용', '것', '위치', '시설', '가격', '생각', '안', '티비', '샴푸', '린스', '바스', '드라이어', '등등', '다행', '와이파이', '사장', '기분', '묵', '수', '잠깐', '가성', '비', '숙소', '추천', '친구', '둘이서', '트윈룸', '박', '만원', '안', '가격', '조식', '포함', '객실', '층', '카페', '분위기', '가격', '가성', '비', '짱', '호텔', '친구', '여행', '커플', '여행', '모두', '추천', '화장실', '일단', '가성', '비', '일', '분', '사장', '보이시', '분', '조식', '셀프', '토스트', '계란후라이', '직접', '약간', '셀러드', '우유', '콘후', '레이크', '가격', '생각', '장말', '조식', '층', '카페', '식', '차', '저녁때', '맥주', '마시기', '바로', '앞', '편의점', '다만', '좀', '건물', '방이', '욕실', '드라이기', '냉장고', '있을껀', '욕실', '샴푸', '바디', '워시', '비누', '칫솔', '치약', '준비', '카운터', '칫솔', '치약', '선', '판매', '약간', '단점', '분명', '가격', '대비', '생각', '정말', '호스텔', '생각', '박', '원', '친구', '둘이서', '가격', '정말', '시설', '세면', '도구', '비치', '체크', '시', '칫솔', '치약', '주어', '또', '방', '와이파이', '라우터', '와이파이', '거기', '아침', '조식', '수', '하루', '시작', '수', '호스텔', '바로', '앞', '편의점', '간식', '거리', '사', '수', '또', '호스텔', '바로', '앞', '길', '버스정거장', '버스', '여행', '단', '엘리베이터', '짐', '조금', '것', '객실', '방음', '조금', '공항', '위치', '면', '호텔', '월풀', '욕조', '단', '층', '고가', '뷰', '점', '좀', '사진', '것', '건물', '외관', '내부', '정돈', '침구', '류', '위치', '공항', '바다', '거리', '마지막', '날', '일찍', '기회', '또', '사장', '가족', '여행', '제주도', '숙박', '바닷가', '뷰', '정말', '신축', '건물', '디자인', '고려', '시설', '다시', '한번', '방문', '제주', '여행', '마지막', '날', '체크', '위치', '뷰', '첫째', '예약', '하자', '마자', '호텔', '연락', '확인', '스페셜', '것', '예약', '신경', '둘째', '사진', '리조트', '분위기', '직원', '정말', '결혼식', '신혼여행', '이야기', '방', '와인', '배달', '하나', '하나', '신경', '직원', '감동', '자체', '수영장', '놀', '생각', '아이', '포함', '가족', '여행', '것', '젤', '자체', '완전', '만족', '뭐', '제주도', '애월쪽', '강력', '추천', '패밀리', '룸', '바다', '전망', '침실', '객실', '작은방', '화장실', '개', '것', '해', '인덕션', '주방', '쇼파', '거실', '가장', '건', '창문', '바다', '보이', '정원', '리조트', '매력', '특급', '수준', '관리', '가격', '생각', '준수', '침대', '공간', '가족', '수영장', '다만', '여기저기', '세심', '보수', '가격', '방', '상태', '화장실', '샤워', '기', '물때', '청소', '좀', '신경', '수영장', '물', '사람', '별로', '수영', '정말', '라커룸', '왜', '관리', '곰', '무지막지', '가격', '모두', '용서', '이제', '수영장', '폐장', '때문', '아주', '가격', '굳이', '필요', '생각', '리조트', '마레', '보', '비치', '호텔', '이용', '애월', '거의', '호텔', '인테리어', '인상', '호텔', '단', '해변', '저녁', '주변', '파티', '게스트하우스', '소음', '조금', '내부', '시설', '침구', '류', '우리', '곳', '하룻밤', '공항', '근처', '것', '택시', '타고', '분', '공항', '약', '원', '우리', '방', '좀', '침대', '샤워실', '화장실', '세면대', '팬', '이', '조합', '샤워실', '구분', '파티션', '모든', '것', '나', '이', '호텔', '수', '파악', '수', '전체', '평균', '호텔', '다시', '호텔', '일', '밤', '공항', '매우', '약', '분', '버스', '주요', '쇼핑', '거리', '분', '거리', '호텔', '시간', '이상은', '호텔', '차', '타고', '매우', '택시', '타고', '화산', '방', '매우', '매우', '우리', '우리', '방', '화장실', '음식', '음료', '수', '곳', '저녁', '식사', '밤', '음식', '문제', '도', '편의점', '수', '공항', '운전', '제주도', '여행', '추천', '따라서', '문제', '거리', '처음', '한국', '여행', '우리', '일', '한국', '제주', '강남', '우리', '호텔', '중이', '최고', '이', '객실', '문자', '최신', '프론트', '데스크', '직원', '아주', '사람', '문제', '은행', '카드', '가지', '때', '제', '여자', '친구', '국제', '로컬', '취출된', '직원', '무료', '서비스', '주장', '이', '주장', '우리', '방이', '청구', '호텔', '쇼핑', '지역', '근처', '위치', '젠', '충돌', '시', '바오', '거리', '쇼핑', '거리', '바로', '코', '앞', '레스토랑', '카페', '식당', '철손', '직원', '매우', '그', '곳', '수', '또한', '그', '남아', '핸드폰', '이나', '다시', '때', '수집', '및', '보상', '충성', '게', '거절', '사진', '좀', '엉망', '매우', '가격', '성능', '비', '호텔', '실용', '분', '추천', '방도', '더블', '싱글', '침대', '방', '혼자', '아침', '식사', '한식', '토스트', '모텔', '여기', '강', '공항', '내부', '편입', '니', '조식', '만', '중국', '손님', '맣', '걸', '중국', '단체', '여행', '숙소', '활용', '듯', '싱글', '침대', '개', '방이', '관광', '호텔', '하진', '하룻밤', '쉬', '시내', '교통', '편리', '객실', '매우', '크기', '무료', '수건', '주전자', '냉장고', '및', '헤어', '드라이어', '제공', '수건', '매일', '병', '물이', '방', '배달', '아침', '식사', '오전', '시부', '터', '아침', '시', '일찍', '시도', '번만', '시도', '음식', '버터', '빵', '일종', '두부', '국수', '우리', '이웃', '편의점', '매일', '아침', '식사', '제공', '때문', '역', '겹', '점', '무료', '버스', '터미널', '길', '아래', '숙박', '품격', '아침', '식사', '업그레이드', '다시', '여기', '호텔', '리셉션', '직원', '영어', '우리', '통신', '아주', '아침', '식사', '환경', '호텔', '내', '기대', '못', '호텔', '예약', '은', '우리', '사진', '온라인', '때문', '알', '이', '더블', '침대', '욕실', '욕조', '우리', '자신', '미니', '냉장고', '이', '곳', '분', '정도', '바다', '실제', '해변', '창문', '바다', '볼', '수', '단점', '구성', '침대', '꽤', '비치', '스토리', '호텔', '하룻밤', '처음', '도착', '때', '제주도', '위치', '호텔', '바다', '전형', '한국인', '현지', '스타일', '중간', '가격', '호텔', '예', '욕실', '리넨', '베드', '커버', '등', '객실', '와이파이', '작동', '제', '생각', '약간', '시즌', '오프', '레스토랑', '식료품점', '해변', '한국어', '안내', '판이', '찾기', '약간', '뿐', '더', '그랜드', '호텔', '건너편', '해변', '찾기', '공항', '근처', '위치', '도착', '하루', '듯해', '가격', '대비', '룸', '컨디션', '중국인', '지은지', '얼', '마안', '옥상', '공항', '도보', '시내', '한눈', '화장실', '샤워실', '세면대', '분리', '친구', '끼리', '사용', '볼일', '보고', '바로', '샤워', '남편', '좀', '대요', '침대', '매트리스', '호텔', '뒤척', '도', '옆', '사람', '침대', '끝', '다른사람', '기우', '정도', '침대', '별로', '조식', '종류', '음식', '하나', '하나', '정말', '제대로', '조리', '느낌', '체적', '사전', '결제', '예약', '면서', '산', '전망', '방', '예약', '체크', '때', '완전', '전망', '꽉', '방', '기분', '완전', '예약', '완전', '출장', '시내', '중심', '위치', '책상', '위', '콘센트', '노트북', '작업', '침대', '화장실', '샤워', '공간', '분리', '인', '이상', '이용', '가격', '매우', '매우', '호텔', '위치', '매우', '화장실', '객실', '모두', '주차', '타워', '주차', '걱정', '안해', '다만', '조식', '조금', '다방', '명', '투썸', '카페', '바로', '옆', '길', '쇼핑', '거리', '아주', '위치', '공항', '근처', '택시', '수', '호텔', '공항', '택시', '공항', '호텔', '가격', '대비', '성능', '수', '거리', '돼지', '고기국수', '등', '맛집', '공항', '위치', '장점', '제주도', '오후', '도착', '수', '소셜커머스', '통해', '예약', '수', '체크', '때', '무료', '룸', '업그레이드', '룸', '컨디션', '꽤', '다만', '샤워', '나니', '욕실', '냄새', '조금', '합리', '가격', '비', '시설', '볼', '수', '것', '담배', '냄새', '호텔', '모텔', '환기', '전혀', '침구', '방', '전체', '담배', '냄새', '정말', '내내', '기분', '공항', '택시', '분', '거리', '위치', '비지니스', '스타일', '호텔', '체크', '인시', '프론트', '외국인', '로', '외국인', '응대', '또한', '시설', '정말', '무난', '수준', '청결', '도', '제', '방문', '때', '앞', '건물', '공사', '인지', '아침', '중장비', '기계', '소음', '저녁', '제주', '시내', '분', '정도', '식사', '해결', '호텔', '바로', '옆', '조그만', '슈퍼마켓', '이번', '제주', '여행', '미국', '아들', '상황', '무엇', '안전', '제', '아들', '환전', '문제', '분실', '문제', '발생', '호텔', '박', '과장', '이하', '여러분', '도움', '해결', '손님', '가족', '앳눈', '호텔', '직원', '여러분', '얼마나', '무조건', '별', '개', '호텔', '쇼핑', '지역', '가까이', '위치', '디자인', '현대', '직원', '우리', '요청', '것', '영어', '의사소통', '수', '직원', '정말', '택시', '운전사', '의사소통', '어려움', '요청', '직원', '우리', '단지', '조금', '점', '세면대', '화장실', '침대', '옆', '것', '베개', '물렁거리', '방안', '와이파이', '무료', '수', '웹페이지', '한국말', '비밀번호', '사용', '만약', '직원', '물어', '것', '우리', '직원', '제주', '동안', '인터넷', '필요', '때문', '남편', '나', '제주', '불', '축제', '동안', '곳', '하룻밤', '달러', '요금', '그', '요금', '가격', '방', '현대', '직원', '항상', '호텔', '도착', '후', '아침', '자동차', '렌트', '결정', '호텔', '직원', '자동차', '랜트', '회사', '전화', '것', '준비', '택시', '주어', '자동차', '랜트하', '곳', '수', '해', '호텔', '공항', '분', '정도', '수', '도심', '블럭', '정도', '가면', '도심', '몇개', '나이트', '클럽', '거리', '하나', '전부', '만약', '둥근지붕', '건물', '무엇', '확인', '호텔', '분만', '박', '동안', '여기', '나', '방', '제주', '시내', '위치', '낮', '밤', '수', '밤', '배', '때', '것', '잡', '수', '시', '가까이', '직원', '매우', '도움', '요리사', '팀', '나', '여기', '것', '다시', '제주', '가면', '여기', '것', '고려', '것', '정말', '시설', '내', '이', '선택', '공항', '이유', '매우', '조금', '침대', '기숙사', '객실', '하나', '침대', '개', '침대', '개', '방', '안', '모든', '설비', '거실', '가지', '공용', '공간', '제주', '여행', '동안', '개인', '추구', '경우', '꽤', '곳', '여성', '및', '남성', '객실', '구분', '층', '여자', '남자', '층', '사용', '나', '원', '달러', '하룻밤', '예약', '조금', '직접', '예약', '온라인', '예약', '다른', '아이러니', '나', '여행', '다른', '유럽', '여행', '매우', '아침', '식사', '침대', '담요', '시트', '플러스', '한국', '당신', '나', '이틀', '전', '여기', '방문', '정말', '시간', '모든', '직원', '아주', '곳', '도', '추천', '더', '바비큐', '파티', '가장', '이벤트', '꼭', '때', '거기', '시설', '정말', '모두', '나무', '침대', '화장실', '저', '투어', '그룹', '클레어', '환영', '케', '다른', '직원', '객실', '카페', '호스텔', '바로', '앞', '위치', '돼지', '전문점', '햄버거', '감자', '튀김', '커피', '맥주', '점심', '식사', '직원', '손님', '저녁', '게임', '참가', '경쟁', '체험', '이', '호스텔', '매우', '서귀포', '두', '개', '주요', '폭포', '항구', '음식', '거리', '및', '게스트', '하우스', '제주', '공항', '매우', '대중', '버스', '수', '게스트하우스', '근처', '검사', '인텔', '관리자', '기본', '작동', '수', '영어', '매우', '협조', '정보', '수', '곳', '주인', '밤', '그', '정보', '아주', '방과', '화장실', '매일', '청소', '곳', '욕실', '남녀', '나', '문제', '발생', '정말', '호스텔', '주인', '나', '더', '곳', '나', '운', '좀', '혼합', '기숙사', '룸메이트', '잠', '수', '우이', '집', '유충', '돌', '밀', '초가', '집', '매우', '실내', '및', '실외', '집주인', '주방', '제공', '대의', '자전거', '이용', '수', '세탁기', '호텔', '매트리스', '비교', '수', '매트리스', '가장', '식료품', '점', '도보', '거리', '택시', '집주인', '제주', '최대', '속도', '아무', '타지', '것', '레프트', '핸더', '게스트하우스', '제주', '시골', '교외', '지역', '정말', '추천', '서귀포', '제주시', '버스', '탈', '수', '정류장', '근처', '이용', '데', '무리', '게스트하우스', '근처', '일출봉', '성산', '일출봉', '피닉스', '아일랜드', '곳', '건물', '서귀포', '제주시', '지역', '다른', '맛', '게스트하우스', '사장', '무료', '오름', '체험', '수', '저희', '시간', '사장', '지역', '관해', '알', '서귀포', '제주시', '방법', '주변', '경관', '대한', '정보', '날씨', '날', '근처', '바닷가', '해녀', '제주', '여성', '잠수부', '기리', '해녀', '박물관', '것', '곳', '시골', '이기', '때문', '버스', '정류장', '근처', '편의점', '제외', '레스토랑', '상점', '게스트하우스', '저녁', '위해', '것', '호스텔', '사장', '저녁', '수도', '무료', '전반', '잠시', '도시', '정말', '패밀리', '스위트', '룸', '박', '일', '제주도', '여행', '위', '북', '동부', '쪽', '서비스', '중', '저녁', '식사', '수', '주인', '요리', '마지막', '밤', '식당', '수', '가치', '합리', '가격', '곳', '박물관', '체크', '아웃', '이', '게스트하우스', '추천', '정돈', '통풍', '더', '나은', '개선', '경우', '주방', '거실', '절곡', '절', '곡부', '내', '마지막', '봄', '도착', '이', '게스트하우스', '주인', '꽤', '저녁', '우리', '그', '수', '매우', '우리', '포기', '다음', '몇', '활용', '몇', '가지', '레스토랑', '제공', '돼지고기', '여기', '그', '또한', '우리', '차로', '레스토랑', '음식', '볼', '수', '것', '우리', '방', '정말', '우리', '여행', '해', '몇', '가지', '크레이터', '스', '게스트', '하우스', '그', '후', '우리', '차', '가버', '가장', '마음', '숲', '동굴', '김녕', '미로', '공원', '해변', '바다', '바람', '불어', '운전', '전반', '나', '별', '호의', '리뷰', '곳', '정말', '직원', '마치', '집', '빵', '치즈', '러브', '여기', '벤치', '밤', '집앞', '사람', '추천', '생각', '가지', '매일', '등산', '성산', '강추', '서울', '가기', '전', '성산일출봉', '해녀', '박물관', '등', '주요', '관광지', '이', '호텔', '박', '위치', '도심지', '근처', '이마트', '현지', '음식점', '여럿', '객실', '냉', '온수', '정수기', '와이파이', '인터넷', '슬리퍼', '등', '비치', '품', '체크', '인도', '아무', '문제', '방', '매우', '두', '명', '욕실', '매우', '욕조', '샤워실', '및', '화장실', '별도', '세면대', '앞', '추가', '객실', '바닥', '난방', '시설', '요청', '수', '바닥', '프론트', '데스크', '더블', '침대', '매트리스', '이', '방', '방음', '수', '때문', '아침', '조금', '움', '단점', '아침', '식사', '수', '맥도날드', '주변', '레스토랑', '점', '호텔', '제주', '국제', '공항', '매우', '위치', '전략', '지안', '바오', '거리', '좀', '호텔', '근처', '위치', '이마트', '근처', '맥도날드', '방이', '가격', '지불', '직원', '매우', '협조', '영어', '그', '사람', '전화', '쇼핑', '장소', '근처', '호텔', '식당', '위치', '백화점', '수', '뿐', '편의점', '분', '정도', '곳', '위치', '저', '재미', '라면', '방', '수', '욕실', '욕조', '침실', '공간', '곳도', '정도', '짐', '실행', '수', '와이드', '인터넷', '기본', '모든', '것', '심지어', '펜', '데스크', '직원', '매우', '도움', '또한', '귤', '이', '바구니', '제주', '서명', '제품', '접수', '데스크', '무료', '수', '정말', '동정', '내', '요청', '핑크', '룸', '다음', '곳', '방', '욕실', '우리', '방', '매일', '전체', '지속', '시간', '내', '체크', '시', '호텔', '방', '예약', '하라', '직원', '영어', '수', '중국어', '구사', '직원', '아침', '운', '우리', '가지', '기본', '중국어', '수', '이해', '수', '호텔', '신라', '면세점', '과', '시내', '거리', '산책', '직원', '주장', '제주도', '여행', '관광지', '때', '시티', '투어', '버스', '방법', '안내', '버스', '작성', '관광명소', '누구', '한국어', '가격', '위치', '자랑', '객실', '화장실', '한편', '주위', '식당', '찾기', '위해', '제주도', '위치', '이', '호텔', '생각', '뷔페', '아침', '식사', '곳', '이틀', '밤', '호텔', '연결', '직원', '영어', '우리', '침대', '두', '개', '층첫', '호텔', '플러스', '시간', '비행', '끝', '우리', '호텔', '중', '것', '기대', '곳', '우리', '선택', '패키지', '투어', '내', '속도', '이', '호텔', '매우', '허용', '알', '그', '이', '방', '크기', '더블', '침대', '호텔', '아들', '기대', '여행', '준비', '더', '것', '우리', '우리', '여행사', '통해', '예약', '곳', '인상', '호텔', '대해', '것', '정말', '것', '불평', '수도', '모든', '기본', '요구', '사항', '충족', '방', '비교', '침대', '쇼핑', '호텔', '뒤', '편의점', '바로', '옆', '밤', '간식', '은', '라면', '아침', '식사', '호텔', '공항', '가장', '위치', '관광', '쇼핑', '레스토랑', '호텔', '로비', '었습니', '직원', '방', '방', '모든', '스위치', '하나', '제어', '보드', '조명', '에어컨', '차', '커피', '수', '난방', '물', '주전자', '자재', '품', '방이', '었습니', '욕실', '었습니', '펀관', '거리', '소음', '호텔', '기본', '높이', '조금', '길', '호텔', '프런트', '나무', '대표', '괴체', '나', '이', '호텔', '추천', '주인', '분', '매우', '매우', '곧', '출시', '미스터', '파크', '및', '호스트', '및', '제주', '추천', '곳', '곳', '그', '또한', '수', '수도', '경험', '해안', '도로', '위치', '수', '바다', '전망', '또한', '여러', '음식점', '만', '거리', '스타벅스', '취하', '기', '방', '기상', '은', '아침', '식사', '준비', '및', '몇', '가지', '바다', '해안', '도로', '바로', '앞', '위치', '방', '곳', '바다', '바', '소리', '수', '사장', '부부', '방과', '복도', '등', '인상', '방도', '온수', '조식', '인상', '직접', '아침', '빵', '각종', '야채', '과일', '여행', '싱가폴', '친구', '또', '말', '숙소', '다음', '제주도', '방문', '꼭', '꼭', '다시', '게스트', '하우스', '매우', '전략', '위치', '바다', '볼', '수', '주변', '레스토랑', '카페', '호스트', '미스터', '파크', '영어', '아주', '매우', '그', '우리', '방문', '수', '곳', '우리', '숙박', '뷰', '게스트', '하우스', '가지', '방', '지하', '조식', '제공', '장식', '우리', '다른', '손님', '호스트', '및', '공유', '수', '또한', '우리', '방', '호스트', '정도', '꼭', '다발', '매우', '추천', '곳', '꼭', '다음', '방문', '제주', '제주', '막', '도착', '차', '출발', '전', '핸폰', '문지', '안내', '주란', '좀', '일찍', '도착', '대표', '막', '출타', '손님', '오신', '방', '꽃', '꽃꺽으러', '손수', '꽃', '준비', '사이', '집', '주위', '차', '차', '차로', '경우', '말', '입구', '세운', '팻말', '건물', '바로', '앞', '바다', '바로', '벤치', '거', '차선', '화가', '손씨', '그림', '방문', '손님', '휴식', '처', '이자', '아침식사', '공간', '반지하', '리빙룸', '창', '앞쪽', '둥', '파', '햇볕', '밖', '지하', '느낌', '공간', '무었', '방', '바다', '품', '대표', '사모님', '의', '숨결', '집안', '곳곳', '여유', '로움', '아침', '맞이', '창밖', '바다', '더', '버스', '타고', '택시', '타고', '현지', '사람', '도움', '찾기', '약속', '것임', '욕실', '방', '제공', '할인', '대해', '협상', '다음', '날', '방', '수', '주인', '영어', '첫날', '이후', '적', '우리', '길', '건너', '다른', '호텔', '숙박', '연장', '때문', '박', '위해', '모나코', '호텔', '이동', '바깥', '호텔', '외견상', '조금', '우리', '땐', '아마', '어두운색', '타일', '쓰기', '선택', '때문', '내부', '편의', '시설', '난방', '시스템', '온수', '공급', '침대', '안정', '와이파이', '연결', '우리', '영어', '프런트', '직원', '대화', '수', '그', '우리', '이틀', '여정', '섬', '여행', '때', '택시', '기사', '연락', '직원', '우리', '다른', '택시', '사혹', '그', '의도', '점', '우리', '공항', '준비', '때', '즉시', '택시', '준', '점', '대해', '생각', '방', '꽤', '모든', '기본', '편의', '시설', '이용', '장식', '조금', '스타일', '주요', '문제', '음식', '쇼핑', '문제', '반대쪽', '호텔', '거리', '하나', '때문', '우리', '돈', '제주시', '내의', '다른', '선택', '표', '제주시', '대한', '저', '다른', '리뷰', '호텔', '꽤', '스타', '일임', '방', '컴퓨터', '인터넷', '라운지', '커피', '머신', '위치', '아주', '버스', '정류장', '대도시', '제주시', '버스', '터미널', '향', '버스', '중문', '향', '공항', '버스', '그랜드', '호텔', '카지노', '주변', '식당', '공항', '택시', '요금', '정도', '여행', '시간', '영어', '대화', '수', '그', '이해', '해도', '문제', '한국', '정말', '여행자', '서비스', '그', '핫라인', '전화', '누군가', '통역', '나', '이', '호텔', '일', '모든', '수직', '도', '비', '도', '가격', '아주', '방', '생각', '레스토랑', '근처', '위치', '때문', '지역', '시내', '가격', '위치', '것', '요', '모나코', '위치', '도', '정말', '월', '몇', '단계', '편의점', '작', '은', '포장', '마차', '하나', '아주', '저렴', '고', '은', '국수', '바로', '오른쪽', '모텔', '때', '기본', '적', '이', '모텔', '은', '주변', '음식점', '모든', '종류', '은', '도보', '거리', '이', '사용자', '알', '소유자', '수', '방', '신발', '착용', '슬리퍼', '제공', '고', '구두', '방', '밖', '저', '도', '이', '었다', '공항', '매우', '고', '주위', '비용', '만', '사용', '캐브', '다음', '여행', '꼭', '이', '호텔', '선택', '다시', '제주도', '이번', '주', '금토일', '박', '일단', '합리', '가격', '오션', '뷰', '수', '무료', '조식', '역시', '한식', '조식', '정도', '사장', '매우', '편이', '방', '역시', '숙박', '예정', '호텔', '수', '때문', '밤', '현지', '인도', '그것', '수', '이', '호텔', '바다', '해변', '매우', '저녁', '공항', '택시', '분', '콘은', '지역', '주위', '식사', '필요', '방', '스위치', '그것', '자동', '모든', '빛', '에어컨', '안', '것', '밤', '매우', '움직', '것', '그것', '자기', '자신', '나', '평균', '결혼', '언니', '가족', '팀', '가족', '여행지', '선택', '호텔', '사실', '더', '등급', '곳', '중', '차이점', '급', '수영장', '주변', '시설', '날씨', '조금', '우리', '가족', '수영장', '계속', '가족', '일정', '때문', '실내', '숙박', '조식', '보고', '선택', '정말', '무척', '조식', '가짓수', '음식', '음식', '과일', '한식', '고기', '채소', '등등', '정말', '점', '하나', '점', '조식', '때', '커피', '로비', '미니', '커피숍', '부모님', '무척', '조카', '방안', '맨발', '추천', '합', '다트', '윈', '베드', '사용', '조식', '다만', '점', '베개', '약간', '수영', '가격', '대비', '가성', '비', '매우', '일몰', '사실', '호텔', '위치', '일몰', '베란다', '밖', '몸', '욕조', '베란다', '객실', '기대', '이상', '조식', '대신', '고봉', '민', '김밥', '층', '제주도', '다시', '숙소', '위치', '이', '호텔', '호텔', '아주', '바다로', '파도', '소리', '수', '호텔', '직원', '매우', '도움', '나', '제주도', '경우', '이', '호텔', '매우', '추천', '우리', '서울', '며칠', '후', '도착', '버스', '때문', '호텔', '택시', '내', '추천', '제주', '차', '것', '어쨌든', '곧장', '수', '공항', '자동차', '이용', '시', '분', '거리', '공항', '멀리', '해변', '해상', '및', '위치', '근처', '숙박', '요금', '생각', '것', '내', '가장', '것', '호텔', '표준', '접수', '전혀', '도움', '것', '영어', '사용자', '정보', '것', '매우', '또한', '방', '난로', '냉장고', '등', '기구', '포크', '나이프', '처음', '조리', '영역', '포함', '필요', '저', '쿠지는', '장소', '최소한', '위', '나', '마음', '사람', '저', '쿠지를위', '거품', '시간', '위치', '것', '다른', '명소', '호텔', '근처', '더', '설명', '위해', '더', '나', '그것', '평가', '매우', '친절', '것', '내', '기회', '나', '롯데', '호텔', '하얏트', '리젠시', '신라', '등', '고급', '호텔', '것', '당신', '일', '예약', '경우', '가격', '바다', '체재', '이별', '아마', '여분', '그것', '값', '바다', '바다', '체재', '경험', '었습니다넓', '객실', '호텔', '우리', '간이', '주방', '트윈', '룸', '더블', '침대', '및', '싱글', '침대', '선택', '나', '청결', '함', '그', '단정', '수', '리셉션', '영어', '말', '수', '직원', '서비스', '한국', '보기', '곳', '그', '택시', '등', '가장', '도움', '또한', '호텔', '내', '레스토랑', '바다', '바로', '앞', '전망', '바다', '해조류', '파리', '방충', '망', '절대', '날', '때', '스파', '방', '진짜', '파리', '부들부들', '횟집', '거리', '바로', '앞', '돼지', '거리', '위치', '앞', '놀이기구', '하나', '약간', '소음', '감안', '듯', '시설', '모던', '모텔', '이상', '수준', '가격', '대비', '수준', '수', '맞은편', '슈퍼마켓', '물건', '구입', '때', '객', '실내', '대형', '엔터테인먼트', '즐', '기기', '부족함', '우리', '방', '방', '컴퓨터', '스마트', '티비', '거리', '그', '창문', '근처', '여행', '소음', '거의', '무료', '세면', '용품', '접수', '창구', '기부', '환영', '이', '위치', '정말', '곳', '바로', '뒤', '우리', '묵', '이', '호텔', '추천', '더', '기대', '이상', '객실', '매우', '기술', '센트럴', '거', '해변', '레스토랑', '첨단', '기술', '조개', '공항', '약', '아침', '식사', '전체', '위치', '다른', '음식점', '중', '선택', '수', '이마트', '쇼핑', '거리', '위치', '단점', '방이', '수건', '중', '저희', '더블', '베드룸', '만', '제공', '것', '문제', '불구', '에어컨', '모두', '몇', '초', '안', '호출', '통해', '해결', '수', '청소', '이', '호텔', '제', '만난', '중', '최고', '시설', '다른', '호텔', '수', '티비', '헤어', '드라이어', '게임', '리모콘', '구글', '검색', '옵션', '중간', '방', '냉장고', '에어컨', '및', '구축', '전체', '방', '것', '남아', '것', '또한', '종류', '빗', '헤어', '스프레이', '직선', '및', '스타일', '곱슬', '겔상', '부분', '바다', '전망', '방', '층', '객실', '밀도', '만', '볼', '수', '메인', '도로', '이', '길', '멀리', '또한', '동문', '시장', '근처', '아주', '호텔', '건너편', '맥도날드', '해산물', '거리', '이', '호텔', '대체', '공사', '진행', '중인', '작업', '동시', '하나', '하나', '편', '그', '아리마', '시작', '수', '또한', '놀이', '공원', '의', '맞은편', '여행', '경우', '일찍', '관광', '위', '밤', '소음', '상관', '나', '이', '호텔', '다시', '선택', '것', '다음', '우리', '이', '호텔', '트', '레비', '그룹', '일', '동안', '방', '매우', '공간', '호텔', '위치', '아주', '대중', '교통', '근처', '레스토랑', '수', '곳', '저녁', '맥주', '커피', '감사', '그', '도움', '주어', '우리', '모든', '문제', '커플', '스파', '룸', '방도', '생각', '시설', '입욕', '제도', '무료', '제공', '조식', '스파', '숙소', '가격', '추천', '지리', '애월', '위치', '숙소', '위치', '애월', '중간', '애월쪽', '둘러보기', '주변', '편의', '시설', '서비스', '자쿠지', '쉬', '우선', '뷰', '매우', '풍경', '보기', '아주', '가격', '거의', '펜션', '일회용품', '구매', '점', '조금', '조식', '시설', '면', '아주', '수건', '침구', '검정색', '뭍', '물질', '꼭', '체크', '잠', '편이', '호텔', '협상', '가격', '아주', '서부', '제주', '관광명소', '해변', '공원', '차', '농장', '등', '제주도', '작', '의', '주요', '도시', '근처', '지역', '시장', '직원', '영어', '제한', '오프', '거리', '주차', '나', '내', '옷', '세탁', '세탁', '시설', '및', '무료', '관광', '일반', '그', '그', '그', '영어', '한국', '장점', '모든', '음식', '시장', '곳', '매우', '공덕', '시장', '한국', '돼지', '고기', '너', '주인', '나', '준', '무료', '한국', '위스키', '첨단', '기술', '하나', '컨트롤러', '제어', '수', '조명', '에어컨', '방', '꽤', '두', '번', '싱글', '베드', '화장실', '샤워실', '수압', '좀', '낮', '포트', '및', '포트', '주변', '여러', '레스토랑', '제한', '주차', '전용', '주차장', '즉', '베이', '속', '호텔', '때문', '저희', '밤', '에어컨', '바닥', '난방', '시스템', '밤', '철', '소리', '체크', '때', '무료', '세면', '용품', '제공', '칫솔', '면도기', '등', '그것', '개', '객실', '오두막집', '침대', '호텔', '매우', '장소', '주인', '매우', '상세', '사람', '그', '장소', '위해', '것', '나', '겨울', '뜻', '나', '서울', '출신', '전형', '제주', '경치', '바람', '수', '제주', '여행', '중', '일', '곳', '사장', '덕분', '길', '헤메', '차', '타고', '숙소', '때', '픽업', '수', '더더', '곳', '애견', '동반', '선택', '곳', '주인', '감동', '방도', '경치', '곳', '재', '방문', '의사', '야경', '예뻣던', '곳', '방', '바다', '보이', '고깃배', '불빛', '제주', '다운', '정경', '시설', '마음', '듭', '다그', '것', '바다', '경치', '수', '호텔', '비치', '레드', '화이트', '말', '모양', '등대', '근처', '동문', '시장', '택시', '로', '약', '분', '거리', '지역', '더', '머', '무르려', '곳', '일과', '여행', '후', '휴식', '취할', '수', '소파', '커피', '테이블', '침대', '내', '스튜디오', '요리', '수', '기회', '냉장고', '요리', '바비큐', '위해', '요리', '및', '웍룸', '설치', '저녁', '가족', '및', '친구', '수', '야외', '테이블', '여러', '개', '하모니', '리조트', '아이', '환영', '전망대', '그네', '및', '놀이', '위해', '예약', '장소', '태양열', '온수', '수영장', '야외', '의류', '세탁', '수', '공용', '세탁기', '제공', '전기', '자동차', '충전', '대가', '소유자', '그', '아내', '매우', '도움', '서비스', '지향', '장소', '절대', '대도시', '생활', '번잡', '함', '변화', '객실', '관리', '소유자', '그', '가족', '최고', '가족', '우리', '보석', '발견', '우리', '오기', '수', '회사', '통해', '방도', '리조트', '작', '부족함', '푹', '쉬', '겨울', '창', '인지', '리조트', '길가', '주변', '곳', '차', '렌트', '체크아웃', '날', '폭설', '비행기', '결항', '난리', '리조트', '사장', '아침', '차', '눈', '오후', '공항', '확인', '전화', '진짜', '감동', '뻔', '폭설', '생', '고생', '당분간', '제주도', '하모니', '리조트', '정말', '룸', '가구', '연식', '하나', '청소', '상태', '매우', '묵고', '아침', '일어나서', '오션', '뷰', '한림읍', '위치', '주변', '관광지', '프런트', '직원', '매우', '인상', '가지', '행마', '한림', '위치', '서쪽', '바다', '보기', '해변', '바로', '옆', '호텔', '해변', '풍력', '발전기', '뷰', '객실', '컨디션', '썩', '침대', '화장실', '그냥', '가정', '집', '화장실', '일단', '방음', '시설', '이동', '곳', '위치', '호텔', '수영장', '애기', '이용', '시설', '공항', '해안', '뷰', '전망', '침대', '스프링', '허리', '스프링', '랄', '그것', '전망', '물', '가격', '대비', '편입', '니', '서해', '바다', '가까이', '바다로', '가기', '프론트', '남', '직원', '친절', '도', '바닥', '고객', '대하', '교육', '제대로', '인터넷', '와이파이', '말', '수', '답변', '어이', '개인', '수영', '고급', '풀', '빌라', '가격', '외국', '풀', '빌라', '개인', '정원', '바베큐', '가구', '하나', '하나', '모던', '스타일', '신경', '흔적', '기념일', '가면', '로맨틱', '곳', '박일', '명', '가족', '여행', '출발', '전날', '숙소', '루온토', '출발', '전날', '오후', '예약', '가격', '조금', '편이', '전체', '로', '생각', '남자', '의', '친절', '감동', '아침', '식사', '간식', '회', '식당', '더', '수영장', '매일', '야간', '사용', '수', '전체', '제주도', '중', '최고', '서비스', '시설', '가지', '월', '정리', '해수욕장', '도보', '이동', '비치', '뷰', '룸', '독립', '통', '유리', '밖', '블라인드', '거', '모든', '호텔', '정말', '풀', '빌라', '평이', '걱정', '제', '방문', '때', '풀', '둘', '이용', '튜브', '튜브', '물놀이', '또', '자전거', '처음', '때', '보증금', '말', '줄', '그냥', '금액', '당', '천원', '정도', '하루', '종일', '꼭', '자전거', '금방', '월', '정리', '카페', '거리', '갈수', '반대쪽', '가면', '등대', '곳도', '위치', '이번', '월', '남편', '제주', '여행가', '면서', '처음', '먼저', '언니', '추천', '가게', '월', '정리', '해변', '바로', '주변', '저녁', '월', '정리', '쪽', '카페', '가도', '거린데', '각각', '개인', '방', '마다', '이', '배정', '애기', '가도', '다만', '오픈', '밖', '이', '점', '참조', '심', '아침', '무인', '언제', '예약', '시간', '완전', '추천', '진짜', '출장', '이용', '호텔', '서비스', '계속', '이용', '중', '무료', '와이파이', '무료', '차등', '서비스', '위치', '적합', '때문', '공항', '맛집', '대도', '로비', '작고', '곳', '비', '리셉션', '지배인', '매우', '안내', '객실', '청소', '상태', '매우', '바닥', '욕실', '침구', '전부', '관리', '객실', '다시', '방문', '의사', '객실', '무료', '와이파이', '매우', '체크', '및', '체크', '아웃', '시', '나', '월', '일', '월', '일', '그', '엘리베이터', '이용', '때', '짐', '때', '엘리베이터', '로비', '첫', '방이', '것', '내', '었다', '방', '사용', '순간', '단계', '침대', '화장실', '좀', '새', '호텔', '나', '보이지', '것', '아침', '식사', '제공', '모든', '것', '로비', '커피', '차', '직접', '언제', '수', '로비', '물', '필터', '링', '수', '나', '밤', '숙박', '때문', '저', '장점', '호텔', '찾기', '택시', '기사', '직원', '도움', '방이', '매우', '제', '예약', '더블', '룸', '매우', '숙박', '모든', '와이파이', '신호', '곳', '호텔', '위치', '곳', '위치', '레스토랑', '바', '카페', '이', '때', '도움', '저', '스쿠터', '공원', '무료', '공항', '매우', '단점', '직원', '영어', '수준', '듭니', '호텔', '멀리', '섬', '주요', '관광', '스쿠터', '수', '이', '방법', '제', '방문', '섬', '제', '추천', '그랜드', '풀', '빌라', '아이', '가기', '최고', '풀', '빌라', '중앙', '수영장', '매우', '명', '객실', '수', '숙소', '찾기', '아주', '수', '게다가', '스파', '수영장', '하루', '종일', '수영', '스파', '아이', '세탁기', '건조기', '수영복', '바로', '세탁', '수', '세탁기', '객', '실내', '리조트', '처음', '진짜', '대박', '게다가', '오픈', '한지', '얼마', '더', '재', '방문', '의사', '완전', '추천', '성산일출봉', '인근', '스파', '층', '객실', '이용', '층', '야외', '월', '풀이', '프라이', '빗', '리조트', '층', '월풀', '개인', '풀이', '함', '메인', '풀', '월', '이용', '이용', '층', '리가', '동', '구성', '각층', '개', '객실', '객실', '아주', '테라스', '티', '테이블', '야외', '월', '풀이', '시간', '이용', '수', '매우', '더블베드', '개', '창밖', '풍경', '단', '야외', '월풀', '물이', '안', '부유', '월풀', '내부', '청소', '관리', '것', '주차공간', '근처', '해안', '도로', '산책', '월', '초', '대중', '문', '성산', '일출봉', '단', '몇', '분', '관광', '명소', '또한', '제주', '동부', '매우', '장소', '인', '화', '해수욕장', '해안선', '운전', '거리', '가장', '곳', '매우', '때문', '항해', '발견', '직원', '매우', '우리', '리조트', '문제', '디자인', '마치', '리조트', '구역', '때', '발리', '섬', '어딘가', '것', '그것', '아주', '작', '모든', '것', '분위기', '공기', '및', '일부', '녹지', '빌라', '매우', '현대', '디자인', '라운지', '및', '객실', '주변', '개인', '손길', '가미', '그것', '모든', '것', '새', '양질', '야외', '스파', '발코니', '공간', '우리', '그것', '사용', '기회', '태양', '바람', '및', '와인', '잔', '수', '지역', '사용', '음식', '그것', '프리', '젠', '테이', '션', '취향', '한국', '스타일', '서양', '요리', '매일', '다른', '세트', '메뉴', '나', '보통', '한국', '식당', '반찬', '더', '주문', '수', '실제', '당신', '더', '것', '요구', '수', '리조트', '일', '전체', '직원', '매우', '보살', '것', '근처', '레스토랑', '리조트', '다른', '주제', '매달', '수업', '계획', '추가', '요금', '빌라', '손님', '무료', '룸', '테라스', '국적', '경치', '호텔', '조경', '가을', '수영장', '시설', '및', '옥상', '인피니티', '풀', '매력', '호텔', '중문', '단지', '위치', '근처', '볼거리', '맛집', '딸', '생일', '여행', '시간', '바다', '앞', '전망', '시설', '노후', '주변', '거리', '차로', '단점', '시설', '노후', '복도', '곳곳', '곰팡이', '냄새', '남', '객실', '해변', '근처', '산책', '리조트', '시설', '난방', '문제', '다른', '객실', '주지', '소형', '이동식', '풍기', '바다', '바로', '경치', '위락시설', '별로', '객실', '마음', '다만', '공항', '리조트', '거리', '좀', '시간', '조금', '한라산', '등반', '후', '호텔', '체크', '수영장', '피로', '월', '수영장', '도로', '유지', '이용', '운영', '가성', '비', '아주', '객실', '취사', '거기', '가격', '매우', '호텔', '중앙', '실외', '풀이', '수영', '호텔', '추천', '단점', '바다', '근처', '바다', '보이지', '접근', '점', '근처', '살', '때문', '이', '호텔', '선택', '매우', '요인', '해변', '수영장', '존재', '호텔', '버스', '정류장', '여태껏', '내', '정보', '버스', '정류장', '분', '정도', '이', '호텔', '도착', '공항', '찾기', '가운데', '주거지역', '사람', '이', '호텔', '섬', '도착', '때', '차', '호텔', '욕실', '침구', '방', '부엌', '아침', '식사', '수영장', '물', '가끔', '주말', '물이', '때', '손님', '었습니다저', '곳', '별', '개', '때문', '신발', '대부분', '서양인', '사용', '비누', '샤워', '바', '한국', '살', '지원', '이', '신발', '비누', '및', '특정', '장소', '예상', '공유', '수', '침대', '전형', '한국', '우리', '우리', '자신', '샤워', '신발', '신고', '침대', '비누', '한국', '호텔', '것', '방', '주방', '정도', '이', '포크', '필요', '대부분', '서양인', '생각', '아래', '필요성', '수건', '수건', '크기', '뿐', '아시아', '평벅', '매우', '스', '캐리', '이', '진입', '로', '간판', '신발', '평가', '비누', '그', '이', '자', '수', '거실', '우리', '두', '개', '침실', '베드', '우리', '일행', '중', '집', '수', '크기', '냉장고', '스토브', '탑', '전자레인지', '전기', '주전자', '물', '인스턴트', '커피', '가지', '수영장', '국가', '전망', '수', '내', '어머니', '마음', '내', '아이', '거실', '남편', '저', '의', '개인', '정보', '별도', '침실', '저희', '제', '층', '계단', '액세스', '주차', '수', '분', '드라이브', '씨', '분', '분', '제주', '시내', '쪽', '관광명소', '전반', '가족', '느낌', '아주', '제주', '여행', '시', '이용', '것', '식사', '직원', '정말', '전망', '한라산', '해변', '볼', '수', '다만', '서귀포', '쪽', '해당', '지역', '방문', '시', '시간', '꽤', '아들', '친구', '생일', '날', '여러', '가족', '다', '모', '곳', '요', '생일', '주인공', '가족', '수영장', '풀', '빌라', '저', '제일', '일반', '객실', '수영장', '커서', '풀', '빌라', '크기', '실내', '약간', '여러', '가족', '크기', '야외', '바베큐', '파티', '식탁', '온', '것', '약간', '큰길', '안쪽', '눈', '곳', '차로', '접근', '어려움', '오히려', '주변', '건물', '수', '곳', '요', '층', '편의점', '지하', '오락', '시설', '가족', '끼리', '친구', '끼리', '놀러와', '다음', '날', '조식', '보지', '조식', '제공', '때문', '다음', '묵', '수', '것', '프론트', '직원', '체크', '인과', '체크아웃', '모두', '가족', '여행', '시', '이용', '것', '식사', '직원', '정말', '전망', '한라산', '곽', '해변', '볼', '수', '리조트', '입구', '길', '제주', '향기', '물씬', '수', '호텔', '방', '욕실', '샤워', '시설', '작동', '무더위', '에어컨', '미국', '방', '전망', '수', '옷', '수', '다만', '열', '매우', '눈', '현지', '농장', '비료', '냄새', '베란다', '문', '자마자', '냄새', '순간', '전반', '경험', '제주도', '기본', '호텔', '방', '수리', '조금', '우리', '먼저', '안함', '예약', '수', '발코니', '방이', '그', '우리', '방', '발코니', '하루', '밤', '후', '하나', '바베큐', '식당', '아주', '시설', '대형', '수영장', '가족', '활동', '때문', '호스텔', '목조', '주택', '그것', '분위기', '나', '그', '집', '밤', '더', '기숙사', '수건', '매일', '었습니', '손님', '샤워', '아침', '식사', '기본', '정원', '호스트', '그', '어머니', '정말', '나', '외국인', '손님', '한국', '인도', '영빈', '관', '것', '위치', '곳', '더', '서쪽', '위치', '일부', '호스텔', '픽업', '때문', '동쪽', '코스', '투어', '참가', '것', '허용', '글쎄', '나', '픽업', '지점', '았', '시내', '버스', '분', '이상', '더', '나은', '차', '시오', '국제', '운전', '면허증', '비', '수기', '특가', '선택', '가성', '비', '난방', '수압', '와이파이', '빵빵', '기본', '것', '위치', '관덕정', '정류장', '시장', '정도', '주변', '식당', '편의점', '메가박스', '이', '정도', '가격', '최상인', '듯', '단점', '침대', '메', '트리스', '저', '예비', '이불', '하나', '더', '제주', '국제공항', '근처', '시내', '호텔', '객', '실내', '크기', '욕실', '욕조', '편이', '좀', '호텔', '근처', '시장', '현지', '맛집', '관광', '위치', '호텔', '랍', '다방', '생각', '시설', '편입', '니', '다만', '외부', '벽', '하나라', '외부', '소음', '좀', '기적', '냉장고', '소음', '배치', '위치', '때문', '방', '전체', '처음', '공사', '소음인', '줄', '알', '잠', '부분', '위치', '전체', '시설', '으리', '으리', '하진', '방이', '취사', '시설', '탑동', '근처', '쪽', '맛집', '기도', '공항', '비행기', '잠깐', '자고', '비지니스', '호텔', '룸바닥', '매우', '조심', '공항', '택시', '비', '원', '아침', '유명', '해장국', '집', '분', '거리', '저녁때', '한잔', '술집', '근처', '룸안', '조리', '시설', '그릇', '수저', '젓가락', '등', '요사', '최고', '장소', '위치', '숨', '그것', '자신', '연금', '바다', '마주', '보고', '연금', '인분', '이', '건물', '요리', '허용', '연금', '지역', '밖', '지정', '지역', '쓰레기', '쓰레기', '사실', '일', '가장', '바다', '경치', '추천', '출발', '전', '예약', '통해', '박', '동안', '예약', '여행', '개월', '전', '도착', '전', '일정', '금액', '입금', '제공', '계정', '세부', '정보', '언어', '장벽', '프로세스', '크게', '방해', '체크', '후', '전체', '비용', '지불', '수', '체크', '위치', '공항', '약', '곳', '위치', '연금', '바다', '전경', '연금', '도중', '일부', '식료품', '쇼핑', '위', '주요', '도로', '위치', '지역', '슈퍼마켓', '체크', '절차', '순조', '롭', '만', '사무실', '실제', '지하', '때문', '처음', '사무실', '수', '바람', '자신', '보호', '수', '장소', '도로', '몇', '개', '주차장', '모든', '손님', '도로', '우리', '연금', '명의', '방이', '었는데', '성인', '명과', '살', '살의', '어린이', '명', '위', '최고', '장소', '그', '우리', '요리', '모든', '것', '주방', '용품', '밥솥', '등', '제외', '근처', '산토', '연금', '약', '거리', '인근', '시간', '동전', '세탁기', '사용', '수', '세탁기', '건조기', '제외', '우리', '약간', '결함', '우리', '제', '의', '밤', '우리', '자동', '자물쇠', '열쇠', '기능', '녔던', '것', '위해', '집', '기술자', '마침내', '화장실', '창문', '통', '등', '발', '열기', '전', '약', '분', '작동', '그', '우리', '소풍', '도중', '금능', '해수욕장', '편의점', '이', '펜션', '층', '금능', '해수욕장', '제일', '기도', '방도', '펜션', '감안', '수기', '가격', '주인', '편이', '수건', '교체', '바로', '해주시', '층', '세탁기', '이용도', '최고', '호스텔', '한국', '일', '장변', '제주도', '아주', '기간', '동안', '우리', '차', '가지', '후', '공항', '운전', '곳', '거', '생각', '도시', '멀리', '약', '시간', '반', '야간', '드라이브', '가시', '바다', '것', '아침', '바람', '상상', '수', '그', '새', '축하', '곡', '일부', '걸즈', '아마', '즉시', '취할', '수', '수', '그', '휴가', '우리', '하나', '밤', '직원', '말', '그대로', '영어', '아주', '신체', '언어', '인치', '이', '때', '여행', '부분', '위치', '룸', '컨디션', '별로', '구석구석', '먼지', '리뷰', '보고', '이용', '사진', '다른', '룸', '매우', '습', '디', '직원', '사무', '별로', '습', '디', '다시', '이용', '일', '듯', '곽', '해수욕장', '바로', '앞', '뷰', '정말', '편의점', '맛집', '등', '여행', '곳', '층', '로비', '오픈', '공간', '바다', '맥주', '한잔', '것', '룸', '재', '방문', '의사', '씨뷰', '호텔', '월초', '바닷가', '앞', '때', '중앙', '난방', '방식', '면서', '난방', '에어컨', '밤', '난방', '불가', '함', '룸', '바닥', '카펫', '청소', '남편', '아이', '계속', '재체기', '박', '콧물', '나기', '시작', '명', '예약', '모든', '애', '티', '수건', '슬리퍼', '칫솔', '등', '명', '준비', '가격', '대비', '인테리어', '숙소', '지어짅', '얼마', '매우', '편', '바닥', '나무', '재질', '색상', '모던', '인테리어', '인상', '호텔', '분', '거리', '바로', '아이', '곽', '해수욕장', '있었느', '태풍', '시즌', '모래바람', '사이', '사진', '한장', '겨우', '룸서비스', '조식', '건너편', '쌀국수', '집', '거기', '만원', '안쪽', '특급', '호텔', '시설', '분', '꽤', '비수', '이용', '곽', '과물', '해변', '조금', '해변', '식당', '다만', '내부', '정돈', '느낌', '청결', '신경', '더', '것', '왼쪽', '오른쪽', '가면', '분안', '번화가', '호텔', '위치', '정말', '밤', '뭐', '가기', '교통', '가장', '장점', '조식', '함정', '제주도', '때', '여기', '방이', '조식', '한식', '양식', '깨끗', '선택', '직원', '정말', '공항', '교통', '행정', '쇼핑', '최상', '위치', '주차장', '로비', '좀', '작', '직원', '친절', '배려', '마음', '쉬', '비수', '가격', '조식', '커피', '대박', '케냐', '커피', '싱글', '오리진', '합리', '선택', '동안', '여행', '가성', '비', '최강', '요', '공항', '인근', '추천', '성비', '오픈', '호텔', '공항', '도', '편의', '시설', '주변', '조식', '공항', '분', '거리', '도로', '변', '위치', '밤', '도착', '한눈', '보', '리조트', '거의', '호텔', '침구', '아기', '전동차', '수상', '자전거', '놀이터', '퇴', '시간', '다음', '여기', '리조트', '안', '놀', '거리', '객실', '직원', '장난감차', '아이', '함', '점도', '실내', '바비큐', '고기', '집', '식당', '거', '숙소', '잠자리', '아침', '사장', '토스트', '사과', '제주도', '가을', '여기', '제대로', '정리', '우리', '예약', '트윈', '룸', '트리플', '룸', '호스트', '우리', '방', '방', '이동', '수', '위치', '정말', '로컬', '주거', '지역', '내', '동생', '블렌드', '주민', '전반', '곳', '매일', '청소', '저', '제', '동생', '그', '인사', '도움', '그', '를', '우리', '옷', '도', '천', '랙', '방', '그', '한국어', '도', '주인', '말', '중국어', '및', '일본어', '영어', '조금', '만', '그', '영어', '실력', '꽤', '문제', '제주도', '다시', '미래', '이', '호텔', '다시', '오', '설명', '작업', '계속', '편', '위치', '전망', '제공', '호텔', '근처', '식사', '장소', '직원', '내', '예약', '방', '창문', '해변', '향', '방', '안', '욕조', '실용', '이지', '아들', '그것', '실용', '샤워', '공간', '샤워', '후', '화장실', '바닥', '내', '방', '마', '모의', '흔적', '호텔', '바로', '편', '무료', '주차장', '우리', '단지', '박', '동안', '것', '체적', '그것', '체재', '직원', '분', '숙소', '조식', '바다', '서우', '봉', '산책', '수', '거리', '루프', '탑', '수영장', '가족', '우리', '신혼', '여행', '제주도', '방문', '이', '호텔', '숙박', '해변', '근처', '그', '객실', '내부', '스스로', '요리', '수', '우리', '아주', '가격', '아침', '식사', '형편', '우리', '적극', '이', '호텔', '추천', '호스트', '아주', '도움', '그', '우리', '픽업', '근처', '동안', '애월', '버스', '정류장', '길', '체크', '때', '우리', '편입', '니', '방', '부엌', '자신', '요리', '수', '그', '이상', '여가', '시간', '또한', '이', '곳', '아주', '주변', '환경', '바다', '뿐', '식당', '이', '위치', '버스', '정류장', '분', '거리', '타고', '제주시', '수', '아주', '대중', '교통', '수단', '차', '렌트', '강력', '추천', '원', '일박', '공항', '시간', '도착', '렌터', '사람', '하루', '듯', '네이버', '검색', '결과', '리뷰', '정도', '다만', '시설', '사실', '임', '방', '온수', '크게', '불만', '휴가', '겸', '태교여행', '선택', '제주', '월', '마지막', '날', '숙박', '비', '포함', '모든', '여행자', '물가', '아기', '여행', '숙박', '업체', '선택', '제일', '신경', '급', '호텔', '요금', '때문', '폭풍', '검색', '끝', '신규', '오픈', '호텔', '군데', '예약', '객실', '곳', '별로', '리치', '호텔', '검색', '후기', '고민', '규모', '가격', '애월', '바다', '월풀', '욕조', '호텔', '가성', '비', '제주', '숙박', '업체', '강', '신축', '건물', '모던', '방', '디자인', '인테리어', '스파', '실', '침실', '모두', '펜션', '음식', '해먹', '수', '인덕션', '그릇', '방', '사진', '위치', '보기', '성산일출봉', '곳', '이', '방', '꽤', '이유', '성산', '일출봉', '은', '여러', '해산물', '식당', '수', '것', '수', '지역', '마트', '레스토랑', '호텔', '앞', '저', '이', '호텔', '추천', '경우', '시간', '곳', '실내', '저', '전혀', '생각', '방', '청소', '때문', '나', '냉장고', '유리', '사용', '수', '저', '제', '남편', '갑자기', '새벽', '시', '잠', '수', '때문', '침대', '갑자기', '문', '노크', '를', '선택', '때', '화가', '것', '사면', '제', '남편', '한국', '우리', '마트', '직원', '청원', '뭐', '나', '한국', '문화', '이해', '아마', '그', '외국인', '어쨌든', '저', '캄보디아', '말', '태도', '여름', '수기', '방문', '가격', '리', '모델링', '신축', '건물', '시설', '물', '위생', '제주', '기후', '탓', '벽지', '등', '곰팡이', '슬어', '제습기', '가동', '곰팡이', '흔적', '남아', '조금', '한여름', '이외', '방문', '권장', '성산일출봉', '우도', '실', '전날', '여기', '숙박', '객실', '룸', '상태', '가격', '대비', '다만', '금연', '객실', '달라', '불구', '담배', '냄새', '그', '부분', '별로', '가격', '대비', '룸상태', '편이', '관광', '정이', '빼곡', '호텔', '이용', '날', '곳', '이용', '가성', '비', '일단', '해안', '도로', '근처', '주변', '산책', '주변', '시설', '이용', '펍', '편의점', '차', '타고', '조금', '가면', '노', '시내', '나오니', '문제', '생각', '제', '곳', '신관', '룸', '싱글', '베드', '더블베드', '방이', '아마', '신관', '룸', '호텔', '방만', '곳', '구관', '주방', '펜션', '룸', '룸', '컨디션', '정말', '이', '정도', '그냥', '겉보기', '정도', '가지', '계속', '눈', '방', '아래쪽', '벽지', '복도', '벽지', '아래쪽', '벽지', '튿어져', '여', '보수', '신경', '안', '사람', '손때', '느낌', '군데', '데', '오염', '부분', '규모', '편의점', '바베큐', '수영장', '등', '편의', '시설', '세탁', '시설', '바로', '앞', '도', '두봉', '전경', '해안', '도로', '오션', '뷰', '객실', '전망', '공항', '분', '정도', '거리', '위치', '해안', '도로', '바로', '옆', '전망', '층', '도보', '분', '거리', '까페', '편의점', '약국', '등', '편의', '시설', '고루', '리조트', '본관', '이용', '사진', '욕실', '주방', '침대', '등', '풀', '장도', '관리', '바베큐', '장도', '무료', '이용', '야자나무', '조경이', '제주시', '근처', '도', '휴양지', '느낌', '자전거', '대여', '이용', '바로', '앞', '도', '두봉', '산책', '코스', '공항', '필드', '분', '택시', '최저', '박', '예약', '작업', '및', '에어컨', '시설', '인터넷', '및', '꽤', '침대', '피', '에이', '개선', '유지', '보수', '부족함', '자신', '시설', '세도', '칫솔', '공항', '예', '수', '전반', '공항', '움', '우리', '온라인', '통해', '우리', '가격', '약시', '사람', '조금', '에어컨', '일반', '불만', '요금', '와이파이', '무료', '및', '확인', '세탁기', '다리미', '등', '바로', '앞', '바다', '창밖', '뷰', '탁', '사장', '분', '맞이', '신경', '소수', '인원', '명도', '이용', '수', '구조', '커플', '다수', '인원', '그룹', '수', '것', '생각', '숙소', '더욱', '여행', '것', '강추', '박', '우선', '공항', '숙소', '바다', '앞', '바다', '냄새', '생선', '냄새', '주변', '주택가', '숙소', '초입', '동네', '마트', '약국', '편의점', '사장', '분도', '숙소', '앞', '부담', '숙소', '주변', '마트', '일일이', '위치', '어디', '뭘', '추천', '첫날', '밤', '바닥', '화장실', '찬물', '무릅쓰', '시간', '연락', '사장', '분', '확인', '방', '수', '신경', '화장실', '샴푸', '샤워', '용품', '구비', '수건', '바구니', '토스트', '수', '식빵', '초콜렛', '준비', '잼', '버터', '냉장고', '준비', '아침', '침대', '생각', '좀', '생각', '전혀', '베개', '폭', '폭', '신하', '매트리스', '폭', '폭신', '여분', '침구', '류', '사용', '수', '전체', '정말', '다시', '방문', '숙소', '사장', '두', '분도', '다음', '또', '수', '시설', '좀', '노후', '건', '단체', '생각', '진짜', '명', '정도', '콘도', '정도', '생각', '가끔', '거름', '냄새', '때', '가족', '여행', '때', '친구', '명', '때', '연인', '끼리', '제', '때', '근처', '축사', '작업', '똥', '냄새', '가족', '여행', '식구', '식구', '걱정', '숙소', '아빠', '장애', '휠체어', '사용', '그것', '행사', '차', '여명', '두', '채', '집', '구조', '방', '개', '거실', '주방', '등', '형태', '베드', '방', '독', '채식', '분리', '수', '안방', '격인', '트윈베드', '단체', '좀', '점', '개', '화장실', '군데', '주방', '시설', '소규모', '단체', '숙박', '구조', '거실', '독채', '각각', '인터넷', '점', '월임', '주변', '숲', '때문', '파리', '모기', '전자렌지', '냉장고', '정도', '수', '가성', '비', '볼', '때', '선택', '수', '생각', '곳', '명', '제주', '보석', '저', '책', '아고다', '통해', '사실', '프로', '곳', '우리', '퀸스', '사이즈', '침대', '싱글', '침대', '식', '객실', '부엌', '티비', '발코니', '거실', '심지어', '화장', '시청', '방법', '퀸', '사이즈', '침대', '폭', '신하', '정말', '무료', '와이파이', '아주', '서비스', '꽤', '물질', '중국어', '및', '영어', '전혀', '문제', '이야기', '우리', '체크', '및', '관리', '사람', '봉사', '여자', '저녁', '식사', '경치', '곳', '꽤', '우리', '아주', '단점', '아주', '원격', '및', '리뷰', '심지어', '택시', '길', '다음', '체크', '인', '시간', '꽤', '우리', '겨', '의', '짐', '수', '우리', '방', '준비', '통화', '싱글', '침대', '베개', '모든', '플랫', '기', '다음', '사용', '수', '핸드', '요청', '시', '이', '하드', '를', '방', '코딱지', '하나', '개미', '득시', '글', '및', '전원', '포트', '다른', '방', '침대', '옆', '램프', '또한', '예약', '저녁', '각', '싱가폴', '달러', '무제한', '바베', '큐', '돼지고기', '스프', '측부', '모두', '나', '다시', '데', '전반', '숙박', '실내', '인테리어', '것', '근본', '엘리베이터', '등', '시설', '문제', '주차', '앞쪽', '옆', '골목', '쪽', '밤낮', '문제', '큰길', '차', '소리', '가격', '대비', '적극', '추천', '곳임', '터미널', '옆', '음식점', '시간', '식당', '부집', '도', '휴가', '친구', '명과', '제주', '다인', '리조트', '카라반', '박', '달', '정도', '전', '예약', '카라반', '상대', '가격', '이용', '수', '것', '장점', '위치', '공항', '애월', '해변', '근처', '위치', '접근성', '카라반', '명', '이상', '정도', '마음', '카라반', '객실', '객실', '청소', '제공', '것', '단점', '기본', '제공', '어메니티', '휴지', '치약', '비누', '수건', '정도', '교체', '에어컨', '가동', '시', '물이', '상황', '카라반', '바베큐', '시설', '이용', '수', '메리', '카라반', '공간', '추억', '곳', '생각', '겉', '조금', '허름', '내부', '것', '비지니스', '호텔', '느낌', '공항', '정말', '일찍', '출발', '사람', '것', '어른', '중학생', '초', '가족', '연휴', '마지막', '날', '새벽', '비행기', '일부러', '공항', '앞', '가격', '온돌룸', '예약', '방', '리', '모델링', '침구', '류', '욕실', '포함', '전체', '장점', '공항', '차로', '분', '호텔', '층', '시간', '코인', '빨래', '방', '주중', '낮', '동안', '빨래', '건조', '후', '수', '서비스', '제공', '인', '약시', '인', '침구', '개', '온돌방', '기준', '물', '병', '수건', '제공', '단점', '옷장', '협소옷걸', '개', '욕실', '문', '변기', '바로', '앞', '문', '무릎', '다음', '기회', '조식', '렌트카', '서비스', '보고', '지난', '월', '두', '차례', '박', '총', '박', '우선', '호텔', '시설', '정리정돈', '상태', '것', '트윈룸', '숙박', '침대', '하루', '이틀', '처음', '층', '숙박', '객실', '공항', '비행기', '장면', '좀', '무렵', '정말', '게다가', '공항', '가장', '가까이', '호텔', '것', '알', '도청', '분', '정도', '거리', '번화가', '연동', '바오', '젠', '거리', '등', '것', '고층', '공항', '전망', '객실', '수', '가성', '비', '호텔', '방', '나름', '느낌', '예전', '베니키아', '인수', '리', '모델링', '바', '외관', '조금', '손보', '베니키아', '호텔', '보통', '부띠', '호텔', '클래스', '여행', '계속', '호텔', '한마디', '추천', '요다음', '날', '새벽', '비행기', '공항', '근처', '숙박', '가격', '대비', '매우', '미리', '말', '다음', '날', '새벽', '호텔', '셔틀', '줌', '관광', '호텔', '매우', '나', '둘이서', '인', '가족', '묵', '수', '사이즈', '렌터카', '곳', '더', '기도', '무', '가격', '대비', '정말', '호텔', '임', '직원', '매우', '친절', '안경', '직원', '호텔', '실수', '저', '사과', '그', '추가', '비용', '지불', '요청', '침대', '머리카락', '거울', '모기', '시체', '여행', '마지막', '날', '다시', '제주도', '우리', '호텔', '결정', '두', '가지', '이유', '무료', '공항', '교통', '편', '제공', '자전거', '두', '가지', '여행', '중', '대형', '호텔', '때문', '우리', '자전거', '상자', '계속', '수', '바랬습니', '며칠', '동안', '우리', '제주', '자전거', '우리', '호텔', '체크', '아웃', '전', '우리', '보관', '위해', '그', '두', '개', '상자', '것', '것', '우리', '물어', '우리', '호텔', '때', '아무', '상자', '대해', '알', '우리', '체크', '날', '직원', '점원', '확인', '직원', '요청', '때', '우리', '상자', '것', '매우', '실망', '마음', '상한', '사과', '설명', '상황', '해결', '시도', '말', '것', '우리', '그', '밖', '곳', '결정', '호텔', '자체', '무료', '공항', '교통', '편', '그것', '공항', '호텔', '인근', '별로', '우리', '아침', '식사', '각각', '원', '지불', '가치', '차라리', '그', '중', '일부', '소비', '편의점', '커피', '샌드위치', '구입', '것', '제주', '공항', '고객', '서비스', '박의', '제주', '노블레스', '렀습니', '경영', '지원', '팀', '리더', '인', '테드', '에이', '김', '은', '제주', '우리', '위해', '그', '년', '이상', '경험', '택시', '박희', '경', '과', '원', '일', '동안', '개인', '자동차', '준비', '업무', '열정', '그', '영어', '번역', '사용', '대화', '제주', '관해', '이야기', '우리', '체', '재는', '아침', '식사', '포함', '음식', '날', '준비', '주로', '한국', '음식', '야채', '볶음', '쌀', '달걀', '수프', '과일', '종', '파인애플', '및', '바나나', '컷', '시리얼', '및', '빵', '호텔', '무료', '주차', '인근', '지역', '걷기', '관광', '위해', '개발', '때문', '자동차', '소지', '여행', '준비', '것', '가장', '공항', '거리', '서쪽', '여행', '위치', '최고', '밤', '문화', '시내', '오분', '거리', '이호', '해변', '가두', '선택', '위치', '이', '펜션', '협재', '해변', '모래사장', '중심', '위치', '상점', '레스토랑', '주변', '펜션', '숙박', '우리', '해변', '하루', '후', '택시', '수', '때문', '호텔', '주말', '우리', '우리', '도움', '요청', '여부', '주인', '이', '펜션', '클라라', '관리자', '그녀', '우리', '매우', '문제', '대한', '여러', '택시', '회사', '마지막', '우리', '발견', '때', '호출', '해', '주소', '다시', '설명', '드라이버', '해', '다음', '것', '이기', '때문', '아주', '위치', '펜션', '이여름', '협재해수욕장', '바로', '앞', '층', '카페베네', '최근', '층', '뷰', '우도', '성산일출봉', '근처', '숙소', '예약', '욜', '펜션', '곳', '위치', '주변', '주택', '몇', '채', '보이', '것', '보시', '사장', '저희', '방문', '예상', '시간', '생각', '도착', '사장', '일찍', '부터', '에어컨', '켜', '월달', '여름', '정도', '방이', '저희', '바베큐', '신청', '안해', '구나', '사용', '방', '다음', '날', '출발', '때', '저희', '사장', '운영', '카페', '와플', '음료', '주문', '커피', '그냥', '정말', '카페', '앞', '핀', '해바라기', '꽃', '빨간색', '컨테이너', '박스', '모습', '욜', '펜션', '저', '지난', '주', '펜션', '끝', '숙박', '자주', '비즈니스', '레저', '여행객', '저', '이', '환상', '부부', '환영', '여기', '집', '것', '팁', '배정', '제주', '방법', '한라산', '여행', '곳', '사우나', '해변', '등', '위치', '곳', '연결', '버스', '제주', '공공', '체육', '시설', '수', '미터', '펜션', '헬스장', '외부', '비어', '가든', '아침', '해변', '달리', '체육관', '운동', '및', '마무리', '환상', '아침', '식사', '수', '방법', '전', '나', '일', '물', '커피', '무료', '일', '것', '매우', '저', '펜션', '강력', '추천', '호텔', '추천', '처음', '나', '제주', '도착', '때', '내', '나', '나라', '예약', '나', '이전', '숙소', '그것', '일', '취소', '제주', '마침내', '나', '것', '발견', '매우', '그녀', '우리', '할인', '이', '호텔', '방이', '가격', '원', '인의', '숙박', '그녀', '주차장', '엘리베이터', '수건', '헤어', '드라이어', '비누', '샴푸', '차', '커피', '가지', '아침', '위치', '아주', '여기', '밤', '생활', '수', '레스토랑', '쇼핑', '거리', '및', '바', '새', '건물', '침구', '욕실', '냉장고', '소음', '생수', '병과', '음료', '캔', '에어컨', '도', '치약', '면도기', '방이', '침구', '제외', '매우', '협소하', '슬리퍼', '의자', '주차장', '대정', '호텔', '모텔', '편입', '니', '객실', '서비스', '호텔', '서비스', '제', '예약', '호텔', '및', '도착', '때', '리셉션', '직원', '다소', '제한', '영어', '제', '지적', '이', '우리', '예약', '분', '대해', '다른', '시간', '나', '나', '여행', '파트너', '욕실', '밤', '로비', '나', '내', '확인', '요청', '방', '키', '제', '기분', '상하', '옷', '간', '것', '관광', '한국', '인', '다운', '재킷', '도', '주위', '때', '었다', '나', '점', '확인', '의심', '그', '수', '방법', '더', '불쾌', '가장', '제한', '이기', '때문', '그', '영어', '가격', '주변', '다른', '호텔', '가격', '꼭', '호스텔', '이', '모든', '것', '경우', '객실', '제', '방', '전체', '이', '한국', '여러', '호텔', '저', '제주도', '호텔', '방', '생각', '수', '서울', '호텔', '서울', '부티크', '호텔', '더블', '침대', '방', '대부분', '차지', '정말', '공간', '움직', '이화', '열', '이', '상상', '수', '욕실', '욕실', '나', '이해', '수', '한국', '호텔', '샤워', '부스', '화장실', '파티션', '커튼', '세면대', '이', '사례', '호텔', '파티션', '커튼', '욕실', '샤워', '곳', '후', '그', '화장실', '업로드', '욕실', '마련', '편의', '시설', '이', '호텔', '제주', '공항', '자동차', '약', '분', '거리', '우리', '바다', '전망', '방', '디럭스', '임대', '보기', '객실', '주방', '용품', '제공', '호텔', '바로', '옆', '이', '것', '평화로', '웠', '우리', '정말', '제주', '움', '감상', '수', '해수욕장', '해', '맞이', '해안로', '중간', '위치', '지미', '스테이', '태풍', '때문', '날씨', '혼자', '숙박시설', '독점', '재미', '정말', '곳', '힐링', '공간', '지미', '카페', '분위기', '단점', '태풍', '불면', '조금', '외진', '곳', '대리', '기사', '구', '점', '건물', '내부', '시설', '관리', '직원', '다음', '기회', '꼭', '다시', '곳', '주차', '아주', '주차장', '호텔', '위치', '환상', '방문', '현지', '시장', '매우', '방', '박', '우리', '욕실', '가지', '때문', '나', '방', '욕실', '및', '주방', '매우', '것', '강조', '예산', '호스텔', '가격', '관계', '품질', '균형', '직원', '영어', '불구', '그', '도움', '노력', '월', '일', '공항', '혼자', '하루', '정도', '조식', '아무', '드', '구', '위치', '나', '그것', '사랑', '것', '나', '제', '의', '체', '그것', '해변', '해변', '레스토랑', '도시', '최고', '나', '거기', '다시', '생각', '바다', '마주', '옆', '면', '주인', '위치', '시설', '및', '경치', '환대', '가장', '그', '가격', '상대', '손님', '층', '건물', '사용', '수', '각', '층', '매우', '독립', '사용', '수', '나', '부부', '가족', '모두', '그것', '권장', '최전선', '바다', '조', '수', '것', '최고', '수', '일단', '주변', '유흥주점', '여자', '끼리', '진짜', '또', '환풍', '담배', '냄새', '진짜', '금연', '리뷰', '맛', '예약', '진짜', '담배', '냄새', '상상', '초월', '해', '건물', '공사', '진짜', '대충', '담배', '냄새', '화장실', '겹겹', '저', '진짜', '구역질', '경험', '그냥', '밤', '친구', '정말', '모텔', '용', '여행', '가격', '도', '진짜', '여행', '최악', '경험', '스테이', '호텔', '은', '여관', '호텔', '그', '손님', '위해', '체크', '리셉션', '가지', '객실', '위성', '채널', '시청', '수', '평면', '냉장고', '및', '무료', '전용', '대형', '욕실', '샤워', '시설', '제한', '무료', '세면', '도구', '헤어', '드라이어', '여행자', '위', '기본', '필요성', '지하', '쇼핑', '단지', '거리', '동문', '시장', '불과', '과', '관광', '명소', '도보', '도달', '수', '환전', '정', '파빌리온', '버스', '버스', '정류장', '시내', '관광', '버스', '를', '이용', '수도', '주변', '전혀', '호텔', '옆', '프라이드', '치킨', '맥주', '하우스', '개', '해산물', '레스토랑', '플러스', '호텔', '바로', '편', '미니', '마트', '체적', '나', '개', '날', '체', '재는', '그', '리셉션', '자주', '때문', '직원', '대해', '말', '것', '매일', '방', '청소', '합', '다애', '월', '해안', '도로', '전망', '숙소', '임신', '축', '숙소', '내', '집기', '상태', '아주', '층', '건물', '공간', '층', '모두', '침실', '욕실', '거실', '간', '아이', '층', '공간', '개인', '테라스', '마음', '바다', '동안', '자주', '테라스', '청소', '상태', '아주', '집주인', '다음', '여행', '다시', '숙소', '임명', '자도', '문제', '나', '여기', '매우', '로비', '무료', '만다린', '합리', '가격', '대당', '원', '모든', '것', '작동', '생선', '시장', '근처', '도시', '매우', '중앙', '위치', '도착', '시', '바다', '방', '달라', '우리', '보기', '이', '해변', '도로', '바로', '옆', '트래픽', '사람', '방해', '최소한', '및', '식당', '지역', '돼지고기', '해산물', '전체', '계속', '옆', '방', '자체', '꽤', '평균', '모든', '것', '수건', '층', '커피숍', '침대', '돌', '개인', '마음', '내', '파트너', '숙소', '엄철', '내부', '인테리어', '아주', '중문', '렌트', '방문', '어디', '가기', '숙소', '추천', '직장', '장기', '휴가', '월', '일', '일', '일주일', '도미', '토리', '게스트하우스', '바다', '자전거', '자전거', '수', '도미', '토리', '커플', '가족', '위', '룸', '커피', '조식', '포함', '혹시', '낚시', '포구', '앞', '배', '저', '낚시', '사장', '문의', '고내포구', '바로', '앞', '통', '유리', '바다', '뷰', '환상', '호스트', '호텔', '수건', '정말', '곳', '아침식사', '커피', '저', '커피', '사장', '원두', '문의', '원가', '봉지', '볶음밥', '토스트', '등', '포함', '사장', '자전거', '협재', '것', '참고', '자전거', '길', '이름', '제주도', '환상', '자전거', '길', '자전거', '길', '달리', '중간', '바다', '술책', '서점', '카페', '근처', '마틸다', '판', '바', '바다', '자전거', '숙박', '예정', '시', '팝', '예전', '가요', '생각', '바', '음악', '신청', '술', '한잔', '곳', '천국', '저녁', '시', '새벽', '시', '영업', '화요일', '휴무', '마틸다', '안쪽', '분만', '가시', '애월', '도서관', '금요일', '관', '게스트하우스', '바로', '옆', '건물', '시간', '영업', '일단', '최저', '생활', '걱정', '반대쪽', '옆', '횟집', '정류장', '번', '버스', '타고', '공항', '층', '편의점', '까페', '레스토랑', '테라스', '화장실', '마루', '바닥', '점', '편', '가성', '비', '곳', '제주시', '호텔', '나름', '전망', '주차장', '주차', '타워', '게', '좀', '점', '조식', '시간', '시', '부터', '단체', '손님', '시', '부터', '것', '데', '비행', '시간', '때문', '일찍', '데', '단체', '손님', '조식', '편', '롱', '마을', '제주', '전통', '가옥', '꾸밈', '분', '거리', '화', '해변', '편의점', '버스정류장', '가까이', '카페', '맛집', '꽤', '며칠', '진짜', '지역', '주민', '주말', '화', '민속', '오일장', '플리', '마켓', '거리', '쿠팡', '가격', '구매', '간곳', '기대', '공항', '바로', '옆', '비행기', '이착륙', '소리', '그다지', '공항', '활주로', '끝', '자락', '잔디', '부분', '마치', '오름', '보이', '해안', '도로', '따라서', '전망', '단', '하룻밤', '날씨', '해안', '도로', '산책', '다음', '꼭', '다시', '조식', '기대', '가격', '대비', '미역국', '밥', '김치', '여행지', '로', '닭', '볶음', '맛', '더', '조언', '탕수육', '메뉴', '추천', '아침', '메뉴', '소스', '차라리', '장아찌', '나물', '생선', '구이', '더', '양식', '조식', '토스트', '커피', '달걀', '한식', '스크램블', '영', '한식', '양식', '매하', '맛', '저', '커피', '티', '직원', '청소', '관리', '분도', '투숙', '객', '인사', '모습', '특급', '호텔', '경험', '서비스', '인상', '다음', '시간', '일', '이번', '여행', '숙소', '선택', '기준', '공항', '거리', '주변', '환경', '혼자', '여행', '이기', '편리', '가지', '모두', '숙소', '공항', '택시', '분', '천원', '정도', '거리', '한번', '공항', '호텔', '쉬엄쉬엄', '시간', '여분', '소요', '용담', '도로', '공항', '올레길', '걸', '수', '코스', '마지막', '날', '첫', '날', '도보', '여행', '계획', '분', '한번', '것', '주변', '바로', '옆', '편의점', '카페', '식당', '모두', '위치', '번잡', '거나', '체적', '숙소', '위치', '곳', '어', '마을', '곳', '숙소', '바로', '앞', '공원', '침대', '바다', '일몰', '볼', '수', '트윈룸', '성인', '명', '정도', '이용', '수', '구', '기본', '욕실', '용품', '비치', '칫솔', '조식', '크게', '것', '그냥', '일반', '아침', '가정식', '정도', '생각', '박', '일', '이용', '마루', '바닥', '나름', '씨뷰', '공항', '근처', '하루', '조식', '무조건', '포함', '던데', '가격', '대비', '사진', '스위트룸', '이틀', '동안', '객실', '인용', '일반', '한국', '호텔', '객실', '객실', '편의', '시설', '작동', '문제', '두', '가지', '점', '욕실', '목욕', '타월', '호텔', '핸드', '타월', '만', '제공', '방', '목욕', '타', '추가', '아침', '식사', '스프레드', '매우', '아침', '식사', '이름', '나', '회교도', '음식', '돼지', '고기', '여부', '결정', '매우', '음식', '이름', '매우', '유용', '것', '위치', '공항', '도심', '근처', '그것', '단지', '호텔', '단체', '여행객', '만', '이용', '수', '호텔', '수면', '전용', '만', '사용', '년', '일', '이틀', '이', '여행사', '예약', '이', '호텔', '선택', '기본', '이', '호텔', '것', '꽤', '주변', '내', '호텔', '외관', '기반', '새', '것', '체크', '인도', '방', '심플', '디자인', '욕실', '면도', '구가', '칫솔', '제외', '방', '편의점', '층', '위치', '프론트', '데스크', '카운터', '기본', '옆', '이', '근처', '것', '아침', '일간', '평균', '전반', '목적', '잠', '수행', '호텔', '공항', '매우', '로비', '개', '서비스', '수하물', '보이', '영어', '의사', '소통', '수', '프론트', '데스크', '접수', '아침', '뷔페', '거의', '매일', '엘리베이터', '객실', '기본', '세면', '도구', '제공', '위치', '대부분', '관광', '사이트', '중심', '나', '다음', '다른', '호텔', '예약', '것', '선호', '공항', '매우', '대로', '변', '곰팡이', '냄새', '창문', '열', '에어컨', '바로', '침대', '위', '직', '방이', '화장실', '문도', '불편', '밤낮', '잠', '자지', '호텔', '방', '확인', '감사', '우리', '매우', '모든', '필수품', '제공', '제공', '아침', '식사', '매우', '준비', '주변', '제주', '시내', '먹거리', '찾기', '스킨로션', '류', '어매니티', '것', '함', '조금', '교통', '골목길', '제', '곳', '별로', '스파', '칫솔', '치약', '세트', '방이', '프런트', '말', '스탠드', '하나', '차이', '화장실', '유리', '벽', '내부', '누군가', '큰일', '날', '뻔', '호텔', '전혀', '외관', '다만', '리', '모델링', '호텔', '것', '흔적', '좀', '조명도', '좀', '공항', '접근성', '하루', '곳', '김포공항', '시', '출발', '비행기', '공항', '곳', '컬리', '넌', '호텔', '숙박', '실제', '공항', '번', '번', '버스', '타고', '분', '정도', '곳', '호텔', '약', '분', '정도', '도착', '예약', '방', '무료', '업그레이드', '더', '이용', '이용', '비즈니스', '호텔', '제일', '것', '샴푸', '바디', '클렌', '저', '생수', '병', '드라이기', '구비', '욕조', '욕', '푹', '가격', '대도', '소셜', '및', '각종', '루트', '통해', '예약', '박', '저렴', '하겐', '만원', '대도', '것', '다음', '제주도', '다시', '이용', '예정', '정원', '바다', '사진', '때문', '를', '선택', '이건', '정말', '보기', '내', '때', '세', '이상', '한국', '젊은이', '거주', '때문', '실제', '패', '장소', '시설', '공용', '구역', '기숙사', '사이', '청각', '적분', '리가', '모든', '사람', '때', '중간', '것', '것', '또한', '원래', '개인', '주택', '므', '욕실', '수', '위치', '현재', '용량', '최적화', '팁', '더블', '집', '선라이즈', '포인트', '근처', '정말', '소유자', '서핑', '클래스', '참가', '다른', '방법', '제주', '제주', '바다', '볼', '수', '곳', '찾기', '위해', '나', '검색', '나', '숙소', '데', '익숙', '여기', '것', '호스트', '매우', '환영', '분위기', '매우', '뒤', '내', '저녁', '식사', '참여', '수', '대부분', '밤', '박', '동안', '여기', '그것', '처음', '아라', '방문', '때', '집', '주인', '언덕', '저택', '두', '팀', '스테이', '제주도', '경치', '주인', '와인', '교수', '영어', '프랑스어', '그', '그', '집', '문제', '삼성', '냉장고', '새', '파워', '에어콘', '매우', '세탁기', '케이블', '채널', '슈퍼', '화장실', '환상', '산', '의', '매우', '침대', '소파', '침대', '제주', '시청', '버스', '정류장', '곳', '제주도', '곳', '로', '이동', '수', '방법', '에어', '버스', '어', '월령항', '바로', '앞', '펜션', '방도', '침대', '쉬', '가요', '주인', '아주머니', '기분', '놀수', '풀', '자쿠지', '인테리어', '종업원', '주변', '풍력', '발전기', '다이지', '저희', '친구', '봄', '생각', '이상', '시설', '바다', '경치', '리조트', '정말', '이뻣다', '나중', '시간', '다시', '한번', '추억', '바다', '전망', '무엇', '환상', '제주시', '라마', '프라자', '호텔', '한눈', '비즈니스', '이용', '객실', '관리', '다음', '가족', '다시', '무엇', '직원', '인상', '사진', '직원', '별로', '무뜩뚝', '편이', '비행기', '소음', '감안', '분실물', '우편', '달라', '우편', '비', '세금', '문제', '등등', '별로', '전반', '우리', '공항', '더', '여행', '끝내기', '위해', '호텔', '어제', '도착', '그것', '분', '버스', '버스', '아마', '택시', '가족', '위', '장소', '매우', '우리', '가족', '방', '우리', '개', '싱글', '침대', '개', '방', '개', '이중', '개', '방', '개', '욕실', '식당', '라운지', '부엌', '것', '바로', '가족', '것', '우리', '해변', '도보', '택시', '분', '시간', '우리', '해변', '매우', '객실', '스파', '피로', '풀기', '호텔', '리조트', '객실', '안', '취사', '객실', '바로', '앞', '해변', '가가', '도보', '분거', '리도', '채', '해안', '도로', '객실', '내', '바다', '볼', '수', '한라산', '등산', '때', '왕복', '셔틀', '이용', '등산', '스틱', '점심', '도시락', '미리', '주문', '프런트', '직원', '등산', '때', '조식', '한식', '등산', '때', '여기', '해', '근처', '위치', '해변', '이', '호텔', '이동', '수', '차', '아주', '주변', '환경', '평화', '수', '이', '호텔', '아침', '식사', '제공', '빵', '계란', '계란', '요리', '직접', '스타일', '것', '셀프', '서비스', '다리', '뷰', '보고', '호텔', '모텔', '펜션', '얼마', '걸', '화장실', '청소', '상태', '별로', '문', '물질', '거', '후회', '가격', '대비', '더', '곳', '지은지', '얼마', '저녁', '미리', '주위', '편의점', '가격', '호텔', '호텔', '객실', '세명', '더블베드', '하나', '싱글', '베드', '하나', '가구', '심플', '촐', '모자라', '화장실', '욕조', '편임', '난방', '개별', '온도', '수', '월', '겨울', '밤', '수', '방이', '약간', '시간', '체크', '하자', '마자', '온도', '것', '추천', '이불', '두툼', '솜', '이불', '좀', '무지', '층', '야외', '풀이', '내', '방문', '시', '인지', '비닐', '덮어놓고', '폐쇄', '좀', '아쉬움', '조식', '부', '폐식', '만원', '좀', '가격', '음식', '맛', '종류', '렌터카', '운전', '위치', '애월', '다시', '거', '곳', '택', '이유', '객', '실내', '스파', '동물원', '때문', '스파', '시설', '동물원', '말', '돼지', '앵무새', '토끼', '등', '동물', '애', '내내', '밖', '동물', '돼지', '그냥', '마당', '막', '마트', '차', '동물', '스파', '모든', '불편', '해소', '아침', '포함', '한식', '토스트', '근처', '갈수', '마트', '아침', '커텐', '보시', '깜짝', '광경', '해변', '주차공간', '호텔', '옆', '건너편', '주차', '다방', '주인', '아저씨', '것', '것', '안내', '앞', '바다', '훤히', '보이', '곳', '장점', '공항', '및', '및', '맥도널드', '근처', '분', '비교', '단점', '대략', '방', '명', '매우', '아침', '식사', '매우', '변경', '음식', '대부분', '매일', '반복', '방', '주전자', '가물', '피치', '전혀', '수', '급', '호텔', '체크', '때', '나', '모든', '모서리', '이웃', '국가', '투어', '관광객', '공공장소', '정렬', '수', '그', '자정', '중간', '밤', '프론트', '데스크', '직원', '프론트', '데스크', '단지', '한국어', '구사', '프론트', '데스크', '직원', '매우', '제목', '이름', '호텔', '내부', '시설', '모텔', '그다지', '공항', '도보', '약', '분', '정도', '거리', '접근성', '침대', '매트리스', '아주', '보이', '누울', '때', '생각', '숙소', '선택', '곳임', '박', '만원', '선택', '방', '아주', '욕조', '가가', '조식', '포함', '조식', '아메리칸', '스타일', '주인', '직접', '줌', '방', '매우', '리', '모델링', '매우', '단', '숙소', '길이', '골목', '리조트', '겉', '모양', '매우', '첫인상', '매우', '수', '매일', '욕조', '몸', '바다', '수', '가격', '고려', '선택', '판단', '제주', '조이', '랜드', '약', '개', '분리', '목조', '층', '주택', '구성', '부엌', '식당', '시설', '한국', '독립', '아파트', '바다', '언덕', '위', '부분', '위치', '제주', '서부', '자동차', '약', '분', '거리', '경내', '과일', '나무', '회의실', '컨퍼런스', '시설', '한국인', '인기', '것', '대형', '슈퍼마켓', '제주도', '주변', '주요', '도로', '약', '소나무', '통나무', '침실', '층', '거실', '층', '주방', '스토브', '싱크대', '및', '냉장고', '직원', '영어', '수', '도움', '위치', '모든', '버스', '출발', '버스', '정류장', '공항', '버스', '여기', '멈', '이', '모텔', '가족', '운영', '사업', '직원', '보너스', '인', '영어', '말', '수', '그것', '돈', '위해', '아주', '가치', '현지', '레스토랑', '미니', '마트', '근처', '이', '호텔', '약간', '날짜', '일부', '객실', '개조', '것', '우리', '박', '동안', '거기', '우리', '주', '집', '방', '이', '방과', '보관', '부엌', '매우', '를', '사용', '집', '찾기', '한국', '모든', '것', '마찬가지', '커뮤니케이션', '어려움', '예', '우리', '방', '히터', '모든', '지시', '사항', '한국어', '주인', '사용', '방법', '설명', '전반', '곳', '추천', '합', '다방', '위치', '매력', '리셉션', '건물', '개략', '인', '것', '보이', '대적', '인', '개조', '직원', '영어', '의사', '소통', '매우', '주차', '공간', '제공', '공용', '주차', '공간', '사용', '이', '호텔', '풍력', '터빈', '전망', '해변', '근처', '위치', '장점', '도움', '소유자', '모든', '것', '단점', '게스트', '하우스', '도로', '입구', '나머지', '제주도', '방문', '여러', '호텔', '펜션등', '이용', '한가지', '아쉬움', '시설', '문제', '느낌', '수', '곳', '주인', '숙소', '여행객', '편안함', '주어', '여행', '여유', '수', '해', '준', '다세', '해변', '근처', '위치', '와락', '게스트하우스', '주말', '화', '여', '프리', '마켓', '구경', '날', '해변', '가가', '바로', '옆', '게스트하우스', '내', '잔디밭', '야외', '정원', '바람', '사장', '다락방', '층', '만화책', '오락', '기', '혼자', '여행', '다른', '여행객', '수다', '수', '위치', '시내', '공항', '근처', '해변', '약', '객실', '부엌', '제공', '방', '매일', '청소', '국제', '기준', '준비', '수건', '손수건', '것', '간주', '식료품', '가게', '시내', '분', '거리', '세계', '마트', '식사', '위', '메뉴', '인접', '레스토랑', '요리', '호텔', '식사', '제공', '및', '제공', '수', '선택', '메뉴', '호텔', '주인', '주문', '데', '도움', '스테이', '징', '것', '비행기', '이륙', '소리', '볼', '수', '우리', '숙박', '감소', '공항', '밤', '아침', '일어나서', '매일', '아침', '귀', '새', '수탉', '울음', '빨강', '해변', '향', '볼', '말', '모양', '등대', '여성', '집', '보기', '해변', '수', '사람', '개', '산책', '조깅', '건조', '시', '야채', '야영', '검토', '마을', '향', '일', '여성', '저', '산', '봉', '조감도', '의', '제주시', '공항', '바다새', '호텔', '현대', '장비', '룸', '사이즈', '발코니', '바다', '볼', '수', '제공', '수건', '매우', '작고', '손수건', '아침', '식사', '포함', '레스토랑', '호텔', '근처', '수', '꽤', '태국', '음식', '맛', '태국', '음식', '에이', '가격표', '나', '이번', '매우', '표준', '하나', '나', '얼마나', '때', '객실', '것', '시설', '욕실', '샤워', '기', '및', '욕조', '아래층', '커피숍', '가격', '대비', '이벤트', '호텔', '최악', '물', '응대', '형편', '대한', '사과', '객실', '빨대', '찌꺼기', '그냥', '만원', '호텔', '갈껄', '돈', '목말', '냉장고', '종이컵', '공항', '밤', '도착', '오전', '일찍', '출발', '시', '비행기', '이륙', '아이', '잠깐', '공항', '근처', '호텔', '실내', '수영장', '커피숍', '마사지', '리조트', '객실', '모텔', '정도', '규모', '시설', '년', '신설', '곳', '시설', '저희', '때', '오픈', '이벤트', '건', '모든', '숙박', '객', '계속', '서비스', '제공', '시간', '정도', '안마', '의자', '이용', '족욕', '서비스', '수영장', '정도', '규모', '저희', '전날', '밤', '렌트카', '반납', '곳', '태풍', '비행기', '딜', '레이', '때', '공항', '근처', '일정', '조정', '호텔', '방과', '욕실', '자동차', '호텔', '로비', '약간', '겨울', '식당', '문', '미리', '예약', '생각', '금릉', '항', '협재', '해수욕장', '호텔', '여행자', '위', '더', '식당', '카페', '더', '것', '서비스', '매우', '호텔', '난방', '매우', '저', '호텔', '숙소', '다소', '노후', '천장', '등', '전체', '방이', '관리', '부분', '보', '화장실', '타일', '사이', '곰팡이', '슬', '점', '층', '엘레베이터', '점', '짐', '커플', '부분', '좀', '근처', '편의점', '편의점', '간식', '꼭', '사서', '기대', '이하', '고간', '곳', '프라이', '베이트', '풀', '빌라', '비', '수기', '만원', '기본', '룸', '예약', '엘베', '층', '기본', '방과', '층', '루프', '트탑', '수영', '위치', '박동', '안', '수영', '일단', '이', '호텔', '예약', '이유', '굳이', '풀', '빌라', '루프', '탑', '풀', '이용', '수', '장점', '때문', '예약', '저녁', '중', '이용', '시간', '대해', '리셉션', '전화', '청소', '정보', '며', '직원', '총지배인', '여직원', '말투', '소셜', '구매', '손님', '이란', '표현', '정말', '억', '순간', '호텔', '어플', '및', '포털', '사이트', '공개', '정보라', '루프', '탑', '수풀', '이용', '말', '정보', '며', '마치', '얘기', '직원', '태도', '당황', '호텔', '로비', '리플렛', '루프', '탑', '사계절', '수풀', '영화', '상영', '요즘', '손님', '선택', '얼마나', '정보', '진행', '전혀', '이해', '듯', '상황', '직접', '제', '정보', '인지', '증명', '위해', '동영상', '첨부', '일', '손님', '제', '나중', '서비스', '라며', '병', '맥주', '병', '풀', '빌라', '이용', '나머지', '호텔', '리셉션', '층', '룸', '가격', '대비', '정말', '별로', '나중', '명', '여기', '풀', '빌라', '직원', '때문', '절대', '이용', '제주', '공항', '택시', '타고', '분', '정도', '소요', '택시', '기사', '주소', '비', '감', '외관', '내부', '로얄', '호텔', '가격', '대비', '공항', '시내', '셔틀', '이동', '골프장', '사우나', '무료', '이용', '식당', '음식', '별로', '매점', '밤', '피자', '수', '것', '룸', '욕실', '상탲', '여행객', '수', '수영장', '입퇴', '실시간', '입', '실시', '퇴실', '다소', '것', '보통', '숙소', '가족', '끼리', '가야', '곳', '공항', '도착', '시간', '때문', '공항', '인근', '바다', '곳', '숙소', '곳', '일반', '제주', '도미', '토리', '인', '숙박', '가격', '곳', '개인실', '잡', '수', '체크', '가능', '주인', '근처', '편의점', '식당', '직원', '숙박', '그', '거의', '영어', '말', '수', '그', '인터넷', '접속', '덕택', '우리', '를', '통', '대화', '수', '위치', '공항', '근처', '객실', '그', '무료', '아침', '식사', '제공', '가장', '레스토랑', '카페', '분', '이상', '가야', '호텔', '사람', '위', '제주도', '여행', '누가', '적', '곳', '묵', '수', '밤', '방', '자체', '이틀', '동안', '잠', '푹', '자지', '장점', '무료', '주차장', '호텔', '외부', '객실', '에어컨', '호텔', '때문', '잠', '단점', '청결', '개선', '침대', '얼룩', '서피스', '그', '영어', '우리', '것', '우리', '동안', '더욱', '경우', '질문', '찾기', '이유', '이', '호텔', '위치', '구글', '맵', '차', '렌트', '찾기', '우리', '사람', '캐리어', '지적', '사람', '전체', '이', '호텔', '곳', '제주', '가격', '럭셔리', '다른', '곳', '것', '위치', '공항', '우리', '도착', '이', '호텔', '합리', '가격', '나중', '건', '다음', '날', '아침', '매우', '호텔', '북부', '관광명소', '길', '머리', '바위', '해산물', '벨트', '용', '직원', '영어', '나', '볼', '수', '그', '약간', '손상', '전원', '어댑터', '하나', '작동', '것', '금속', '이', '기', '때문', '선택', '경우', '중', '하나', '방', '편이', '전체', '일부', '테이블', '서피스', '및', '머리', '전체', '허용', '우린', '잠', '제주', '항구', '옆', '지역', '게스트', '하우스', '주인', '매우', '도움', '우리', '제', '의', '마루', '방', '가지', '그것', '아주', '그것', '분', '다음', '음식점', '가기', '합리', '방', '그', '곳', '것', '태풍', '겨우', '첵', '방', '주시', '우리', '요구', '아침식사', '척척', '제공', '곳', '평', '대리', '간다', '곳', '비', '수기', '더더', '것', '하늘', '시간', '밥', '맛', '집밥', '메뉴', '인테리어', '청소', '상태', '모두', '양호', '애월', '바닷가', '다소', '렌트카', '이동', '곳', '공항', '도착', '애월쪽', '숙소', '숙소', '무엇', '가격', '일본', '비즈니스', '호텔', '곳도', '객실', '수하물', '여', '공간', '휴식', '곳', '라면', '곳', '당신', '위', '곳', '호텔', '약시', '지정', '주소', '사용', '지도', '사이트', '사용', '를', '사용', '위치', '파악', '절반', '정도', '버스', '정류장', '도보', '몇', '분', '메인', '스트리트', '그것', '버스', '터미널', '도보', '약', '분', '내', '호텔', '예약', '때', '나', '단지', '명', '침대', '남성', '용', '기숙사', '말', '나', '그것', '숙소', '무엇', '다라', '생각', '그것', '의미', '것', '당신', '방', '커플', '수', '생각', '단지', '성의', '사람', '방', '수', '호텔', '현대', '객실', '겨울철', '난방', '제공', '나', '불만', '짐', '열', '수', '공간', '것', '나', '다른', '비즈니스', '호텔', '도쿄', '비즈니스', '호텔', '거의', '나', '방', '다소', '매우', '호텔', '영화관', '및', '레스토랑', '구역', '도보', '약', '분', '거리', '거기', '레스토랑', '대부분', '내', '개', '레스토랑', '양식', '음식', '제외', '영국', '메뉴', '가지', '그것', '버스', '터미널', '공항', '때문', '수', '곳', '그것', '약', '원', '밤', '나', '다시', '장소', '나', '친구', '추천', '우리', '주인', '이', '공항', '우리', '오기', '장소', '다른', '침실', '식당', '부엌', '방문객', '위', '거실', '집', '주인', '서울', '방문', '때문', '우리', '박', '동안', '여기', '지난', '밤', '홀로', '쇼핑', '거리', '단', '몇', '걸음', '거리', '방', '파울', '인근', '상점', '때문', '호스텔', '위치', '제주시', '고급', '위치', '곳', '적극', '추천', '곳', '바로', '옆', '쇼핑', '거리', '또한', '공항', '근처', '게스트', '하우스', '적', '베스트', '우리', '예약', '더', '블룸', '통해', '호텔', '우리', '도착', '때', '주인', '말', '게스트', '하우스', '그녀', '전화번호', '예약', '사실', '간', '그녀', '걱정', '그녀', '그녀', '문제', '우리', '호텔', '사이', '그녀', '그녀', '사무실', '예약', '취소', '및', '환불', '해', '것', '수', '하자', '그녀', '다시', '그', '돈', '다시', '생각', '것', '환불', '거부', '하자', '이', '호텔', '예약', '처음', '마지막', '주인', '우리', '다른', '호텔', '모두', '예약', '주말', '사용', '마을', '비젼', '게스트', '하우스', '호스트', '수', '느낌', '우선', '공항', '픽업', '드롭', '오프', '일', '때', '또한', '계획', '우리', '하루', '여행', '제주도', '가장', '점', '위치', '하우스', '돼지고기', '바로', '옆', '약', '너', '처럼', '레스토랑', '전부', '물건', '팔고', '제', '실망', '네', '책', '비록', '그', '나', '더', '방', '예약', '경우', '장치', '그', '시간', '동안', '안', '나', '그냥', '변경', '수', '인테리어', '조금', '심지어', '곳', '민박', '호텔', '그냥', '빵', '토스트', '잼', '버터', '자신', '위해', '커피', '오렌지', '주스', '그녀', '그녀', '곧', '내년', '일부', '내부', '혁신', '저', '저', '우선', '서비스', '심지어', '좀', '실망', '것', '우리', '여행', '상상', '수', '나머지', '전체', '일', '아주', '사람', '이틀', '밤', '동안', '대부분', '실속', '문', '우리', '다시', '돼지', '바비큐', '우리', '모습', '이', '이후', '그', '약', '플러스', '곧바로', '그녀', '곳', '었다', '기도', '우리', '감동', '배려', '제주도', '위치', '호텔', '시티', '센터', '위치', '수산', '시장', '버스', '정류장', '도보', '거리', '호텔', '짐', '수', '두', '개', '중간', '크기', '시간', '식당', '층', '지금', '찾기', '숙박시설', '제주도', '몇', '가지', '후기', '아고다', '통해', '예약', '후', '일부', '지원', '정말', '경험', '예약', '취소', '이윽고', '우리', '이', '호텔', '곳', '지역', '즉', '바다', '호텔', '아주', '인기', '중국', '여행', '또한', '게스트', '하우스', '바로', '호텔', '우리', '게스트', '하우스', '방지', '투어', '또한', '새', '우리', '방', '아주', '우리', '조식', '불', '포함', '지급', '위치', '룸', '컨디션', '별로', '구석구석', '먼지', '리뷰', '보고', '이용', '사진', '다른', '룸', '매우', '습', '디', '직원', '사무', '별로', '습', '디', '다시', '이용', '일', '듯', '곽', '해수욕장', '바로', '앞', '뷰', '정말', '편의점', '맛집', '등', '여행', '곳', '층', '로비', '오픈', '공간', '바다', '맥주', '한잔', '것', '룸', '재', '방문', '의사', '씨뷰', '호텔', '월초', '바닷가', '앞', '때', '중앙', '난방', '방식', '면서', '난방', '에어컨', '밤', '난방', '불가', '함', '룸', '바닥', '카펫', '청소', '남편', '아이', '계속', '재체기', '박', '콧물', '나기', '시작', '명', '예약', '모든', '애', '티', '수건', '슬리퍼', '칫솔', '등', '명', '준비', '가격', '대비', '인테리어', '숙소', '지어짅', '얼마', '매우', '편', '바닥', '나무', '재질', '색상', '모던', '인테리어', '인상', '호텔', '분', '거리', '바로', '아이', '곽', '해수욕장', '있었느', '태풍', '시즌', '모래바람', '사이', '사진', '한장', '겨우', '룸서비스', '조식', '건너편', '쌀국수', '집', '거기', '만원', '안쪽', '특급', '호텔', '시설', '분', '꽤', '비수', '이용', '곽', '과물', '해변', '조금', '해변', '식당', '다만', '내부', '정돈', '느낌', '청결', '신경', '더', '것', '위치', '규모', '호텔', '별로', '애월', '비교', '규모', '호텔', '로서', '푸른', '바다', '바로', '앞', '저녁', '석양', '무렵', '직원', '직원', '편입', '니', '룸', '바다', '전망', '욕실', '방', '전체', '비릿', '냄새', '나', '단점', '조식', '전체', '가성', '비', '기타', '바다', '눈', '보이', '사시', '사철', '수영', '루프', '탑', '수영장', '아주', '다시', '가격', '할인', '가도', '밤', '디제이', '모로', '수준', '그닥', '실내', '환기', '팬', '및', '에어컨', '소음', '침대', '객실', '외부', '유리창', '사이', '스파', '객실', '이', '스파', '위쪽', '상시', '작동', '팬', '현관', '룸키', '마스터', '전원', '저속', '작동', '화장실', '팬', '작동', '고속', '작동', '시스템', '일단', '룸', '키', '이', '스파', '위쪽', '팬', '끌', '수', '스위치', '저', '이', '팬', '소음', '수면', '방해', '정도', '매우', '관리직', '환기', '팬', '원선', '분리', '직원', '분', '말씀', '전', '컴', '플레인', '적', '또', '천정', '삼성', '시스템', '에어컨', '설치', '설치', '문제', '종', '문제', '소음', '저', '경우', '밤', '에어컨', '수', '정도', '날씨', '사용', '분', '문제', '수준', '소음', '여름', '투숙', '분', '고민', '듯', '관리', '직원', '분', '에어컨', '소음', '방법', '숙박', '포기', '다른', '호텔', '가신', '고객', '말씀', '객실', '내부', '청결', '및', '하우스', '키핑', '문제', '제', '경우', '객실', '청소', '실제', '담당', '분', '테', '이', '정도', '가격', '호텔', '수준', '응대', '관련', '그', '분과', '대화', '더', '나누기', '프런트', '관련', '컴', '플레인', '프런트', '해결', '려고', '노력', '것', '다만', '호텔', '직원', '서비스', '마인드', '교육', '하우스', '키핑', '제대로', '느낌', '가족', '국적', '분위기', '애월', '호텔', '밑', '여자', '정', '황상', '입금', '지인', '강아지', '데리', '적반하장', '화', '우리', '가족', '한텐', '친절', '저런', '바로', '글', '보시', '가족', '여행', '중', '우리', '관광', '간', '사이', '호텔', '직원', '무단', '허락', '객실', '난입', '온', '방', '우선', '이', '팩트', '이유', '메이드', '청소', '중', '애완', '용품', '것', '우리', '허락', '객실', '내부', '물건', '사진', '몰래', '직원', '단체', '방', '유포', '호텔', '총지배인', '및', '직원', '사실', '확인', '차', '명', '이서', '그것', '확인', '우리', '객실', '무단', '것', '관광', '총지배인', '사람', '우리', '말', '자기', '객실', '직접', '물건', '확인', '벌금', '내', '것', '정말', '말', '정도', '실물', '강아지', '것', '그로', '민원', '것', '하물며', '및', '증거', '추정', '물건', '호텔', '관계자', '명', '무단', '객실', '출입', '가요', '이', '대한민국', '호텔', '수', '일일', '물건', '추정', '컨데', '강아지', '스위트룸', '박', '더', '내', '객실', '뒤', '컴', '플레인', '및', '것', '내', '직원', '우리', '객실', '무단', '출입', '것', '하니', '박치', '돈', '경찰', '객실', '수색', '계속', '확인', '협박', '및', '강압', '말로', '우리', '모욕감', '조성', '그', '누가', '부모님', '가족', '쉬', '공간', '직원', '수색', '동의', '하나요', '혹', '나', '그', '안', '호텔', '규율', '담배', '고기', '흔적', '해도', '그', '누구', '우리', '허락', '우리', '점유', '객실', '나', '그것', '사랑', '것', '나', '제', '의', '체', '그것', '해변', '해변', '레스토랑', '도시', '최고', '나', '거기', '다시', '생각', '바다', '마주', '옆', '면', '주인', '위치', '시설', '및', '경치', '환대', '가장', '그', '가격', '상대', '손님', '층', '건물', '사용', '수', '각', '층', '매우', '독립', '사용', '수', '나', '부부', '가족', '모두', '그것', '권장', '최전선', '바다', '조', '수', '것', '최고', '수', '이틀', '동안', '객실', '인용', '일반', '한국', '호텔', '객실', '객실', '편의', '시설', '작동', '문제', '두', '가지', '점', '욕실', '목욕', '타월', '호텔', '핸드', '타월', '만', '제공', '방', '목욕', '타', '추가', '아침', '식사', '스프레드', '매우', '아침', '식사', '이름', '나', '회교도', '음식', '돼지', '고기', '여부', '결정', '매우', '음식', '이름', '매우', '유용', '것', '위치', '공항', '도심', '근처', '그것', '단지', '호텔', '단체', '여행객', '만', '이용', '수', '호텔', '수면', '전용', '만', '사용', '년', '일', '이틀', '이', '여행사', '예약', '이', '호텔', '선택', '기본', '이', '호텔', '것', '꽤', '주변', '내', '호텔', '외관', '기반', '새', '것', '체크', '인도', '방', '심플', '디자인', '욕실', '면도', '구가', '칫솔', '제외', '방', '편의점', '층', '위치', '프론트', '데스크', '카운터', '기본', '옆', '이', '근처', '것', '아침', '일간', '평균', '전반', '목적', '잠', '수행', '일단', '주변', '유흥주점', '여자', '끼리', '진짜', '또', '환풍', '담배', '냄새', '진짜', '금연', '리뷰', '맛', '예약', '진짜', '담배', '냄새', '상상', '초월', '해', '건물', '공사', '진짜', '대충', '담배', '냄새', '화장실', '겹겹', '저', '진짜', '구역질', '경험', '그냥', '밤', '친구', '정말', '모텔', '용', '여행', '가격', '도', '진짜', '여행', '최악', '경험', '스테이', '호텔', '은', '여관', '호텔', '그', '손님', '위해', '체크', '리셉션', '가지', '객실', '위성', '채널', '시청', '수', '평면', '냉장고', '및', '무료', '전용', '대형', '욕실', '샤워', '시설', '제한', '무료', '세면', '도구', '헤어', '드라이어', '여행자', '위', '기본', '필요성', '지하', '쇼핑', '단지', '거리', '동문', '시장', '불과', '과', '관광', '명소', '도보', '도달', '수', '환전', '정', '파빌리온', '버스', '버스', '정류장', '시내', '관광', '버스', '를', '이용', '수도', '주변', '전혀', '호텔', '옆', '프라이드', '치킨', '맥주', '하우스', '개', '해산물', '레스토랑', '플러스', '호텔', '바로', '편', '미니', '마트', '체적', '나', '개', '날', '체', '재는', '그', '리셉션', '자주', '때문', '직원', '대해', '말', '것', '매일', '방', '청소', '호텔', '공항', '매우', '로비', '개', '서비스', '수하물', '보이', '영어', '의사', '소통', '수', '프론트', '데스크', '접수', '아침', '뷔페', '거의', '매일', '엘리베이터', '객실', '기본', '세면', '도구', '제공', '위치', '대부분', '관광', '사이트', '중심', '나', '다음', '다른', '호텔', '예약', '것', '선호', '공항', '매우', '대로', '변', '곰팡이', '냄새', '창문', '열', '에어컨', '바로', '침대', '위', '직', '방이', '화장실', '문도', '불편', '밤낮', '잠', '자지', '호텔', '방', '확인', '감사', '우리', '매우', '모든', '필수품', '제공', '제공', '아침', '식사', '매우', '공항', '페리', '부두', '버스', '터미널', '분', '분', '거리', '거리', '안', '호텔', '그레이스', '호텔', '꽤', '버스', '정류장', '이름', '그레이스', '호텔', '사용', '주요', '도로', '레오', '호텔', '비교', '발견', '것', '다음', '검색', '호텔', '이름', '잘못', '수', '단지', '그레이스', '레오', '도보', '분', '위치', '대중', '교통', '버스', '레스토랑', '및', '편의점', '도보', '분', '거리', '호텔', '방', '매일', '하우스', '키핑', '수건', '교체', '직원', '소유자', '도움', '근무', '교대', '근무', '직원', '영어', '야간', '직원', '중국어', '그', '중국어', '영어', '모두', '알', '층', '물', '물', '사용', '수', '공기', '컨디션', '및', '온수', '샤워', '상태', '양호', '헤어', '드라이어', '샴푸', '목욕', '젤', '이용', '가능', '목포', '목포', '개', '부두', '음', '유의', '제주', '간다', '것', '것', '온라인', '예약', '페리', '한국', '발급', '신용', '카드', '만', '수락', '한국', '신용', '카드', '다른', '나라', '신용', '카드', '로만', '예약', '페리', '회사', '이슈', '티켓', '은행', '통보', '마침내', '사용', '수', '위치', '매우', '근처', '쇼핑', '센터', '레스토랑', '카지노', '방', '좀', '침대', '주문', '공간', '남아', '거의', '이', '타월', '제공', '수', '또한', '화장실', '매우', '의', '새', '그동안', '컴퓨터', '고장', '안전', '금고', '해', '말', '수', '조건', '때문', '또한', '대부분', '시간', '아무', '누구', '그', '그', '곳', '그녀', '자신', '어쨌든', '전원', '어댑터', '중', '하나', '달라', '그', '판매', '호텔', '중앙', '위치', '버스', '정류장', '아주', '분', '직원', '영어', '구사', '수', '및', '위치', '당신', '구성', '수', '이', '호텔', '거의', '모든', '서비스', '편의점', '클럽', '한국', '바베큐', '과', '세탁', '및', '보행자', '전용', '거리', '다시', '우리', '층', '객실', '과', '하루', '일', '제', '욕실', '작동', '나', '그', '이야기', '국', '이나', '바닥', '바로', '프런트', '데스크', '및', '변경', '수', '아주', '숙박', '시작', '우리', '여행', '렌트카', '제한', '주차', '호텔', '일도', '분거', '리', '체크', '검토', '디셈버', '호텔', '위치', '매우', '음식', '주요', '도로', '근처', '쇼핑', '트리플', '룸', '옷장', '그냥', '당신', '코트', '후크', '이', '호텔', '중', '놈', '연인', '끼리', '제주도', '중문', '통나무', '펜션', '의상', '스튜디오', '로프트', '프런트', '데스크', '음식', '거리', '대환영', '서비스', '지붕', '머리', '호텔', '가치', '저', '가격', '비교', '사이트', '가장', '가격', '걸', '예약', '취소', '가격', '부닷', '잘못', '도리어', '저', '성', '네이버', '다른', '인터넷', '가격', '만원', '이상', '말씀', '취소', '사이트', '얘기', '근처', '가기', '고객', '어디', '사이트', '통해', '정보', '확인', '호텔', '주인', '분', '왜', '저', '화', '내시', '상황', '설명', '이해', '될껄', '고아', '말', '전날', '다른', '카라반', '침대', '히터', '소리', '걱정', '여기', '카라반', '커서', '침실', '거실', '사이', '문', '침실', '양키', '캔들', '등', '등', '밝기', '조절', '제일', '것', '매트', '침대', '정말', '푹', '수', '다른', '일행', '텔레비전', '보고', '부엌', '쪽', '텔레비전', '각자', '거', '수', '샤워실', '작', '온수', '부엌', '후기', '걱정', '여행', '출장', '국내', '및', '해외', '숙박시설', '숙박', '예약', '및', '숙박', '경험', '항상', '업무', '후기', '못', '이번', '내', '생', '최악', '경험', '다른', '여행자', '위', '후기', '꼭', '참고', '첫날', '날', '각각', '경험', '곳', '절대', '이용', '사이트', '반', '및', '반', '로', '구별', '예약', '사진', '내부', '구조', '주방', '일자', '구조', '및', '주방', '디귿', '자형', '구조', '요리', '아내', '상의', '반', '로', '예약', '것', '다른', '숙소', '예약', '것', '낮', '일정', '마치', '저녁', '분경', '숙소', '체크', '안내', '반', '안', '예약', '형', '주방', '아주', '형', '예약', '방과', '사장', '듯', '아주머니', '말', '예약', '대로', '방', '것', '우리', '정', '대로', '것', '라며', '말씀', '사이트', '우리', '예약', '반', '사진', '주방', '자형', '이방', '일자', '우리', '지금', '장', '온', '요리', '하니', '사이트', '딸', '사진', '나', '다른', '사람', '그동안', '불만', '왜', '구', '실랑이', '고장', '온', '해산물', '어차피', '요리', '기분', '시간', '오늘', '그냥', '자고', '은성', '수기', '때', '평', '복층', '우선', '청소', '제대로', '상태', '입실', '실외', '수영장', '역시', '조식', '시', '빵', '느낌', '말', '리조트', '테', '시설', '역시', '모텔', '못', '시설', '주차장', '역시', '협소하', '주차', '시', '문제', '손님', '숙박', '키', '및', '자동차', '키', '마치', '강제', '느낌', '기분', '상', '이제껏', '제주도', '몇번', '이', '모텔', '못', '숙소', '때문', '생각', '월', '마지막', '가족', '힐링', '여행', '번', '여행', '처음', '자유', '여유', '여행', '수', '힐링', '것', '여행', '비', '덕분', '계획', '곳', '모두', '보지', '무엇', '오픈', '한지', '얼마', '물뜰', '펜션', '아이', '우리', '부부', '즐거움', '예정', '에코랜드', '범퍼보트', '날', '관계', '운영', '펜션', '수영장', '수상', '자전거', '투명', '카약', '수', '비용', '절감', '효과', '누리', '감사', '초등', '아이', '동반', '가족', '여행', '라면', '꼭', '제주', '항공', '우주', '박물관', '추천', '함', '장점', '가격', '방', '자연', '단점', '침대', '시트', '이불', '베개', '곰팡이', '냄새', '나', '모기', '등', '벌레', '거미', '등', '크기', '우리', '내', '아내', '방', '세', '번', '버그', '때문', '분', '단지', '내', '방', '네', '방', '벌레', '등', '것', '수', '호스텔', '매니저', '처리', '문제', '듯', '예', '등', '문제', '잘못', '예약', '호스텔', '다시', '수', '뷰', '수', '호스텔', '사람', '위', '별도', '개인', '정보', '보호', '휴가', '중', '우리', '동안', '우리', '방', '구', '수', '벽', '벽', '등반', '은', '우리', '방', '저', '수', '직원', '매우', '도움', '예', '투어', '위해', '수', '방법', '대한', '도움말', '그', '버스', '정류장', '정말', '치료', '해', '손님', '준비', '제주', '다시', '가게', '저', '이', '호텔', '두', '번', '다시', '생각', '가격', '곳', '이기', '때문', '말', '표', '중', '말레이시아', '정말', '가격', '이', '호텔', '예약', '다른', '여행', '사이트', '위치', '여행자', '아주', '방이', '장점', '라면', '주인', '매우', '협조', '수', '단점', '택시', '타고', '분', '시내', '멀리', '때', '밤', '시내', '수', '구매', '참나', '멀리', '버스', '정류장', '주인', '우리', '드라이브', '버스', '정류장', '택시', '타고', '시내', '비용', '택시', '기사', '호텔', '수', '탐색', '호출', '소유자', '방향', '이', '의사', '교환', '영어', '이해', '매우', '수', '입자', '호텔', '이웃', '이나', '소주', '주인', '냄새', '나', '저', '오히려', '더', '가격', '대비', '그냥', '방', '트레이드', '호텔', '느낌', '버스', '역', '길', '건너', '오름', '단면', '볼', '수', '버스', '정류장', '길', '후', '짐', '추천', '것', '그냥', '수', '약', '이', '호텔', '오렌지', '왼쪽', '벽', '때', '주인', '영어', '매우', '도움', '그', '그', '우리', '기본', '요구', '수', '패스트', '푸드', '등', '이', '곳', '모든', '것', '최고', '더', '나은', '서비스', '시설', '것', '내야', '기숙사', '방', '볼', '수', '싱글', '침대', '의', '층', '침대', '싱글', '침대', '방', '반면', '친구', '저', '점유', '공간', '그냥', '우리', '두', '딸', '모든', '것', '수', '방', '평면', '개인', '욕실', '미니', '냉장고', '헤어', '드라이기', '저', '정말', '이', '평화', '분위기', '월', '월', '것', '호텔', '근처', '하이킹', '거문도', '미리', '예약', '또', '다른', '가장', '점', '버스', '정류장', '바로', '앞', '버스', '하루', '몇', '번', '또한', '저', '그', '분', '사람', '제안', '그룹', '친구', '더욱', '시간', '이', '곳도', '것', '생각', '곳', '박', '이', '투어', '예약', '예약', '수', '체크', '두', '명', '당', '번', '하나', '키', '할당', '공유', '수', '변경', '다른', '사용자', '이', '허용', '입구', '방', '얼마나', '비', '첫인상', '었습니', '바닥', '난방', '것', '이', '헤어', '드라이어', '냉장고', '전기', '모두', '사용', '수', '전선', '엉망', '어디', '서나', '아침', '식사', '최악', '차', '커피', '이', '수건', '가지', '그', '오직', '손', '수건', '목욕', '수건', '제공', '수', '사진', '내부', '좀', '편이', '입구', '당나귀', '토끼', '개', '닭', '동물', '분', '거', '화장실', '욕조', '온수', '제한', '공용', '실', '워', '게', '거', '이야기', '밤', '어디', '보이지', '다른', '건', '내부', '나무', '냄새', '나', '거', '침대', '아주', '잠', '수', '매트릭스', '거의', '안', '보심', '이', '호텔', '상대', '곳', '세', '밤', '시부', '터', '밤', '가족', '룸', '밤', '세부', '사항', '실망', '체크', '때', '목욕', '수건', '때문', '프런트', '수거', '수건', '그', '컵', '주전자', '가지', '티백', '커피', '제공', '최악', '부분', '침대', '시트', '곰', '나', '냄새', '때문', '마지막', '체크', '아웃', '후', '세탁', '체크', '아웃', '나', '모든', '것', '인지', '나', '그', '여성', '냄새', '나', '침대', '시트', '대해', '이야기', '그녀', '대답', '다방', '냄새', '침구', '침대', '시트', '곰팡이', '개', '침대', '하나', '포기', '수', '곳', '외국인', '잠', '국가', '망신', '생각', '방', '주말', '방이', '돈', '포기', '다른', '숙박', '업체', '물', '느낌', '꼭', '다른', '곳', '가세', '제주', '시내', '호텔', '주차장', '조금', '이용', '문제', '시설', '조금', '낙후', '가격', '저희', '문제', '하루', '밤', '인생', '최악', '호텔', '호텔', '말', '우리', '일행', '중', '명', '분도', '피부', '이상', '증상', '가려움', '반점', '동반', '호소', '내', '객실', '비치', '요', '세트', '모두', '정체', '크기', '얼룩', '돈', '간다', '말리', '호텔', '숙박', '포기', '다른', '호텔', '길', '초등학생', '가족', '초등학생', '학년', '정도', '아이', '엄마', '여기', '말함', '격하', '공감', '어른', '유리', '공포', '체험', '침대', '위치', '조금', '응급실', '뻔', '위치', '것', '공항', '움', '점', '전혀', '로비', '관리', '매우', '리셉션', '온돌방', '침대', '시트', '보이지', '욕실', '결코', '재', '방문', '의사', '우리', '제주', '여행', '때', '우리', '몇', '밤', '여기', '우리', '렌트카', '탐색', '장치', '찾기', '매우', '공항', '약', '분', '우리', '아파트', '발코니', '바다', '거실', '주방', '기본', '요리', '도구', '아파트', '지시', '사항', '영어', '모든', '고문', '밖', '동시', '발코니', '문', '개', '것', '대한', '번역', '앱', '사용', '또한', '아파트', '거실', '패널', '장소', '조명', '제어', '리모콘', '셀프', '세탁', '시설', '공항', '것', '차로', '분', '거리', '시간', '코인', '세탁소', '제주', '때', '가치', '기반', '므', '다시', '예약', '방', '나', '그', '지역', '새', '개발', '생각', '그것', '매우', '바다', '발코니', '전망', '수', '직원', '별로', '우리', '에어', '컨디셔너', '문제', '관해', '그', '말', '우리', '통제', '이해', '수', '다음', '날', '그', '우리', '제어판', '더', '광고', '영어', '녹음', '우리', '공항', '오전', '시', '택시', '요청', '비록', '문제', '직원', '우리', '위해', '또', '다른', '택시', '우리', '택시', '확신', '우리', '그', '대화', '나누기', '그', '아주', '사람', '다음', '번', '거기', '것', '공항', '분', '거리', '교통', '정체', '달러', '때문', '매우', '합리', '요금', '대부분', '직원', '정말', '말', '서비스', '제공', '직원', '차량', '가지', '박', '숙박', '낮', '업무', '처리', '장소', '차', '방치', '차량', '차량', '스티커', '보고', '회사', '전화', '차량', '방치', '말함', '출장', '복귀', '후', '제주도', '쉣', '심지어', '차', '연락처', '체크', '시', '차량', '번호', '기입', '회사', '내', '연락처', '호텔', '객실', '차량', '방치', '연락처', '알', '마치', '짓', '것', '처럼', '객실', '프론트', '호텔', '시스템', '부재', '자기', '일이', '자기', '큰소리', '침', '거참', '나', '호텔', '밥', '년', '호텔', '경영학', '박사', '데', '가차', '그냥', '키', '주변', '편의점', '분', '정도', '로비', '슈퍼', '함', '차량', '공항', '항공기', '이착륙', '소리', '룸', '컨디션', '침대', '허리', '아픔', '조식', '포함', '토스트', '정도', '생각', '이면', '시설', '대해', '가격', '대비', '결정', '부분', '나름', '씨뷰', '가성', '저', '직원', '나름', '호텔', '임', '나머지', '직원', '모두', '사장', '아들', '이면', '그거', '제발', '교육', '짜르', '심', '회사', '발전', '도움', '듯', '조식', '준', '이유', '공항', '바로', '앞', '진짜', '렌트', '좀', '대중교통', '접근성', '요조', '진짜', '직원', '친절', '숙소', '청결', '우수', '뷰', '아주', '숙박', '시설', '공항', '또한', '조식', '단체', '때문', '나름', '조식', '가격', '비', '뜻', '친절', '별로', '밑', '슈퍼', '룸', '컨디션', '별로', '바닥', '얼룩', '냄새', '화장실', '청소', '건', '안', '변기', '머리카락', '그대로', '기분', '오션', '뷰', '쪽', '비행기', '소음', '진짜', '신경', '온돌방', '원', '예약', '예약', '자마자', '취소', '하니', '취소', '수수료', '방', '시설', '기대', '이하', '구류', '별로', '여서', '잠자리', '가격', '대비', '별로', '공항', '나머진', '별로', '저', '가격', '요', '가', '그것', '해안', '옆', '재산', '나', '항상', '파도', '소리', '주변', '몇', '가지', '상점', '내', '경험', '이', '호텔', '버스', '정류장', '약', '분', '거리', '제주', '국제', '공항', '심지어', '최', '재해', '해변', '향합', '니', '초등학교', '버스', '정류장', '도보', '약', '분', '도보', '분', '거리', '인', '대형', '슈퍼마켓', '이', '호텔', '애월', '해안', '도로', '직원', '영어', '말', '버스', '식당', '어디', '수', '대한', '몇', '가지', '질문', '도', '나', '또한', '매일', '무료', '물병', '수건', '교체', '호텔', '제주도', '해안', '전망', '호텔', '사람', '추천', '것', '더블', '하나', '싱글', '하나', '베드', '방', '뷰', '그냥', '만원', '박', '관광지', '요금', '차', '그냥', '화근', '침대', '불편', '침구', '베개', '이불', '수건', '냄새', '겉보기', '남편', '난리', '숙소', '란', '방이', '모두', '충족', '친구', '추천', '엄마', '동생', '가족', '모두', '여행', '창밖', '바로', '바다', '동안', '재주', '수압', '너', '무', '여독', '침대', '개', '찍', '방이', '전혀', '가격', '정도', '조건', '조식', '힐', '파크', '제주', '도심', '복판', '근처', '면세점', '근처', '맛집', '등', '가기', '호의', '인', '한국인', '가족', '소유', '호텔', '뉴타운', '매우', '위치', '무료', '식수', '무료', '와이파이', '액세스', '엘리베이터', '마이너스', '더블', '침대', '싱글', '침대', '구비', '및', '그', '이하', '공간', '수', '수하물', '보관', '소가', '일', '밤', '하이트', '호텔', '리셉션', '직원', '영어', '이', '호텔', '시청', '근처', '레스토랑', '위치', '공항', '움', '버스', '번호', '여기', '우리', '방', '아침', '식사', '김치', '쌀', '빵', '것', '수', '수', '이', '가격', '이면', '여행자', '경우', '이', '날', '수도', '와이파이', '제', '마음', '화장실', '냄새', '나', '이', '호텔', '박', '수', '저', '저', '사람', '제외', '모두', '볼', '수', '리셉션', '도로', '옆', '정말', '향', '잡음', '방', '욕실', '데', '최대', '분', '전', '때', '사람', '바디', '워시', '비누', '바디', '로션', '사용', '수', '병', '반', '빈', '시장', '수', '아주', '곳', '위치', '사용', '수', '호텔', '조식', '공항', '도착', '주위', '유흥', '시설', '무료', '조식', '렌트카', '분', '뚜벅', '여행자', '호텔', '버스', '동시', '환승', '필수', '버스', '배차', '간격', '청결', '상태', '이불', '바닥', '머리카락', '그닥', '가격', '여관', '수준', '방도', '방음', '낭', '모텔', '주인', '분', '시설', '아주', '신식', '청결', '도', '호텔', '침구', '방', '구석구석', '신경', '것', '흔적', '와이파이', '무료', '공항', '주차', '공간', '아주', '빠듯하', '맛집', '동도', '카페', '어머니', '빵집', '등', '다음', '날', '아침', '사', '더욱', '가격', '투숙', '역시', '비지', '떡', '요', '방음', '객실', '다음', '다시', '투숙', '것', '대해', '생각', '중국인', '개별', '여행', '길', '제', '묵고', '디셈버', '호텔', '버스', '타고', '호텔', '신화', '거리', '국수', '직선', '길', '호텔', '객실', '편이', '주인', '방', '침대', '욕실', '깨끗', '냉장고', '뭐', '단', '냉장고', '소음', '때', '좀', '폭설', '비행', '가가', '결항', '때', '곳', '알', '호텔', '직원', '분', '매우', '침대', '화장실', '등', '친구', '이용', '옛날', '모텔', '개조', '듯', '점', '중국인', '단체', '숙박', '장소라', '런가', '조식', '포함', '위치', '공항', '근처', '직원', '매우', '무엇', '가성', '비', '매우', '원', '더', '블룸', '생각', '조식', '아주', '자전거', '대여', '노래방', '이용', '노래방', '시간', '천원', '로', '기억', '로비', '놀', '거리', '위치', '터', '공항', '이동', '매우', '보안', '매우', '조식', '매우', '시외버스', '터미널', '정거장', '거리', '위치', '근처', '약국', '병원', '까페', '편의점', '외관', '및', '내부', '시설', '실내', '엘리베이터', '설치', '전', '층', '도미', '토리', '박', '일', '방', '안', '화장실', '두', '개', '수영장', '이용', '공항', '택시', '이용', '시', '료', '원정', '추가', '거리', '숙소', '아래', '편의점', '근처', '분', '거리', '맥도날드', '방', '스텐다드트윈', '베드룸', '숙박', '룸', '컨디션', '다만', '취침', '후', '새벽', '화장실', '사용', '시', '하수', '구', '냄새', '다소', '아침', '조식', '정말', '전복죽', '퀄', '제주', '식주', '호텔', '군데', '이용', '퀄', '수영장', '호텔', '이용권', '이용', '좀', '은감', '침대', '곳', '좀', '침대', '편이', '욕실', '편', '면도', '구도', '구비', '수압', '세지', '편', '실내', '편', '월', '런가', '에어컨', '안', '지하', '주차공간', '층', '외부', '공간', '다행', '객실', '직원', '인상', '호텔', '택시', '타고', '맛집', '즐비', '해', '공항', '위치', '굿임', '재', '방문', '의사', '공항', '도착', '때', '숙박', '호텔', '공항', '택시', '타고', '분', '정도', '스탠다드', '타입', '숙박', '생각', '가장', '침대', '킹', '사이즈', '정도', '듯', '룸', '컨디션', '시설', '만족', '제주', '출장', '자주', '편', '그동안', '숙박', '곳', '곳', '발견', '곳', '주변', '잠깐', '한잔', '곳도', '일단', '공항', '직원', '조식', '기대', '정말', '출장', '때', '고민', '안', '엠버', '투숙', '예정', '출장', '공항', '주변', '호텔', '검색', '투숙', '호텔', '요', '번화가', '보행', '거리', '식당', '음식', '객', '실내', '커피', '머싱', '이용', '아이', '요구', '햇던', '사항', '무엇', '방음', '잘됏', '잇엇습니', '조식', '한번', '이용', '햇', '음식', '전반', '맛', '엇', '집', '아침', '식사', '생각', '좀', '못', '외', '것', '다음', '또', '방문', '공항', '주변', '공항', '렌탈업체', '공항', '버스', '도', '이동', '시내', '중심', '편의점', '등등', '주변', '맛집', '저녁', '호텔', '차후', '한라산', '등산', '위해', '숙소', '공항', '근처', '바로', '앞', '시외버스', '터미널', '한라산', '버스', '이용', '저녁', '치킨', '파티', '묵고', '밤', '비행기', '도착', '때', '이용', '저녁', '비헹', '근처', '밥', '숙소', '잠', '자고', '다음', '날', '아침', '일찍', '출발', '자동차', '스쿠터', '렌트', '시외버스', '여행', '실', '다만', '가성', '비', '퀄리티', '자체', '율', '제주', '항공', '편요', '긐', '각', '이영', '다미', '일리지', '적립', '시설', '공항', '방', '각자', '락커', '짐', '보관', '주차공간', '골목', '주차', '해', '다음', '가도', '또', '묵고', '곳', '조식', '거', '생각', '테라스', '방도', '전체', '만족', '저녁', '식사', '후', '산책', '구경', '수', '풍경', '최고', '어이', '가격', '대비', '닥', '욕조', '가격', '라면', '체인', '호텔', '룸', '컨디션', '직원', '느낌', '아침', '물', '안개', '잠깐', '겨울', '바다', '안개', '가슴', '벅착', '직원', '여름', '다시', '나', '홀로', '여행', '시일', '가격', '위치', '마음', '또한', '아주', '직원', '한번', '가격', '부담', '가지', '해수욕장', '안고', '산책로', '객실', '테라스', '바다', '커피한잔', '정말', '머리', '도움', '위치', '몇', '번', '이용', '룸', '컨디션', '전체', '베딩', '청소', '상태', '청소', '메이드', '이번', '리뉴얼', '피트니스', '사우나', '기프트샵', '기프트샵', '종류', '건', '초코렛', '디', '퓨저', '엽서', '등', '선물', '살', '만', '것', '호텔', '가격', '생각', '초코렛', '치약', '등', '선물', '구입', '호텔', '위치', '선물', '사서', '공항', '바로', '가기', '지하', '피트니스', '사우나', '사진', '못', '운동', '안쪽', '사우나', '크기', '해도', '나무', '향', '온도', '게', '월', '둘째', '주', '가족', '여행', '때', '투숙', '제주', '호텔', '박', '예약', '이용', '레노', '베이', '션', '객실', '침구', '류', '뽀숑', '뽀숑', '주변', '맛집', '관광지', '문의', '안내', '주신', '직원', '때문', '이틀', '동안', '구경', '담', '제주', '숙소', '호텔', '방이', '뷰', '청소', '요청', '거', '즉각', '해결', '미소', '응답', '감동', '다음', '제주도', '때', '또', '친구', '제주도', '여행', '잠깐', '곳', '시설', '직원', '서비스', '이클립스', '스포츠', '바', '영상', '보고', '당구', '가격', '생맥주', '수', '지난주', '가족', '호텔', '박일', '숙박', '가격', '호텔', '호텔', '정', '기분', '일단', '제', '운동', '호텔', '헬스장', '헬스', '기구', '또한', '사우나', '시설', '아침', '식도', '직원', '담', '또', '방문', '의', '위치', '제주도', '쇼핑', '지역', '근처', '비교', '공항', '호텔', '공항', '차로', '분', '정도', '쇼핑', '지역', '도보', '분', '정도', '근처', '만', '곳', '저', '호텔', '곳', '위치', '치킨', '추천', '편의점', '호텔', '바로', '옆', '아침', '식사', '거나', '생수', '구', '수', '객실', '내부', '비록', '약간', '작', '모든', '것', '침대', '약간', '일', '동안', '수', '정도', '제공', '목욕', '수건', '조금', '때문', '직접', '더', '수건', '수도', '접수', '처', '직원', '협조', '도착', '첫', '날', '근처', '대한', '정보', '제공', '그', '영어', '실력', '도움', '경우', '그', '대화', '수', '전반', '시간', '다음', '제주도', '방문', '꼭', '곳', '선택', '것', '저', '꼭대기', '층', '스위트', '룸', '엘리베이터', '층', '것', '저', '제', '부모님', '에어컨', '비상', '계단', '통해', '짐', '직원', '우리', '마찬가지', '객실', '곳', '욕실', '욕조', '무슨', '의미', '정말', '알', '수', '기본', '침대', '분리', '수', '커플', '위', '객실', '정말', '당황', '영어', '정말', '직원', '명', '그녀', '자리', '때', '관광', '목적지', '대한', '질문', '택시', '때', '대화', '나누기', '그', '정말', '영어', '실력', '우리', '가족', '나', '호텔', '일', '밤', '전체', '옆방', '위층', '중국', '관광객', '제외', '그', '자정', '정도', '소음', '소리', '또한', '위층', '소리', '크게', '방음', '소음', '관광객', '제외', '프론트', '데스크', '직원', '항상', '여직원', '덕분', '가족', '식당', '한국', '전통', '갈비탕', '수', '교통', '여직원', '전통', '시장', '공항', '픽업', '차량', '준비', '그녀', '친절', '카운터', '여직원', '그녀', '호텔', '밖', '주차장', '우리', '치킨', '해물탕', '음식점', '추천', '호텔', '조식', '제공', '호텔', '바로', '옆', '편의점', '방', '아주', '전원', '플러그', '정말', '샤워실', '모든', '한국', '호스텔', '수건', '제공', '때문', '개인', '수건', '꼭', '위치', '주요', '쇼핑', '거리', '움', '우리', '매일', '밤', '정말', '리뷰', '호텔', '흥분', '전체', '우리', '숙박', '예약', '호텔', '로비', '도착', '자마자', '나', '로비', '호텔', '만약', '거의', '눈', '확인', '체크', '스태프', '객실', '크기', '기대', '청결', '정격', '위', '꼭', '먼지', '수영장', '박', '내내', '커피', '테이블', '우리', '베드', '시트', '변경', '요청', '둘', '중', '하나', '일어나지', '호텔', '수건', '매우', '크기', '제공', '위치', '밤', '식당', '아침', '식사', '즉', '한국', '일반', '문제', '것', '호텔', '레스토랑', '대부분', '시간', '옆', '아침', '필요', '호텔', '월', '호텔', '길', '아마', '단계', '신용', '호텔', '공항', '가까이', '호텔', '내', '제주도', '다시', '이', '호텔', '다시', '것', '양', '염소', '말', '토끼', '거위', '오리', '사슴', '닭', '봉', '오골계', '밥', '주기', '체험', '동물', '별로', '공간', '분리', '뿐', '정말', '관리', '애', '얼마나', '진짜', '양털', '합성수지', '불', '바스락', '거리', '무엇', '사슴', '몸', '파리', '모기', '마리', '정도', '건', '충격', '입장료', '천원', '기본', '사료', '추가', '당근', '당근', '사료', '손바닥', '침', '각오', '아이', '예약', '운', '분', '취소', '갈수', '아침', '저녁', '애', '토끼', '양', '말', '오리', '칠면조', '산양', '꽃사슴', '염소', '돼지', '등등', '의', '동물', '먹이', '산양', '젖', '체험', '양치기', '개', '원반던지기', '숙소', '조금', '관리', '통나무', '사장', '부부', '아이', '심', '최고', '경험', '객', '아이', '동물', '다음', '제주도', '가면', '또', '숙박', '뜨내기', '손님', '곳', '손님', '대한', '생각', '전혀', '곳', '립', '서비스', '존재', '비수', '푸대접', '수기', '더', '푸대접', '듯', '제주', '망신', '곳', '모슬포', '박', '여기', '박', '비교', '떼', '대관령', '가지', '왜', '여기', '유형', '호텔', '시골', '지역', '수', '생각', '밤', '휴식', '취하', '거나', '파티', '수', '주위', '정말', '소리', '걱정', '다음', '날', '아침', '아침', '식사', '후', '목장', '말', '그', '친구', '먹이', '공항', '호텔', '투숙', '가격', '대비', '화장실', '가성', '비', '그닥', '호텔', '가성', '공항', '근처', '호텔', '카지노', '호텔', '맞은편', '위치', '주차', '약간', '직원', '주차', '주차', '객실', '아주', '인테리어', '침구', '류', '중간', '이상은', '가격', '대비', '제주시', '일이', '재', '방문', '의사', '당일', '예약', '이용', '사진', '걱정', '호텔', '관광', '일정', '빠듯', '잠', '자고', '가기', '가격', '대비', '다만', '직원', '서비스', '마인드', '좀', '프런트직원', '새벽', '공항', '콜', '택시', '달라', '시간', '배차', '직접', '좀', '당황', '나름', '얼마', '호텔', '호텔', '자체', '새', '냄새', '나', '복도', '때', '스태프', '룸상태', '어', '매니', '티', '또한', '머리', '고무줄', '준비', '정도', '평일', '룸', '업그레이드', '싱글', '더블', '침대', '룸', '하룻밤', '점', '어매니티', '편이', '무슨', '브랜드', '것', '공항', '근처', '이동', '가격', '라면', '만원', '더', '신라', '스테이', '것', '번화가', '조금', '편이', '것', '분', '선택', '것', '중국인', '밀집', '지대', '점', '조금', '걱정', '와이파이', '빵빵', '제주', '가격', '근처', '시장', '저녁', '쇼핑', '맛집', '우리', '공항', '버스', '타고', '시청', '맞은편', '이', '배낭여행', '호스텔', '메인', '도로', '골목', '위치', '우리', '처음', '곳', '때', '약간', '어려움', '지인', '길', '방', '자체', '매트', '바닥', '우리', '조건', '에어컨', '수건', '세면', '도구', '온수', '샤워', '제공', '욕실', '화장실', '바로', '우리', '방', '수압', '욕실', '옆', '무료', '사용', '세탁기', '무료', '와이파이', '수신', '상태', '무료', '아침', '식사', '아주', '건강', '홈', '메이드', '통밀', '빵', '잼', '요거트', '과일', '주스', '제공', '커피', '차', '및', '생수', '또한', '시나몬', '운', '허브', '계란', '주인', '영어', '해', '위치', '대중', '교통', '버스', '곳', '버스', '타고', '움직', '이기', '저', '제', '아내', '통해', '월', '일', '이', '호텔', '호텔', '거의', '점', '우리', '통해', '더블', '베드룸', '예약', '주인', '그', '버스', '이용', '수', '제주', '명소', '제주', '공항', '호텔', '교통', '편', '대한', '모든', '정보', '그', '충고', '여러분', '대중', '버스', '제주도', '전체', '여행', '수', '월', '일', '제주', '공항', '도착', '후', '동쪽', '코스', '여행', '여행', '기사', '로', '우리', '시', '우리', '여행', '중', '아무', '음식', '호텔', '때', '정문', '환영', '메시지', '벽', '걸', '보고', '깜짝', '그', '냉장고', '음식', '방', '바닥', '침대', '욕실', '아침', '식사', '아침', '식사', '패킷', '오전', '시', '분', '시', '제공', '리셉션', '데스크', '마련', '패킷', '이름', '시스템', '게다가', '이', '지역', '모든', '종류', '교통', '시설', '연결', '우린', '여행', '이튿날', '원화', '그', '만원', '것', '우리', '도움', '제공', '우리', '시간', '때', '언제', '은행', '환전', '다음', '달라', '그', '정말', '우리', '현지', '문화', '대한', '주제', '것', '교환', '곳', '가세', '나', '당신', '곳', '것', '을제', '친구', '저', '이', '곳', '박일', '수', '상점', '가까이', '이', '호스텔', '아주', '안', '걸음', '시나몬', '냄새', '마음', '진정', '주인', '김씨', '그', '영어', '제주도', '여행', '대한', '조언', '심지어', '손님', '우산도', '제공', '가정식', '빵', '요거트', '잼', '한국', '운', '계란', '아침식사', '곳', '깜빡', '심지어', '주인', '후', '근육통', '손님', '발', '마사지', '제공', '것', '감동', '꼭', '다시', '봄', '여행', '박', '동인', '숙소', '위치', '버스', '터미널', '섬', '곳', '곳', '방문', '수', '숙소', '직접', '아침', '환상', '요거트', '빵', '잼', '커피', '어', '우려', '방', '사이즈', '침대', '욕실', '모든', '부분', '정돈', '여기', '정말', '이번', '달', '다시', '예정', '숙소', '함덕', '해수욕장', '서우', '봉', '건너편', '주변', '아무', '것', '곳', '분', '듯', '호텔', '바로', '앞', '바다', '경치', '호텔', '아주', '관리', '앞', '낚시', '서우', '봉', '산책', '함덕', '해수욕장', '연결', '가격', '대비', '강추', '함덕', '숙소', '바닷가', '바로', '코', '앞', '위치', '숙소', '정말', '관리', '서비스', '사장', '우리', '힐링', '타임', '수', '제주도', '다운', '숙소', '밤', '도착', '짐', '바로', '앞', '바다', '방도', '바닥', '푹', '수', '체크', '아웃', '때', '커피', '공항', '가기', '전', '산책', '바다', '바로', '앞', '위치', '모든', '객실', '바다', '향', '호텔', '한국', '펜션', '객실', '최신', '시설', '주인', '제주도', '바다', '수', '곳', '비교', '곳', '위치', '저', '곳', '웨딩촬영', '아주', '사진', '가장', '환상', '숙박', '제', '친구', '제', '봉사', '누구', '객실', '매우', '위치', '바다', '전망', '가지', '긴장', '풀', '수', '장소', '스파', '정말', '우리', '일', '이', '호텔', '가족', '분위기', '침대', '매우', '샤워', '시설', '욕조', '수영장', '살', '아들', '트램펄린', '해안', '및', '커피숍', '도보', '거리', '직원', '정말', '경험', '바다', '전망', '객실', '이용', '명의', '대가족', '층', '독채', '전망', '아주', '풀', '빌라', '개인', '수영', '수사', '아이', '층', '거실', '워낙', '명', '부족함', '침대', '예술', '정말', '강추', '야외', '메인', '수영장', '월', '운영', '보기', '다른', '가족', '모두', '숙소', '바다', '아이', '조식', '직원', '숙소', '바다', '숙소', '애', '맘', '일단', '협재', '바다색', '모래사장', '위', '위치', '게스트하우스', '층', '휴식', '외국', '무조', '건강', '추', '사장', '뷰', '조식', '무료', '석식', '파티', '가성', '비', '게스트하우스', '꼭', '추천', '파리', '빗', '비치', '문', '바로', '바닷가', '모든', '방', '안', '비치', '볼', '수', '해', '거름', '방', '창', '통해', '볼', '수', '저녁', '무료', '식사', '타임', '조식', '꽤', '편이', '컵라면', '았', '카레', '미역국', '씨리얼', '전기장판', '각', '방', '도어락', '욕실', '최고', '위치', '바로', '바다', '언제', '물', '수', '직원', '손님', '대한', '통제', '잠', '자기', '조금', '공항', '시설', '바라지', '비용', '수', '곳', '냉장고', '생수', '개', '제공', '소셜', '구매', '숙박', '위치', '칼', '호텔', '바로', '앞', '중국', '관광객', '가끔', '주말', '결혼식', '시설', '엘리베이터', '그냥', '계단', '침대', '정말', '쿠션', '방', '여관', '느낌', '가격', '하루', '참고', '아주', '차장', '매우', '박만', '해결', '때문', '가격', '이', '호텔', '선택', '건물', '자체', '점도', '가격', '레벨', '호텔', '한국', '방', '밖', '욕조', '발견', '것', '호텔', '발견', '것', '생명', '은인', '이', '곳', '시청', '밤', '수', '장소', '객실', '항상', '가격', '대비', '공간', '호텔', '동네', '위치', '고속도로', '정면', '장교', '매우', '그', '아트', '리움', '공연', '가야', '때문', '조기', '체크', '요청', '매우', '합리', '가격', '도시', '전망', '유닛', '구', '수', '방', '매우', '전혀', '불평', '수', '매일', '아침', '조식', '뷔페', '제공', '아침', '항공', '편', '경우', '대비', '공항', '호텔', '위치', '공항', '편', '화장실', '가성', '비', '추천', '호텔', '그랜드', '보이', '실내', '그다지', '의', '외부', '모습', '제공', '목욕', '수건', '커피', '차', '기본', '세면', '도구', '사셰', '이', '근처', '카페', '거리', '편', '섬', '일', '주제', '공항', '터치', '다운', '이후', '이동', '호텔', '게스트', '하우스', '위치', '택시', '교통', '수단', '도처', '여행', '아무', '를', '비난', '그', '여행자', '제주', '대부분', '한국인', '영어', '해석', '때문', '말', '방법', '여기', '택시', '나', '영어', '그', '호텔', '저축', '심지어', '예산', '대한', '계획', '위해', '것', '하나', '선택', '것', '숙소', '앞', '바다', '풍경', '연인', '나', '혼자', '여행', '대부분', '용품', '구비', '다만', '매트리스', '인지', '숙면', '허리', '아팟으', '실내', '공기', '해변', '바로', '앞', '주변', '객실', '비양도', '전망', '객실', '취사', '시설', '콘도', '부엌', '전망', '동네', '협재', '해수욕장', '가격', '가격', '직원', '또한', '고유', '점', '지하', '노래방', '과', '로비', '그', '또한', '마무리', '공사', '야외', '수영장', '저', '이', '리조트', '강력', '추천', '호텔', '위치', '조금', '번화가', '맛집', '무엇', '객실', '제주시', '위치', '위치', '이동', '객실', '욕실', '묵고', '객실', '욕조', '마음', '근처', '바오', '젠', '번화가', '거기', '집', '다음', '기회', '또', '제', '제주도', '출장', '자주', '편', '엠버', '시티', '호텔', '가장', '마음', '드네', '방도', '화장실', '청소', '상태', '매우', '추천', '방도', '화장실', '마음', '듭니', '직원', '저', '일간', '투숙', '더블', '침대', '하나', '싱글', '침대', '하나', '방', '예약', '테이블', '침대', '제외', '공간', '사업', '차', '제주', '시내', '위치', '리뉴', '호텔', '체크', '때', '사장', '항상', '호텔', '느낌', '공항', '근처', '비행기', '기도', '사업', '차', '자주', '제주도', '또', '이용', '월', '단체', '관광', '이틀', '밤', '제주', '첫', '호텔', '전체', '방', '가장', '단점', '크기', '내', '호텔', '중', '방', '크기', '가장', '제주', '섬', '이기', '때문', '방', '인터넷', '수', '로비', '무료', '와이파이', '이용', '수', '위치', '조금', '산책로', '거리', '식당', '술집', '상점', '등', '밤', '만', '것', '스탠다드', '미니', '우리', '욕실', '매우', '매우', '현대', '세면', '도구', '방', '도', '아침', '식사', '우리', '체크', '아웃', '때문', '시험', '시간', '수용체', '월', '제공', '봉사', '매우', '감명', '그녀', '참을성', '예의', '우리', '주의', '것', '외', '그녀', '호텔', '버스', '정류장', '값', '호텔', '근처', '스케치', '위해', '고통', '버스', '도시', '간', '버스', '아침', '식사', '매우', '실망', '별로', '선택', '여지', '방', '정도', '나', '를위', '공간', '나', '구석', '그것', '척', '그것', '아마', '나', '더', '호텔', '위해', '더', '지불', '운', '나', '체', '재는', '개', '밤', '첫', '저', '이', '호텔', '무료', '공항', '셔틀', '버스', '정류장', '호텔', '도착', '때', '셔틀', '버스', '앞쪽', '위치', '호텔', '파킹', '방', '매우', '작고', '곳', '벽', '얼룩', '침대', '시트', '구멍', '가격', '호텔', '것', '골프', '치', '가족', '여행', '숙박', '가족', '아주', '방도', '독채', '층', '숙소', '앞', '산책로', '차량', '진입', '아이', '안전', '다만', '고양이', '움', '시내', '위치', '조금', '우선', '방이', '골프텔', '조금', '커서', '경우', '프론트', '픽업', '요청', '골프', '장안', '편의점', '모로', '볼', '치기', '곳', '조금', '오픈', '한지', '곳', '필드', '뷰', '엘지', '기업', '소유', '리조트', '인테리어', '자연', '친', '적', '골프', '호스텔', '방', '사람', '우리', '일행', '방', '수영장', '시간', '밤', '바베큐', '파티', '시간', '친구', '끼리', '가족', '끼리', '더', '것', '독채', '식이', '거실', '하나', '방', '개', '구조', '방', '화장실', '조리', '시설', '냉장고', '냉동', '실', '커서', '여유', '거실', '커서', '근처', '시장', '회', '사서', '먹기', '마음', '건', '아침', '커튼', '밖', '잔디밭', '나무', '풍경', '절로', '힐링', '풍경', '숙소', '따라서', '바퀴', '산책', '굳이', '골프', '치', '숙박', '정말', '곳', '생각', '위치', '시내', '생각', '이틀', '전혀', '위치', '여름', '야외', '수영장', '운영', '수영장', '크기', '아이', '잠깐', '물놀이', '기', '것', '한가지', '에어컨', '필터', '청소', '좀', '듯', '투어', '패키지', '중', '하룻밤', '호텔', '탑동', '거리', '시장', '약', '분', '안', '수', '거리', '말', '필요', '편의점', '것', '살', '수', '은', '길', '건너', '오른쪽', '방', '정수기', '정수기', '방', '공용', '식당', '호텔', '지하', '호텔', '복도', '카펫', '방', '안도', '마찬가지', '에어컨', '것', '직원', '영어', '거의', '못', '해', '관광', '패키지', '포함', '이', '곳', '호텔', '꽤', '편임', '로비', '수', '메인', '로비', '소파', '연식', '말', '방', '바다', '수', '발코니', '곳', '편의점', '길', '건너', '세븐일레븐', '생각', '것', '곳', '하루', '침대', '편이', '방', '여러가지', '텔레비전', '프로그램', '볼', '수', '방', '경치', '또한', '발코니', '바다', '볼', '수', '교통', '정체', '아주', '주변', '분', '동안', '택시', '잡', '수', '바로', '앞', '이마트', '편의점', '옆', '호텔', '무난', '수', '어른', '여자', '명', '이서', '숙박', '보조', '침대', '제대로', '침대', '동문', '시장', '못', '걸', '정도', '시간', '좀', '분', '정도', '것', '공항', '택시', '분', '정도', '도착', '바다', '좀', '문제', '호텔', '시장', '번화가', '해변', '해산물', '요리', '레스토랑', '등', '좀', '도보', '권내', '방도', '수', '가격', '대비', '호텔', '가격', '우선', '공항', '근처', '이호우', '테', '해변', '시설', '조식', '맛', '호텔', '모텔', '이호', '테', '해변', '도보', '분', '도로', '밤', '아침', '잠깐', '이용', '가격', '무엇', '호텔', '동남아', '분', '야간', '데스크', '동남아', '분', '호텔', '층', '매점', '방', '테라스', '방도', '정말', '주변', '뭐', '티몬', '특가', '가족', '여행', '호텔', '공항', '가격', '합리', '다시', '이용', '근처', '관광', '공항', '가격', '비', '지은지', '얼마', '주차공간', '좀', '빡빡', '제주시', '하루', '홀로', '예약', '숙소', '체크', '불구', '안내', '신식', '건물', '방도', '룸', '컨디션', '책', '수', '휴게', '공간', '조식', '성게', '미역국', '정말', '감동', '방장', '호텔', '쉐프', '출신', '역시', '다음', '또', '의사', '프러', '독립', '방', '인근', '한라', '수목원', '푸드', '트럭', '한번', '주변', '볼거리', '볼', '만하', '시설', '매우', '가격', '매우', '주차', '매우', '저녁', '도착', '공항', '근처', '아침', '일찍', '출발', '분', '정말', '강', '스태프', '월급', '제주', '여행', '하라', '유류', '지원', '해주시', '걸', '제주도', '가면', '꼭', '곳', '하나', '편안함', '븐', '게스트하우스', '이용', '후기', '단어', '표현', '무엇', '인상', '호텔', '또한', '도미', '토리', '형식', '임', '불구', '블라인드', '공간', '혼자', '휴식', '취할', '수', '형태', '지하', '커뮤니티', '공간', '여느', '게스트하우스', '수', '공간', '책', '음악', '여유', '공간', '혼자', '시간', '사람', '혼자', '사색', '사람', '누군가', '수', '공간', '사람', '사람', '공간', '월말', '월초', '번', '숙박', '번', '모두', '매우', '너븐팡', '게스트하우스', '것', '조차', '여행', '스케쥴', '것', '다음', '제주', '여행', '스케쥴', '너븐팡', '고정', '다른', '게스트하우스', '비교', '때', '장점', '제주시', '시내', '위치', '만천원', '가격', '대비', '시설', '최고급', '침대', '개인', '스탠드', '침대', '노트북', '수', '받침', '자식', '개인', '사물함', '조식', '한식', '지하', '모임', '공간', '매우', '체크', '때', '물', '병', '매우', '사려', '도미', '토리', '화장실', '매니저', '무', '내', '제주', '게', '중', '최고', '재', '방문', '의사', '공항', '가격', '대중교통', '이용', '수', '위치', '시설', '꽤', '편이', '곳', '고급', '시설', '공항', '청결', '상태', '호텔', '약간', '골목', '위치', '처음', '때', '찾기', '공항', '거리', '보나', '숙소', '상태', '보나', '모로', '호텔', '공항', '밤', '도착', '공항', '인근', '하룻밤', '묵', '숙소', '곳', '선택', '제주', '최근', '만원', '만원', '하루', '밤', '수', '숙소', '그', '곳', '곳', '선택', '이유', '욕실', '컵', '기소', '내용', '사회', '기업', '것', '보고', '곳', '선택', '좀더', '관리', '하리', '란', '믿음', '스탠다드', '더', '블룸', '거의', '시가', '체크', '배정', '층', '우리룸외', '모두', '숙박', '객', '다른', '객실', '소음', '별로', '욕실', '침구', '류', '꽤', '느낌', '자신', '광고', '욕실', '컵', '사실', '욕실', '컵', '이용', '자신', '광고', '화장', '겸', '책상', '거울', '이용', '옷장', '옷', '가장', '점', '전', '호텔', '펜션', '게스트하우스', '침대', '이외', '쓸모', '쇼파', '데이', '베드', '선택', '침대', '딸', '곳', '거나', '장식', '용', '쇼파', '사실', '침대', '이외', '때', '여행', '일정', '정리', '거나', '약간', '사무', '처리', '때', '탁자', '쇼파', '중요시', '호텔', '펜션', '게', '하등', '탁자', '의자', '경우', '엘린', '호텔', '침대', '옆', '탁자', '쓸모', '의자', '개', '게', '맘', '선택', '역시', '저녁', '도착', '과일', '맥주', '한잔', '자기', '남편', '메일', '보고', '위치', '공항', '택시', '불과', '분', '거리', '프론트', '직원', '도움', '방', '기본', '매우', '방', '모든', '것', '다음', '날', '아침', '일찍', '비행기', '경우', '권장', '를', '가지', '거기', '아이', '유모차', '그', '짐', '밀고', '눈', '날', '저녁', '도착', '직원', '정말', '도움', '처음', '유모차', '계단', '통해', '직원', '휠체어', '전용', '엘리베이터', '객실', '히터', '작동', '위치', '공항', '버스', '정류장', '우리', '서귀포', '때', '공항', '번', '버스', '버스', '만하', '이', '호텔', '근처', '레스토랑', '바', '젠', '거리', '수', '거리', '편의점', '도보', '분', '거리', '중국', '관광객', '좀', '편입', '니', '시설', '가격', '대비', '조식', '나름', '수영장', '편이', '제주도', '때', '이용', '숙박', '호텔', '근처', '뭐', '편의', '시설', '편의점', '주차장', '야외', '주자', '구', '제주도', '렌트', '동시', '위치', '규모', '편', '추천', '곳', '제주시', '동쪽', '길목', '위치', '위치', '호텔', '층', '수가', '아침', '바다', '조식', '주차장', '여유', '편이', '주차', '모처럼', '연휴', '아내', '제주', '호텔', '검색', '중', '함덕', '동북', '리', '길목', '메이', '더', '호텔', '박', '예약', '첫날', '도착', '시', '느낌', '꽤', '느낌', '호텔', '방', '느낌', '우리', '우려', '것', '달리', '확', '공간', '전망', '마음', '휠씐', '더', '정돈', '방과', '구조', '시간', '내내', '그', '자체', '앞', '바다', '뒤', '산이', '산', '바다', '풍경', '감상', '야외', '수영장', '룸', '컨디션', '좀', '드하', '욕실', '점', '외관', '곳', '왜', '내부', '관리', '안', '듯', '중국', '관광객', '좀', '듯', '고요', '위치', '뭐', '잠', '자기', '주변', '뭐', '별', '일부러', '곳', '관리', '해도', '구만', '워크숍', '여러', '동료', '곳', '화장실', '부족', '것', '외', '체적', '밖', '휴식', '공간', '동료', '사진', '관리', '야자수', '제주', '리조트', '콘도', '독채', '통나무', '여행', '인원', '선택', '수', '가정', '집', '가족', '여행', '곳', '우리', '곳', '주', '년', '아기', '이', '평화', '호텔', '위치', '근처', '공원', '산책', '뒤', '리조트', '사람', '영어', '구사', '때문', '적극', '추천', '가격', '대비', '성능', '주위', '편의', '시설', '단점', '객실', '크기', '욕실', '크기', '욕실', '샤워', '부스', '욕조', '점', '좀', '외진', '곳', '위치', '관광지', '위주', '여행', '동선', '위치', '가성', '비', '숙소', '생각', '소셜커머스', '통해', '예약', '수', '리조트', '편', '관리', '실', '직원', '분', '룸', '위치', '안내', '수', '합리', '가격', '룸', '컨디션', '꽤', '마음', '제주도', '처음', '이', '펜션', '주인', '정말', '사랑', '나무', '집', '켈빈', '매우', '협조', '강아지', '이름', '자기', '제주도', '운전', '우리', '우리', '입력', '업로드', '케빈', '주변', '펜션', '집', '것', '느낌', '저', '곳', '추천', '제', '조언', '자', '드라이브', '및', '의', '도움', '수', '이', '펜션', '다시', '곳', '것', '곳', '자연', '도시', '멀리', '펜션', '하우스', '최고', '선택', '가격', '이상', '가치', '가격', '차', '강력', '추천', '우리', '수', '라이센스', '경우', '만료', '협박', '모든', '것', '주인', '케빈', '택시', '타고', '우리', '이', '여정', '음식', '주문', '수', '현지', '음식', '분실', '때', '그', '전화', '하나', '택시', '타고', '통신', '수', '방', '주방', '용품', '및', '주전자', '밥솥', '가스렌지', '등등', '또한', '운', '빵', '아침', '식사', '제공', '정말', '그', '서비스', '우리', '여행', '제주', '기억', '때문', '저', '제', '친구', '꼭', '다시', '펜션', '추천', '고해', '다만', '세면', '용품', '주지', '참고', '시설', '입실', '때', '목욕탕', '냄새', '아주', '살짝', '공항', '편이', '이동', '무리', '골목', '찾기', '시설', '가격', '대비', '양호', '편입', '니', '다만', '침구', '류', '락스', '냄새', '좀', '냄새', '때문', '머리', '냉장고', '모터', '소리', '수면', '방해', '공항', '근처', '기', '가격', '합리', '시설', '위치', '분', '정도', '도로', '변', '서귀포', '출장', '시', '버스', '타고', '기', '곳', '박', '방', '크기', '현대', '호텔', '호텔', '용도', '냉장고', '치약', '제공', '영화', '채널', '영어', '내', '건', '샴푸', '샤워', '폼', '냄새', '정말', '세븐일레븐', '편의점', '수', '또한', '롯데', '면세점', '도보', '이동', '수', '예', '언급', '주차장', '사용', '수', '주차', '강', '수', '근처', '도로', '편입', '니', '바닥', '난방', '방', '정말', '더', '정보', '요구', '수', '호텔', '우리', '방', '컨셉', '잠', '거의', '치', '매우', '전반', '장소', '매우', '직원', '정말', '도움', '위치', '레스토랑', '편의점', '가까이', '것', '걱정', '필요', '우리', '개', '밤', '동안', '여기', '나', '장소', '소유', '것', '주방', '무엇', '요리', '수', '밥솥', '난로', '후드', '전자', '레인지', '가정', '용', '식', '기류', '해변', '공항', '매우', '걱정', '우리', '것', '소리', '당신', '잠', '방해', '것', '커튼', '덕택', '우리', '장소', '근처', '해변', '해산물', '레스토랑', '것', '만', '그', '중', '하나', '시도', '수', '호스트', '매우', '의사', '소통', '수', '이', '곳', '전적', '추천', '가치', '모든', '원', '하하', '하룻밤', '장소', '부부', '도움', '곳', '우리', '냉장고', '요리', '시설', '인승', '사람', '위해', '임대', '사람', '당신', '운전', '경우', '연금', '공원', '도보', '거리', '상점', '식당', '함덕', '해변', '조금', '곳', '위치', '내부', '프런트', '직원', '다만', '객실', '방음', '편', '단점', '가격', '대비', '가족', '여행', '제주', '여행', '아이', '해수욕장', '함덕', '해수욕장', '결정', '인근', '호텔', '검색', '중', '베스트', '호텔', '알', '오픈', '한지', '정말', '얼마', '아마', '달', '내인', '듯', '더', '이미지', '호텔', '직원', '급', '호텔', '저리', '인근', '놀', '거리', '먹거리', '호텔', '오션', '뷰', '두루', '두루', '가성', '비', '최고', '최고', '직원', '호텔', '가족', '여행', '직원', '맛집', '안내', '가족', '간만', '제주도', '여행', '아이', '서우', '봉', '함덕', '해수욕장', '스노', '쿨링', '바베큐', '고기', '여름', '휴가', '호텔', '직원', '친절', '서비스', '가을', '겨울', '한번', '더', '주변', '차도', '숙박', '최적', '화장실', '방', '방도', '무엇', '사장', '조식', '바다', '조식', '분위기', '것', '공항', '호스텔', '방', '그룹', '여행', '제주도', '추천', '근처', '음식', '한국', '음식점', '이', '지역', '여름', '아이', '바다', '곳', '방문', '차', '택시', '예약', '권장', '더', '나은', '사용', '수', '경우', '사용', '주차', '공간', '이', '명', '묵', '수', '점', '층', '침대', '개', '일반', '싱글', '침대', '하나', '제공', '방음', '전혀', '시', '제지', '방', '편이', '조식', '조식', '과일', '제공', '점', '아주', '방값', '아주', '편이', '무료', '와이파이', '제공', '자주', '사용', '위치', '약간', '마레', '카펜션', '사장', '정말', '개', '동이', '바', '마을', '자리', '펜션', '잠자리', '추천', '금', '능리', '마을', '안쪽', '위치', '펜션', '주인', '아저씨', '기분', '하룻밤', '펜션', '총', '크기', '건', '겨울', '난방', '시설', '방', '해', '숙소', '안', '인테리어', '소품', '생필품', '등', '정말', '퀄리티', '진짜', '힐링', '숙소', '사장', '조식', '호텔', '동네', '위치', '고속도로', '정면', '장교', '매우', '그', '아트', '리움', '공연', '가야', '때문', '조기', '체크', '요청', '매우', '합리', '가격', '도시', '전망', '유닛', '구', '수', '방', '매우', '전혀', '불평', '수', '매일', '아침', '조식', '뷔페', '제공', '아침', '항공', '편', '경우', '대비', '공항', '호텔', '위치', '공항', '편', '화장실', '가성', '비', '추천', '호텔', '그랜드', '보이', '실내', '그다지', '의', '외부', '모습', '제공', '목욕', '수건', '커피', '차', '기본', '세면', '도구', '사셰', '이', '근처', '카페', '거리', '편', '우리', '개', '밤', '동안', '여기', '나', '장소', '소유', '것', '주방', '무엇', '요리', '수', '밥솥', '난로', '후드', '전자', '레인지', '가정', '용', '식', '기류', '해변', '공항', '매우', '걱정', '우리', '것', '소리', '당신', '잠', '방해', '것', '커튼', '덕택', '우리', '장소', '근처', '해변', '해산물', '레스토랑', '것', '만', '그', '중', '하나', '시도', '수', '호스트', '매우', '의사', '소통', '수', '이', '곳', '전적', '추천', '가치', '모든', '원', '하하', '하룻밤', '장소', '부부', '도움', '곳', '우리', '냉장고', '요리', '시설', '인승', '사람', '위해', '임대', '사람', '당신', '운전', '경우', '연금', '공원', '도보', '거리', '상점', '식당', '나', '그것', '수영장', '가지', '때문', '여기', '예약', '수영장', '물이', '방', '그', '가격', '나', '해변', '다른', '장소', '수', '객실', '간이', '주방', '옷장', '비트', '냄새', '내', '체크', '전', '었는', '얼마', '아주', '방도', '가구', '고급', '지고', '숙소', '박만', '게', '부엌', '다음', '보고', '숙소', '분', '거리', '올레길', '산책', '함덕', '해수욕장', '분', '정도', '방', '침대', '포함', '욕실', '았', '총', '인의', '객실', '공항', '근처', '것', '제외', '쇼핑', '경우', '위치', '우리', '개인', '투어', '때문', '우리', '우리', '자신', '이', '지역', '중', '호텔', '확인', '수도', '아침', '식사', '아주', '전복', '층', '커넥티드', '룸', '방', '두', '개', '하나로', '인테리어', '꽤', '가격', '숙소', '경험', '터', '꽤', '공항', '정말', '비행기', '소리', '저', '다만', '주차장', '층', '바로', '호텔', '수', '점', '층', '출입구', '비', '눈', '앞', '입구', '좀', '화가', '짐', '수가', '수', '층', '로비', '겸', '카페', '앞', '차', '대고', '짐', '다시', '주차', '가야', '날씨', '거리', '편이', '하니', '더', '기억', '서비스', '제공', '호텔', '위치', '약간', '치마', '오르막', '호텔', '입구', '자신', '수하물', '끌', '필요', '제한', '조식', '뷔페', '버터', '빵', '제공', '샤워', '룸', '벽', '화장실', '칸막이', '것', '외', '매우', '특급', '나름', '제주시', '쪽', '공항', '다만', '저녁식사', '위', '렌터카', '택시', '급', '부엌', '객실', '해변', '수', '거리', '층', '상점', '프론트', '목적지', '돈', '가치', '도시', '지역', '공항', '택시', '버스', '돈', '위해', '추천', '것', '직원', '정도', '그', '도움', '가격', '매우', '방', '보기', '해변', '바로', '길', '건너', '모든', '시설', '당구', '테이블', '및', '탁구', '테이블', '활동', '실', '단', '어디', '안', '고려', '차', '렌트', '섬', '효과', '이', '리조트', '추천', '점', '방', '대부분', '부엌', '공급', '모든', '접시', '컵', '포크', '칼', '냄비', '팬', '해변', '정말', '이', '호텔', '대해', '제도', '점', '수', '고객', '서비스', '직원', '매우', '것', '우리', '체크', '그', '우리', '인사', '느낌', '돈', '투숙', '객', '더', '부담', '수', '또한', '우리', '침대', '시트', '욕실', '변경', '우리', '여러', '날', '수건', '매일', '만', '추가', '수', '입구', '문', '매우', '분', '호텔', '밖', '더', '나은', '사람', '가끔', '청소', '해', '주어', '전반', '호텔', '느낌', '온라인', '사진', '거', '아무', '우리', '우리', '미소', '수', '수', '이', '호텔', '것', '가치', '나', '결코', '정보', '호텔', '가격', '얼마나', '일', '수', '집', '호텔', '나', '때', '우리', '돈', '수', '제주', '보석', '호텔', '이', '관련', '것', '생각', '호텔', '이름', '제외', '초콜릿', '객실', '샤워', '시설', '가격', '근처', '상점', '하나', '버스', '타고', '약', '공항', '객실', '흡연', '수', '방이', '준비', '자신', '데스크톱', '한국인', '직원', '영어', '나', '밤', '도착', '체크', '아웃', '초콜릿', '호텔', '꽤', '신식', '이', '개인', '생각', '값', '호텔', '셔', '위치', '소매', '상점', '주차장', '호텔', '객실', '한국', '표준', '것', '수건', '제공', '일부', '부정', '포인트', '부족', '호텔', '게스트', '초콜릿', '호텔', '간판', '오히려', '곳', '해', '동안', '한글', '은', '호텔', '수', '주인', '영어', '이해', '프론트', '데스크', '만다린', '전반', '이', '호텔', '아주', '관리', '사람', '제주시', '아침', '식사', '제주도', '시내', '조금', '숙소', '바로', '앞', '해변', '도로', '주인', '침구', '류', '락스', '냄새', '점', '정말', '로비', '인터넷', '이용', '객실', '바다', '풍경', '가격', '대비', '숙소', '협재해수욕장', '차로', '분', '거리', '바다', '보이', '정원', '뻣', '바베큐', '장도', '객실', '가격', '것', '통증', '게스트', '하우스', '제주도', '의', '처음', '제주', '지원', '분', '한국', '언어', '더', '것', '여기', '여러', '이름', '리베라', '호텔', '리베라', '호텔', '호텔', '리베로', '호텔', '거의', '모든', '불행', '의', '게스트', '하우스', '제', '체크', '인', '하나', '그것', '모든', '시설', '깜짝', '제', '방', '엘이디', '티비', '컴퓨터', '기능', '웹', '브라우저', '설치', '의', '양성', '도', '미니', '바', '온수', '보일러', '정수기', '예', '바로', '해당', '및', '무료', '와이파이', '꼭', '안', '가격', '이', '정도', '방', '두', '원', '하룻밤', '또한', '나', '질', '침대', '베개', '허용', '화장실', '이', '욕조', '커튼', '또한', '사용', '화장실', '문', '내', '체력', '테스트', '접수', '영어', '저', '때', '그', '나', '최고', '골퍼', '피', '공물', '예', '를', '요청', '때', '주변', '여기', '디너', '지적', '의', '지도', '근처', '레스토랑', '몇', '군데', '위치', '말', '것', '이', '게스트', '하우스', '위치', '쇼핑', '거리', '로부터', '멀리', '킬로미터', '이상', '제주도', '마누카꿀', '밤', '쇼핑', '코스', '메', '제품', '식료품', '등', '또한', '분', '거리', '단지', '제주', '공항', '제주', '국제', '공항', '또한', '임대', '자동차', '차고', '조식', '제공', '결론', '곳', '매력', '가격', '위치', '만약', '휴가', '것', '곳', '이', '게스트', '하우스', '건축', '한지', '콘도', '기타', '시설', '중국', '관광객', '대상', '시설', '고급', '자재', '얘기', '제주도', '골프장', '겨울', '피크', '골퍼', '페어', '웨이', '상태', '디봇', '모래', '수리', '골프장', '캐디', '냐', '에너지', '월', '다른', '무자', '전반', '불친절', '애월', '해변', '발코니', '바로', '바다', '볼', '수', '분', '정도', '해변', '커피', '디저트', '건물', '앞', '펜션', '오징어', '배', '불빛', '보고', '시', '은', '밤', '방', '부엌', '주차', '전체', '점', '이', '건물', '바닥', '욕실', '바닥', '욕조', '및', '시피', '강', '잔류', '전기', '방전', '이', '장식', '주인', '매일', '수건', '준', '나', '사람', '영어', '생각', '가격', '해변', '대해', '캠핑', '장', '다시', '것', '우리', '양식', '콘도', '렀는데', '퀸', '침대', '개', '이불', '방', '바다', '전망', '감상', '수', '안뜰', '전체', '편의', '시설', '현대', '수용', '이', '펜션', '호텔', '성산', '일출봉', '자동차', '시간', '마운트', '산', '자동차', '분', '한라산', '관음사', '트레일', '헤드', '우리', '예약', '가격', '나', '가치', '생각', '합', '다애', '월', '해안', '도로', '구암', '위치', '직원', '친절', '한편', '시설', '좀', '좀', '층', '편의점', '커플', '여행', '좀', '별로', '구', '남자', '끼리', '여행', '가격', '아보', '요원', '격', '시골', '위치', '객실', '편안함', '장점', '아침', '식사', '호텔', '비용', '포함', '파일', '프로비저닝', '빵', '잼', '화장실', '시설', '별로', '사실', '우리', '방', '에어컨', '작동', '직원', '수정', '거절', '나', '내', '친구', '이', '펜션', '호텔', '추천', '센트럴', '시티', '호텔', '예약', '센트럴', '호텔', '예약', '시간', '취소', '왜', '취소', '가격', '숙박시설', '부담', '직원', '영어', '그', '저', '왜', '나', '불평', '중국', '방이', '구식', '사진', '인터넷', '에어컨', '경우', '침대', '직접', '객실', '청소', '수건', '호텔', '그냥', '모텔', '인테리어', '정도', '변기', '고장', '방사', '이즈', '벽', '걸이', '에어컨', '하나', '전부', '명', '일회용품', '개', '수건', '요', '예약', '필요', '현장', '하든', '암버', '호텔', '일명', '이비사', '호텔', '호텔', '말', '그대로', '암버', '중앙', '분', '거리', '위치', '서로', '혼합', '또한', '이', '덜', '중', '하나', '것', '세면', '도구', '수건', '차', '안', '주전자', '컵', '주', '급', '호텔', '방', '침대', '베개', '이불', '방', '직원', '매우', '도움', '슈퍼마켓', '호텔', '건너편', '편의점', '바로', '분', '거리', '아침', '식사', '숙박', '비', '포함', '가격', '대비', '에어컨', '모든', '것', '숙박', '그냥', '러브', '모텔', '객실', '냄새', '공항', '점', '장점', '하나', '다시', '여기', '숙박', '안', '것', '몸', '지지', '풀겸', '찜질방', '그냥', '호텔', '나우', '예약', '주차공간', '말', '그냥', '키', '차', '동시', '키시', '문도', '일부', '월풀', '욕조', '객실', '예약', '월풀', '청소', '청소', '물', '녹물', '난리', '샤워', '기', '거', '건', '세면대', '물', '객실', '비품', '구색', '것', '것', '정체', '불명', '브랜드', '제주도', '관광', '특성', '투숙', '객', '대부분', '박', '그', '중', '반수', '첫날', '이후', '다음', '날', '예약', '취소', '환불', '다수', '돈', '굳이', '취소', '사유', '가장', '최악', '건', '시설', '시설', '극악', '이구', '정말', '아프리카', '기분', '또한', '이', '게', '하의', '가장', '장점', '게', '내', '술', '계속', '소등', '시간', '점', '그게', '타', '게', '소등', '시간', '시설', '파티', '모두', '별로', '또한', '직원', '사장', '포함', '세명', '상주', '정리', '설거지', '투숙', '객', '가세', '정말', '술', '술', '사람', '라면', '추천', '화장실', '방이', '좀', '파티', '최적화', '처음', '방', '잠', '평상', '거', '해괴', '소리', '뭐', '것', '나름', '낭만', '생각', '낮', '게스트', '하우스', '바다', '풍경', '워낙', '밤', '낭만', '개뿔', '평상', '주변', '테이블', '명', '막걸리', '술', '파티', '퍽', '스타일', '낮', '일정', '사람', '쉬', '평상', '평상', '주변', '술', '파티', '벌이', '어쩌', '거', '억지로', '술', '밤새', '건가', '네', '그냥', '수준', '유흥업소', '누울', '수', '수', '돈', '테이블', '술', '안주', '전국', '온', '남자', '여자도', '아예', '노리', '이', '게', '사람', '엔조이', '거', '다만', '게', '인장', '부킹', '인장', '그냥', '사파리', '구경', '듯', '구경만', '매칭', '공률', '장담', '도심', '속', '만남', '강추', '화이팅', '정말', '아프리카', '느낌', '나', '곳', '촌장', '자연인', '거기', '분', '프리', '마음', '분', '인지', '저희', '일행', '흐트러질', '수', '시간', '청결', '약속', '드릴', '수', '한번', '정도', '추억', '개', '바다', '관경', '예약', '체크', '인시', '객실', '개', '바다', '보기', '예약', '완료', '이유', '주인', '방', '사진', '보이지', '것', '마루', '망', '모든', '가구', '침대', '냉장고', '의자', '테이블', '심지어', '년', '이상', '사용', '화장실', '바닥', '어', '두운', '얼룩', '우리', '밤', '체크', '때', '바다', '전망', '얼마나', '방', '때문', '현장', '취소', '주인', '협상', '만', '회수', '수', '환', '불금', '우리', '끝', '다른', '호텔', '위해', '예약', '또한', '주차', '공간', '아주', '약', '대의', '차', '주차', '수', '커플', '여행', '신혼', '여행', '추천', '곳', '공항', '활주로', '옆', '소리', '수도', '것', '뼈', '연금', '그것', '대해', '것', '발코니', '바다', '전경', '그것', '매우', '편리', '공항', '매우', '침목', '대해', '조금', '수', '예산', '휴가', '선택', '수', '후회', '곳', '공항', '가기', '매우', '어려움', '뒷골목', '러브', '모텔', '단체', '패키지', '숙소', '가격', '대비', '깨끗', '다만', '엘리베이터', '복도', '싸구려', '향수', '잔뜩', '조식', '최악', '반찬', '류', '준비', '곳', '밥', '추천', '룸', '컨디션', '가격', '대비', '중국인', '복도', '새벽', '시간', '동안', '잠', '절대', '가지', '서비스', '완전', '최악', '건', '둘째', '총지배인', '가몬', '완전', '최악', '건', '직원', '실수', '몬지', '동의', '취소', '분', '말', '그냥', '객실', '취소', '가라', '더', '이상', '여행기', '잠깐', '인터넷', '검색', '분', '아무', '안내', '다른', '호텔', '이용', '약속', '환불', '건', '처리', '주', '말', '한마디', '왜', '또', '식', '서비스', '직', '고객', '일단', '말', '불편', '말', '먼저', '줄', '압니다', '서비스', '기본', '총지배인', '이', '호텔', '교욱받', '직원', '얼마나', '서비스', '제공', '절대', '가지', '제주', '공항', '분도', '호텔', '가격', '편이', '방도', '오피스텔', '개조', '호텔', '방안', '싱크대', '인덕션', '구가', '사용', '못', '대신', '조식', '천원', '부담', '먹기', '조식', '토요코인', '스타일', '단점', '대로', '변', '위치', '차량', '소음', '조금', '호텔', '구들장', '롱', '탁자', '훼손', '커튼', '못', '침대', '주변', '콘센트', '이건', '손님', '대한', '예의', '잠', '분', '상태', '이', '거리', '나', '사진', '기대', '꼭', '다른', '매우', '혼란', '나', '제주도', '첫', '날', '거기', '다른', '호텔', '선택', '것', '이름', '호텔', '제', '호텔', '때문', '제', '여기', '제', '북한', '간', '적', '것', '수용', '거부', '나', '내', '여행', '주', '전', '곳', '나', '휴가', '망치', '위해', '해변', '어딘가', '선택', '박', '숙박', '위', '이', '호텔', '약', '인', '것', '청구', '것', '약', '정도', '더', '수치', '그것', '이름', '호텔', '본질', '당신', '초', '안', '발코니', '매우', '방', '내', '거기', '주', '동안', '방이', '것', '이외', '청소', '그', '침대', '욕실', '그것', '꽤', '진절머리', '나', '매일', '해변', '때', '모래', '방', '침대', '하나', '모래', '구덩이', '것', '침대', '관', '내', '뒤', '매듭', '정리', '위해', '영국', '두', '번의', '티슈', '마사지', '것', '호텔', '시설', '거의', '리셉션', '유인', '도착', '시', '공항', '교통', '편', '제공', '거절', '공항', '길', '마', '택시', '고', '식', '때', '아침', '식사', '위', '무엇', '그', '다음', '카페', '분', '나', '예정', '장소', '역설', '나', '호텔', '나', '체재', '파멸', '고', '노력', '종류', '사건', '경험', '적', '부터', '시작', '나', '것', '일찍', '도착', '호텔', '도착', '로비', '프론트', '데스크', '아무', '호텔', '전화', '약', '회', '재판', '후', '전화', '누군가', '즉시', '그', '반응', '매우', '위협', '그', '태도', '왜', '새벽', '시', '그', '오전', '시', '호텔', '몸가짐', '말', '나', '치', '발언', '대답', '수', '일찍', '체크', '수', '그', '반응', '더', '이상', '논평', '매우', '나', '그', '내', '일찍', '방', '수', '관해', '나', '그것', '지불', '그', '반응', '다시', '나', '내', '가방', '수', '그', '반응', '로비', '나', '호텔', '프론트', '데스크', '아무', '때', '로비', '내', '가방', '어도', '그', '반응', '침묵', '서핑', '위해', '친구', '때문', '나', '그', '내', '곳', '그', '대답', '그', '다음', '나', '그', '내', '당신', '옷', '입', '수', '욕실', '그', '반응', '왜', '나', '것', '당신', '내', '당신', '얼굴', '보고', '때', '로비', '그', '다음', '그', '또', '다른', '사람과', '로비', '그', '사람', '바로', '그', '지역', '갱스터', '말', '수', '그', '술', '냄새', '담배', '왜', '당신', '호텔', '그', '중', '서쪽', '협재', '다', '위치', '때문', '비치', '가장', '인기', '부분', '분', '해변', '이', '호텔', '점', '바로', '해변', '길', '정말', '위치', '직원', '도움', '요', '편의점', '호텔', '발코니', '오른', '편', '매우', '해변', '전망', '매우', '샤워실', '수압', '점', '호텔', '호텔', '시작', '침대', '베개', '도', '아주', '장소', '경영', '관리', '마루', '끈', '거리', '문', '무료', '아침', '식사', '제공', '점', '대중', '교통', '인생', '더', '밤', '모든', '것', '화장실', '냄새', '심지어', '객실', '냄새', '부엌', '객실', '주인', '직원', '오전', '시', '밤', '야간', '스', '사람', '발', '안', '운영', '내', '평생', '동안', '최악', '숙박', '방', '나', '영빈', '관', '나머지', '대해', '말', '인도', '사람', '이야기', '음악', '퍼팅', '악몽', '모기', '어디', '서나', '방', '주인', '전혀', '이', '장소', '피해', '나', '그냥', '가격', '위치', '공항', '근처', '곳', '선택', '가격', '조금', '더', '여러', '가지', '고려', '생각', '침대', '설치', '더', '소음', '침대', '기숙사', '화장실', '자주', '더러', '움', '냄새', '나', '팬', '작동', '안', '확인', '전체', '시설', '관리', '시설', '관리자', '소유자', '전문', '그', '음료', '일부', '대화', '친구', '손님', '밤', '하드', '때문', '밤', '잠', '락커', '점', '전체', '분위기', '규칙', '마사지', '기계', '무료', '버스', '타고', '공항', '취하', '위치', '아이러니', '고객', '곳', '매우', '손님', '곳', '다시', '요청', '경우', '차라리', '대안', '추가', '달러', '지불', '호스텔', '매우', '위치', '내', '내부', '때', '그것', '단지', '내', '것', '중', '아주', '호스텔', '냄새', '화장실', '주차장', '시', '면', '여기', '수'] 12# 빈도 탐색counter = Counter(nouns) 1counter.most_common(10) [('호텔', 803), ('수', 498), ('것', 436), ('방', 330), ('위치', 328), ('우리', 327), ('곳', 320), ('공항', 307), ('직원', 267), ('매우', 264)] &gt;&gt; 한글자 명사 제거 위 결과에서 보이듯이, 두 글자 키워드가 대부분 의미 있는 단어지만, ‘수’, ‘것’, '곳’과 같은 한 글자 키워드는 분석에 딱히 좋은 영향을 미치지 않은 것으로 보입니다. 그래서 우리는 한글자 명사를 제거해보도록 하겠습니다. 12available_counter = Counter({x: counter[x] for x in counter if len(x) &gt; 1})available_counter.most_common(10) [('호텔', 803), ('위치', 328), ('우리', 327), ('공항', 307), ('직원', 267), ('매우', 264), ('가격', 245), ('객실', 244), ('시설', 215), ('제주', 192)] 이제 한글자 키워드 모두 제거됐습니다. 하지만 “우리”, “매우” 와 같은 실질적인 의미가 없고 꾸민 역할을 하는 불용어들 아직 존재합니다. 한국어 불용어 사전을 정의하여 불용어도 제거해줄게요. 3-3. 불용어 사전 RANKS NL에 제공해주는 한국어 불용어 사전을 활용하겠습니다. 12stopwords = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/korean_stopwords.txt\").values.tolist()stopwords[:10] [['휴'], ['아이구'], ['아이쿠'], ['아이고'], ['어'], ['나'], ['우리'], ['저희'], ['따라'], ['의해']] 이 외에도 우리가 분석하고자 하는 데이터셋에 특화된 불용어들이 있습니다. 예를 들면: “제주”, “호텔”, “숙소” 등. 이런 단어들도 불용어 사전에 추가해보도록 할게요. 123jeju_hotel_stopwords = ['제주', '제주도', '호텔', '리뷰', '숙소', '여행', '트립']for word in jeju_hotel_stopwords: stopwords.append(word) 3-4. Word Count &gt;&gt; BoW 벡터 생성 123456789101112131415from sklearn.feature_extraction.text import CountVectorizerdef text_cleaning(text): hangul = re.compile('[^ ㄱ-ㅣ 가-힣]') # 정규 표현식 처리 result = hangul.sub('', text) okt = Okt() # 형태소 추출 nouns = okt.nouns(result) nouns = [x for x in nouns if len(x) &gt; 1] # 한글자 키워드 제거 nouns = [x for x in nouns if x not in stopwords] # 불용어 제거 return nounsvect = CountVectorizer(tokenizer = lambda x: text_cleaning(x))bow_vect = vect.fit_transform(df['text'].tolist())word_list = vect.get_feature_names()count_list = bow_vect.toarray().sum(axis=0) 12# 단어 리스트word_list ['가가', '가게', '가격', '가격표', '가구', '가급', '가기', '가까이', '가끔', '가능', '가도', '가동', '가두', '가득', '가든', '가라', '가량', '가려움', '가로', '가면', '가몬', '가무', '가물', '가미', '가방', '가버', '가성', '가세', '가스레인지', '가스렌지', '가슴', '가시', '가신', '가야', '가옥', '가요', '가용', '가운데', '가을', '가인', '가장', '가정', '가정식', '가족', '가지', '가짓수', '가차', '가치', '가품', '각각', '각오', '각자', '각종', '각층', '간격', '간곳', '간다', '간단', '간만', '간식', '간이', '간주', '간직', '간판', '간혹', '갈껄', '갈비', '갈비탕', '갈수', '갈수록', '감각', '감동', '감명', '감사', '감상', '감소', '감안', '감자', '감히', '갑인', '갑자기', '갑작스레', '강남', '강력', '강아지', '강압', '강제', '강조', '강추', '개념', '개략', '개미', '개발', '개방', '개별', '개보', '개뿔', '개선', '개수대', '개월', '개인', '개인실', '개인정보', '개조', '개층', '객수', '객실', '갤러리', '갱스터', '거기', '거나', '거두', '거론', '거르세', '거름', '거리', '거린데', '거림', '거문도', '거미', '거부', '거실', '거여', '거울', '거위', '거의', '거절', '거주', '거지', '거참', '거품', '걱정', '건가', '건강', '건너', '건너편', '건물', '건의', '건조', '건조기', '건조대', '건축', '걷기', '걸음', '걸이', '걸즈', '검사', '검색', '검정색', '검토', '것임', '겉보기', '게다가', '게스트', '게스트하우스', '게임', '게재', '겐찮은듯', '겔상', '겨우', '겨울', '겨울철', '격인', '격하', '결과', '결론', '결석', '결재', '결정', '결제', '결코', '결함', '결항', '결혼', '결혼식', '겸비', '겸용', '겹겹', '경고', '경관', '경내', '경로', '경매', '경영', '경영학', '경우', '경쟁', '경쟁력', '경찰', '경치', '경험', '계단', '계란', '계란후라이', '계산', '계속', '계정', '계획', '고가', '고간', '고객', '고급', '고기', '고기국수', '고깃배', '고내포구', '고려', '고루', '고무줄', '고문', '고민', '고봉', '고분', '고생', '고속', '고속도로', '고아', '고양이', '고여', '고오', '고요', '고유', '고작', '고장', '고정', '고층', '고통', '고트', '고함', '고해', '곡부', '곧바로', '곧장', '골드스타', '골목', '골목길', '골퍼', '골프', '골프장', '골프텔', '곰팡이', '곱슬', '곳곳', '곳곳이', '곳도', '곳임', '공간', '공감', '공개', '공공', '공공장소', '공급', '공기', '공덕', '공률', '공물', '공사', '공시', '공실이', '공연', '공연장', '공영', '공용', '공원', '공유', '공짜', '공차', '공터', '공포', '공항', '과거', '과물', '과언', '과일', '과장', '관경', '관계', '관계자', '관광', '관광객', '관광명소', '관광지', '관덕정', '관련', '관리', '관리인', '관리자', '관리직', '관음사', '관해', '광경', '광고', '광천수', '괴체', '교대', '교수', '교외', '교욱받', '교육', '교체', '교통', '교환', '교회', '구가', '구경', '구경만', '구관', '구글', '구나', '구내', '구덩이', '구도', '구두', '구둣주걱', '구들장', '구류', '구만', '구매', '구멍', '구별', '구분', '구비', '구사', '구색', '구석', '구석구석', '구성', '구식', '구암', '구역', '구역질', '구이', '구입', '구조', '구축', '국가', '국내', '국도', '국립', '국수', '국적', '국제', '국제공항', '군더더기', '군데', '군데군데', '굳럭', '굳이', '굿굿', '굿굿굿', '굿앤굿', '굿임', '권내', '권장', '권한', '귀중', '규모', '규율', '규칙', '균형', '그거', '그것', '그게', '그냥', '그네', '그녀', '그다음', '그다지', '그닥', '그대로', '그동안', '그때', '그랜드', '그레이스', '그로', '그룹', '그릇', '그린', '그림', '극복', '극악', '근래', '근무', '근본', '근육통', '근처', '근해', '글래드', '글쎄', '금고', '금늘', '금능', '금릉', '금방', '금속', '금액', '금연', '금요일', '금은', '금지', '금토일', '급상승', '급속', '기간', '기계', '기구', '기기', '기념일', '기능', '기대', '기도', '기류', '기리', '기반', '기본', '기부', '기분', '기사', '기상', '기소', '기숙사', '기술', '기술자', '기억', '기업', '기여', '기용', '기우', '기입', '기적', '기전', '기점', '기존', '기준', '기지', '기타', '기프트샵', '기호', '기회', '기후', '긴장', '길가', '길림', '길목', '길이', '김녕', '김녕해변', '김밥', '김씨', '김치', '김포공항', '까페', '깜빡', '깜짝', '깨끗', '깨끗깔끔', '께빵', '꼭대기', '꽃꺽으러', '꽃사슴', '꾸러미', '꾸밈', '꿀잠', '끝내기', '끼리', '나기', '나누기', '나니', '나라', '나름', '나머지', '나머진', '나무', '나물', '나보', '나오니', '나우', '나은', '나이', '나이트', '나이프', '나중', '나탈리', '낙후', '낚시', '난로', '난리', '난방', '난입', '난타', '날수', '날씨', '날짜', '남녀', '남성', '남아', '남자', '남자친구', '남짓', '남쪽', '남편', '낭만', '내겐', '내내', '내년', '내부', '내부시', '내시', '내야', '내외', '내용', '내의', '내인', '내일', '냄비', '냄새', '냉동', '냉장고', '너븐팡', '넓이', '네스프레소', '네이버', '년대', '년전', '녔던', '노곤', '노래', '노래방', '노력', '노리', '노블레스', '노선', '노을', '노크', '노트북', '노화', '노후', '녹물', '녹음', '녹지', '논평', '놀러와', '놀수', '놀이', '놀이기구', '놀이터', '농부가', '농장', '높이', '놨더군', '누가', '누구', '누군가', '누락', '누리', '누울', '눈앞', '뉴타운', '느낌', '는걸', '늘송', '능리', '다가', '다그', '다다미', '다라', '다락방', '다른', '다른사람', '다리미', '다만', '다미', '다발', '다섯', '다소', '다수', '다시', '다운', '다음', '다이지', '다인', '다정', '다행', '단계', '단기', '단면', '단어', '단위', '단점', '단정', '단지', '단체', '달걀', '달걀프라이', '달라', '달러', '달리', '달성', '닭머르', '담당', '담배', '담소', '담요', '답변', '당구', '당근', '당나귀', '당분간', '당시', '당신', '당일', '당황', '대가', '대가족', '대고', '대관령', '대답', '대당', '대도', '대도시', '대뜸', '대략', '대로', '대리', '대명', '대박', '대부분', '대비', '대상', '대신', '대안', '대여', '대요', '대욕', '대응', '대의', '대입', '대적', '대접', '대정', '대중', '대중교통', '대처', '대체', '대충', '대포', '대표', '대하', '대한', '대한민국', '대한항공', '대해', '대행', '대형', '대화', '대환영', '댐핑할', '더군다나', '더더', '더러', '더블', '더블베드', '더욱', '더원', '덕림사', '덕분', '덕택', '던데', '덮어놓고', '데리', '데스크', '데스크톱', '데이', '데이즈', '델문', '도구', '도달', '도대체', '도도', '도둑', '도로', '도록', '도리어', '도미', '도보', '도서관', '도시', '도시락', '도심', '도심지', '도어', '도어락', '도움', '도움말', '도일', '도정', '도중', '도착', '도처', '도청', '도쿄', '도크', '독립', '독서', '독점', '독채', '돈까스', '돌담', '돌잔치', '동계', '동광양', '동굴', '동남', '동남아', '동네', '동도', '동료', '동문', '동물', '동물원', '동반', '동부', '동북', '동생', '동선', '동시', '동안', '동영상', '동의', '동이', '동인', '동작', '동전', '동정', '동쪽', '돼지', '돼지고기', '됏다', '될껀', '될껄', '두루', '두번째', '두봉', '두부', '두엄', '두운', '두툼', '둘러보기', '둘이서', '둘째', '둥근지붕', '뒤쪽', '뒤척', '뒷골목', '뒷마당', '뒷문', '뒷쪽', '드네', '드라이기', '드라이버', '드라이브', '드라이어', '드롭', '드릴', '드타', '드하', '득시', '듭니', '듯이', '듯해', '등급', '등대', '등등', '등반', '등산', '등정후', '디귿', '디너', '디럭스', '디봇', '디셈버', '디자이너', '디자인', '디저트', '디제이', '따라서', '때로는', '때문', '떡국', '또오', '또한', '뚜벅', '뜨근뜨근', '뜨내기', '라그', '라마', '라며', '라면', '라서', '라스베가스', '라우터', '라운지', '라이센스', '라커룸', '락스', '락심이', '락커', '락타', '란딩', '랍니', '랜드', '랜트', '랜트카', '랜트하', '램프', '러닝', '러브', '럭셔리', '런가', '렀는데', '렀습니', '렀으', '레노', '레드', '레벨', '레비', '레스토랑', '레시', '레오', '레이', '레이크', '레인지', '레저', '레프트', '렌즈', '렌탈업체', '렌터', '렌터카', '렌트', '렌트카', '려고', '려운', '로고', '로그', '로만', '로맨틱', '로부터', '로비', '로서', '로션', '로얄', '로움', '로컬', '로터리', '로프트', '롯데', '롯데리아', '롱보드', '루온토', '루트', '루프', '룸메이트', '룸바닥', '룸상태', '룸서비스', '룸안', '룸키', '룸타입', '를위', '리가', '리기', '리넨', '리뉴', '리뉴얼', '리더', '리도', '리모콘', '리베라', '리베로', '리빙룸', '리셉션', '리움', '리젠시', '리조트', '리지', '리치', '리트', '리플렛', '린스', '링잉', '마누카꿀', '마늘', '마다', '마담', '마당', '마레', '마련', '마루', '마리', '마모', '마무리', '마사지', '마술', '마스코트', '마스크', '마스터', '마시기', '마안', '마운트', '마을', '마음', '마이너스', '마인드', '마일리지', '마자', '마저', '마주', '마지막', '마지막여행', '마차', '마찬가지', '마치', '마침내', '마켓', '마트', '마틸다', '막걸리', '만끽', '만난', '만날', '만남', '만다린', '만두', '만들기', '만료', '만약', '만요', '만원', '만점', '만족', '만족도', '만천원', '만큼', '만하', '만해', '만화책', '말레이시아', '말레이시아인', '말로', '말리', '말씀', '말투', '말함', '맘스', '맛사지', '맛잇엇어', '맛집', '망각', '망신', '망치', '맞은편', '맞이', '매년', '매니', '매니저', '매달', '매듭', '매력', '매번', '매우', '매운탕', '매일', '매장', '매점', '매칭', '매트', '매트리스', '매트릭스', '매하', '맥도날드', '맥도널드', '맥주', '맥주잔', '맨발', '머리', '머리카락', '머신', '머싱', '먹거리', '먹기', '먹방', '먹이', '먼저', '먼지', '멀리', '메가박스', '메뉴', '메리', '메리어트', '메시지', ...] 12# 각 단어가 전체 리뷰중에 등장한 총 횟수count_list array([ 4, 8, 245, ..., 1, 7, 14], dtype=int64) 12# 각 단어의 리뷰별 등장 횟수bow_vect.toarray() array([[0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], ..., [0, 0, 0, ..., 0, 0, 0], [0, 0, 2, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]], dtype=int64) 1bow_vect.shape (1001, 3599) 1234# \"단어\" - \"총 등장 횟수\" Matchingword_count_dict = dict(zip(word_list, count_list))word_count_dict {'가가': 4, '가게': 8, '가격': 245, '가격표': 1, '가구': 8, '가급': 1, '가기': 20, '가까이': 20, '가끔': 5, '가능': 10, '가도': 7, '가동': 2, '가두': 1, '가득': 2, '가든': 1, '가라': 3, '가량': 1, '가려움': 1, '가로': 2, '가면': 14, '가몬': 1, '가무': 1, '가물': 1, '가미': 1, '가방': 4, '가버': 1, '가성': 49, '가세': 3, '가스레인지': 1, '가스렌지': 1, '가슴': 1, '가시': 4, '가신': 3, '가야': 10, '가옥': 1, '가요': 5, '가용': 1, '가운데': 3, '가을': 4, '가인': 1, '가장': 42, '가정': 4, '가정식': 2, '가족': 94, '가지': 55, '가짓수': 3, '가차': 1, '가치': 15, '가품': 1, '각각': 7, '각오': 1, '각자': 2, '각종': 3, '각층': 1, '간격': 2, '간곳': 1, '간다': 4, '간단': 1, '간만': 1, '간식': 5, '간이': 3, '간주': 1, '간직': 1, '간판': 2, '간혹': 1, '갈껄': 1, '갈비': 1, '갈비탕': 1, '갈수': 7, '갈수록': 1, '감각': 1, '감동': 12, '감명': 1, '감사': 6, '감상': 3, '감소': 1, '감안': 5, '감자': 1, '감히': 1, '갑인': 1, '갑자기': 4, '갑작스레': 1, '강남': 1, '강력': 9, '강아지': 7, '강압': 2, '강제': 1, '강조': 1, '강추': 8, '개념': 1, '개략': 1, '개미': 1, '개발': 3, '개방': 2, '개별': 3, '개보': 1, '개뿔': 1, '개선': 4, '개수대': 1, '개월': 1, '개인': 23, '개인실': 1, '개인정보': 2, '개조': 5, '개층': 1, '객수': 1, '객실': 244, '갤러리': 2, '갱스터': 1, '거기': 24, '거나': 6, '거두': 1, '거론': 1, '거르세': 1, '거름': 2, '거리': 156, '거린데': 1, '거림': 1, '거문도': 1, '거미': 1, '거부': 4, '거실': 29, '거여': 1, '거울': 5, '거위': 1, '거의': 27, '거절': 3, '거주': 1, '거지': 1, '거참': 1, '거품': 2, '걱정': 27, '건가': 1, '건강': 2, '건너': 8, '건너편': 11, '건물': 55, '건의': 1, '건조': 2, '건조기': 3, '건조대': 2, '건축': 2, '걷기': 2, '걸음': 3, '걸이': 2, '걸즈': 1, '검사': 1, '검색': 13, '검정색': 1, '검토': 3, '것임': 3, '겉보기': 2, '게다가': 5, '게스트': 25, '게스트하우스': 30, '게임': 2, '게재': 1, '겐찮은듯': 1, '겔상': 1, '겨우': 3, '겨울': 15, '겨울철': 2, '격인': 1, '격하': 1, '결과': 2, '결론': 3, '결석': 1, '결재': 2, '결정': 12, '결제': 1, '결코': 2, '결함': 1, '결항': 2, '결혼': 1, '결혼식': 2, '겸비': 1, '겸용': 1, '겹겹': 2, '경고': 1, '경관': 3, '경내': 1, '경로': 1, '경매': 1, '경영': 2, '경영학': 1, '경우': 41, '경쟁': 1, '경쟁력': 2, '경찰': 2, '경치': 17, '경험': 26, '계단': 4, '계란': 11, '계란후라이': 1, '계산': 2, '계속': 23, '계정': 1, '계획': 13, '고가': 1, '고간': 1, '고객': 14, '고급': 8, '고기': 8, '고기국수': 1, '고깃배': 1, '고내포구': 1, '고려': 9, '고루': 1, '고무줄': 1, '고문': 2, '고민': 9, '고봉': 1, '고분': 2, '고생': 1, '고속': 2, '고속도로': 2, '고아': 1, '고양이': 3, '고여': 1, '고오': 1, '고요': 3, '고유': 2, '고작': 1, '고장': 3, '고정': 3, '고층': 2, '고통': 1, '고트': 1, '고함': 2, '고해': 1, '곡부': 1, '곧바로': 2, '곧장': 2, '골드스타': 1, '골목': 6, '골목길': 2, '골퍼': 2, '골프': 9, '골프장': 5, '골프텔': 2, '곰팡이': 14, '곱슬': 1, '곳곳': 4, '곳곳이': 1, '곳도': 8, '곳임': 2, '공간': 73, '공감': 1, '공개': 1, '공공': 2, '공공장소': 1, '공급': 2, '공기': 8, '공덕': 1, '공률': 1, '공물': 1, '공사': 12, '공시': 1, '공실이': 1, '공연': 8, '공연장': 2, '공영': 1, '공용': 8, '공원': 17, '공유': 5, '공짜': 1, '공차': 1, '공터': 1, '공포': 1, '공항': 307, '과거': 1, '과물': 2, '과언': 1, '과일': 9, '과장': 2, '관경': 1, '관계': 3, '관계자': 2, '관광': 38, '관광객': 15, '관광명소': 4, '관광지': 12, '관덕정': 4, '관련': 6, '관리': 39, '관리인': 1, '관리자': 3, '관리직': 2, '관음사': 1, '관해': 5, '광경': 2, '광고': 4, '광천수': 1, '괴체': 1, '교대': 1, '교수': 1, '교외': 1, '교욱받': 1, '교육': 5, '교체': 7, '교통': 30, '교환': 2, '교회': 2, '구가': 3, '구경': 7, '구경만': 1, '구관': 4, '구글': 2, '구나': 2, '구내': 1, '구덩이': 1, '구도': 1, '구두': 2, '구둣주걱': 1, '구들장': 1, '구류': 1, '구만': 2, '구매': 14, '구멍': 7, '구별': 1, '구분': 3, '구비': 11, '구사': 6, '구색': 2, '구석': 2, '구석구석': 5, '구성': 7, '구식': 1, '구암': 1, '구역': 3, '구역질': 2, '구이': 1, '구입': 5, '구조': 12, '구축': 1, '국가': 3, '국내': 1, '국도': 1, '국립': 1, '국수': 3, '국적': 3, '국제': 11, '국제공항': 1, '군더더기': 1, '군데': 8, '군데군데': 2, '굳럭': 1, '굳이': 7, '굿굿': 1, '굿굿굿': 1, '굿앤굿': 1, '굿임': 1, '권내': 1, '권장': 5, '권한': 2, '귀중': 1, '규모': 12, '규율': 2, '규칙': 1, '균형': 1, '그거': 3, '그것': 70, '그게': 1, '그냥': 42, '그네': 1, '그녀': 20, '그다음': 1, '그다지': 4, '그닥': 4, '그대로': 11, '그동안': 4, '그때': 3, '그랜드': 6, '그레이스': 3, '그로': 3, '그룹': 9, '그릇': 3, '그린': 1, '그림': 4, '극복': 1, '극악': 1, '근래': 1, '근무': 4, '근본': 1, '근육통': 1, '근처': 164, '근해': 1, '글래드': 3, '글쎄': 2, '금고': 2, '금늘': 1, '금능': 2, '금릉': 1, '금방': 3, '금속': 1, '금액': 8, '금연': 6, '금요일': 1, '금은': 1, '금지': 1, '금토일': 1, '급상승': 1, '급속': 1, '기간': 3, '기계': 4, '기구': 2, '기기': 4, '기념일': 1, '기능': 4, '기대': 15, '기도': 7, '기류': 3, '기리': 1, '기반': 4, '기본': 45, '기부': 1, '기분': 29, '기사': 8, '기상': 1, '기소': 1, '기숙사': 7, '기술': 3, '기술자': 1, '기억': 11, '기업': 2, '기여': 1, '기용': 1, '기우': 1, '기입': 1, '기적': 1, '기전': 1, '기점': 1, '기존': 1, '기준': 4, '기지': 1, '기타': 5, '기프트샵': 2, '기호': 1, '기회': 11, '기후': 1, '긴장': 1, '길가': 4, '길림': 1, '길목': 2, '길이': 2, '김녕': 1, '김녕해변': 1, '김밥': 1, '김씨': 1, '김치': 4, '김포공항': 1, '까페': 5, '깜빡': 1, '깜짝': 3, '깨끗': 5, '깨끗깔끔': 1, '께빵': 1, '꼭대기': 2, '꽃꺽으러': 1, '꽃사슴': 1, '꾸러미': 1, '꾸밈': 1, '꿀잠': 2, '끝내기': 1, '끼리': 18, '나기': 2, '나누기': 6, '나니': 1, '나라': 2, '나름': 13, '나머지': 6, '나머진': 1, '나무': 13, '나물': 1, '나보': 1, '나오니': 2, '나우': 1, '나은': 5, '나이': 3, '나이트': 2, '나이프': 2, '나중': 8, '나탈리': 2, '낙후': 3, '낚시': 3, '난로': 3, '난리': 3, '난방': 30, '난입': 2, '난타': 9, '날수': 1, '날씨': 12, '날짜': 1, '남녀': 1, '남성': 2, '남아': 5, '남자': 6, '남자친구': 2, '남짓': 1, '남쪽': 1, '남편': 10, '낭만': 2, '내겐': 1, '내내': 8, '내년': 1, '내부': 40, '내부시': 1, '내시': 1, '내야': 1, '내외': 2, '내용': 2, '내의': 2, '내인': 1, '내일': 2, '냄비': 1, '냄새': 58, '냉동': 1, '냉장고': 35, '너븐팡': 2, '넓이': 1, '네스프레소': 1, '네이버': 3, '년대': 2, '년전': 1, '녔던': 1, '노곤': 2, '노래': 1, '노래방': 3, '노력': 8, '노리': 1, '노블레스': 1, '노선': 2, '노을': 1, '노크': 1, '노트북': 2, '노화': 1, '노후': 6, '녹물': 1, '녹음': 4, '녹지': 1, '논평': 1, '놀러와': 2, '놀수': 1, '놀이': 3, '놀이기구': 2, '놀이터': 2, '농부가': 1, '농장': 3, '높이': 2, '놨더군': 1, '누가': 5, '누구': 5, '누군가': 4, '누락': 1, '누리': 1, '누울': 2, '눈앞': 3, '뉴타운': 1, '느낌': 49, '는걸': 2, '늘송': 3, '능리': 1, '다가': 1, '다그': 1, '다다미': 1, '다라': 1, '다락방': 1, '다른': 88, '다른사람': 1, '다리미': 2, '다만': 54, '다미': 1, '다발': 1, '다섯': 1, '다소': 21, '다수': 2, '다시': 93, '다운': 4, '다음': 102, '다이지': 1, '다인': 1, '다정': 2, '다행': 3, '단계': 4, '단기': 1, '단면': 1, '단어': 2, '단위': 2, '단점': 40, '단정': 1, '단지': 16, '단체': 19, '달걀': 3, '달걀프라이': 1, '달라': 13, '달러': 7, '달리': 6, '달성': 1, '닭머르': 1, '담당': 2, '담배': 19, '담소': 2, '담요': 1, '답변': 3, '당구': 2, '당근': 2, '당나귀': 2, '당분간': 1, '당시': 1, '당신': 21, '당일': 3, '당황': 7, '대가': 3, '대가족': 2, '대고': 1, '대관령': 1, '대답': 3, '대당': 1, '대도': 3, '대도시': 2, '대뜸': 1, '대략': 6, '대로': 8, '대리': 3, '대명': 1, '대박': 3, '대부분': 23, '대비': 64, '대상': 1, '대신': 8, '대안': 2, '대여': 3, '대요': 2, '대욕': 1, '대응': 2, '대의': 4, '대입': 1, '대적': 1, '대접': 1, '대정': 1, '대중': 9, '대중교통': 6, '대처': 2, '대체': 2, '대충': 3, '대포': 1, '대표': 4, '대하': 1, '대한': 19, '대한민국': 2, '대한항공': 1, '대해': 21, '대행': 1, '대형': 10, '대화': 11, '대환영': 1, '댐핑할': 1, '더군다나': 1, '더더': 2, '더러': 1, '더블': 29, '더블베드': 4, '더욱': 5, '더원': 1, '덕림사': 1, '덕분': 6, '덕택': 3, '던데': 1, '덮어놓고': 1, '데리': 5, '데스크': 30, '데스크톱': 1, '데이': 1, '데이즈': 1, '델문': 2, '도구': 18, '도달': 3, '도대체': 1, '도도': 1, '도둑': 1, '도로': 41, '도록': 1, '도리어': 1, '도미': 9, '도보': 35, '도서관': 1, '도시': 18, '도시락': 4, '도심': 14, '도심지': 1, '도어': 3, '도어락': 1, '도움': 51, '도움말': 1, '도일': 1, '도정': 1, '도중': 2, '도착': 69, '도처': 1, '도청': 2, '도쿄': 1, '도크': 1, '독립': 6, '독서': 1, '독점': 1, '독채': 5, '돈까스': 1, '돌담': 1, '돌잔치': 1, '동계': 1, '동광양': 1, '동굴': 1, '동남': 1, '동남아': 2, '동네': 7, '동도': 1, '동료': 2, '동문': 14, '동물': 9, '동물원': 2, '동반': 3, '동부': 2, '동북': 1, '동생': 3, '동선': 3, '동시': 7, '동안': 48, '동영상': 1, '동의': 3, '동이': 1, '동인': 2, '동작': 1, '동전': 1, '동정': 1, '동쪽': 5, '돼지': 16, '돼지고기': 4, '됏다': 1, '될껀': 1, '될껄': 1, '두루': 2, '두번째': 2, '두봉': 2, '두부': 1, '두엄': 1, '두운': 2, '두툼': 1, '둘러보기': 1, '둘이서': 3, '둘째': 5, '둥근지붕': 1, '뒤쪽': 4, '뒤척': 1, '뒷골목': 1, '뒷마당': 1, '뒷문': 1, '뒷쪽': 2, '드네': 1, '드라이기': 7, '드라이버': 1, '드라이브': 11, '드라이어': 11, '드롭': 1, '드릴': 1, '드타': 1, '드하': 2, '득시': 1, '듭니': 5, '듯이': 1, '듯해': 1, '등급': 3, '등대': 3, '등등': 8, '등반': 3, '등산': 6, '등정후': 1, '디귿': 1, '디너': 4, '디럭스': 6, '디봇': 1, '디셈버': 2, '디자이너': 1, '디자인': 11, '디저트': 1, '디제이': 2, '따라서': 4, '때로는': 1, '때문': 112, '떡국': 2, '또오': 1, '또한': 76, '뚜벅': 3, '뜨근뜨근': 1, '뜨내기': 1, '라그': 1, '라마': 4, '라며': 3, '라면': 15, '라서': 1, '라스베가스': 1, '라우터': 1, '라운지': 9, '라이센스': 1, '라커룸': 1, '락스': 2, '락심이': 1, '락커': 2, '락타': 1, '란딩': 1, '랍니': 1, '랜드': 1, '랜트': 1, '랜트카': 1, '랜트하': 1, '램프': 2, '러닝': 1, '러브': 3, '럭셔리': 5, '런가': 2, '렀는데': 1, '렀습니': 2, '렀으': 1, '레노': 1, '레드': 1, '레벨': 1, '레비': 1, '레스토랑': 64, '레시': 1, '레오': 2, '레이': 1, '레이크': 1, '레인지': 3, '레저': 1, '레프트': 1, '렌즈': 1, '렌탈업체': 1, '렌터': 1, '렌터카': 4, '렌트': 17, '렌트카': 8, '려고': 4, '려운': 1, '로고': 1, '로그': 3, '로만': 1, '로맨틱': 2, '로부터': 2, '로비': 49, '로서': 2, '로션': 1, '로얄': 1, '로움': 1, '로컬': 3, '로터리': 1, '로프트': 1, '롯데': 6, '롯데리아': 2, '롱보드': 1, '루온토': 1, '루트': 1, '루프': 17, '룸메이트': 1, '룸바닥': 1, '룸상태': 2, '룸서비스': 9, '룸안': 1, '룸키': 2, '룸타입': 1, '를위': 1, '리가': 2, '리기': 1, '리넨': 1, '리뉴': 1, '리뉴얼': 1, '리더': 1, '리도': 1, '리모콘': 3, '리베라': 2, '리베로': 1, '리빙룸': 2, '리셉션': 29, '리움': 2, '리젠시': 1, '리조트': 53, '리지': 1, '리치': 1, '리트': 1, '리플렛': 1, '린스': 2, '링잉': 1, '마누카꿀': 1, '마늘': 1, '마다': 1, '마담': 2, '마당': 2, '마레': 2, '마련': 7, '마루': 5, '마리': 11, '마모': 1, '마무리': 3, '마사지': 4, '마술': 1, '마스코트': 2, '마스크': 1, '마스터': 2, '마시기': 2, '마안': 1, '마운트': 1, '마을': 9, '마음': 31, '마이너스': 1, '마인드': 4, '마일리지': 2, '마자': 2, '마저': 1, '마주': 4, '마지막': 21, '마지막여행': 1, '마차': 1, '마찬가지': 4, '마치': 12, '마침내': 3, '마켓': 9, '마트': 14, '마틸다': 2, '막걸리': 1, '만끽': 1, '만난': 1, '만날': 1, '만남': 1, '만다린': 2, '만두': 1, '만들기': 1, '만료': 1, '만약': 6, '만요': 1, '만원': 20, '만점': 1, '만족': 12, '만족도': 1, '만천원': 1, '만큼': 2, '만하': 2, '만해': 2, '만화책': 1, '말레이시아': 1, '말레이시아인': 1, '말로': 2, '말리': 1, '말씀': 7, '말투': 3, '말함': 2, '맘스': 1, '맛사지': 1, '맛잇엇어': 1, '맛집': 25, '망각': 1, '망신': 2, '망치': 2, '맞은편': 7, '맞이': 5, '매년': 2, '매니': 1, '매니저': 3, '매달': 1, '매듭': 1, '매력': 5, '매번': 1, '매우': 265, '매운탕': 1, '매일': 36, '매장': 3, '매점': 3, '매칭': 1, '매트': 5, '매트리스': 13, '매트릭스': 1, '매하': 1, '맥도날드': 5, '맥도널드': 1, '맥주': 22, '맥주잔': 1, '맨발': 3, '머리': 7, '머리카락': 4, '머신': 3, '머싱': 1, '먹거리': 7, '먹기': 2, '먹방': 1, '먹이': 3, '먼저': 3, '먼지': 3, '멀리': 14, '메가박스': 1, '메뉴': 15, '메리': 1, '메리어트': 1, '메시지': 1, ...} 3-5. TF-IDF 적용 &gt;&gt; TF-IDF 변환 Bag of Words 벡터에 대해서 TF-IDF변환 진행합니다. 1234from sklearn.feature_extraction.text import TfidfTransformertfidf_vectorizer = TfidfTransformer()tf_idf_vect = tfidf_vectorizer.fit_transform(bow_vect) 1print(tf_idf_vect.shape) (1001, 3599) 변환 후 1001*3599 matrix가 출력됩니다. 여기서 한 행(row)은 한 리뷰를 의미하고 한 열(column)은 한 단어를 의미합니다. 12# 첫 번째 리뷰에서의 단어 중요도(TF-IDF 값) -- 0이 아닌 것만 출력print(tf_idf_vect[0]) (0, 3588) 0.35673213299026796 (0, 2927) 0.2582351368959594 (0, 2925) 0.320251680858207 (0, 2866) 0.48843555212083145 (0, 2696) 0.23004450213863206 (0, 2311) 0.15421663035331626 (0, 1584) 0.48843555212083145 (0, 1527) 0.2928089229786031 (0, 790) 0.2528176728459411 123# 첫 번째 리뷰에서 모든 단어의 중요도 -- 0인 값까지 포함print(tf_idf_vect[0].toarray().shape)print(tf_idf_vect[0].toarray()) (1, 3599) [[0. 0. 0. ... 0. 0. 0.]] &gt;&gt; “벡터” - “단어” mapping 1vect.vocabulary_ {'집중': 2866, '휴식': 3588, '제공': 2696, '위치': 2311, '선정': 1584, '또한': 790, '청소': 2927, '청결': 2925, '상태': 1527, '이상': 2392, '침대': 3022, '이불': 2388, '침구': 3021, '교체': 299, '어메니티': 2013, '보강': 1296, '베스트': 1277, '웨스턴': 2299, '회원': 3564, '경우': 185, '객실': 106, '층수': 3009, '요청': 2234, '적극': 2606, '반영': 1188, '지인': 2837, '소개': 1629, '처음': 2910, '당황': 611, '세면': 1607, '도구': 675, '잠옷': 2555, '필수': 3358, '그것': 361, '정도': 2673, '다음': 578, '여기': 2074, '박만': 1171, '저녁': 2595, '맥주': 981, '한잔': 3414, '렌트': 838, '뚜벅': 791, '바로': 1159, '버스': 1247, '정류': 2676, '도착': 697, '가방': 24, '일찍': 2487, '정비': 2685, '방이': 1225, '입실': 2500, '업그레이드': 2038, '직원': 2849, '정말': 2680, '바다': 1148, '전망': 2623, '전일': 2636, '함덕': 3425, '대명': 624, '콘도': 3091, '실내': 1861, '분위기': 1384, '손님': 1659, '가장': 40, '배치': 1241, '대해': 651, '대응': 634, '써비스': 1889, '조식': 2730, '부분': 1351, '신경': 1838, '아주': 1922, '특급': 3208, '트랜디': 3191, '고민': 210, '흔적': 3593, '여름': 2082, '수영장': 1700, '사용': 1483, '보고': 1297, '엄마': 2035, '가격': 2, '대비': 627, '주위': 2769, '마트': 924, '식당': 1826, '시장': 1816, '방문': 1217, '의사': 2361, '동안': 726, '정해진': 2695, '휘슬': 3580, '공항': 269, '생각': 1539, '시설': 1809, '모두': 1028, '친절': 3017, '모드': 1029, '마지막': 917, '마무리': 900, '테라스': 3156, '전경': 2612, '인근': 2427, '재래시장': 2583, '야시장': 1979, '이용도': 2402, '이용': 2400, '일차': 2488, '휘슬락': 3581, '체크': 2940, '주변': 2761, '여친': 2094, '추억': 2975, '가성': 26, '추천': 2977, '후회': 3575, '예전': 2145, '그랜드': 372, '저희': 2605, '아이': 1918, '돌잔치': 708, '다정': 581, '했었더랬': 3470, '전통': 2642, '메종': 1004, '글래드': 387, '서비스': 1563, '매우': 969, '합리': 3428, '대의': 635, '명절': 1018, '숙박': 1721, '아티': 1928, '백미': 1243, '커피': 3061, '베이커리': 1280, '가족': 43, '플러스': 3342, '지금': 2816, '우선': 2257, '접근성': 2664, '쇼핑': 1671, '만족도': 940, '최고': 2957, '무엇': 1078, '기억': 423, '우리': 2251, '찾기': 2902, '교통': 300, '이틀': 2418, '정원': 2691, '거기': 109, '겨울': 160, '친구': 3016, '놀러와': 541, '투숙': 3185, '야외': 1981, '방향': 1235, '야간': 1976, '조명': 2726, '순간': 1723, '대접': 638, '실명': 1868, '거론': 112, '프론트': 3337, '이름': 2378, '안나': 1938, '기분': 416, '모습': 1037, '첫날': 2921, '스타트': 1761, '다시': 576, '선물': 1578, '카운터': 3032, '안내': 1939, '디너': 777, '기회': 438, '미니바': 1121, '무료': 1067, '최근': 2959, '관광지': 281, '숙고': 1719, '강추': 88, '야경': 1977, '일부러': 2475, '일어나서': 2476, '동네': 714, '바퀴': 1168, '먹방': 990, '신라': 1843, '퀄리티': 3105, '모녀': 1024, '제주시': 2711, '위해': 2313, '선택': 1586, '오픈': 2180, '예약': 2143, '대로': 622, '거리': 115, '더군다나': 657, '셔틀버스': 1627, '운행': 2271, '데스크': 670, '차안': 2880, '분도': 1374, '인상': 2438, '트윈': 3201, '사이즈': 1489, '만족': 939, '스타': 1758, '가짓수': 45, '느낌': 558, '화장실': 3538, '내부': 505, '인테리어': 2455, '질적': 2859, '이건': 2368, '개인': 100, '취향': 3005, '구비': 321, '과일': 273, '나이프': 480, '포크': 3295, '부탁': 1364, '준비': 2786, '표방': 3305, '모텔': 1046, '결론': 165, '훌륭': 3577, '시간': 1799, '슈페리어킹룸': 1737, '하루': 3376, '후기': 3570, '지은지': 2836, '얼마': 2033, '건물': 136, '약간': 1985, '유럽': 2318, '스타일': 1760, '그림': 378, '조각': 2715, '복도': 1323, '전시': 2633, '전부': 2630, '카펫': 3039, '등급': 770, '다른': 567, '이서': 2394, '자기': 2512, '조금': 2722, '외투': 2218, '완전': 2206, '진짜': 2856, '셔틀': 1626, '미리': 1127, '시티': 1821, '오름': 2162, '다만': 570, '도로': 680, '가인': 39, '관계': 276, '차량': 2876, '소리': 1638, '다소': 574, '방도': 1215, '편의점': 3273, '칫솔': 3027, '동계': 709, '훈련': 3576, '라마': 795, '연인': 2116, '전체': 2641, '사진': 1493, '첨부': 2920, '엘리베이터': 2064, '실시간': 1873, '비행기': 1440, '택시': 3151, '미만': 1128, '이동': 2374, '가능': 9, '최상': 2961, '욕실': 2235, '슬리퍼': 1791, '위생': 2304, '염려': 2123, '설날': 1590, '떡국': 788, '려고': 840, '현장': 3495, '결재': 167, '황스': 3559, '려운': 841, '중국': 2789, '만두': 932, '종류': 2744, '별로': 1293, '구만': 316, '메뉴': 996, '답변': 603, '제일': 2709, '주차': 2779, '걱정': 131, '할아버지': 3423, '안심': 1945, '컨디션': 3067, '문어': 1095, '처리': 2909, '회사': 3561, '출장': 2988, '서울': 1567, '간혹': 64, '이벤트': 2386, '해주시': 3460, '부대': 1344, '항상': 3435, '롯데': 855, '비지니스': 1434, '여행객': 2097, '손색': 1664, '욕조': 2236, '겸비': 175, '사계절': 1459, '수풀': 1715, '중문': 2794, '표선등': 3306, '원거리': 2281, '여행지': 2101, '복귀': 1322, '시내': 1805, '유명': 2323, '일단': 2462, '주차장': 2781, '지하': 2844, '공간': 246, '응대': 2356, '문의사항': 1097, '신지': 1850, '감동': 71, '역시': 2106, '장도': 2566, '락타': 807, '샤워': 1550, '마련': 896, '코인': 3089, '세탁실': 1620, '오션': 2167, '멀리': 994, '남자친구': 497, '덕분': 665, '이번': 2385, '프런트': 3331, '배정': 1239, '이착륙': 2415, '클리닝': 3120, '근무': 382, '아주머니': 1923, '인사': 2436, '코로나': 3085, '사태': 1496, '노화': 535, '벽지': 1286, '주름': 2756, '지고': 2814, '타일': 3133, '가구': 4, '코너': 3082, '곳곳이': 243, '관광객': 279, '인지': 2449, '사람': 1463, '북적': 1369, '전반': 2627, '관리': 284, '편이': 3274, '피드백': 3346, '편입': 3276, '도시': 686, '관광': 278, '특화': 3214, '지역': 2834, '근처': 385, '카페': 3034, '가기': 6, '고유': 221, '특색': 3210, '스테이': 1768, '가도': 10, '스타벅스': 1759, '번화가': 1263, '아침': 1924, '커서': 3057, '방음': 1224, '먹거리': 988, '단점': 588, '라면': 797, '오심': 2170, '이중': 2411, '혼자': 3523, '겐찮은듯': 157, '다그': 563, '도일': 694, '께빵': 456, '중국인': 2793, '타고': 3127, '눈앞': 556, '가지': 44, '힐링': 3598, '피트니스': 3354, '패키지': 3254, '미닫이': 1122, '로비': 847, '비롯': 1421, '모든': 1030, '각종': 52, '물건': 1103, '아침식사': 1926, '밥맛': 1207, '피아노': 3349, '연주': 2118, '룸타입': 867, '패밀리': 3250, '거실': 121, '한실': 3412, '서부': 1562, '수산시장': 1690, '새벽': 1534, '경매': 182, '구경': 304, '추가': 2972, '어차피': 2022, '현재': 3496, '묵고': 1090, '인터넷': 2453, '지정': 2840, '안해': 1952, '프런터': 3330, '문의': 1096, '영화': 2135, '시스템': 1810, '티브이': 3219, '채널': 2903, '몇개': 1020, '콘센트': 3092, '플러그': 3341, '와이프': 2201, '충전': 2995, '결정': 168, '달라': 594, '경험': 190, '장점': 2579, '인생': 2439, '최악': 2966, '중심': 2797, '바닷가': 1153, '비교': 1413, '편임': 3275, '한번': 3408, '예정': 2146, '휴가': 3585, '스위트룸': 1750, '유리창': 2322, '위트': 2312, '캠핑': 3050, '테이블': 3160, '세트': 1621, '텐트': 3161, '에어컨': 2054, '작은방': 2543, '매트': 975, '자리': 2520, '탑동': 3142, '공원': 263, '프리': 3338, '마켓': 923, '공연': 259, '매일': 971, '식사': 1833, '관덕정': 282, '정문': 2682, '도보': 684, '소요': 1645, '해장국': 3458, '동문': 717, '서문시장': 1560, '목관': 1047, '맞은편': 960, '슬슬': 1792, '별관': 1291, '본관': 1330, '갈수': 68, '최신': 2965, '그린': 377, '환경': 3545, '때문': 787, '별도': 1292, '대중교통': 641, '구매': 317, '심플': 1882, '비품': 1438, '트윈침대': 3205, '스탠다드': 1763, '높이': 548, '한라산': 3404, '노곤': 525, '터미널': 3152, '온돌룸': 2189, '세면대': 1608, '물이': 1114, '치약': 3013, '것임': 150, '생수': 1545, '환승': 3550, '곧바로': 231, '동광양': 710, '정류장': 2677, '시청': 1818, '스텝': 1771, '협소하': 3502, '거품': 130, '타월': 3131, '화장': 3537, '대가': 612, '거울': 123, '쇼파': 1670, '조합': 2739, '금액': 395, '주차공간': 2780, '공터': 267, '태풍': 3150, '개층': 104, '오후': 2184, '한시': 3409, '사우나': 1485, '부모님': 1349, '할머니': 3422, '모시': 1038, '계획': 197, '일로': 2464, '빠듯해': 1445, '어디': 2004, '길가': 441, '골목길': 235, '이륙': 2377, '착륙': 2887, '보이': 1310, '그냥': 363, '일반': 2469, '대욕': 633, '헬스장': 3489, '가면': 19, '고려': 206, '렌터카': 837, '입구': 2496, '반대쪽': 1182, '한정': 3416, '단체': 591, '더블': 660, '제외': 2708, '여유': 2088, '반대편': 1183, '도심': 688, '불구': 1387, '소음': 1648, '거의': 125, '세명': 1609, '트리플': 3199, '전날': 2618, '남아': 495, '자체': 2534, '당일': 610, '정보': 2683, '햇반': 3468, '장조림': 2580, '전자': 2637, '레인지': 831, '가야': 33, '세미나': 1610, '한국인': 3400, '그대로': 369, '나름': 469, '제과점': 2697, '정거장': 2670, '모기': 1022, '만해': 944, '마리': 898, '가량': 16, '방안': 1222, '에프킬라': 2058, '비치': 1435, '계속': 195, '뿌리': 1456, '잡고': 2557, '찬장': 2891, '천장': 2915, '곳곳': 242, '측은': 3008, '벌레': 1265, '기본': 414, '요금': 2223, '건너편': 135, '번호': 1262, '샐러드': 1538, '음식': 2349, '구성': 326, '전복죽': 2629, '저번': 2601, '핸드폰': 3464, '충전기': 2996, '불편': 1400, '센터': 1622, '공사': 256, '숙면': 1720, '무난': 1061, '노력': 528, '지불': 2826, '비용': 1430, '로맨틱': 845, '독립': 702, '북유럽': 1368, '유리': 2321, '커튼': 3059, '바깥': 1145, '설치': 1595, '모던': 1025, '비데': 1418, '효율': 3569, '인치': 2451, '삼성': 1512, '만끽': 927, '편안함': 3270, '여정': 2091, '바닥': 1151, '목적': 1052, '커플': 3060, '끼리': 464, '직진': 2852, '운전': 2268, '공영': 261, '애기': 1962, '무선인터넷': 1074, '갑자기': 80, '서전': 1568, '항공': 3432, '다가': 562, '가급': 5, '결제': 169, '은방': 2342, '상황': 1533, '아시': 1914, '고트': 227, '지도': 2822, '세심': 1614, '공시': 257, '시작': 1815, '맥주잔': 982, '쿠폰': 3102, '일도': 2463, '크기': 3108, '룸서비스': 864, '정신': 2690, '평가': 3277, '편의': 3272, '요즘': 2233, '여러': 2078, '직언': 2848, '블룸': 1412, '변기': 1288, '물질': 1115, '얘기': 1997, '수건': 1675, '환불': 3548, '월일': 2293, '푸른': 3313, '파도': 3223, '철썩': 2918, '풍경': 3320, '생선회': 1544, '장소': 2573, '놀이': 543, '양도': 1989, '돼지': 735, '전골': 2613, '매운탕': 970, '형편': 3512, '브런치': 1406, '뒤쪽': 751, '맛집': 956, '쭈욱': 2869, '갑인': 79, '드타': 764, '방파제': 1233, '횟집': 3567, '타운': 3129, '해산물': 3448, '규모': 356, '가까이': 7, '어르신': 2008, '깨끗': 454, '대신': 629, '작고': 2538, '수영': 1697, '아쉬움': 1912, '인도': 2430, '소독약': 1634, '스비': 1745, '홀로': 3525, '등정후': 775, '부터': 1365, '혹시': 3520, '확인': 3543, '전화': 2645, '통해': 3180, '휘트니': 3582, '운동복': 2266, '수영모': 1698, '고오': 219, '바람': 1157, '대여': 631, '여직원': 2093, '무시': 1077, '말투': 951, '원래': 2284, '제로': 2700, '운영': 2267, '일반인': 2470, '입장': 2503, '선심': 1583, '필요': 3360, '기전': 430, '대뜸': 620, '화가': 3528, '고객': 200, '플레인': 3343, '시경': 1800, '아웃': 1917, '하야': 3382, '메리어트': 998, '여럿': 2081, '이어도': 2397, '수준': 1707, '이군': 2370, '실망': 1867, '종일': 2747, '리셉션': 880, '컨시어': 3070, '태도': 3147, '유료': 2319, '사고': 1460, '학생': 3393, '선생님': 1580, '어딘': 2005, '사항': 1498, '무슨': 1075, '거지': 128, '리빙룸': 879, '하나요': 3368, '트윈룸': 3202, '무려': 1065, '게재': 156, '실물': 1869, '차이': 2881, '실화': 1879, '파우더': 3231, '곰팡이': 240, '자국': 2511, '작동': 2539, '골드스타': 233, '냉장고': 517, '절대': 2649, '레스토랑': 826, '자꾸': 2513, '정색': 2687, '살짝': 1510, '서버': 1561, '데리': 669, '가신': 32, '나머지': 470, '물기': 1105, '직접': 2851, '체계': 2931, '엉망': 2048, '소규모': 1630, '시기': 1803, '마음': 910, '리트': 886, '라그': 794, '기대': 409, '실내수영장': 1862, '수온': 1701, '스위트': 1749, '비수': 1427, '상대': 1515, '노후': 536, '정가': 2669, '무리': 1072, '할인': 3424, '행사': 3473, '참고': 2893, '포함': 3298, '마일리지': 913, '대한항공': 650, '하룻밤': 3377, '확실': 3542, '연식': 2115, '고급': 201, '원가': 2280, '서우': 1566, '해수욕장': 3453, '한눈': 3402, '창문': 2900, '겨울철': 161, '온도': 2187, '리기': 870, '방기': 1214, '동시': 725, '방식': 1221, '대략': 621, '도정': 695, '부스': 1352, '옆방': 2137, '티비': 3220, '취침': 3001, '초등학생': 2946, '양호': 1996, '한식당': 3411, '차라리': 2875, '반드시': 1184, '크게': 3107, '씨유': 1896, '델문': 674, '카페나': 3035, '해수욕': 3452, '최적': 2969, '디럭스': 778, '발코니': 1203, '모로': 1034, '트윈룸입니': 3203, '선착순': 1585, '예술': 2142, '물놀이': 1106, '모래': 1031, '피크': 3352, '시즌': 1817, '날씨': 491, '선선': 1581, '근래': 381, '편리': 3269, '코르': 3086, '기지': 434, '사양': 1481, '주체': 2782, '교회': 302, '절반': 2653, '인수': 2440, '보임': 1314, '아트': 1927, '추정': 2976, '프로': 3333, '페셔': 3264, '인력': 2432, '매트리스': 976, '나무': 472, '허리': 3482, '안감': 1934, '해변': 3447, '워낙': 2275, '가시': 31, '주말': 2757, '한국': 3397, '벚꽃': 1270, '기간': 403, '협재': 3503, '옹포': 2197, '밥집': 1209, '산책': 1505, '루프': 860, '비바람': 1425, '불어': 1396, '블로거': 1410, '물떄': 1108, '그거': 360, '위주': 2308, '풀이': 3317, '온수': 2192, '미온수': 1133, '미온': 1132, '자쿠지': 2536, '잠깐': 2551, '인피니트': 2458, '환상': 3549, '하나': 3365, '스페': 1782, '치킨': 3015, '빠에야': 1446, '스파': 1779, '구조': 333, '스파룸': 1780, '자쿠': 2535, '이용권': 2401, '하니': 3371, '사이': 1487, '시트': 1820, '정리': 2678, '삼다수': 1511, '병과': 1294, '네스프레소': 520, '캡슐': 3051, '여자': 2089, '피로': 3347, '스페인': 1784, '영업': 2132, '종료': 2743, '버거': 1245, '오른쪽': 2161, '마담': 893, '나탈리': 482, '음악': 2351, '필터': 3362, '실외수영장': 1875, '검색': 147, '옥상': 2186, '결과': 164, '대형': 653, '만큼': 942, '번잡': 1260, '개수대': 98, '이전': 2407, '아무': 1909, '리지': 884, '제한': 2714, '경치': 189, '이웃': 2403, '일몰': 2467, '실제': 1877, '리조트': 883, '홍보': 3527, '상통': 1529, '화산': 3532, '바위': 1166, '정상': 2686, '기점': 431, '스템': 1770, '잠자리': 2556, '기타': 435, '부족함': 1359, '길이': 444, '다행': 582, '중국어': 2792, '영어': 2131, '도움': 692, '해결': 3438, '목적지': 1053, '해피': 3461, '음료': 2346, '사이다': 1488, '주스': 2764, '달걀': 592, '치즈': 3014, '히터': 3597, '투어': 3187, '호스텔': 3515, '질문': 2858, '상품': 1530, '과거': 270, '게스트하우스': 154, '자고': 2510, '오기': 2150, '일이': 2479, '발전': 1201, '예상': 2141, '토스터': 3165, '이후': 2424, '소등': 1635, '불키': 1399, '조용조': 2733, '방키': 1232, '고여': 218, '남자': 496, '안전': 1946, '차로': 2878, '이내': 2373, '뷔페': 1403, '여느': 2076, '롯데리아': 856, '방만': 1216, '고정': 224, '무궁화': 1060, '수기': 1676, '사이트': 1490, '홈페이지': 3526, '마치': 921, '무척': 1088, '전기차': 2617, '건너': 134, '급속': 402, '소가': 1628, '유치원': 2333, '주택가': 2784, ...} 12invert_index_vectorizer = {v: k for k, v in vect.vocabulary_.items()}print(str(invert_index_vectorizer)[:100]+'...') {2866: '집중', 3588: '휴식', 2696: '제공', 2311: '위치', 1584: '선정', 790: '또한', 2927: '청소', 2925: '청결', 1527... 4. 감성 분류 – Logistic Regression 이제 전처리된 리뷰 데이터를 활용하여 감성 분류 예측 모델을 만들겠습니다. 감성 분류 예측 모델이란, 이용자 리뷰의 평가 내용을 통해 이 리뷰가 긍정적인지, 부정적인지를 예측하여, 이용자의 감성을 파악하는 겁니다. 따라서, 모델의 X 값(즉, feature 값)은 이용자 리뷰의 평가 내용이 되겠고, 모델의 Y 값(즉, label 값)은 이용자의 긍/부정 감성이 되겠습니다. 4-1. 데이터셋 생성 &gt;&gt; Label 우리는 이용자의 리뷰를 “긍정” / “부정” 두가지 부류로 나누고자 합니다. 하지만 이러한 이용자의 감성을 대표할 수 있는 “평가 점수” 변수는 1 ~ 5의 value를 가지고 있습니다. 따라서 \"평가 점수\"변수 (rating: 1 ~ 5)를 이진 변수 (긍정: 1, 부정:0)으로 변환해야 합니다. 1df.sample(10) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating text 951 3 나는 그것이 수영장을 가지고 있기 때문에 여기에서 예약했다. 그러나 수영장에 물이 ... 47 4 시설은 좀 오래 되었지만 동문시장, 서문시장 도보 10분거리이고 공항에서도 가깝습니... 574 4 호스트는 아주 친절하고 도움이 되었습니다. 그는 우리를 픽업해서 근처에 있는 동안 ... 637 4 제주시에 있는 호텔로 깔끔한 편이었고 나름 전망도 괜찮았습니다. 주차장은 주차타워에... 113 4 루프탑 바와 수영장이 있어서 사용가능하고 깨끗하고 친절하셔서 좋은곳이었습니다. 다만... 416 3 다양한 음식과 음료를 걸어갈 수 있는 곳. 저녁 식사는 늦은 밤에 음식을 찾는 문제... 671 2 리뷰보고 기대했는데 호텔이라기 보단 모텔이나 펜션 느낌이네요 생긴지 얼마 안된걸로 ... 235 5 위치가 바로 해변 근처라, 룸에서 보이는 뷰가 너무 좋습니다. 세화해변 자체가 조용... 875 3 Jeju 섬에서 4 일째되는 주제와 같이 Jeju 공항에서 터치 다운 이후로 이동 ... 254 4 출장 때문에 제주도에 오게 됐습니다. 가성비가 좋고 전체적으로 깨끗했습니다. 난방이... 리뷰 내용와 평점을 살펴보면, 4 ~ 5점 리뷰는 대부분 긍정적이었지만, 1 ~ 3점 리뷰에서는 부정적인 평가가 좀 많이 보였습니다. 그래서 4점, 5점인 리뷰는 \"긍정적인 리뷰\"로 분류하여 1를 부여하고, 1 ~ 3점 리뷰는 \"부정적인 리뷰\"로 분류하여 0을 부여하도록 할게요. 1df['rating'].hist() &lt;matplotlib.axes._subplots.AxesSubplot at 0x154887d0b08&gt; 1234567def rating_to_label(rating): if rating &gt; 3: return 1 else: return 0 df['y'] = df['rating'].apply(lambda x: rating_to_label(x)) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } rating text y 0 4 여행에 집중할수 있게 편안한 휴식을 제공하는 호텔이었습니다. 위치선정 또한 적당한 ... 1 1 4 2일 이상 연박시 침대, 이불, 베게등 침구류 교체 및 어메니티 보강이 필요해 보입... 1 2 4 지인에소개로온 호텔 깨끗하고 좋은거같아요 처음에는 없는게 많아 많이 당황했는데 ... 1 3 5 방에 딱 들어서자마자 눈이 휘둥그레질정도로 이렇게 넓은 호텔 처음 와본 것 같아요!... 1 4 5 저녁에 맥주한잔 하는게 좋아서 렌트 안하고 뚜벅이 하기로 했는데 호텔 바로 앞에 버... 1 1df[\"y\"].value_counts() 1 726 0 275 Name: y, dtype: int64 &gt;&gt; Feature 모델의 Feature 변수는 리뷰에서 추출된 형태소와 그들의 중요도를 나타나는 tf_idf_vect로 대체하겠습니다. 4-2. Training set / Test set 나누기 12345from sklearn.model_selection import train_test_splitx = tf_idf_vecty = df['y']x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=1) 1x_train.shape, y_train.shape ((700, 3599), (700,)) 1x_test.shape, y_test.shape ((301, 3599), (301,)) 4-3. 모델 학습 &gt;&gt; Logistic Regression 모델 학습 123456789from sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score# fit in training setlr = LogisticRegression(random_state = 0)lr.fit(x_train, y_train)# predict in test sety_pred = lr.predict(x_test) &gt;&gt; 분류 결과 평가 123456# classification result for test setprint('accuracy: %.2f' % accuracy_score(y_test, y_pred))print('precision: %.2f' % precision_score(y_test, y_pred))print('recall: %.2f' % recall_score(y_test, y_pred))print('F1: %.2f' % f1_score(y_test, y_pred)) accuracy: 0.72 precision: 0.72 recall: 1.00 F1: 0.84 12345678910# confusion matrixfrom sklearn.metrics import confusion_matrixconfu = confusion_matrix(y_true = y_test, y_pred = y_pred)plt.figure(figsize=(4, 3))sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')plt.title('Confusion Matrix')plt.show() 모델 평가결과를 살펴보면, 모델이 지나치게 긍정(“1”)으로만 예측하는 경향이 있습니다. 따라서 긍정 리뷰를 잘 예측하지만, 부정 리뷰에 대한 예측 정확도가 매우 낮습니다. 이는 샘플데이터의 클래스 불균형으로 인한 문제로 보입니다. 따라서, 클래스 불균형 조정을 진행하겠습니다. 4-4. 샘플링 재조정 &gt;&gt; 1:1 Sampling 1df['y'].value_counts() 1 726 0 275 Name: y, dtype: int64 12positive_random_idx = df[df['y']==1].sample(275, random_state=12).index.tolist()negative_random_idx = df[df['y']==0].sample(275, random_state=12).index.tolist() 1234random_idx = positive_random_idx + negative_random_idxx = tf_idf_vect[random_idx]y = df['y'][random_idx]x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1) 1x_train.shape, y_train.shape ((412, 3599), (412,)) 1x_test.shape, y_test.shape ((138, 3599), (138,)) 4-5. 모델 재학습 &gt;&gt; 모델 학습 123lr2 = LogisticRegression(random_state = 0)lr2.fit(x_train, y_train)y_pred = lr2.predict(x_test) &gt;&gt; 분류 결과 평가 123456# classification result for test setprint('accuracy: %.2f' % accuracy_score(y_test, y_pred))print('precision: %.2f' % precision_score(y_test, y_pred))print('recall: %.2f' % recall_score(y_test, y_pred))print('F1: %.2f' % f1_score(y_test, y_pred)) accuracy: 0.72 precision: 0.70 recall: 0.74 F1: 0.72 12345678910# confusion matrixfrom sklearn.metrics import confusion_matrixconfu = confusion_matrix(y_true = y_test, y_pred = y_pred)plt.figure(figsize=(4, 3))sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')plt.title('Confusion Matrix')plt.show() 이제 모델이 “긍정적인” 케이스와 “부정적인” 케이스를 모두 적당히 잘 맞춘 것을 확인할 수 있습니다. 5. 긍정 / 부정 키워드 분석 기계는 이처럼 리뷰 내용에 나타나는 사람의 감성을 구별할 수 있을 뿐만 아니라, 학습된 Logistic Regression 모델을 이용하여 긍/부정 키워드도 추출해낼 수 있습니다. 추출된 키워드를 통해서 이용자가 느끼는 제주호델의 장,단점을 파악할 수 있고, 이를 기반으로 앞으로 유지해야 할 좋은 서비스와 개선이 필요한 아쉬운 서비스에 대해서도 어느정도 판단할 수 있습니다. 긍 / 부정 키워드를 추출하기 위해 먼저 Logistic Regression 모델에 각 단어의 coeficient를 시각화해보겠습니다. 1lr2.coef_ array([[ 0.28196772, 0.10796991, -0.04978601, ..., 0. , -0.18315162, 0.28434689]]) 1234# print logistic regression's coefplt.figure(figsize=(10, 8))plt.bar(range(len(lr2.coef_[0])), lr2.coef_[0]) &lt;BarContainer object of 3599 artists&gt; 여기서 계수가 양인 경우는 단어가 긍정적인 영향을 미쳤다고 볼 수 있고, 반면에, 음인 경우는 부정적인 영향을 미쳤다고 볼 수 있습니다. 이 계수들을 크기순으로 정렬하면, 긍정 / 부정 키워드를 출력하는 지표가 되겠습니다. 먼저 \"긍정 키워드\"와 \"부정 키워드\"의 Top 5를 각각 출력해볼게요. 123print(sorted(((value, index) for index, value in enumerate(lr2.coef_[0])), reverse = True)[:5])print(sorted(((value, index) for index, value in enumerate(lr2.coef_[0])), reverse = True)[-5:])# enumerate: 인덱스 번호와 컬렉션의 원소를 tuple형태로 반환함 [(1.2644550507381787, 1217), (0.9079356150239053, 2400), (0.895609472071521, 1148), (0.8859075267474583, 2730), (0.8795111499693716, 43)] [(-0.7201222787741572, 1310), (-0.7519681298547074, 3022), (-0.8672956005075485, 567), (-0.9190158099937462, 515), (-0.9945592515966041, 2143)] 이처럼 단어의 coeficient와 index가 출력이 됩니다. 이제 전체 단어가 포함한 \"긍정 키워드 리스트\"와 \"부정 키워드 리스트\"를 정의하고 출력해볼게요. 123coef_pos_index = sorted(((value, index) for index, value in enumerate(lr2.coef_[0])), reverse = True)coef_neg_index = sorted(((value, index) for index, value in enumerate(lr2.coef_[0])), reverse = False)coef_pos_index [(1.2644550507381787, 1217), (0.9079356150239053, 2400), (0.895609472071521, 1148), (0.8859075267474583, 2730), (0.8795111499693716, 43), (0.8541915649753757, 26), (0.8362541212560809, 578), (0.7714811231976703, 2957), (0.7375280889735719, 1491), (0.7203390936359615, 956), (0.6503260268852225, 2977), (0.6488836121942877, 115), (0.6467914172687944, 910), (0.6264469987695738, 1159), (0.5943145305412955, 883), (0.5505354129422678, 2988), (0.5294632094678557, 692), (0.5240729254152497, 2455), (0.5207834696883535, 1922), (0.5153917648445299, 2361), (0.49372825531123943, 1215), (0.49360869707006777, 246), (0.4854919888814009, 680), (0.4854086392859413, 269), (0.4748702738145659, 686), (0.4703566749364605, 1194), (0.45896954031613635, 790), (0.45586600022584467, 2834), (0.45372800281293535, 19), (0.4500540795581468, 2779), (0.44412671542407905, 416), (0.4425720292652355, 1805), (0.4364684750426245, 263), (0.4308546124247834, 3267), (0.4255898116545533, 2797), (0.4212941284904679, 2680), (0.41423556597532674, 489), (0.4121691212201187, 826), (0.4118068110883225, 937), (0.402234791816506, 353), (0.39915216217204813, 136), (0.3906502087724938, 131), (0.38863745777148795, 2180), (0.38330015115324956, 322), (0.37909051494174656, 1027), (0.3776598665737952, 1926), (0.36980255314279886, 2760), (0.3609360208520378, 3034), (0.3601455791606223, 1342), (0.3511486012544648, 344), (0.35030155043520095, 3447), (0.34810767211689553, 2674), (0.3448646839750021, 3021), (0.34466834073677766, 2070), (0.3341929597049384, 1750), (0.3332295460784216, 2849), (0.3291725978477463, 3435), (0.3276653378330499, 2530), (0.3221942756247239, 1483), (0.3217689173991826, 3397), (0.32047891465181083, 2013), (0.3080484198419967, 3029), (0.3062772550220064, 939), (0.30478483149478314, 627), (0.30438930158469363, 2606), (0.3027703771200994, 3454), (0.2989615171043252, 4), (0.2960030540205178, 1991), (0.2941392017845358, 3347), (0.290078280630203, 3593), (0.28793362240859766, 1090), (0.2861006595602784, 3404), (0.28434689214226744, 3598), (0.2819677181770861, 0), (0.2818546705602182, 1809), (0.2796034993266096, 1440), (0.2783451949177126, 3410), (0.27700777474574007, 1078), (0.2764799249539472, 278), (0.2757845449039994, 2074), (0.27449374217124756, 1697), (0.27211400542938347, 860), (0.26958773489776877, 276), (0.26894024258506205, 2642), (0.2679652653240931, 451), (0.26659353628773785, 2605), (0.2642541001710917, 1073), (0.2602933330998526, 71), (0.2601225988013697, 2727), (0.25898398896658026, 395), (0.25523176043119644, 109), (0.25400402242362763, 1120), (0.25346771390562256, 2311), (0.2525923917872476, 1760), (0.252483390540294, 3549), (0.25243556295192593, 44), (0.2523758090983611, 410), (0.25096842816549325, 3286), (0.25030837769014164, 3013), (0.2478963860060586, 3064), (0.24711051623367455, 1700), (0.24639626607741794, 532), (0.24423718622136711, 2339), (0.24419509835066824, 817), (0.24268824175871553, 1646), (0.24020390663531643, 847), (0.23613168717319782, 1277), (0.2356739894439279, 3547), (0.23333780634901968, 1966), (0.2331264370168398, 1350), (0.23268102047017378, 769), (0.23262817998676638, 3166), (0.23066409348184064, 1384), (0.23010041799635683, 210), (0.22586220283294378, 1885), (0.22523607425083558, 260), (0.2222412951070305, 281), (0.22091253142370337, 68), (0.21922527479299828, 1147), (0.21868875489181047, 1465), (0.21807039000574996, 3299), (0.21807039000574996, 172), (0.2177926484819077, 3223), (0.21751093007081115, 2634), (0.2163036212275728, 1171), (0.2162361260915301, 1671), (0.21591443393848506, 1552), (0.21530945315363187, 2038), (0.21450361502341533, 385), (0.2130004456328932, 2018), (0.21283349877228466, 2752), (0.21171382727695384, 1523), (0.21156875238749653, 2906), (0.21149936066156635, 3273), (0.2107420524603348, 3062), (0.2089604714261007, 2167), (0.20857560294926117, 705), (0.20849174650373709, 751), (0.2084323782944626, 2374), (0.2083850088267226, 1421), (0.2076716418538995, 1823), (0.20734493904041118, 2837), (0.20719074367652907, 1455), (0.20632098174995006, 2421), (0.20497429689912247, 2866), (0.20497429689912247, 1584), (0.20460844733702388, 1309), (0.20460135810671237, 1721), (0.2026617971957564, 192), (0.2021896255723423, 574), (0.20076231770123473, 1122), (0.20007368092656116, 981), (0.1994615301156886, 2722), (0.1987204932053518, 1895), (0.1982476502888129, 1622), (0.19668791935266033, 1816), (0.19602558824910057, 767), (0.195808499032481, 581), (0.1954442410972148, 2551), (0.19543920090503364, 2244), (0.19535829875348126, 1249), (0.19513316286959848, 2451), (0.1932943416840944, 2561), (0.19241691136362254, 1278), (0.19188249800399276, 221), (0.19059569732190523, 341), (0.18931948208829832, 2965), (0.18863137833398097, 2225), (0.188233216963001, 1067), (0.18823116402871, 1510), (0.18591329718666444, 2556), (0.1858513716606046, 1853), (0.18475568229990585, 1553), (0.1842332027380814, 15), (0.18385370069092052, 490), (0.183698940971588, 646), (0.18352145151744345, 2709), (0.18179588928699872, 1821), (0.18141472902160485, 356), (0.18101860699904043, 3325), (0.17968533410962978, 1517), (0.17894437469027485, 1441), (0.1785803255429378, 203), (0.17749094181502081, 1291), (0.17745689661710926, 423), (0.17691919755039834, 748), (0.17681729295382825, 629), (0.17650785942100156, 2042), (0.17521436890986974, 2822), (0.17420775259072946, 3525), (0.17407554594971275, 1376), (0.17390397512207328, 1508), (0.17390397512207328, 584), (0.1735238781146927, 509), (0.1729437410073151, 2188), (0.17166919021535662, 2761), (0.1711332476240707, 1505), (0.17079932615633314, 300), (0.1706243328180457, 795), (0.16989041829422863, 1577), (0.16965179412684628, 1028), (0.16919925883678436, 2705), (0.1687459695340302, 667), (0.16815742142636886, 1625), (0.1676232210748594, 2755), (0.16757499046872387, 2274), (0.16736563458006257, 1485), (0.16735261847037675, 2476), (0.16642204341549788, 2035), (0.16595006133727253, 760), (0.16475334154520693, 1208), (0.1646740028459598, 1937), (0.16464847364532936, 690), (0.1636808432150993, 3274), (0.16348761826549618, 1676), (0.16301112079103763, 2399), (0.1629849886257, 3591), (0.1629118596848168, 3186), (0.1626689828520234, 3210), (0.16142787916860177, 1598), (0.1613522761276804, 3417), (0.1603451229219545, 3116), (0.1599203302911822, 2487), (0.15983057428397826, 589), (0.1586108439130326, 2331), (0.15849368672169892, 1647), (0.15826740340037068, 625), (0.15743176994516933, 3490), (0.1571722075528101, 3567), (0.15712518230005013, 3027), (0.15687460543471862, 3428), (0.15651108129304298, 1307), (0.15600166572103646, 1961), (0.15583305075516699, 106), (0.15577941820129187, 1617), (0.155766902206714, 3017), (0.15491622812261568, 382), (0.15485968714815496, 1528), (0.1545939535424059, 259), (0.15411614699130288, 684), (0.1535726280760412, 3293), (0.1535726280760412, 2892), (0.15341384775377642, 2726), (0.15325471176173253, 1533), (0.1529359648993235, 1983), (0.1523311300168501, 1432), (0.15231484413753682, 1030), (0.15231397485990963, 556), (0.15139635636201898, 2078), (0.1511214654825413, 1312), (0.15101670800091527, 2998), (0.14887052306393284, 3096), (0.14887052306393284, 1457), (0.1485864638932176, 2600), (0.14818094009147514, 2223), (0.14810636314705725, 1859), (0.14763883239448744, 1738), (0.14724688251552864, 2328), (0.1471683691325973, 1841), (0.14705200941823965, 2268), (0.14704245351541728, 660), (0.14646359476664114, 3297), (0.14621204479849256, 2226), (0.14615889360176976, 3350), (0.14576749911151465, 2851), (0.14545079981853645, 2275), (0.1447568799500706, 2798), (0.1444313715254008, 2022), (0.1444180222221931, 1654), (0.1444180222221931, 1548), (0.14434325571263137, 2445), (0.14412764469019354, 1396), (0.1439309933360322, 3220), (0.14364997884743677, 3272), (0.14359122893612475, 1814), (0.14339034972990414, 2983), (0.14305710787294673, 1085), (0.14276222540097244, 348), (0.14269270587505128, 996), (0.14200348649786682, 3275), (0.14175159317612532, 3189), (0.14173146008479248, 714), (0.14095242066301328, 306), (0.14092668743912232, 2678), (0.14086483039942074, 570), (0.14061627821721584, 3414), (0.14047941175558679, 387), (0.1404004427633594, 3476), (0.1404004427633594, 1112), (0.13978500519793755, 2847), (0.13978500519793755, 780), (0.13964073789423023, 665), (0.13934374266681135, 3500), (0.13829992453370865, 3161), (0.13817992752504213, 1768), (0.13745049759016625, 3511), (0.13665192952568253, 757), (0.13642162742786484, 1351), (0.1359845468368403, 271), (0.13597476793796576, 534), (0.135852916769958, 2497), (0.13574633450491594, 3009), (0.13574633450491594, 2299), (0.13574633450491594, 1296), (0.13574633450491594, 1188), (0.13549762485752148, 3571), (0.13549762485752148, 3391), (0.13549762485752148, 2640), (0.13541454362686076, 1332), (0.13519719011184664, 238), (0.13515286340239754, 2047), (0.13500163846144472, 3152), (0.1347989845038155, 2353), (0.13477156350779324, 1527), (0.13474112790096265, 1889), (0.13474112790096265, 1196), (0.13474112790096265, 462), (0.13469292571022845, 11), (0.13458956235978478, 924), (0.13442001799674802, 2069), (0.1342034640274507, 2869), (0.1341559282111133, 2145), (0.13415237816410766, 3471), (0.13415237816410766, 3406), (0.13388090777365988, 94), (0.13342324387367194, 2971), (0.1332930603370377, 3432), (0.1330404844897235, 1506), (0.13293873503860765, 3087), (0.13272932864456133, 3073), (0.13232986210850453, 2246), (0.13218242328559932, 2082), (0.13197846164836427, 3285), (0.13197846164836427, 2297), (0.13197846164836427, 1741), (0.13197846164836427, 69), (0.13179675529668713, 1549), (0.1316814762162865, 3441), (0.13154581005598, 3192), (0.1314192595003537, 1386), (0.13129169059042645, 969), (0.1311653774611966, 244), (0.13071289286611526, 3003), (0.13067314069850974, 697), (0.12989273592089953, 466), (0.1297746134602387, 411), (0.12976187780923948, 39), (0.12975779444471916, 3176), (0.12975779444471916, 3066), (0.1296539223346817, 3169), (0.1295761221334622, 2132), (0.12915915165160174, 3585), (0.12912049655247929, 3475), (0.12912049655247929, 455), (0.12897380261630323, 1053), (0.12884028806560763, 2910), (0.1283431735744972, 2344), (0.1283431735744972, 1542), (0.12780627572336126, 2207), (0.12780627572336126, 531), (0.1277445628861703, 2975), (0.12741425172305826, 669), (0.1268676275287745, 424), (0.12600280097170596, 2053), (0.1255687931546876, 1578), (0.1251082717170878, 3287), (0.12501636694175655, 3082), (0.12485375424445369, 988), (0.12485077138187695, 1247), (0.12477317035474626, 1638), (0.12470562190989118, 1234), (0.12418537178635555, 3201), (0.12412494478481371, 1572), (0.12356427400475413, 720), (0.12346465010011236, 3190), (0.1232984083336477, 3384), (0.12290996269246392, 2930), (0.12272802616213961, 3448), (0.12252951158801757, 73), (0.12243269952395211, 3105), (0.12240812373820147, 2735), (0.12169970934221791, 2781), (0.12150853668051385, 1722), (0.12148978639712985, 1301), (0.12147421457137794, 2320), (0.12147421457137794, 2289), (0.12135904501371637, 3339), (0.12135904501371637, 1602), (0.12085540050886351, 3206), (0.12085540050886351, 2067), (0.12085540050886351, 1282), (0.12085540050886351, 1170), (0.12085540050886351, 199), (0.12073634202256898, 2460), (0.12051291677661294, 2250), (0.12051291677661294, 730), (0.12036501072581905, 3263), (0.12036501072581905, 373), (0.11982407529162177, 74), (0.11941421355306232, 2814), (0.11941421355306232, 2193), (0.11909411357560733, 2028), (0.11903875427006184, 403), (0.11887476984730765, 1374), (0.11855602046019094, 912), (0.11826793727408907, 2664), (0.11797129443799506, 147), (0.11792307582322151, 1752), (0.11792307582322151, 518), (0.1177499125052935, 1838), (0.11735274081083348, 2526), (0.11728847189963591, 1299), (0.11682555059780918, 702), (0.11662484295496746, 3453), (0.11615131711727657, 777), (0.11608095184078544, 771), (0.11598871515918448, 2677), (0.11589077346213462, 1341), (0.11572533411469992, 2492), (0.11567709862499206, 2587), (0.11567709862499206, 2077), (0.11542281429727001, 2221), (0.11525735836070924, 3389), (0.11501634646006889, 2886), (0.11501634646006889, 835), (0.11449108387629879, 267), (0.11419455143266674, 41), (0.11410478259093633, 2499), (0.11410478259093633, 636), (0.11391082531008434, 1939), (0.11379525876290054, 1779), (0.11369189505531267, 3279), (0.11359623354805377, 3362), (0.11328311707861126, 1626), (0.11309515954317759, 2033), (0.11309203979609482, 1163), (0.11306723080679525, 446), (0.11300787365565511, 88), (0.11281954183130295, 2799), (0.1125643845359886, 359), (0.1125643845359886, 87), (0.11236486622722328, 1599), (0.11236486622722328, 1462), (0.11202792916061027, 1320), (0.11168083926782998, 2088), (0.1116425153114436, 801), (0.11160861926991839, 2298), (0.11095938208098642, 304), (0.11091238300534989, 773), (0.1100077175343078, 2162), (0.10976564909688623, 1790), (0.10961263739649914, 258), (0.10941413976516044, 3488), (0.10941413976516044, 2819), (0.10941413976516044, 1828), (0.10917777932688458, 723), (0.10864303256976575, 747), (0.10864303256976575, 148), (0.10852304491119706, 1106), (0.10844777870744055, 1289), (0.10844777870744055, 619), (0.10832336961288917, 2692), (0.10832336961288917, 1454), (0.10830603618528553, 84), (0.10796991064699014, 1), (0.10795721696924253, 2315), (0.10795721696924253, 425), (0.1077710568146692, 3317), (0.1077710568146692, 2663), (0.10769380388975194, 2008), (0.10720615786237517, 583), (0.10673796206207481, 888), (0.10671454696616327, 601), (0.10656205646300153, 201), (0.1064891137904478, 1554), (0.10637660107629578, 1759), (0.10634735402569995, 3408), (0.10626212376589807, 2386), (0.10623995311965392, 3319), (0.10622168812753784, 333), (0.10615533943965197, 772), (0.10595924232583608, 337), (0.10595924232583608, 272), (0.10508229441497294, 3028), (0.10485989916431773, 2462), (0.10473698952461245, 3086), (0.10473698952461245, 434), (0.10473698952461245, 381), (0.10461042411497755, 3129), (0.10461042411497755, 1233), (0.10461042411497755, 764), (0.10461042411497755, 79), (0.10445117600612656, 3513), (0.10445117600612656, 3143), (0.10445117600612656, 401), (0.1041925044133613, 1207), (0.10388289797906243, 3088), (0.10359537183826453, 2766), (0.10359537183826453, 822), (0.10357097224199376, 3528), (0.10298171781942682, 3460), (0.10261708591617978, 527), (0.10237985140859761, 1290), (0.10223721967543753, 863), (0.10222967216366273, 582), (0.10189163932285969, 903), (0.10174059857006298, 31), (0.1015489083625263, 696), (0.10152723059467353, 1012), (0.10132218984016486, 2342), (0.10132218984016486, 1914), (0.10132218984016486, 1568), (0.10132218984016486, 562), (0.10132218984016486, 257), (0.10132218984016486, 227), (0.10132218984016486, 169), (0.10132218984016486, 5), (0.10129687975732969, 2385), (0.10126776819935551, 3117), (0.10063103908292556, 284), (0.10055954160111301, 3081), (0.10031435374070032, 1260), (0.10028094106951953, 1317), (0.10027605850365232, 3072), (0.1000059209109059, 2336), (0.1000059209109059, 479), (0.09995417863737927, 1670), (0.09946866203075326, 299), (0.09937460223662734, 1955), (0.09937460223662734, 355), (0.0991931372321024, 3367), (0.0991931372321024, 3052), (0.0991931372321024, 2987), (0.0991931372321024, 614), (0.09885234039929348, 1496), (0.0985825853170792, 2753), (0.09833844719113422, 3349), (0.09833844719113422, 2118), (0.09828284940929058, 900), (0.09826909686300346, 2262), (0.09826909686300346, 1765), (0.09826909686300346, 904), (0.09826909686300346, 652), (0.09820798725090112, 2536), (0.09820798725090112, 1967), (0.0979795780346747, 2907), (0.09782691886062657, 377), (0.09760724210433858, 3516), (0.09755885308766699, 3164), (0.09755885308766699, 683), (0.09730186511202356, 3329), (0.09730186511202356, 1733), (0.09730186511202356, 1226), (0.097102913934461, 2625), (0.09610978450473183, 2087), (0.09582399417186592, 1439), (0.09577717071956568, 47), (0.09574004674208489, 2532), (0.09567949353604623, 153), (0.09563595118779827, 1248), (0.09563595118779827, 800), (0.0955218528925641, 2265), (0.0954330687710674, 1715), (0.09490960244197376, 3079), (0.09479895154722345, 3167), (0.09479895154722345, 2182), (0.09464204684604893, 2919), (0.09464204684604893, 1007), (0.09464204684604893, 421), (0.0945793543479756, 3346), (0.0945793543479756, 3214), (0.09456116933710224, 1829), (0.09452473946342346, 736), (0.09441875395888008, 3102), (0.09441875395888008, 1541), (0.09418492749174653, 52), (0.0939222882360469, 3558), (0.0939222882360469, 3419), (0.0939222882360469, 2608), (0.0939222882360469, 2598), (0.09392068680284914, 3344), (0.09392068680284914, 2173), (0.09392068680284914, 1138), (0.09392068680284914, 461), (0.09392068680284914, 34), (0.09379123891116847, 2584), (0.09353081179807116, 3259), (0.09353081179807116, 1302), (0.09353081179807116, 293), (0.09309370020530645, 2639), (0.09309370020530645, 2294), (0.09309370020530645, 2083), (0.09309370020530645, 1944), (0.09309370020530645, 162), (0.09298771310954623, 741), (0.09298771310954623, 140), (0.09292587512205373, 1929), (0.09289423937435062, 3561), (0.09274784637141024, 3307), (0.09274784637141024, 2126), (0.09274784637141024, 2025), (0.09274784637141024, 1418), (0.09254637783999758, 217), (0.09226460305753335, 3403), (0.09226460305753335, 1687), (0.09226460305753335, 1592), (0.09192383607443329, 3315), (0.09192383607443329, 875), (0.09183495854900056, 2985), (0.09183495854900056, 1596), (0.09173493202889069, 1770), (0.09173493202889069, 431), (0.09173143027976542, 2876), (0.09113344147288725, 3120), (0.09060526255265101, 3381), (0.09060526255265101, 2287), (0.09060526255265101, 1836), (0.09060526255265101, 1769), (0.09050760723810075, 326), (0.08995529378430658, 340), (0.08987429575682436, 1969), (0.08982977958803778, 1812), (0.08974209619577075, 838), (0.08963253567327513, 2169), (0.08951903081805541, 2618), (0.08947267121555101, 989), (0.08926541208781298, 1369), (0.0890462273393359, 893), (0.0890462273393359, 482), (0.0888304568052451, 1118), (0.08864375178731801, 2759), (0.08862582335907176, 3128), (0.08856874594603148, 2408), (0.08847924280717331, 3541), (0.08847924280717331, 2706), (0.08845733589313011, 1614), (0.08843074951990057, 1330), (0.08827578191477906, 2529), (0.08827578191477906, 548), (0.08811593995641924, 2768), (0.08795612661377235, 1848), (0.0878632294425667, 3204), (0.0878632294425667, 2905), (0.0877915209166029, 2732), (0.08724002705412705, 3125), (0.08681879523440901, 472), (0.0867590941431764, 1371), (0.08591449282742145, 3413), (0.08591449282742145, 1793), (0.08591449282742145, 439), (0.08569361517932625, 2429), (0.08569361517932625, 1886), (0.08564019433508445, 2981), (0.08564019433508445, 2571), (0.08564019433508445, 1852), (0.08564019433508445, 145), (0.0855146046919488, 3001), (0.08482470727509915, 107), (0.08474214619355472, 291), (0.08474214619355472, 92), (0.08464630577025285, 1353), (0.08447795462677392, 83), (0.08442221636455624, 2373), (0.08435306298004447, 3302), (0.08435306298004447, 1842), (0.08435306298004447, 885), (0.08406143202879186, 961), (0.08374180878487095, 2901), (0.08352466261109656, 1451), (0.08248922005074939, 1131), (0.08238017336779274, 2415), (0.08216565036306289, 922), (0.08170778577083812, 503), (0.08139930660843568, 749), (0.0810873859250381, 2703), (0.08099924967644831, 3375), (0.08036733484765383, 103), (0.08024334048387935, 1346), (0.08024334048387935, 1055), (0.08024334048387935, 828), (0.07995951135307515, 2913), (0.07995254170536943, 3142), (0.07975739071961907, 1238), (0.07961368503404338, 3145), (0.07961368503404338, 1102), (0.0791011342722481, 2629), (0.07909734484039603, 375), (0.07903458017917456, 960), (0.07865148217479348, 1387), (0.0779646282219197, 3122), (0.0779646282219197, 350), (0.07794818207773628, 2696), (0.07791539520575948, 2197), (0.07791539520575948, 1425), (0.07791539520575948, 1410), (0.07791539520575948, 1270), (0.07791539520575948, 1209), (0.07791539520575948, 1108), (0.07777326253628294, 2052), (0.07777326253628294, 954), (0.07777326253628294, 812), (0.07776976305397286, 435), (0.0776760937385194, 3588), (0.07766249907323657, 1286), (0.0768120675986713, 979), (0.07633605683651937, 1618), (0.07610302341355955, 1345), (0.07610302341355955, 1329), (0.07610302341355955, 938), (0.07610302341355955, 754), (0.07610302341355955, 502), (0.07493632088882671, 1281), (0.07486036923106522, 3114), (0.07486036923106522, 759), (0.07479212341391864, 3109), (0.07479212341391864, 1125), (0.07479212341391864, 711), (0.07479212341391864, 445), (0.07479212341391864, 25), (0.0744210537557175, 3470), (0.0744210537557175, 1928), (0.0744210537557175, 1280), (0.0744210537557175, 1243), (0.0744210537557175, 1018), (0.0744210537557175, 708), (0.0740577155592499, 726), (0.07358418456629864, 1743), (0.07309840122961515, 1219), (0.07303416054815363, 252), (0.07271877218739466, 3241), (0.07184102679685105, 121), (0.07182717404842677, 587), (0.07177500880745105, 2964), (0.07127209654963827, 120), (0.07087579658806266, 1316), (0.07069880693740326, 339), (0.07068023149332683, 2306), (0.07068023149332683, 253), (0.07065433840741699, 1033), (0.07058992698239872, 3555), (0.07043170609309371, 360), (0.07023970587779339, 1004), (0.06996622272883518, 3203), (0.06996622272883518, 1585), (0.06996622272883518, 1581), (0.06943213017724599, 1461), (0.06931620630006176, 1538), (0.06923101778513037, 1918), (0.06921851239026898, 2146), (0.06914996226685433, 2312), (0.06911832282266693, 206), (0.06905411184938241, 2212), (0.06879868009883609, 1498), (0.06879341064374712, 3369), (0.06829991205551972, 485), (0.06793743237297642, 3094), (0.06793743237297642, 2568), (0.06793743237297642, 2509), (0.06793743237297642, 1624), (0.06793743237297642, 1311), (0.06793743237297642, 830), (0.06793743237297642, 193), (0.06771012152570943, 896), (0.06760842116575855, 3518), (0.06728576906303034, 3478), (0.06728576906303034, 2945), (0.06728576906303034, 2592), (0.06728576906303034, 2586), (0.06728576906303034, 1111), (0.06726031274341861, 2835), (0.0668936390304386, 3283), (0.06683941035275678, 1153), (0.06670561404578652, 3300), (0.06670561404578652, 2952), (0.06670561404578652, 2949), (0.06670561404578652, 2890), (0.06670561404578652, 2481), (0.06670561404578652, 1070), (0.06616432949033017, 3503), (0.0660445367892345, 3515), (0.06603516959037964, 3352), (0.06603516959037964, 1701), (0.06594330439800165, 3537), (0.06529883585157686, 3418), (0.06529883585157686, 2650), (0.06466761703140791, 2780), (0.06451756127861434, 2546), (0.06412036684718043, 906), (0.06406825327936377, 393), (0.06389147199964199, 1562), (0.06389147199964199, 547), (0.06296277600534345, 1898), (0.06295775824880319, 1832), (0.06295775824880319, 1144), (0.06273519650642477, 2108), (0.06257557985594793, 2438), (0.06250818347087828, 2543), (0.06237266652354673, 1818), (0.062097593396214186, 2744), (0.06179423738961337, 925), (0.06141211575679981, 2260), (0.060781144623716234, 3570), (0.06066322422717442, 2844), (0.060370008276426454, 3338), (0.06029861224248649, 2784), (0.06029861224248649, 1986), (0.06029861224248649, 1543), (0.06005526613023247, 897), (0.05947175378230543, 1763), (0.05909565017478048, 1849), (0.05909352311701952, 1352), (0.058961537911610754, 3510), (0.058961537911610754, 3055), (0.058961537911610754, 2737), (0.058961537911610754, 2292), (0.058961537911610754, 1475), (0.058958973694166104, 3589), (0.058958973694166104, 2651), (0.058958973694166104, 1731), (0.058958973694166104, 474), (0.05832232735424722, 484), (0.05776314858186377, 2356), (0.057539284349787875, 2724), (0.057539284349787875, 2716), (0.057539284349787875, 2272), (0.057539284349787875, 1980), (0.057539284349787875, 1713), (0.057539284349787875, 1604), (0.057539284349787875, 1449), (0.057539284349787875, 75), (0.057539284349787875, 61), (0.05679666092137163, 997), (0.05679666092137163, 580), (0.056729924333008365, 2637), (0.056729924333008365, 831), (0.05655015464811865, 487), (0.05652766823426947, 2030), (0.05640871242395038, 735), (0.05614386926874535, 758), (0.0559063955350394, 3184), (0.0559063955350394, 3031), (0.0559063955350394, 2944), (0.0559063955350394, 2647), (0.0559063955350394, 2528), (0.0559063955350394, 2261), (0.0559063955350394, 1269), (0.0559063955350394, 1109), (0.0559063955350394, 554), (0.055648783133438656, 1407), (0.055648783133438656, 586), (0.055646362986584645, 1466), (0.05516895684450839, 2793), (0.054882824548443114, 3173), (0.054882824548443114, 2982), (0.054882824548443114, 2845), (0.054882824548443114, 2542), (0.054882824548443114, 1756), (0.054882824548443114, 899), (0.054882824548443114, 681), (0.054882824548443114, 285), (0.05486846085587583, 3026), (0.05484348857927268, 3469), (0.05484348857927268, 3465), (0.05484348857927268, 2989), (0.05484348857927268, 2879), (0.05484348857927268, 2754), (0.05484348857927268, 2406), (0.05484348857927268, 1730), (0.05484348857927268, 1667), (0.05484348857927268, 1665), (0.05484348857927268, 1615), (0.05484348857927268, 1471), (0.05484348857927268, 1191), (0.05484348857927268, 1100), (0.05484348857927268, 1079), (0.05484348857927268, 851), (0.05484348857927268, 458), (0.054487189903820656, 2204), (0.05430643890657519, 138), (0.054058095179772864, 944), (0.054022724280419834, 3212), (0.05402202766157935, 1762), (0.0533750821753445, 1695), (0.05306742820929221, 2192), (0.05276529397122469, 2809), (0.05276529397122469, 2057), (0.05276529397122469, 1691), (0.0523101884772147, 1923), (0.05215992194245664, 1550), (0.052012698561421676, 2377), (0.052012698561421676, 1984), (0.052012698561421676, 1039), (0.052012698561421676, 149), (0.05179923233388806, 3394), (0.05179923233388806, 846), (0.051762106456659567, 2863), (0.051472967058906464, 1912), (0.051217574472353734, 2778), (0.05110058750877395, 2041), (0.050966072229566624, 1630), (0.05077445418126315, 3336), (0.05077445418126315, 2656), (0.05077445418126315, 2570), (0.05077445418126315, 2522), (0.05077445418126315, 2121), (0.05077445418126315, 2045), (0.05077445418126315, 2010), (0.05077445418126315, 1726), (0.05077445418126315, 1655), (0.05077445418126315, 1509), (0.05077445418126315, 1507), (0.05077445418126315, 732), (0.05077445418126315, 524), (0.05077445418126315, 422), (0.05077445418126315, 196), (0.05077445418126315, 171), (0.05077445418126315, 99), (0.050539089094784995, 100), (0.05053664694441642, 3568), (0.050492996404728846, 2961), (0.050036275129686114, 396), (0.05003297559110967, 2029), (0.04984891386860787, 917), (0.04961138883973778, 143), (0.04958598961322054, 3056), (0.049575831047697035, 1283), (0.048727246055628254, 2248), (0.04872402143683834, 1101), (0.047921690809483164, 1603), (0.047921690809483164, 1321), (0.047921690809483164, 1017), (0.04791436558471306, 2622), (0.04791436558471306, 1241), (0.04770759660795472, 717), (0.04694083335282966, 289), (0.04677698779883914, 2757), (0.04666642228091436, 2141), (0.04647288993080121, 2484), (0.04637599875831547, 2512), (0.045897622985651414, 139), (0.045799053702209366, 1344), (0.04570679344810075, 2147), (0.04516689835379344, 1172), (0.04492238369553648, 1149), (0.04452311366966795, 3051), (0.04452311366966795, 2743), (0.04452311366966795, 2535), (0.04452311366966795, 1784), (0.04452311366966795, 1780), (0.04452311366966795, 1511), (0.04452311366966795, 1245), (0.04452311366966795, 520), (0.04431291167953588, 3124), (0.04431291167953588, 2471), (0.04431291167953588, 2230), (0.04431291167953588, 1380), (0.04379233051095153, 3250), (0.04370894283540041, 2372), (0.04342726715205229, 477), (0.04339655458297072, 1349), (0.04289303347380985, 1420), (0.04209795683366029, 2573), (0.04202158194623495, 2401), (0.04202158194623495, 1294), (0.0419602893158302, 3107), (0.04182319015766572, 3536), (0.04182319015766572, 2839), (0.04182319015766572, 2765), (0.04182319015766572, 1597), (0.04182319015766572, 475), (0.04120970047603527, 2595), (0.04118433740575306, 2043), (0.0410712841055371, 3050), (0.04099650527849089, 1442), (0.04049252050189614, 1797), (0.04024671694278536, 1938), (0.040121670241939675, 3222), (0.040121670241939675, 2395), (0.040121670241939675, 1682), (0.040121670241939675, 1195), (0.040121670241939675, 844), (0.040121670241939675, 294), (0.040056704625578095, 1482), (0.03984593632828475, 2878), (0.03939272315558761, 3076), (0.0390809923939327, 405), (0.038398821000790784, 3545), (0.03814509952790994, 1161), (0.03801064136229472, 321), (0.03786743367501903, 468), (0.037566983103707936, 2969), (0.03725182003350967, 1723), (0.037238370858689175, 2767), (0.03696154627105317, 3205), (0.03679414699666566, 864), (0.036268027377411485, 2345), (0.035970320215902754, 3057), (0.034899356647054146, 3270), (0.03454974613444602, 2350), (0.034383816197631145, 2436), ...] 마지막으로 index를 단어로 변환하여 \"긍정 키워드 리스트\"와 \"부정 키워드 리스트\"의 Top 20 단어를 출력해볼게요. 12invert_index_vectorizer = {v: k for k, v in vect.vocabulary_.items()}invert_index_vectorizer {2866: '집중', 3588: '휴식', 2696: '제공', 2311: '위치', 1584: '선정', 790: '또한', 2927: '청소', 2925: '청결', 1527: '상태', 2392: '이상', 3022: '침대', 2388: '이불', 3021: '침구', 299: '교체', 2013: '어메니티', 1296: '보강', 1277: '베스트', 2299: '웨스턴', 3564: '회원', 185: '경우', 106: '객실', 3009: '층수', 2234: '요청', 2606: '적극', 1188: '반영', 2837: '지인', 1629: '소개', 2910: '처음', 611: '당황', 1607: '세면', 675: '도구', 2555: '잠옷', 3358: '필수', 361: '그것', 2673: '정도', 578: '다음', 2074: '여기', 1171: '박만', 2595: '저녁', 981: '맥주', 3414: '한잔', 838: '렌트', 791: '뚜벅', 1159: '바로', 1247: '버스', 2676: '정류', 697: '도착', 24: '가방', 2487: '일찍', 2685: '정비', 1225: '방이', 2500: '입실', 2038: '업그레이드', 2849: '직원', 2680: '정말', 1148: '바다', 2623: '전망', 2636: '전일', 3425: '함덕', 624: '대명', 3091: '콘도', 1861: '실내', 1384: '분위기', 1659: '손님', 40: '가장', 1241: '배치', 651: '대해', 634: '대응', 1889: '써비스', 2730: '조식', 1351: '부분', 1838: '신경', 1922: '아주', 3208: '특급', 3191: '트랜디', 210: '고민', 3593: '흔적', 2082: '여름', 1700: '수영장', 1483: '사용', 1297: '보고', 2035: '엄마', 2: '가격', 627: '대비', 2769: '주위', 924: '마트', 1826: '식당', 1816: '시장', 1217: '방문', 2361: '의사', 726: '동안', 2695: '정해진', 3580: '휘슬', 269: '공항', 1539: '생각', 1809: '시설', 1028: '모두', 3017: '친절', 1029: '모드', 917: '마지막', 900: '마무리', 3156: '테라스', 2612: '전경', 2427: '인근', 2583: '재래시장', 1979: '야시장', 2402: '이용도', 2400: '이용', 2488: '일차', 3581: '휘슬락', 2940: '체크', 2761: '주변', 2094: '여친', 2975: '추억', 26: '가성', 2977: '추천', 3575: '후회', 2145: '예전', 372: '그랜드', 2605: '저희', 1918: '아이', 708: '돌잔치', 581: '다정', 3470: '했었더랬', 2642: '전통', 1004: '메종', 387: '글래드', 1563: '서비스', 969: '매우', 3428: '합리', 635: '대의', 1018: '명절', 1721: '숙박', 1928: '아티', 1243: '백미', 3061: '커피', 1280: '베이커리', 43: '가족', 3342: '플러스', 2816: '지금', 2257: '우선', 2664: '접근성', 1671: '쇼핑', 940: '만족도', 2957: '최고', 1078: '무엇', 423: '기억', 2251: '우리', 2902: '찾기', 300: '교통', 2418: '이틀', 2691: '정원', 109: '거기', 160: '겨울', 3016: '친구', 541: '놀러와', 3185: '투숙', 1981: '야외', 1235: '방향', 1976: '야간', 2726: '조명', 1723: '순간', 638: '대접', 1868: '실명', 112: '거론', 3337: '프론트', 2378: '이름', 1938: '안나', 416: '기분', 1037: '모습', 2921: '첫날', 1761: '스타트', 576: '다시', 1578: '선물', 3032: '카운터', 1939: '안내', 777: '디너', 438: '기회', 1121: '미니바', 1067: '무료', 2959: '최근', 281: '관광지', 1719: '숙고', 88: '강추', 1977: '야경', 2475: '일부러', 2476: '일어나서', 714: '동네', 1168: '바퀴', 990: '먹방', 1843: '신라', 3105: '퀄리티', 1024: '모녀', 2711: '제주시', 2313: '위해', 1586: '선택', 2180: '오픈', 2143: '예약', 622: '대로', 115: '거리', 657: '더군다나', 1627: '셔틀버스', 2271: '운행', 670: '데스크', 2880: '차안', 1374: '분도', 2438: '인상', 3201: '트윈', 1489: '사이즈', 939: '만족', 1758: '스타', 45: '가짓수', 558: '느낌', 3538: '화장실', 505: '내부', 2455: '인테리어', 2859: '질적', 2368: '이건', 100: '개인', 3005: '취향', 321: '구비', 273: '과일', 480: '나이프', 3295: '포크', 1364: '부탁', 2786: '준비', 3305: '표방', 1046: '모텔', 165: '결론', 3577: '훌륭', 1799: '시간', 1737: '슈페리어킹룸', 3376: '하루', 3570: '후기', 2836: '지은지', 2033: '얼마', 136: '건물', 1985: '약간', 2318: '유럽', 1760: '스타일', 378: '그림', 2715: '조각', 1323: '복도', 2633: '전시', 2630: '전부', 3039: '카펫', 770: '등급', 567: '다른', 2394: '이서', 2512: '자기', 2722: '조금', 2218: '외투', 2206: '완전', 2856: '진짜', 1626: '셔틀', 1127: '미리', 1821: '시티', 2162: '오름', 570: '다만', 680: '도로', 39: '가인', 276: '관계', 2876: '차량', 1638: '소리', 574: '다소', 1215: '방도', 3273: '편의점', 3027: '칫솔', 709: '동계', 3576: '훈련', 795: '라마', 2116: '연인', 2641: '전체', 1493: '사진', 2920: '첨부', 2064: '엘리베이터', 1873: '실시간', 1440: '비행기', 3151: '택시', 1128: '미만', 2374: '이동', 9: '가능', 2961: '최상', 2235: '욕실', 1791: '슬리퍼', 2304: '위생', 2123: '염려', 1590: '설날', 788: '떡국', 840: '려고', 3495: '현장', 167: '결재', 3559: '황스', 841: '려운', 2789: '중국', 932: '만두', 2744: '종류', 1293: '별로', 316: '구만', 996: '메뉴', 603: '답변', 2709: '제일', 2779: '주차', 131: '걱정', 3423: '할아버지', 1945: '안심', 3067: '컨디션', 1095: '문어', 2909: '처리', 3561: '회사', 2988: '출장', 1567: '서울', 64: '간혹', 2386: '이벤트', 3460: '해주시', 1344: '부대', 3435: '항상', 855: '롯데', 1434: '비지니스', 2097: '여행객', 1664: '손색', 2236: '욕조', 175: '겸비', 1459: '사계절', 1715: '수풀', 2794: '중문', 3306: '표선등', 2281: '원거리', 2101: '여행지', 1322: '복귀', 1805: '시내', 2323: '유명', 2462: '일단', 2781: '주차장', 2844: '지하', 246: '공간', 2356: '응대', 1097: '문의사항', 1850: '신지', 71: '감동', 2106: '역시', 2566: '장도', 807: '락타', 1550: '샤워', 896: '마련', 3089: '코인', 1620: '세탁실', 2167: '오션', 994: '멀리', 497: '남자친구', 665: '덕분', 2385: '이번', 3331: '프런트', 1239: '배정', 2415: '이착륙', 3120: '클리닝', 382: '근무', 1923: '아주머니', 2436: '인사', 3085: '코로나', 1496: '사태', 535: '노화', 1286: '벽지', 2756: '주름', 2814: '지고', 3133: '타일', 4: '가구', 3082: '코너', 243: '곳곳이', 279: '관광객', 2449: '인지', 1463: '사람', 1369: '북적', 2627: '전반', 284: '관리', 3274: '편이', 3346: '피드백', 3276: '편입', 686: '도시', 278: '관광', 3214: '특화', 2834: '지역', 385: '근처', 3034: '카페', 6: '가기', 221: '고유', 3210: '특색', 1768: '스테이', 10: '가도', 1759: '스타벅스', 1263: '번화가', 1924: '아침', 3057: '커서', 1224: '방음', 988: '먹거리', 588: '단점', 797: '라면', 2170: '오심', 2411: '이중', 3523: '혼자', 157: '겐찮은듯', 563: '다그', 694: '도일', 456: '께빵', 2793: '중국인', 3127: '타고', 556: '눈앞', 44: '가지', 3598: '힐링', 3354: '피트니스', 3254: '패키지', 1122: '미닫이', 847: '로비', 1421: '비롯', 1030: '모든', 52: '각종', 1103: '물건', 1926: '아침식사', 1207: '밥맛', 3349: '피아노', 2118: '연주', 867: '룸타입', 3250: '패밀리', 121: '거실', 3412: '한실', 1562: '서부', 1690: '수산시장', 1534: '새벽', 182: '경매', 304: '구경', 2972: '추가', 2022: '어차피', 3496: '현재', 1090: '묵고', 2453: '인터넷', 2840: '지정', 1952: '안해', 3330: '프런터', 1096: '문의', 2135: '영화', 1810: '시스템', 3219: '티브이', 2903: '채널', 1020: '몇개', 3092: '콘센트', 3341: '플러그', 2201: '와이프', 2995: '충전', 168: '결정', 594: '달라', 190: '경험', 2579: '장점', 2439: '인생', 2966: '최악', 2797: '중심', 1153: '바닷가', 1413: '비교', 3275: '편임', 3408: '한번', 2146: '예정', 3585: '휴가', 1750: '스위트룸', 2322: '유리창', 2312: '위트', 3050: '캠핑', 3160: '테이블', 1621: '세트', 3161: '텐트', 2054: '에어컨', 2543: '작은방', 975: '매트', 2520: '자리', 3142: '탑동', 263: '공원', 3338: '프리', 923: '마켓', 259: '공연', 971: '매일', 1833: '식사', 282: '관덕정', 2682: '정문', 684: '도보', 1645: '소요', 3458: '해장국', 717: '동문', 1560: '서문시장', 1047: '목관', 960: '맞은편', 1792: '슬슬', 1291: '별관', 1330: '본관', 68: '갈수', 2965: '최신', 377: '그린', 3545: '환경', 787: '때문', 1292: '별도', 641: '대중교통', 317: '구매', 1882: '심플', 1438: '비품', 3205: '트윈침대', 1763: '스탠다드', 548: '높이', 3404: '한라산', 525: '노곤', 3152: '터미널', 2189: '온돌룸', 1608: '세면대', 1114: '물이', 3013: '치약', 150: '것임', 1545: '생수', 3550: '환승', 231: '곧바로', 710: '동광양', 2677: '정류장', 1818: '시청', 1771: '스텝', 3502: '협소하', 130: '거품', 3131: '타월', 3537: '화장', 612: '대가', 123: '거울', 1670: '쇼파', 2739: '조합', 395: '금액', 2780: '주차공간', 267: '공터', 3150: '태풍', 104: '개층', 2184: '오후', 3409: '한시', 1485: '사우나', 1349: '부모님', 3422: '할머니', 1038: '모시', 197: '계획', 2464: '일로', 1445: '빠듯해', 2004: '어디', 441: '길가', 235: '골목길', 2377: '이륙', 2887: '착륙', 1310: '보이', 363: '그냥', 2469: '일반', 633: '대욕', 3489: '헬스장', 19: '가면', 206: '고려', 837: '렌터카', 2496: '입구', 1182: '반대쪽', 3416: '한정', 591: '단체', 660: '더블', 2708: '제외', 2088: '여유', 1183: '반대편', 688: '도심', 1387: '불구', 1648: '소음', 125: '거의', 1609: '세명', 3199: '트리플', 2618: '전날', 495: '남아', 2534: '자체', 610: '당일', 2683: '정보', 3468: '햇반', 2580: '장조림', 2637: '전자', 831: '레인지', 33: '가야', 1610: '세미나', 3400: '한국인', 369: '그대로', 469: '나름', 2697: '제과점', 2670: '정거장', 1022: '모기', 944: '만해', 898: '마리', 16: '가량', 1222: '방안', 2058: '에프킬라', 1435: '비치', 195: '계속', 1456: '뿌리', 2557: '잡고', 2891: '찬장', 2915: '천장', 242: '곳곳', 3008: '측은', 1265: '벌레', 414: '기본', 2223: '요금', 135: '건너편', 1262: '번호', 1538: '샐러드', 2349: '음식', 326: '구성', 2629: '전복죽', 2601: '저번', 3464: '핸드폰', 2996: '충전기', 1400: '불편', 1622: '센터', 256: '공사', 1720: '숙면', 1061: '무난', 528: '노력', 2826: '지불', 1430: '비용', 845: '로맨틱', 702: '독립', 1368: '북유럽', 2321: '유리', 3059: '커튼', 1145: '바깥', 1595: '설치', 1025: '모던', 1418: '비데', 3569: '효율', 2451: '인치', 1512: '삼성', 927: '만끽', 3270: '편안함', 2091: '여정', 1151: '바닥', 1052: '목적', 3060: '커플', 464: '끼리', 2852: '직진', 2268: '운전', 261: '공영', 1962: '애기', 1074: '무선인터넷', 80: '갑자기', 1568: '서전', 3432: '항공', 562: '다가', 5: '가급', 169: '결제', 2342: '은방', 1533: '상황', 1914: '아시', 227: '고트', 2822: '지도', 1614: '세심', 257: '공시', 1815: '시작', 982: '맥주잔', 3102: '쿠폰', 2463: '일도', 3108: '크기', 864: '룸서비스', 2690: '정신', 3277: '평가', 3272: '편의', 2233: '요즘', 2078: '여러', 2848: '직언', 1412: '블룸', 1288: '변기', 1115: '물질', 1997: '얘기', 1675: '수건', 3548: '환불', 2293: '월일', 3313: '푸른', 3223: '파도', 2918: '철썩', 3320: '풍경', 1544: '생선회', 2573: '장소', 543: '놀이', 1989: '양도', 735: '돼지', 2613: '전골', 970: '매운탕', 3512: '형편', 1406: '브런치', 751: '뒤쪽', 956: '맛집', 2869: '쭈욱', 79: '갑인', 764: '드타', 1233: '방파제', 3567: '횟집', 3129: '타운', 3448: '해산물', 356: '규모', 7: '가까이', 2008: '어르신', 454: '깨끗', 629: '대신', 2538: '작고', 1697: '수영', 1912: '아쉬움', 2430: '인도', 1634: '소독약', 1745: '스비', 3525: '홀로', 775: '등정후', 1365: '부터', 3520: '혹시', 3543: '확인', 2645: '전화', 3180: '통해', 3582: '휘트니', 2266: '운동복', 1698: '수영모', 219: '고오', 1157: '바람', 631: '대여', 2093: '여직원', 1077: '무시', 951: '말투', 2284: '원래', 2700: '제로', 2267: '운영', 2470: '일반인', 2503: '입장', 1583: '선심', 3360: '필요', 430: '기전', 620: '대뜸', 3528: '화가', 200: '고객', 3343: '플레인', 1800: '시경', 1917: '아웃', 3382: '하야', 998: '메리어트', 2081: '여럿', 2397: '이어도', 1707: '수준', 2370: '이군', 1867: '실망', 2747: '종일', 880: '리셉션', 3070: '컨시어', 3147: '태도', 2319: '유료', 1460: '사고', 3393: '학생', 1580: '선생님', 2005: '어딘', 1498: '사항', 1075: '무슨', 128: '거지', 879: '리빙룸', 3368: '하나요', 3202: '트윈룸', 1065: '무려', 156: '게재', 1869: '실물', 2881: '차이', 1879: '실화', 3231: '파우더', 240: '곰팡이', 2511: '자국', 2539: '작동', 233: '골드스타', 517: '냉장고', 2649: '절대', 826: '레스토랑', 2513: '자꾸', 2687: '정색', 1510: '살짝', 1561: '서버', 669: '데리', 32: '가신', 470: '나머지', 1105: '물기', 2851: '직접', 2931: '체계', 2048: '엉망', 1630: '소규모', 1803: '시기', 910: '마음', 886: '리트', 794: '라그', 409: '기대', 1862: '실내수영장', 1701: '수온', 1749: '스위트', 1427: '비수', 1515: '상대', 536: '노후', 2669: '정가', 1072: '무리', 3424: '할인', 3473: '행사', 2893: '참고', 3298: '포함', 913: '마일리지', 650: '대한항공', 3377: '하룻밤', 3542: '확실', 2115: '연식', 201: '고급', 2280: '원가', 1566: '서우', 3453: '해수욕장', 3402: '한눈', 2900: '창문', 161: '겨울철', 2187: '온도', 870: '리기', 1214: '방기', 725: '동시', 1221: '방식', 621: '대략', 695: '도정', 1352: '부스', 2137: '옆방', 3220: '티비', 3001: '취침', 2946: '초등학생', 1996: '양호', 3411: '한식당', 2875: '차라리', 1184: '반드시', 3107: '크게', 1896: '씨유', 674: '델문', 3035: '카페나', 3452: '해수욕', 2969: '최적', 778: '디럭스', 1203: '발코니', 1034: '모로', 3203: '트윈룸입니', 1585: '선착순', 2142: '예술', 1106: '물놀이', 1031: '모래', 3352: '피크', 1817: '시즌', 491: '날씨', 1581: '선선', 381: '근래', 3269: '편리', 3086: '코르', 434: '기지', 1481: '사양', 2782: '주체', 302: '교회', 2653: '절반', 2440: '인수', 1314: '보임', 1927: '아트', 2976: '추정', 3333: '프로', 3264: '페셔', 2432: '인력', 976: '매트리스', 472: '나무', 3482: '허리', 1934: '안감', 3447: '해변', 2275: '워낙', 31: '가시', 2757: '주말', 3397: '한국', 1270: '벚꽃', 403: '기간', 3503: '협재', 2197: '옹포', 1209: '밥집', 1505: '산책', 860: '루프', 1425: '비바람', 1396: '불어', 1410: '블로거', 1108: '물떄', 360: '그거', 2308: '위주', 3317: '풀이', 2192: '온수', 1133: '미온수', 1132: '미온', 2536: '자쿠지', 2551: '잠깐', 2458: '인피니트', 3549: '환상', 3365: '하나', 1782: '스페', 3015: '치킨', 1446: '빠에야', 1779: '스파', 333: '구조', 1780: '스파룸', 2535: '자쿠', 2401: '이용권', 3371: '하니', 1487: '사이', 1820: '시트', 2678: '정리', 1511: '삼다수', 1294: '병과', 520: '네스프레소', 3051: '캡슐', 2089: '여자', 3347: '피로', 1784: '스페인', 2132: '영업', 2743: '종료', 1245: '버거', 2161: '오른쪽', 893: '마담', 482: '나탈리', 2351: '음악', 3362: '필터', 1875: '실외수영장', 147: '검색', 2186: '옥상', 164: '결과', 653: '대형', 942: '만큼', 1260: '번잡', 98: '개수대', 2407: '이전', 1909: '아무', 884: '리지', 2714: '제한', 189: '경치', 2403: '이웃', 2467: '일몰', 1877: '실제', 883: '리조트', 3527: '홍보', 1529: '상통', 3532: '화산', 1166: '바위', 2686: '정상', 431: '기점', 1770: '스템', 2556: '잠자리', 435: '기타', 1359: '부족함', 444: '길이', 582: '다행', 2792: '중국어', 2131: '영어', 692: '도움', 3438: '해결', 1053: '목적지', 3461: '해피', 2346: '음료', 1488: '사이다', 2764: '주스', 592: '달걀', 3014: '치즈', 3597: '히터', 3187: '투어', 3515: '호스텔', 2858: '질문', 1530: '상품', 270: '과거', 154: '게스트하우스', 2510: '자고', 2150: '오기', 2479: '일이', 1201: '발전', 2141: '예상', 3165: '토스터', 2424: '이후', 1635: '소등', 1399: '불키', 2733: '조용조', 1232: '방키', 218: '고여', 496: '남자', 1946: '안전', 2878: '차로', 2373: '이내', 1403: '뷔페', 2076: '여느', 856: '롯데리아', 1216: '방만', 224: '고정', 1060: '무궁화', 1676: '수기', 1490: '사이트', 3526: '홈페이지', 921: '마치', 1088: '무척', 2617: '전기차', 134: '건너', 402: '급속', 1628: '소가', 2333: '유치원', 2784: '주택가', ...} 12for coef in coef_pos_index[:20]: print(invert_index_vectorizer[coef[1]], coef[0]) 방문 1.2644550507381787 이용 0.9079356150239053 바다 0.895609472071521 조식 0.8859075267474583 가족 0.8795111499693716 가성 0.8541915649753757 다음 0.8362541212560809 최고 0.7714811231976703 사장 0.7375280889735719 맛집 0.7203390936359615 추천 0.6503260268852225 거리 0.6488836121942877 마음 0.6467914172687944 바로 0.6264469987695738 리조트 0.5943145305412955 출장 0.5505354129422678 도움 0.5294632094678557 인테리어 0.5240729254152497 아주 0.5207834696883535 의사 0.5153917648445299 12for coef in coef_neg_index[:20]: print(invert_index_vectorizer[coef[1]], coef[0]) 예약 -0.9945592515966041 냄새 -0.9190158099937462 다른 -0.8672956005075485 침대 -0.7519681298547074 보이 -0.7201222787741572 최악 -0.7142499739127354 에어컨 -0.6786616478611768 별로 -0.6742178511586063 찾기 -0.6584721911054098 취소 -0.6464141509409321 사람 -0.6451323735594592 정도 -0.6240099604615805 사진 -0.6089303470147718 대부분 -0.5889712626646347 다시 -0.5601302753897155 대해 -0.5518124209379022 노후 -0.5484791097700695 느낌 -0.5423970967095598 필요 -0.5413974621071783 문제 -0.5287746123667489 키워드를 살펴보면: 이용객들이 보통 제주 호텔의 바다뷰 혹은 바다 접근성, 주변 맛집 그리고 인테리어 등에 만족하는 것으로 보입니다. 하지만 숙소의 냄새 그리고 침대, 에어컨 등 시설의 상태가 많이 아쉬워 보이고 개선이 필요해보입니다. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Text Mining","slug":"Text-Mining","permalink":"https://hyemin-kim.github.io/tags/Text-Mining/"}]},{"title":"【실습】 Python >> Text Mining -- 영화 시나리오","slug":"E-Python-TextMining-1","date":"2020-08-20T12:58:32.394Z","updated":"2020-08-29T13:44:11.235Z","comments":true,"path":"2020/08/20/E-Python-TextMining-1/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/20/E-Python-TextMining-1/","excerpt":"","text":"【Text Mining 실습】-- 영화 시나리오: Word Cloud &amp; 단어 중요도(TF-IDF) 분석 0. 개요 1. Library &amp; Data Import 2. 데이터셋 살펴보기 2-1. 기본 정보 탐색 3. 텍스트 데이터 전처리 3-1. 정규 표현식 적용 3-2. Word Count (1) 말뭉치(코퍼스) 생성 (2) BoW (Bag of Words) 벡터 생성 (3) 단어 분포 탐색 4. 택스트 마이닝 4-1. 단어별 빈도 분석 (+ Word Cloud) (1) 상위 빈도수 단어 출력 (2) Word Cloud 시각화 4-2. 장면별 중요 단어 시각화 (TF-IDF) (1) TF-IDF 변환 (2) “벡터” - “단어” mapping (3) 중요 단어 추출 - Top 3 TF-IDF 0. 개요 영화 시나리오 데이터를 활용해 2가지의 Text Mining 분석을 진행합니다. 단어별 빈도 분석 (Word Cloud 산출) 장면별 중요 단어 시각화 (TF-IDF 분석) 1. Library &amp; Data Import &gt;&gt; 사용할 Library 123456789%matplotlib inlineimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport warningswarnings.filterwarnings(\"ignore\") &gt;&gt; 사용할 데이터셋 영화 \"The Bourne Supermacy\"의 시나리오를 활용하겠습니다. Link (pdf파일) 1df = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/bourne_scenario.csv\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } page_no scene_title text 0 1 1 EXT. MERCEDES WINDSHIELD -- DUSK 1 It's raining... ... 1 1 A1 INT. MERCEDES -- NIGHT A1 On his knee -- a syringe an... 2 1 2 INT. COTTAGE BEDROOM -- NIGHT 2 BOURNE'S EYES OPEN! -- panic... 3 1 A2 INT. COTTAGE LIVING AREA/BATHROOM ... A2 BOURNE moving for the medic... 4 2 3 INT./EXT. COTTAGE LIVING ROOM/VERA... 3 One minute later. BOURNE mo... &gt;&gt; Feature Description page_no: 데이터가 위치한 pdf파일의 페이지 수 scene_title: 씬 제목 text: 씬에 해당하는 지문/대본 텍스트 정보 2. 데이터셋 살펴보기 2-1. 기본 정보 탐색 12# demensiondf.shape (320, 3) 12# 결측치df.isnull().sum() page_no 0 scene_title 0 text 0 dtype: int64 12# informationdf.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 320 entries, 0 to 319 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 page_no 320 non-null int64 1 scene_title 320 non-null object 2 text 320 non-null object dtypes: int64(1), object(2) memory usage: 7.6+ KB 12# text 변수 확인df['text'][0] \" 1 It's raining... Light strobes across the wet glass at a rhythmic pace... Suddenly -- through the window a face -- JASON BOURNE -- riding in the backseat -- his gaze fixed. \" \"text\"내용을 확인해보면, 여기에 우리가 필요없는 내용들이 포함되어있습니다: 맨 앞에 있는 씬 번호, 공백, 특수 문자 등. 이들을 제거하는 전처리 과정이 필요해보입니다. 또한, Text mining을 진행할 때, 대소분자의 구분이 의미가 없습니다. 따라서, 대분자를 소문자로 변환하는 작업도 함계 진행하겠습니다. 3. 텍스트 데이터 전처리 3-1. 정규 표현식 적용 1df['text'][0] \" 1 It's raining... Light strobes across the wet glass at a rhythmic pace... Suddenly -- through the window a face -- JASON BOURNE -- riding in the backseat -- his gaze fixed. \" 12345678910# 정규 표현식 함수 정의import redef apply_regular_expression(text): text = text.lower() # 대문자 -&gt; 소문자 변환 english = re.compile('[^ a-z]') # 영어 추출 규칙: 띄어 쓰기를 포함한 알파벳 result = english.sub('', text) # 위에 설정한 \"english\"규칙을 \"text\"에 적용(.sub)시킴 result = re.sub(' +', ' ', result) # 2개 이상의 공백을(' +') 하나의 공백(' ')으로 바꿈 return result 만들어 놓은 정규 표현식을 \"text\"의 첫번째 데이터에 적용해보면: 1apply_regular_expression(df['text'][0]) ' its raining light strobes across the wet glass at a rhythmic pace suddenly through the window a face jason bourne riding in the backseat his gaze fixed ' 우리의 예상대로 소문자만 존재하고, 공백과 특수문자가 모두 제거됐습니다. 그럼 이제 이 규칙을 전체 데이터셋에 적용해볼게요. 123# 정규 표현식 적용df['processed_text'] = df['text'].apply(lambda x: apply_regular_expression(x))df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } page_no scene_title text processed_text 0 1 1 EXT. MERCEDES WINDSHIELD -- DUSK 1 It's raining... ... its raining light strobes across the wet glas... 1 1 A1 INT. MERCEDES -- NIGHT A1 On his knee -- a syringe an... a on his knee a syringe and a gun the eyes of... 2 1 2 INT. COTTAGE BEDROOM -- NIGHT 2 BOURNE'S EYES OPEN! -- panic... bournes eyes open panicked gasping trying to ... 3 1 A2 INT. COTTAGE LIVING AREA/BATHROOM ... A2 BOURNE moving for the medic... a bourne moving for the medicine cabinet digs... 4 2 3 INT./EXT. COTTAGE LIVING ROOM/VERA... 3 One minute later. BOURNE mo... one minute later bourne moves out onto the ve... 3-2. Word Count (1) 말뭉치(코퍼스) 생성 123# make corpuscorpus = df['processed_text'].tolist()corpus [' its raining light strobes across the wet glass at a rhythmic pace suddenly through the window a face jason bourne riding in the backseat his gaze fixed ', ' a on his knee a syringe and a gun the eyes of the driver jarda watching bournes pov the passenger back of his head cell phone rings the head turns its conklin bourne returns his stare ', ' bournes eyes open panicked gasping trying to stay quiet marie sleeps ', ' a bourne moving for the medicine cabinet digs through the medicine cabinet downs something specific ', ' one minute later bourne moves out onto the veranda marie pads in watching him for a moment concerned clearly its not the first time this has happened they both look different than last we saw them his hair is longer shes a blonde hippie travelers their cottage is humble but sweet the bedroom opens to a beach and a town just down the hill club music from some all night rave wafting in from the far distance marie where were you jason bourne in the car conklin up front marie ill get the book bourne no theres nothing new marie youre sure he nods we should still we should write it down bourne two years were scribbling in a notebook marie it hasnt been two years bourne its always bad and its never anything but bits and pieces anyway shes gone quiet you ever think that maybe its just making it worse you dont wonder that she lays her hands on his shoulders steadies him marie we write them down because sooner or later youre going to remember something good bourne softens i do remember something good all the time i remember you she smiles kisses him leads him back in ', ' marie getting bourne into the bed turning down the light getting him settled waiting for that pill to kick in what would he do without her bourne im trying marie okay marie i worry when you get like this bourne its just a nightmare marie i dont mean that i worry when you try to ignore it he hesitates but that gets him he knows shes right and with that opening hes letting go resistance folding almost childlike shes gathering him in hes letting her do it marie contd sleep sleep now bourne i should be better by now marie you are better and i think its not memories at all its just a dream you keep having over and over bourne but it ends up the same marie one day it will be different it just takes time beat well make new memories you and me silence she strokes his face he gives in to her tenderness hes fading two waifs in the dark ', ' bourne running in the sun a punishing pace along the sand moving strong effortless deep into it focused the stunning conjunction of sun and scenery are lost on him ', ' a busy market town fishing town hippie town lots of young western faces rundown and happening at the same time marie shopping filling a bag with local produce ', ' bourne still running leaving the beach behind ', ' marie back from the market putting the groceries away almost done when she stops for a moment a photograph there on the windowsill a snapshot jason and marie on a beach her arms around him as if she were the protector big smiles young alive in love marie smiles ', ' funky busy colonial facades in vivid subcontinental technicolor loud morning traffic camera finds bourne coming out of a store with a big bottle of water hes just finished his run standing there chugging away checking the scene when something catches his eye his pov the street a silver car something newish pulling down the block cant quite see whos driving but back to bourne watching this silver car so serious hes casual nobody passing would notice but we do hes on alert moving with him as bourne follows the silver car on foot natural cruising the busy sidewalk blending into the mix chugging on that water bottle and up ahead the silver car making the corner and turning now back to bourne slowing as he reaches the corner his pov the silver car has parked theres a guy welldressed casual physical sunglasses call him kirill hes out of the car and heading across the street toward a building there a telegraph office back to bourne checking his watch the car the guy perimeter ', ' mr mohan at his desk hes a crisp proper man of fifty hes just been handed something a photograph of marie an old passport picture mr mohan and your question sir kirill across the desk kirill shes my sister theres been a death in the family this is the last place we know she called from ', ' a note on the table im at the beach bourne has just come in just read the note balling it quickly in fact everything is quickly now because bourne is bailing fast calm methodical some exfil procedure that hes honed and choreographed packing like a machine rapid time cuts backpacks thrown open on the bed house cash pulled from a lamp base credit cards taped under the counter ', ' kirill coming out of the bank mission accomplished heading back to the silver car getting in and ', ' kirill starting it up glancing around nice and easy hes cool putting the car into gear he makes a slow pass through the marketplace eyes everywhere ', ' bourne done the place is stripped pulling on the backpacks glancing around one last thing shit he almost missed it the photograph the one of he and marie on the beach the one we saw her looking at earlier there it is on the windowsill jamming it into his pocket and ', ' a kirill now parked and out of the car on the move on foot he begins a sweep of the beach ', ' bourne out the back jogging keeping low into the neighborhood through the alleys nothing random about it this has all been worked out and ', ' crowded with tourists sunbathers marie at her favorite spot talking with two women laughing with them happy ', ' a a burly jeep comes roaring up bourne spots the silver car parks at the other end takes off towards the beach ', ' kirill methodically making his way up the beach checking every blue tent every towel ', ' bourne coming up the beach the opposite way one eye on kirill one eye on marie he arrives just as kirill looks up and sees them a hundred yards away a hard stare between them bourne bends down bourne we gotta go marie we gotta go now from the tone of his voice she knows its serious marie grabs her bag a quick goodbye to the friends they hurry off bourne uses the sunbathers as cover kirill retreats ', ' they reach the jeep she knows the drill bag tossed in the back even as the jeep pulls away and ', ' bourne driving marie beside him bourne were blown she hesitates one minute ago everything was fine marie no how bourne the telegraph office marie but we were so careful bourne we pushed it we got lazy ', ' kirill already back at the silver car following them out onto the main street blocked by the local traffic pulling a huge automatic pistol out from his travel bag ', ' the jeep pulling down this narrow little passageway and bournes windshield pov main street packed with traffic and back to bourne not liking this eyes all over trying to decide marie but youre sure bourne he was at the campground yesterday marie so bourne its wrong guy with a rental car and hundred dollar sneakers sleeps in a tent trying to decide whether to pull out or back up marie thats crazy bourne no not this this is real suddenly and hes right there throwing the car into reverse marie where bourne back there at the corner hyundai silver ', ' kirill trapped in some main street gridlock glancing back for a way out freezing suddenly because there his pov the jeep the alley right there twenty yards back a good look at bourne and marie as they disappear and ', ' the jeep backing up the way it came blowing its horn because an old van pulls in and blocks him from behind ', ' bourne leaning on the horn shit now theyve got to wait marie but youre not youre not sure bourne we cant wait to be sure marie i dont want to move againi like it here bourne look we clear out we get to the shack we get safe we hang there awhile ill come back ill check it out but right now we cant marie wheres left to go bourne theres places we cant afford to be wrong ', ' kirill calm possessed of a familiar tactical patience he cant get the hyundai to the alley from where he is and it doesnt make sense to go on foot he checks his rearview fuck it theres an opening ahead and hes taking it even though its away from them hell find another way ', ' bourne sees the hyundai move forward into traffic the old van is still blocking them from behind bourne you drive marie what bourne already squeezing over switch you drive marie where bourne make the left toward the bridge marie scrambling over the seat bourne eyes everywhere checks his watch the jeep squirts back on the main street and ', ' marie at the wheel adrenaline pumping clear running for thirty yards ahead and marie skidding them into the right turn clipping another vehicle mirror shattering speeding up bourne scanning behind them marie moving out to pass veering back an oncoming bus just in time and marie jesus glancing over is he back there bourne not yet marie its just him bourne yeah one guy i dont think he was ready marie hang on marie bearing down pulling out gives him a quick smile bourne knowing hes got a good one here ', ' kirill stopping short on a rise bit of a view from here gets half out the car to look below the jeep headed for a bridge hes gonna lose them kirills mind racing grabs duffle from the back abandons car ', ' marie driving bourne preps his pistol eye out for kirill bourne you keep going to the shack ill meet you there in an hour marie concerned where are you going bourne im going to bail on the other side and wait this bridge is the only way he can follow marie what if its not who you think it is bourne if he crosses the bridge it is marie there must be another way bourne i warned them marie i told them to leave us alone marie jason please dont do thisit wont ever be over like this bourne theres no choice her pov the old concrete bridge ahead almost there ', ' kirill slams into it quick precise grabs into the bag only a moment and hes got a sniper rifle ', ' a bourne pistol in hand spare clip in the other checks his watch bourne at the end make the left when i roll out do not slow down marie nods got it after a beat marie i love you too bourne tell me later marie looks ahead ', ' b kirill eye to the scope sniper scope pov there the jeep rumbling across the bridge no clear target just the back of the full drivers side headrest kirills finger squeezing firing ', ' the jeep jerking front fender tearing into and along the guard rail cement shards fill the air bourne reaching for the wheel too late as the jeep finally crashes through the flimsy guardrail plummets splashes hard begins to sink out of sight ', ' kirill lowers the scope takes a quick look around hes basically gone unnoticed in this little nook with his silenced rifle but people are already rushing toward the bridge then there an old woman looking directly at kirill from a doorway not quite sure what but an old indian woman in goa so what kirill drills her with a look as she sinks back inside ', ' swallowed up bourne and marie gone ', ' kirill scans the surface of the river under the bridge waiting ', ' mud plumes as the jeep settles bourne reaches over to marie tries to urge her out ', ' kirill with a killers patience waiting almost done scope pov the surface of the water unbroken kirill scans his perimeter theres the old woman again but more people with her people coming out of the woodwork kirill checks the surface one last time nothing he breaks down the rifle in moments goes ', ' bourne up into an air pocket held by the jeeps canvas top a big gulp of air and hes back to marie frantic trying to unclip her seatbelt pull her out but its all jammed up ', ' bag chucked in the back all he has left is the scope one last look to the unbroken surface then its time to go kirill drifting away disappears ', ' the red halo growing bigger blood bourne pauses maries face is blank shes dead bourne finally pulling back realizing this is goodbye ', ' we pick up a man with a briefcase on a telephoto lens teddyradio vo the seller has arrived berlin as the man comes to a chinese restaurant he stops squarely so he can be seen clearly then he enters a stark glass office building teddyradio vo contd contd hes inside ', ' two men cross the square to the chinese restaurant vic is forty steelass intel operator he carries a large samples case beside him mike younger exnavyseal ', ' the hub secure anonymous office space somewhere in the city shades drawn lots of gear cabled around the stale improvised feel of a temporary outpost four serious people alone in this room pamela landy is a senior cia counterintelligence officer hovering over the communications console cronin pamelas early forties stonecold facade quarterbacking the operation over the radio kurt and kim are the techs here his and her headphones ruggedized laptops and comm gear spread around them cronin what have you got survey one ', ' dark teddy at the window another military face radio rig night scope watching vic and mike pass below him teddyradio over hub this is survey one mobile one is in motion seller is inside and waiting ', ' vic and mike slow as they come to the same stark glass office building teddyradio over we are ready to go ', ' mike and vic shake hands two tired coworkers parting ways mike will keep walking vic entering the building through the big glass doors smiling as hes approached by a night shift security guard and we hear mike still walking alone now heading away from the glass office building toward a van parked up the block mikeradio sleeve mike earpiece this is escort one im clear ', ' the command post cronin works the communications board cronin all teams listen up we are standing by for final green turning now to pamela who has been listening just as shes about to give the final word kim raises a finger kim langley she hands pamela a phone thats patched into her board pamela a bit surprised martin ', ' three men cia mandarins sit around a round table martin marshall deputy vicedirector hes in charge all is tense marshall im here so is donnie and jack weller we understand youre using the full allocation for this buy pamela thats where we came out marshall its a lot of money pam pamela were talking raw unprocessed kgb files its not something we can go out and comparison shop marshall still pamela for a thief a mole i vetted the source marty hes real if it does nothing more than narrow the list of suspects its a bargain at ten times the price mandarin pamela jack weller here its the quality thats at issue pamela yes sir im in total agreement if theyre fakes theyre expensive furious impatient gentlemen ive got the seller on site and in play quite honestly theres not much more to talk about marshall looks to his mandarians not convinced but doesnt want to lose the opportunity time to wash his hands marshall all right pam your game your call ', ' all eyes on pamela as she puts down the phone to langley nodding to cronin yes croninradio final green you are go repeat you are go for final green ', ' vic has just passed muster with the security guard hes standing alone at an elevator bank vicradio sleeve mike earpiece on my way up vic pulling his earpiece going dark waits for an elevator ', ' a dark a small room full of wiring and infrastructure lit by the glare of someones maglight gloved hands quickly pass over racks of gear and wiring and then stopping at the main electrical risers they carefully place an explosive device no bigger than a pack of cigarettes onto the main riser done with that here comes a second small explosive device but this ones special its being taken from a plastic bag and mounted down by the floor on a subpanel done the hands hold up what looks like a piece of tape ', ' transferring it onto the charge ', ' vic alone with the samples case pressing the button for the top floor the doors close the car rises and then it stops vic bracing himself as the door opens and ivan russian the guy we saw outside with the briefcase standing in an empty darkened hallway ivan show me vic here ivan holding open the door now show now vic flips open the case cash three million dollars ', ' a glass door a suite of offices beyond clean anonymous one light on deep inside caspiexpetroleum cherbourg moscow rome tehran', ' curtains drawn lights low ivan sitting with the samples case counting the cash vic poring over russian document files dozens of kgb files old and new spread sheets financial data incomprehensibly cyrillic marked up but judging by the seals and clearance sign offs all topsecret vic this is everything ivan is there is all there suddenly music a radio some tinny pop tune just started playing from somewhere down the hall vic what the hell is that alone you said alone both of them sure theyre being doublecrossed vic contd contd reaching for his ankle who who else is here ivan no not me no other people vic coming up with a pistol shut up just shut the freaked by the gun ivan to his feet vic pushing him back as he rushes past the sample case spilling cash and wrong snapph snapph snapph snapph snapph five fast suppressed small caliber shots vic falls first ivan crashing back across a desk as the bullets tear into him both of them dead before they hit the floor and reverse to find the gloved hands unscrewing a silencer tucking away the weapon already in motion before we know whats happened pulling a climbing duffel out from his back pack stuffing in the samples case and ivans briefcase all the files all the money except wait hes left out one old kgb file cover and now he pulls a plastic bag from his backpack gloved hands carefully remove a single sheet of paper from inside the bag and this paper looks exactly like all the stuff hes just tucked away another page full of cyrillic blur hes putting this sheet of paper inside the file cover now hes slipping them both underneath the desk tossing them there as if they fell in the struggle and ', ' the electrical risers as one of the two detonation decives blows a single tidy selfcontained explosion and ', ' as the lights flicker and fail and the night shift security guard is suddenly cast into darkness and ', ' as they were waiting but only a moment before teddyradio sudden urgent hub we just we lost power the building the whole place just went dark cronin looking at pamela the first whiff of dread as cronin repeat who is dark the target building or your location radio voices piling up panicked confusion cascading as ab ', ' anonymous drone barn kirill stepping out of a car hes carrying the duffle ', ' kirill heading down the hall ', ' kirill enters its a small room gretkov is waiting hes forty professional trim and polished dominant gretkov russian youre early kirill youre complaining gretkov its clean kirill would i bring it gretkov taking over now tosses some money on the bed checks out the photocopy of the files gretkov what are you doing kirill stripping quickly kirill im taking a shower its been a long day gretkov make it fast my plane is waiting gretkov dumping three million dollars over the bed as kirill sheds his clothes and we ', ' a workmen cluster as a cable winches the jeep is raised from the river bottom as water pours off of it bourne watching from a distance empty ', ' b crime scene police blocking office workers from getting in the building media vans clogging the street pamela and cronin across the street watching the mood is black ashes pamela we need to get in there cronin im working on it pamela stands there silent staring at the disaster across the street a ', ' a bourne is bailing exfil procedure but this is a heartbroken exfil a footlocker open bournes main stash bourne going through the footlocker setting aside his work clothes other things he needs but he also has to separate a growing pile of marie memories bank cards phony student ids loose passport photos with a mix of looks and hairdos clothes vacuumpacked bags spare shoes ', ' b a gasolinestoked fire burning in a rocklined pit bourne feeding his papers and all of maries belongings into the fire a passport cover crinkles back to reveal her photo her face begins to burn gassoaked clothes tossed in nothing left except the photograph the picture of he and marie at the beach the one from his desk bourne hesitates holds the photo out to the flames the rules of exfil say drop it but he cant wont he reaches to his bag sticks the photo on top of his gear then hefting the bag bourne strides away ', ' a folding table covered with xeroxed berlin police paperwork pamela getting a showandtell from cronin and teddy cronin so there were two of these explosive charges placed on the power lines one of them failed the fingerprint pamelas got it thats from the one that didnt go off pamela and the germans cant match it teddy nobodys got it we checked every database we could access nothing cronin show her the other thing teddy this is a kgb file that mustve fallen somehow and then slipped under i guess a desk there or handing it to her pamela do we know what this says teddy yup a scrap of paper the main word there the file heading translates as treadstone pamela what the hell is a treadstone cronin shaking his head nobody knows ', ' c bourne bouncing around on an old punjab bus alone in a crush of humanity going only god knows where ', ' a pamelas pov as she drives toward the entrance cia headquarters virginia ', ' a long bright sterile hallway pamela and cronin walking briskly alongside a uniformed sps officer ', ' pamela and cronin watching the sps officer unlock the operation panel coding in they begin to descend and ', ' drab and desolate pamela and cronin come around a corner walking with a new escort officer passing a sign that reads operations library center ', ' sealed triplelocked numbered door it swings open lights flicker on tons of shit packed away in here shelves bulging boxes tapes binders hard drives pamela steps in a huge filing cabinet labeled treadstone pamelaphone over ward abbott os yes pamelaphone pamela landy a ', ' ward abbott at his desk the cluttered clubhouse hq of a man whos spent the last thirtyfive years in the spy game a picture window offers a commanders view of the bullpen abbottphone what can i do for you pam pamelaphone i was hoping you had some time for me abbottphone time for what pamelaphone im free right now actually abbottphone that sounds ominous let me check my schedule abbott holds the phone eyes drifting out the window and abbotts pov the bullpen cronin is standing with daniel zorn one of abbotts trusted s clearly zorn is getting the less polite version of pamelas invitation zorn managing to shoot a quick questioning glance to abbott as ', ' a cold room desk two chairs abbott and pamela alone pamela treadstone abbott never heard of it pamela thats not gonna fly abbott with all due respect pam i think you mightve wandered a little past your pay grade she has a piece of paper she slides it forward pamela thats a warrant from director marshall granting me unrestricted access to all personnel and materials associated with treadstone abbott rocked and trying to hide it abbott and what are we looking for pamela i want to know about treadstone abbott to know about it almost amused it was a kill squad black on black closed down two years ago more abbott contd nobody wants to know about treadstone not around here the warrant you better take this back to marty and make sure he knows what youre doing pamela trump card he does ive been down to the archives i have the files ward ', ' a a hard working port a big mediterranean ferry coming in naples ferry bourne at the rail unchanged from india staring ahead as europe looms ', ' b bourne disembarking to an immigration queue looking unremarkable just one of many passing through ', ' as they were abbott watching pamela pull a photo from her file sliding it over conklins face peering back pamela lets talk about conklin abbott what are you after pam you want to fry me you want my desk is that it pamela i want to know what happened abbott what happened jason bourne happened fury focusing youve got the files then lets cut the crap it went wrong conklin had these guys wound so tight they were bound to snap more abbott contd bourne was his number one guy went out to work screwed the op and never came back conklin couldnt fix it couldnt find bourne couldnt adjust it all went sideways finally there were no options left pamela so you had conklin killed silence i mean if were cutting the crap abbott ive given thirty years and two marriages to this agency ive shoveled shit on four continents im due to retire next year and believe me i need my pension but if you think im gonna sit here and let you dangle me with this you can go to hell marshall too flat it had to be done pamela and bourne wheres he now abbott shrugs dead in a ditch drunk in a bar in mogadishu who knows pamela i think i do we had a deal going down in berlin last week during the buy both our field agent and the seller were killed we pulled a fingerprint from a timing charge that didnt go off beat they were killed by jason bourne abbott hesitates blindsided what a courtesy knock at the door cronin appearing in the doorway theyre ready for us upstairs ', ' a now at the immigration officer booth bourne hands over an old blue passport it reads jason bourne whats he up to is he giving up immigration officer where you coming from mr bourne bourne tangiers the officer runs the code on the passport through the scanner ', ' a tech turns as a computer alarm begins an incessant beeping the screen as jason bournes passport data begins scrolling through a sleeper waking up on the grid then his photo work station as an interpol supervisor leans in over the techs shoulder to see whats up after a beat as the tech begins typing and hits send ', ' crewcut turns from his monitor to his own superior as at the same time ', ' looking up from his computer the immigration officer gestures bourne to one side immigration officer sir would you be so kind as to step over here please bourne uh sure the immigration officer comes out of his booth as a carabinieri joins him and they escort bourne to a small room at the side of the customs hall immigration officer please wait in here bourne scans the hall as he walks enters room pamelas vo seven years ago twelve million dollars was stolen from a cia account bourne takes a seat carabinieri guards the room ', ' same table more faces marshall back in the throne abbott three cia mandarins plus their s and pamela in warsaw this is click a photo of the man killed in berlin fills the projection screen behind her click crime scene photo of dead body click pecos oil logo pamela contd ivan mevedev senior financial manager worked for one of the new russian petroleum companies pecos oil he claimed to know where the money landed we believe this could have only happened with help from someone inside the agency this click conklins photo pamela contd placing it on the table this is conklins computer click a photocopy of a banking contract pamela contd at the time of his death conklin was sitting on a personal account in the amount of sevenhundred and sixty thousand dollars abbott do you know what his budget was pamela excuse me abbott we were throwing money at him throwing it at him and asking him to keep it dark pamela may i finish abbott conklin mightve been a nut but he wasnt a mole you have me his calendar for a couple of days ill prove he killed lincoln appealing to marshall this is supposed to be definitive pamela whats definitive is that i just lost two people in berlin abbott so whats your theory mocking her conklins reaching out from the grave to protect his good name incredulous the man is dead marshall hes heard enough no ones disputing that ward abbott for crissake marty you knew conklin does this scan i mean at all marshall signals for quiet marshall okay cut to the chase pam what are you selling pamela i think that bourne and conklin were in business that bourne is still involved more pamela contd and that whatever information i was going to buy in berlin it was big enough to make bourne come out from wherever hes been hiding to kill again to abbott hows that scan as the mandarins all start talking at once zorn enters stands at the head of the table tries to get their attention zorn hey they look up look youre not gonna believe this but jason bournes passport just came on the grid in naples abbott blinks what ', ' nevins american a junior cia field officer walking from the parking lot talking on his cellphone nevins what can i do i cant ill call you when i know what im into a hassled pause i dont know some guys name came up on the computer starting toward the building so start without me if i can get there i will later nevins hangs up and pockets the phone he hustles towards the building ', ' the room is jumping agents tracking working the phones and computers pamela giving orders abbott watches cronin looks up from computer screen looks like hes been detained pamela whos going us cronin theres only a consulate they sent a field officer out half an hour ago pamela cuts him off then get a number they need to know who theyre dealing with cronin already on it ', ' as nevins flashes his credentials to carabinieri at door who gives an unimpressed shrug and lets him in nevins takes his overcoat off tosses it on the empty chair we see a big ass for just a second under his suit jacket nevins alright mr bourne is that your name bourne nods names nevins im with the us consulate could i see your passport bourne silent hands over his passport nevins contd so mr bourne nevins studies bournes passport nevins contd what are you doing in tangiers silence nevins contd faux friendly are you travelling alone bourne stares straight ahead nevins comes around the table and sits in front of bourne nevins contd in his face look i dont know what youve done but youre gonna need to play ball here nevins cell starts to ring he shrugs an apology turns away and answers nevins contd contd nevins pamelaphone this is pamela landy a ci supervisor calling from langley virginia are you with a jason bourne now nevins listens looks at bourne yes ', ' a pamela on the phone pamela then use extreme caution he can be very unpredictable and violent use whatever means necessary to ', ' whatever nevins is being told its concerning bourne watching him knows exactly what this is close on nevins as he steps away listening intently his hand just starting to move toward his shoulder holster nevins contd okay ill call you right back nevins flips shut his phone he reaches for his gun even as he turns and bourne is right there in his face whump momentum and gravity reaching mutual agreement as nevins hits the deck carabinieri barely clears his holster before chop chop bourne has him down in a heap bourne is back silent and effective finding nevins cellphone bourne reaches into his bag he holds the phone next to a larger diagnostic mobile unit the confirm light blinks nevins phone has been cloned bourne puts the phone back in nevins coat takes his gun and carabinieris gun and radio and puts them in his duffle were starting to realize theres a plan at work here finally bourne exits the door wedging a desk under the handle so it cannot be opened from the inside and calmly walks away like nothing ever happened ', ' and now we see the old bourne in his long black coat purposely striding out of the building he pauses long enough for the security camera to get a good look at him the ronin returns ', ' bourne crosses the street and approaches a man putting his suitcase in the trunk of a green peugeot bourne reaches into his bag pulls out some cash ', ' nevins stirring the carabinieri still out a phone starts to ring nevins phone finally sitting up he answers nevins hello ', ' pamela at the other end of the line pamelaphone mr nevins nevinsphone whos this pamelaphone pamela landy again where do we stand ', ' a nevins barely knows where he is ', ' bourne sits in the dark car headphones a nest of cool gadgetry on the passenger seat listening in recording he writes pamela landy circles it nevinsphone i think i think he got away pamela looks at the faces waiting around the table shakes her head no pamela have you locked down the area nevinsphone ah were in italy they dont exactly lock down real quick intercut bourne nevins pamela pamelaphone how long have you worked for the agency nevinsphone me four years pamelaphone if you ever want to make it to five youre gonna listen to me real close jason bourne is armed and extremely dangerous a week ago he assassinated two men in berlin one of whom was a highlyexperienced field officer continuing as were totally on bourne at this point sitting there in the dark car struggling to make sense of this what the fuck is she talking about berlin he writes it circles it pamelaphone contd i want that area secured i want any evidence secured and i want it done now is that clear nevinsphone yes sir maam pamelaphone im getting on a plane to berlin in minutes which means you are going to call me back in and when i ask you where we stand i had better be impressed my mobile number is bourne already turning the key in the ignition the peugeot roaring to life as he writes the number dropping the car into gear bourne pulls briskly away from the curb ', ' a pamela finishes hangs up abbott berlin pamela ive already got a team there i doubt bournes in naples to settle down and raise a family abbott you dont know what youre getting into here pamela and you do from the moment he left treadstone he has killed and eluded every person that you sent to find him before it can come to blows marshall riot act enough i want both of you on that plane more marshall contd and we are all of us going to do what we were either too lazy or inept to do the last time around youre going to find this sonofabitch and take him down before he destroys any more of this agency beat is that definitive enough for you abbott nods sharing a look with pamela as we ', ' aa pamela and cronin come screaming around a corner and down a long corridor abbott and zorn trying to keep up cronin kurts reopening all the wyfi and sat links pamela uplink all relevant files to kim a look back at zorn and i want them to contact anyone who had anything to do with treadstone zorn looks to abbott as they disappear around a corner ', ' b the peugeot speeding north north towards germany and ', ' bourne driving listening to playback of pamelas conversation with nevins pamelatape jason bourne is armed and extremely dangerous bournes face eyes tight looking weird pamelatape contd contd a week ago he assassinated two men in berlin one a highly a suddenly a flashback a shard pieces lightning flash of images getting in the back seat of the car rolling brandenburg berlin a mirror the television tower the driver looks back we see him well know him later as jarda then a steel case on the backseat inside a syringe a dark vial pistol as we lay hands on them b back to b bourne out of it jolted almost losing control of the car for a second jerking back into his lane recognition toughing it out steady as she goes catching his rhythm again accelerating and ', ' a bakery on the corner nicky emerging nicky from the old days suddenly she stops abbott stands there beside a parked car the passenger door open message clear get the fuck in ', ' inside a hanger inside an office abbott watching as cronin questions nicky pamela sits on a window sill cronin so your cover at the time was what nicky that i was an american student in paris cronin what exactly did your job with treadstone in paris consist of nicky looks to abbott he nods that its okay to answer pamela bristles at the checkoff nicky i had two responsibilities one was to coordinate logistical operations the other was to monitor the health of the agents to make sure they were up to date with their medications cronin health meaning what nicky their mental health because of what theyd been through they were prone to a variety of problems pamela losing patience what kind of problems nicky depression anger compulsive behaviors they had physical symptoms headaches sensitivity to light pamela amnesia nicky before this before bourne no nicky gets agitated abbott steps in fatherly good cop abbott were you familiar with the training program nicky the details no i mean i was told it was voluntary i dont know if thats true or not but thats what i was told a bit defensive look they took vulnerable subjects okay you mix that with the right pharmacology and some serious behavior modification and i dont know i mean i guess anythings possible zorn arrives from outside zorn the jets ready points to nicky theres a car for you everybody moving nicky relieved shes off the hook she thinks she becomes aware of pamela considering her nicky good luck pamela you were his local contact you were with him the night conklin died youre coming with us ', ' streaks across the sky ', ' quiet in the cabin abbott gets up to use the bathroom pamela sits across from nicky who stares out the window as the bathroom door clicks shut pamela seizes the privacy pamela im curious about bourne your interpretation of his condition you have specific training in the identification and diagnosis of psychological conditions nicky am i a doctor no but pamela are you an expert in amnesia nicky look what do you want me to say i was there i believed him pamela believed what nicky i believed jason bourne had suffered a severe traumatic breakdown pamela so he fooled you nicky frustration building if you say so pamela leans in still low not good enough youre the person who floated this amnesia story shifts gears ever feel sorry for him for what hed been through nicky youre making it out like were friends here or something i met him alone twice pamela you felt nothing no spark two young people in paris dangerous missions life and death nicky incredulous you mean did i want a date pamela did you nicky these were killers conklin had them all jacked up they were dobermans pamela some women like dobermans nicky what do you want from me i was reassigned im out pamela see thats a problem for me nicky whatever hes doing we need to end it this isnt the kind of mess you walk away from pamela leans away nicky looks back out the window ', ' three in the morning as the gulf stream lurches to a stop two black sedans here for the pickup teddy the greeting party as pamela cronin abbott zorn and nicky disembark ', ' a the sedans making their way stopping at a nondescript office building ', ' b elevator opens into their th floor world emergency activity kim ready to debrief kurt work the computers energy up pamela abbott and cronin bring nicky into the room kim so far bournes had no contact with anyone on the list langley pulled an image out of naples its uploading right now kurt coming in now everything stops as the photo blurry oblique begins materializing on halfadozen monitors around the room suddenly theyre surrounded by bourne pamela to nicky is it him looking closer she nods cronin hes not hiding thats for sure zorn why naples why now pamela has gone quiet just staring at the picture as kurt could be random cronin maybe hes running abbott looks skeptical abbott on his own passport kim the image whats he actually doing cronin whats he doing hes making his first mistake and then from behind them nicky its not a mistake everyone looks over they dont make mistakes and they dont do random theres always an objective always a target beat if hes in naples on his own passport theres a reason pamela turns to abbott a silent moment between them theyre in it now and they know it ', ' c the peugeot streaking through the alps passing a sign for the german border moonlit glacial peaks whipping past as club music starts pulsing louder and louder and ', ' d bourne driving hard pushing the car through the night mission bourne as the music keeps just building and building taking us into ', ' packed and loud skin and smoke a doorman on the move taking us with him through the crowd faces voices all the moscow party people and at the back a vip booth kirill simply shitfaced but in a really creepy numb kind of way three women absolutely gorgeous are sitting around him chatting away as if he werent even there the girls looking up to see the doorman standing there can he walk kirill stirs his stupor a futile attempt to escape eyes still those of an exceptionally hard man a minute later kirill can walk the most graceful drunk youve ever seen making his way through the club tuning out everything but the need to get to the door and ', ' yes day its nine am kirill suddenly in the sunlight people going to work kids off to school and gretkov sitting in his mercedes not happy follow car and security and assistant equally unhappy gretkov you told me jason bourne was dead kirill blinking against the sunlight trying to process ', ' discreet and chilly a car pulls up a man gets out munich we dont see his face as he heads in ', ' the man enters his alarm system beep beep starts once he comes through the door theres a keypad on the wall he enters his code and the beeping stops just like everyday its a sad house he hangs his coat on the rack moving now into the kitchen he drops his briefcase on the table opens the fridge for a drink except what he comes out with is a gun wheeling around the salaryman is jarda jarda from bournes dream but as he turns bourne behind him bigger gun waiting so ready bourne i emptied it jarda a total pro felt a little light bourne drop it jarda lets the gun fall looks his old comrade over a beat but bournes not interested in a reunion bourne contd contd here bourne tosses him flexcuffs jarda puts his hands behind his back turns to let bourne cinch them bourne contd contd front use your teeth jarda caught scamming sorry old habits bourne kicks over a chair sit jarda contd word in the ether was youd lost your memory bourne checking jardas briefcase tearing through it bourne you still shouldve moved jarda i like it here a beat more jarda contd last time i saw you was greece you had a good spot bourne reacts doesnt look over but realizes jarda contd i had the girl i had her lined up that whole afternoon waiting for you that was the problem defensive you ever do two targets its tough bourne turns cold jarda contd his real question so why didnt you kill me then bourne she wouldnt let me beat shes the only reason youre alive silence jarda down a peg or two jarda what do you want bourne conklin jarda hes dead bourne the gun right to jardas face bourne try again jarda shot dead in paris dead the night you walked out bournephone then who runs treadstone jarda nobody they shut it down were the last two its over not finishing because hes falling landing hard bourne just kicked the chair out from under him bourne youre lying if its over why are they after me jarda i dont know bourne who sent you to greece jarda a voice a voice from the states someone new bourne pamela landy jarda i dont know who that is bourne whats going on in berlin jarda i dont know why would i lie silence bourne pulls back unsure jarda makes it to his feet jarda contd what the hell did you do you must have really screwed up bourne doesnt know he backs off jarda contd she really did that told you not to kill me beat i had a woman once but after a while what do you talk about i mean for us the work you cant tell them who you are bourne i did jarda hesitates its really like bourne just told him how much he loved her jarda i thought you were here to kill me something in the way he said it plus jarda just glanced at his watch bourne what did you do jarda shrugs almost embarrassed bourne looks across to the alarm pad jarda hit on the way in voltage like a switch bourne contd contd you called it in jarda im sorry bourne how long how long do i have stopping because the phone just started ringing loud insistent bourne contd contd how long ', ' jamming right the fuck into it three guys jarheads dod special force dudes speeding through munich jar is the driver jar is prepping weapons like a maniac in the backseat and jar on the phone its a red flag file so fix it call them back asap jar the call what whatd they do jar bad news she called munich local jar slamming home another clip its probably just a drill anyway ', ' phone ringing jarda in cuffs bourne scanning out the windows everything fast bourne car keys jarda my coat but we should bourne what jarda take the back get another car bourne hesitates just a moment wrong slam out of nowhere jarda swings twohands still cuffed like a mace catching bourne hard and bourne stunned jarda smashing the coffee table slices the flexcuffs through on a shard of glass free jarda follows up knee up in the ribs the gun knocked free from bournes hand skittering across the floor bourne as jarda starts to move backhanding him and ', ' two munich patrol cars rolling and ', ' seen from inside glimpsed through the glass outside its war a flatout closequarter death match jarda older and cuffed but strong and determined bourne still hammered from that opening suckerpunch the two of them braced there grappling falling jarda the cuffs hes got bourne in a chokehold but bourne driving his head back into jardas face and ', ' jamming along through munich ', ' jarda bourne the gun on the floor struggling for it jarda there first bourne on him pinned there four hands one gun and blamm wild shot into the refrigerator still wrestling breaking jardas nose until the gun knocked away again finally their hands locked into each others throats this is as real and up close as it gets until bourne finally holds dead weight eyes fixed staring bourne jumping back blood all over his shirt bournes first kill in a long time a messy one revulsion ', ' jarheads getting close but up ahead another munich patrol car in motion the jarheads react dont need or want the company ', ' bourne all business now pulling the stove away from the wall there the gas line hose bourne ripping it free gas running wide open into the room next a fork grabbing it jamming it down into the mechanism on a toaster wedging it there and now hes grabbing papers jardas stuff on the table jamming a roll of sales projections into the toaster beside the fork bourne coughing from the gas turning the toaster on checking his watch taking one last look at jarda dead on the floor and ', ' theyre just turning into the street ', ' the dod car three dods approaching the house when booooomm jardas kitchen blown out gone ', ' bourne same moment flying out the rear as planned urban backyard exfil hes flying and gone ', ' fire smoke its all burning now munich cops blown back theyll have a story to tell tonight ', ' drives away past arriving police ', ' the bullpen is cranking phones to munich lines to langley abbott watching from the sidelines kurt and kim at their work stations pamela on mobile turns to abbott pamela so he beats a man within an inch of his life strangles him then blows the place up at nicky for someone with amnesia he certainly hasnt forgotten how to kill has he across the room cronin and teddy suddenly excited about what theyre seeing on their screen cronin hey theyve got him boxed in new data coming up on the monitor everyone rushing to look excited except zorn forget it they lost him teddy whatre you talking about theyve got a three block perimeter zorn you cant see him hes not in front of you forget it hes gone cronin fuck you buzzkill its not gonna be like last time zorn you better start listening to someone cause weve been there abbott okay enough stepping in take a walk danny get some air zorn nods happy to nicky piping in i dont think we need to keep looking for him anyway pamela and why is that nicky because hes doing just what he said hed do hes coming for us and for the first time theyre all thinking the same thing ', ' it is pouring rain seen from that hellish car a huge distinctive needlelike tower dominates the skyline lights flashing through the dark and wet ', ' bournes eyes opening heart pounding springing up alone damn his side hurts recoiling from that where is he hes in the car looking around and his windshield pov an autobahn reststop gas station sleeping trucks back to bourne catching his breath shifting away from the pain in his rib checking his watch but what the hell is that on his sleeve fuck its blood jardas blood ', ' bourne out of the car fast careless wrong not even checking whos watching pulling off the shirt tearing it off throwing it down and standing there in the weird light a big bruise ripening on his side looking around its okay nobodys watching but shit man get it together ', ' a streaking along bourne back to his mission ', ' b roaring by a sign berlin km ', ' kirill striding through the terminal moving quickly toward a departure gate and gretkov above watching him go ', ' bourne drives up ', ' quiet and forlorn this early just like bourne whos taking a locker stashing a backpack prepping the evac always ready he heads outside we hear hotel operator vo front desk german berlin hilton how can i help you bournephone vo im trying to reach a guest pamela landy please hotel operator vo im sorry but im not showing that we have a guest by that name continuing as ', ' a bourne tucked in with a berlin guide book a felt tip pen and a fiftyeuro phonecard working it bournephone pamela landy please hotel operator sorry i dont see it here crossing out another hotel off the list four down forty to go as we start time cutting and hotel voices vo overlapping no one here by that name no sir theres no landy here how are you spelling that sir sorry but no i have no landy registered sir continuing until ', ' b clean and plain a bed nobodys slept in the phone begins ringing pamela fresh from the shower rushing out from the bathroom to answer it pamelaphone hello dial tone pamela hangs up that was strange ', ' c a taxi driving through the empty early streets and ', ' d bourne in the backseat staring out the window and his pov the fernsehturm looming as they pass the berlin tv tower that needle in the sky from the flashback and then e suddenly e flashback its raining were still moving still in a car still near alexanderplatz but suddenly its pouring outside turning back we realize were not in the cab anymore theres a driver up front and beside him conklin yes conklin hes in the passenger seat turning back to us handing us something a photograph a face some guy conklin neski vladimir neski the photo hes at the hotel brecker get the papers beat say it bourne treadstone bourne alone in the back staring at the photo bourne neski hotel brecker papers conklin this is not a drill soldier were clear on that this is a live project and you are go training is over bourne yes sir conklin good then gimme the damn picture back taking it see you on the other side to the driver pull over hes getting out f back to f bourne sitting in the back seat of the cab frozen there rocked whats happening to him no chance to work it out because the taxis stopped and taxi driver waiting irritated the hotel brecker or the grand make up your mind bourne what taxi driver this is the westin grand you just said brecker bourne fishing for money yeah sorry this is good ', ' g concentric rings looking down on each other bourne slipping in unnoticed taking a quick look up before moving along ', ' h bourne stepping up to the guy behind the desk the gym mostly empty bourne hi i think i left my backpack here yesterday black nike the guy disappears in back to check bourne leans across the counter scrolling the computer the guest list his finger stabbing down on screen landy pamela bourne clears the screen walks away ', ' j because of the setup bourne pretending to talk on a house phone has a view of room across the way the door opens pamela exits carrying an overnight bag bourne watches ', ' k elevator doors opening pamela coming out into the lobby heading toward the exit and ', ' l a black suburban at the curb cronin standing there waiting as she emerges pamela anything teddy no munichs a bust hes loose pamela are we locked up cronin i told everyone they had an hour eat sleep shave whatever they want but once were back were back for good as they pile in and bourne walking right past them hes got the whole thing scoped heading quickly across the street and ', ' m bourne jumps into the first cab in the rank and ', ' n the driver starting up the car as bourne that black suv fifty euros if you keep me close the driver smiles and ', ' i pt kirill walks down the same hallway gretkov came to meet him last time a guy carrying a briefcase toward him stopping for a moment to light a smoke letting kirill take charge of the briefcase smooth like it never happened ', ' the suv rolling up the cab continuing past and stopping at the corner ', ' a bourne looking back out the rear window his pov as they pile out of the van start inside acknowledged by a security detail pretending to loiter outside as we hear pamela vo munich to berlin check everything flights trains police reports thatll be box teddy thats yours continuing as ', ' i pt kirill opening the briefcase two automatic pistols silencers ammo care package ', ' a bulkhead opening bourne stepping out among the satellite dishes unpacks a bag telescope water food and we hear pamela vo box call it prior german connections nicky i want to rerun all bournes treadstone material every footstep kim box lets call it munich outbound continuing as ', ' weve been hearing it now were seeing it pamela at the chalkboard abbott backing her up everyone else spread around theyre regrouping urgently behind them cots are being set up food water stacked up pamela lets stay on the local cops we need a vehicle parking ticket something langleys offered to upload any satellite imaging we need so lets find a target to look for to zorn danny box i need fresh eyes review the buy where we lost the three million timeline it with what we know about bournes movements turn it upside down and see how it looks continuing as ', ' a decent view into the berlin hq two windows one offers a look at an empty kitchenette the other a nice shot of the bullpen area it looks like they are in for the long haul theres teddy pacing pasta glimpse of zorn conferring with abbottnow kim talking on the phone ', ' bourne eyes locked on the target scanning waiting and then something changes suddenly theres something down there thats clearly a great deal more electric than what hes seen so far a telescopic pov a nicky shes just come into the kitchenette pouring herself a cup of coffee nicky who he knows and bourne lowering the telescope yes now hes getting somewhere thinking it through as ', ' nicky is joined by pamela who goes for the coffee pamela is it fresh nicky its got caffeine in it thats all i know before pamela can pour her cell phone rings she answers pamela pamela landy bournephone i was at the westin this morning i could have killed you pamela who is this intercut with rooftop bourne its me pamela holy christ bourne nicky reacts to the name runs to the other room to try and start a trace pamela contd contd what do you want bourne i want to come in he wants to come in its like a bomb going off nicky back in with conklin pamela waving for a pencil pamela okay how do you want to do it bourne i want someone i know to take me in pamela who bourne there was a girl in paris part of the program she used to handle the medication and now we stay with pamela her eyes flicker over to nicky pamela what if we cant find her bournephone its easy shes standing right in front of you busted pamela okay jason your move bourne alexanderplatz minutes under the world clock alone give her your phone click the line goes dead pamela steps away from the window realizing hes on one of the roofs out there ', ' a as the bulkhead door swings in the wind bourne is gone ', ' b everyone gathered a big detailed map of alexanderplatz spread on the table zorn heres the clock shit hes put her in the middle of everything cronin its a nightmare well never get her covered abbott call a mayday into berlin station we need snipers dod whatever they got pamela snipers hold on he said he wants to come in abbott my ass he does youre playing with fire pamela marshall said nail him to the wall i dont know how you interpreted that but i dont think he meant repatriate him pamela dont you want answers abbott there are no answers theres either jason bourne alive or jason bourne dead and i for one would prefer the latter and what about her points to nicky you just send her out to this lunatic with no protection pamela looks to nicky pamela what do you think is he coming in nicky i dont know he was sick he wanted out i believed him pamela alright pamela gestures to abbott cronin teddy pamela contd make the call get a wire on her if it starts to go wrong take him out ', ' a the rear of the official berlin cia hq and here they come ten delta dudes in civvies sprinting to a couple vehicles with drivers ready and engines running and bc ', ' d nicky her hands overhead as zorn tapes a transmitter and battery between her shoulder blades teddy and cronin plot the area with two men plainclothed delta team kim and kurt on their own lines kim this just in they got the number bournes calls came from nevins phone the field agent in genoa teddy nevins is bourne abbott losing it are you an idiot bourne mustve cloned his phone an embarrassed silence abbott mad at himself for losing his temper looking up to find pamelas eyes on his abbott contd contd i hope you know what youre doing ef ', ' g in all its vastness alone theres the world clock nicky waiting on the periphery two plainclothed deltas nearby in quick succession nicky binocular pov sniper scope pov on a video monitor ', ' h everyone waiting holding their breath watching nicky standing as ', ' j nickys pamelas phone rings she answers as a yellow tram approaches bourne see that tram coming around the corner nicky yes bourne get on it she turns and walks as the tram arrives the delta dudes start moving ', ' k the yellow tram arrives nicky enters one of the delta dudes just barely joining her the tram begins moving nicky looks around nervously nothing happens the tram moves about yards across the platz stops at the next stop people get on and off nicky and delta dude relax a bit doors begin to close and just like that bourne swoops in beside nicky flashes a gun bourne walk bourne takes her arm and they just get off as the doors close leaving the delta dude behind they disappear down into the pedestrian subway lm ', ' n a madhouse a video feed on a monitor pamela wheres nicky as they realize shes gone abbott goddamn it i told you cronin listen listen he cranks the speaker bournes voice what did i say what did i tell you in paris o ', ' p bourne what were my words but she cant speak leave me alone leave me out of it but you couldnt do that could you nicky i didjason i swear i didi told them i told them i believed you bourne who is pamela landy nicky you hear me i believed you bourne is she running treadstone ', ' q pamela all ears nickys voice shes ci counterintelligence shes a deputy director bournes voice what the hell is she doing ', ' r nicky whats she doing nicky looks at him like hes crazy bourne why is she trying to kill me nicky they know defiant reckless they know you were here they know you killed these two guys they know you and conklin had something on the side they dont know what it is but they know as bourne tries to process ', ' s radio chatter going wild panic delta vo into radio where are they anyone ', ' t still walking bourne knowing he must be driving them nuts bourne how do they know that how can they know any of that nicky what is this a game bourne i want to hear it from you she looks at him is he crazy what bourne contd contd say it nicky last week an agency field officer went to make a buy from a russian national bourne a russian nicky it was pamela landys op the guy was going to sellout a mole or something i havent been debriefed on exactly what it was bourne last week when is she supposed to answer nicky shrugs on quicksand nicky and you got to him before we could bourne i killed him nicky you left a print there was kel that didnt go off there was a partial print they tracked it back to treadstone they know its you bourne i left a fingerprint you fucking people suddenly bournes jerking her down to a lower level ', ' u big static on the speakers delta co cooly checks the map delta co she must be in one of the pedestrian tunnels ', ' v as delta dudes fan out head for the subway entrances ', ' w an intersection of three tunnels bourne leads nicky far left she looks really scared ', ' gretkov has landed just coming off the flight a ', ' bourne what was landy buying what kind of files when she doesnt answer instantly what was she buying nicky conklin stuff on conklin trying not to lose it suddenly he rips the microphone out from under her shirt he knew of course dropping it as he yanks her along ', ' as the transmission goes dead christ aboott drills a look at pamela your fault pamela ignoring abbott that phone has a locator on it kurt and kim work their stuff ', ' gloomy deserted a mausoleum here come nicky and bourne she knows shes on her own now bourne dead serious looks at his watch bourne why are you here then nicky please im only here because of paris because they cant figure out what youre doing im here because of abbott bourne abbott nicky he closed down treadstone he took care of me after paris bourne so when was i here nicky what do you mean bourne for treadstone in berlin you know my file i did a job here when nicky no you never worked berlin bourne my first job nicky your first assignment was geneva bourne thats a lie nicky emphatic you never worked berlin bourne raising the gun eyes gone dead oh shit nicky contd nojasonplease bourne i was here nicky its not in the filei sweari know your fileyour first job was genevai swear to god you never worked here hes so ready to kill her nicky starting to cry hands over her face covering up bracing for the bullet she knows is coming bourne about to pull the trigger suddenly a flashback a moment a shard a womans face a backing away begging begging us begging the camera pleading for her life in russian this awful blur of desperation and panic fear too fast too panicked b jam back to b bourne swamped thrown hesitating close on nicky sobbing now when finally looking out and bourne is gone ', ' c an hour later whole new vibe siege mode curtains drawn three delta dudes parked around the room kurt and kim working the phones and screens the mood is dark pamela abbott cronin all in here the safe zone away from the windows cronin on a cell phone got it yeah hang on to the room okay theyve got three guys out front and another two taking the back stairs no word on nicky kurt looks up from screen even if shes still got your phone it might take awhile signals hard to trace down there pamela turns looking at the photo of bourne in naples introspective pamela so whats he doing you believe him abbott its hard to swallow beat the confusion the amnesia but he keeps on killing its more calculated than sick real soft sell what about nicky shes the last one to see bourne in paris shes the one he asks for they disappear pamela well whatever hes doing ive had enough this is now a search and destroy mission turns to the room i want the berlin police fully briefed and handing the photo to cronin get this out to all the agencies abbott agrees ', ' a bmw parked in the shadows ', ' kirill wearing headphones listening to a berlin police frequency theres an interpol wanted picture of jason bourne there on the seat hes in play ', ' d quiet intense activity military radios chirping here and there zorn moving through the bullpen carrying a cup of coffee heading back toward pamelas office where abbott is leaning in the doorway past him inside we can see pamela in the midst of a tough phone conversation cronin and the delta boss sitting there with her zorn the coffee sir abbott thanks abbott nods takes a sip looking beat zorn contd i have that number you wanted abbott hesitates but only a moment he never asked for a number but hes playing along looking satisfied as zorn hands him a slip of paper abbott glancing at it she say what time i should call zorn the sooner the better abbott nods pockets the paper turning back as if it were nothing and ', ' e massive modern busy bourne in the back in a corner doing a search hotel brecker scrolling and then stopping freezing because on the monitor a berlin newspaper archive there it is written large in loud tabloid german oil reformer murdered theres a photograph of the berlin police carrying two body bags out of the hotel brecker theres a caption identifying the dead as vladimir and sonya neski theres even a long article accompanying all this but its in german and we dont need to read it anyway because bourne is reading it and were reading in his face that he is rocked that he has found another bottom to the abyss ', ' f remember the building where vic was killed were back zorn and abbott making their way in zorn steering them away toward a stairwell at the back ', ' zorn and abbott have snuck in here work light signs of repair on the wall zorn nervous i did my box work but i wanted to show you before i showed landy i came out here last night because none of this was making any sense i mean im with you on this conklin was a nut but a traitor i just cant get there abbott what do you have danny zorn the electrical riser you put a fourgam kel on here and its gonna take out power to the building you know that what you cant know is if its gonna blow the room with it abbott and zorn there were two charges they were supposed to go off simultaneously the second one the one that didnt go off was down here pointing it out first of all this is nothing its a sub line for the breaker above second why put the charge all the way down here if youre good enough to get in here and handle the gear youre good enough to know you dont need this beat bourne would know abbott it was staged zorn is it a slam dunk no but abbott jesus zorn spitballing okay what if someone decided to cover their tracks by blaming conklin and bourne what if bourne didnt have anything to do with this abbott keep going zorn somethings been going on here in europe and its still going on post conklin whos been in berlin abbott lots of people zorn including landy jumping off the cliff she had access to the archives zorn hesitates but its out its in the room abbott who else knows about this zorn nobody you hes scared i had to tell you right abbott show me again zorn okay turning away when abbott out of nowhere his hand jamming up into zorns ribcage more than his hand because zorns eyes barely have a moment to register shock before they bulge clenching the younger mans body pulling him close as he turns the knife and zorn is dead abbott without hesitation shifting away from the blood letting the body fall abbott standing there listening checking himself for blood hes clean looking for a place to stash the body as ', ' a bourne across the street staring at the hotel haunted as a police siren edges closer through the empty streets aa flashback aa we are a pov a stakeout watching the hotel across the way the pov checks its watch checks the perimeter the street deserted foreboding the hotel our destiny waiting up there somehow and suddenly a light comes on a terrible signal and as the car suddenly lurches forward and around the corner ab back to ab bourne muscling up his backpack heading toward the hotel ', ' b and hotel fusty but comfortable and busy guests and staff doing their thing a clerk behind the reception desk clerk guten abend bourne playing it american guten abend clerk switching to english can i help you suddenly ba flashback the lobby but seven years ago ba across the room a man buttoning a raincoat as he passes neski bb jamming back to bb bourne stalled coming back as clerk contd contd sir smiling do you have a reservation bourne no sorry i just got in rallying back i is room available off the clerks look i stayed there before my wife and i the clerk nods checking the register the concierge just down the desk glancing over at bourne nodding hello and clerk im sorry that room is occupied would room be okay its just across the hall bourne sure thats fine danka cd shot ', ' a bourne riding up alone dread mounting and ', ' the concierge coming out of the office with a sheet of fax paper placing it quietly down beside the clerk and the fax bournes face the same wanted picture and ', ' bourne off the elevator he makes his way down his pov the sixth floor hallway suddenly scary ', ' a kirill sitting up as the police radio starts broadcoasting an allpoints bulletin the words hotel brecker in there kirill dropping the car into gear and ', ' b bourne walking theres his room but across the hall and down one room bourne steps up listening a moment then he knocks nothing he pulls a knife from his pocket checks the hallway hes clear wedges the blade in there and onetwo pop ', ' bourne enters a suite closing the door behind him and treadstone bourne seven years ago does the same bourne shakes off the flash looks around the lights are on an open suitcase on the bed ', ' the clerk the concierge and the manager are huddled in conversation with three berlin cops whove just arrived and trying to be discreet but this is clearly serious ', ' bourne just standing there breathing it in treadstone bourne doing the same ', ' bourne with his hand on the wall as if he can feel it like its all still here heart pounding and ', ' chaos bournes been found everybody rushing out cronin to teddy go take the van pamela the hotel how far teddy five six minutes cronin kurt youre here keep the comm line open ', ' bourne standing there looking out the window the images the television tower over the city everything but the rain ', ' the berlin police swat team truck arrives discreetly by the back loading area ', ' bourne flat against the wall just as he was leaning forward to see in the mirror just so and there ', ' a a man in the mirror pacing into view neski on the phone a talking in russian its raining bourne standing there treadstone bourne still wet from the rain one eye on that mirror and the other on a syringe that he prepped a predator the mirror the doorbell rings neski gets off the phone bourne tensing new element factoring and the mirror as neski opens the door a new flood of russian happy its mrs neski a surprise but hes very happy to see her bourne pocketing the syringe new weapon pistol quiet methodical watching the lovers bill and coo and the mirror mr neski kisses her takes her bag shes hanging up her coat and moving now toward the bathroom and bourne checking the window the weapon his balance and the mirror mrs neskis face right there seeing him so freaked she cant even register it yet bourne with the pistol in her face finger to his lips shhh but she knows backing away begging for her life in russian this awful blur of desperation and fear mr neski turning back to see his wife backing out of the bathroom and bourne with the pistol with no hesitation snap one shot into neskis heart hes down mrs neski whats just happened bourne has her wrist in his hand raising it to her head to where he holds the pistol her fingers his trigger snap letting the gun fall with her as she drops and bourne starts to move starts to prep his evac but theres something on the dresser a photograph the neski family father mother and a twelveyearold girl arms around each other happy and bourne staring at the picture undone for a moment hard out flashback to ', ' bourne our bourne standing where they fell frozen there paralyzed by the shame of original sin pt ', ' a swat captain conferring discreetly with the manager manager hes in swat captain call all the guests on the th floor tell them to remain in their rooms tell them its a police order then start on the th and th floors ', ' a bourne trying to stabilize to breathe ', ' the swat team on their way up ', ' a ring ring bourne snaps back as the phone in his room starts to ring four times and it stops bourne freezes footsteps shadows under the door he leans into the peephole bournes pov room german swat team taking position ', ' b bourne backs away surveys the room his watch his balance and ', ' c quickly turning into a major event halfadozen police vehicles already parked here more arriving every minute passersby mixing with the cops and people from the hotel whove just come out and kirill jogging over from the bmw hes just parked and ', ' wham the door kicked off its hinges swat team flooding into bournes empty hotel room and ', ' a bourne in motion out the bathroom window and ', ' berlin swat leader gives order to search other rooms and ', ' bourne up the water pipe to the roof as he arrives a swat team member turns bourne pulls him over the edge fires point blank into the nd swat members vest stunning him hes moving fast scrambling along the roof and into the night ', ' wham the door caves in and the swat team moves enters rushing to the window nobody no sign of him and ', ' kirill heading for the hotel entrance blocked by the exiting guests ', ' too many cops and radios swat team boss trying to take charge listen up were clearing the building room by room ', ' pamela jumping out of a van the moment it stops seeing it all the crowd the army of cops the searchlights playing across the hotel facade its another disaster ', ' kirill wants to get upstairs he cant too many guests coming down the stairwell berlin cops trying keep it moving and ', ' kirill hears bourne is on the roof ', ' pamela and cronin listening to teddy who just got the police update teddy black coat possibly leather dark slacks dark tshirt pointing now he says theyre gonna try and corral the guests on the street over there and then check them out but pamela disgusted yeah thatll workwhat the hell was he doing here cronin maybe he just needed a place to spend the night pamela i want to look at the room to teddy as she goes check it out pamelas in charge now they enter the elevator ', ' bourne coming around the other side of the hotel stepping to the left before he spots the swat van bourne aboutfaces heads the other way a sidewalk cop looks over checks the bourne photo print out in his hand ', ' teddy huddled with the hotel manager and a group of high ranking berlin cops turning back as abbott arriving breathless they missed him teddy so far but they found nicky shes back at the westin bourne let her go abbott he let her go great wheres danny he should head over there and debrief her the hotel whats here what was he doing teddy we dont know theyre in a room upstairs i was told to wait down here abbott accepting that because he has to only we see the fear turns to leave abbott ok if you see danny tell him i went back to the hotel abbott steps out into the street as ', ' bourne striding away and following sidewalk cop blowing a whistle fumbling for his holster bourne running now slowly at first and ', ' a now faster as if he can gauge his speed and distance ', ' motion bourne tearing away and ', ' a bourne slows to a walk two patrol cars heading his way no choice there a narrow passageway between two moving trolley trains and sprinting through the patrol cars skidding into s ', ' b the river spree lit by the trolley thats rumbling past and the running lights of a double coal barge up the river bourne runs across the bridge going as fast as he can hearing the police sirens swirling behind him when a third and fourth police car ahead bourne turns hard for a stairwell jumps the walkway curb leaps up the stairs two at a time as all four cop cars skid to a stop as doors open ', ' a tram waiting as the last few passengers get on the doors seem to stay open in slow motion as bourne appears makes a mad last dash and hes on and the doors dont close its not scheduled to go yet and here come the cops bourne off the tram guns appear bourne runs to his left stops short the other cops are coming this way screaming at him not a lot of options bourne looks over the rail down below a coal barge passing the prow just emerging bourne on the rail and jumping even as the first shot is fired ', ' bourne lands hard stands voltage going up one leg and theyre shooting at him he can worry about the leg later he runs back toward them the barge moving slow bourne disappears under the bridge ', ' guns aimed police waiting for a clear shot two of them dash to watch over the other side ', ' countering the barge going one way bourne the other dodging all the superstructure on deck all the while keeping his cover overhead and leaping to the second barge and more of the same until bourne running out of barge leaping back onto the bridge footing and ', ' the police watching the barge fully emerge continuing down river shouting in german that hes either in the water or hiding on the barge off they go down the stairs leaving the passengers on the tram blinking out in shock and bourne climbing back over the rail limping back on the tram just before the doors close and off it goes ', ' police converge from both ends barge goes under as kirill arrives at the center of the bridge missed again behind kirill a train snakes off into the night ', ' pt pamela and cronin move into the living room a couple of cops in the hallway outside cronin the room he checked into was across the hall why why would he come here pamela glances around something bothering her about this space pamela he mustve had a reason thats how they were trained cronin moves around the bedroom then into the bathroom and cronin he went out the window in here ', ' pt there on the mirror scrawled in soap on the glass i killed neski cronin pam you need to see this pamela moves in behind him cronin contd whos neski both of them staring pamela thinking alrighttake it down cronin what pamela this stays between you and i sensing confusion we finally have an edge i dont want to lose it ', ' very late abbott waits on an isolated bridge a lone figure in the shadow of east berlin gretkov arrives by car walks through the darkness abbott barely glancing over abbott you told me bourne was dead gretkov there was a mistake abbott ill say you killed his goddam girlfriend instead now theyre onto neski theyre at the brecker hotel even as we speak gretkov will it track back to us abbott no the files are spotless whatever they find its just going to make conklin look worse gretkov and the landy woman abbott shes done everything i wanted she bit on conklin so fast it was laughable she even found his bogus swiss account gretkov anything else abbott shoves a piece of paper and address into gretkovs hand abbott the paper theres a body in the basement danny zorn hes got to disappear for good clean and fast ill put him in bed with conklin and bourne even the girl nicky give me twentyfour hours ill think it up but get the goddamn body out of there its getting late a taxi now and then abbott contd neski was a roadblock without me theres no company no fortune you owe me uri one last push gretkov one last push one gretkov leaves abbott watches him go ', ' seconds later gretkov getting in slowly ', ' kirill slouched in back waiting gretkov to the driver gretkov airport to kirill were done here kirill nods as they pull away abbott turns and walks into the foggy night ', ' a late abbott walks a lonely figure past someone in the shadows bourne mr abbott he turns to answer when bourne firmly guides him into a side street bourneabbott scene ', ' as pamela and cronin exit the elevator they are met by teddy teddy heres what ive got reads remember vladimir neski russian politician seven years ago he was due to speak to a group of european oil ministers here at the hotel he never did he was murdered pamela by who teddy his wife in room then she shot herself pamela and cronin share a look pamela to teddy alrighti want you kurt and kim to stay on bourne track everything thats out there teddy goes to get in the van pamela follows with cronin pamela contd confidentially to cronin and i want you to go through and cross reference our buy that went bad the neskis and treadstone as they get in pamela contd they have to be related ', ' bournes arrived limping as he continues for the station ', ' bourne retrieving the exfil bag he stashed in the locker changed his clothes ', ' bag slung limping out bourne has changed clothes a big overcoat knit cap ', ' a busy midnight departure big train bourne climbing on the train under the sign moscow express moved ', ' a a blueprint spread across a table nicky kurt kim all gathered around cronin works the treadstone files on another table teddy at center briefing pamela teddy were looking at all berlin outbound good news is every train station in berlin has thirty to forty fixed digital security cameras common feed pamela are we hacking or asking teddy yes in that order pamela and what about you anything cronin its starting to link up the hijacked money the leak pecos oil one last bit is treadstone ', ' crossing the border into poland cold desolate snow ', ' conductors moving quietly through the dark cars checking tickets and visas and bourne hands over his ticket and russian passport off the grid ', ' a am kurt kim and teddy spread around the room theyve been running laptop train station videos for hours just about ready to raise the white flag all they have so far is an isolated loop of bourne limping into the mens room cronin watches it stutter along cronin does it look like hes faking teddy on the way in forget it kurt the legs definitely hurt cronin the blueprint well theres no window in the mens room folks so lets find somebody coming out with a bad left leg kurt worn out maybe hes still in there teddy ive got a limping guy but its the right leg kim walking away or walking toward you cronin jumping on that right there over teddys shoulder cronin thats him its the coat what train is that ', ' bourne asleep in his chair rocked by the rhythm but something wakes him up looks out the window something weird about the light out there then up to see marie looking at him over the back of his chair in front of him no big deal bourne hey she smiles a beat she comes around sits beside him he looks away out the window bourne contd i wanted to kill him marie but you found another choice bourne i did marie it wouldnt have changed the way you feel bourne it might have bourne looks back at her she smiles he accepts it leans back closes his eyes bourne contd i know its a dream marie you do bourne i only dream about people who are dead marie leans over kisses his forehead whispers bourne contd god i miss you i dont know what to do without you marie softly serenely jason you know exactly what to do that is your mission now bourne opens his eyes and its morning outside and marie is gone a little girl smiles at him from over the back of the chair in front bourne cant meet her gaze for long as he looks back out the window ', ' bourne watching the birch trees rush past not quite hiding the smokestacks beyond eyes locked forging something within one final mission as we ', ' abbott coming through its empty this early but heres pamela nicky cronin and the team waiting to report pamela sorry to wake you abbott waves off apology i wasnt sleeping to nicky as he passes you ok nicky yeah thanks abbott whats up pamela bunch of stuff pamela looks to cronin him first cronin we tied the room bourne visited tonight to a murdersuicide seven years ago a russian couple the neskis abbott playing along neski the reformer i remember that cronin he championed the equal distribution of oil leases in the caspian sea when he died they were all released to one petroleum company pecos oil guess what the ceo uri gretkov is ex kgb nicky someone was using treadstone as a private cleaning service abbott conklin a beat its im sorry pamela i guess you were right all along pamela waves him off its okay but pamela theres something else abbott can see by their faces this hits closer to home abbott what pamela they found danny zorns body dead in the basement at the building where my people got hit the first time abbott oh god it must have been bourne pamela did he say anything to you abbott no it must have been bourne pamela straight pamela well know for sure when we get the security tapes cronin but we can relax we tracked him hes on a train to moscow abbott reeling hiding it abbott moscow what the hells he going to moscow for pamela shrugs dont know abbott jesus i zorn i have to call his family tell them pamela im sorry ward they watch as he goes ', ' abbott in the rising elevator imploding ', ' palatial but you cant buy taste gretkov working his computer answers his phone gretkov da abbottphone you didnt stay uri gretkov matter of fact this is not a clean phone ', ' everyone still here cronin answering his cell phone motioning to them hes got news cronin phone to his ear youre sure pamela what the tapes cronin nodding but hold on holding the phone yep and abbott just direct dialed moscow from his room now we realize shes set a trap and abbotts walked in all the same pamela shakes her head wishes it wasnt true and theyre moving ', ' abbott at his desk still on the phone pouring a vodka gretkov leaving was a business decision were both rich come enjoy it abbott what do you mean gretkov go to the airport get a plane ill have a brass band waiting for you abbott save it for bourne gretkov what theres a knocking at his door abbott simply ignores it abbott he left yesterday on the night train hes probably just getting in now he drinks youll have to hurry gretkov bourne comes here why more knocking abbott good luck ', ' a speeding east through the russian countryside the forest is gone replaced by factories and refineries a wasteland of rust and gray that seems to go on forever ', ' pamela knocking again nicky teddy and cronin behind her pamela open it cronin with a pass key teddy prepped and ', ' a pamela leading they enter stop short abbott at his desk calmly pointing a pistol at pamela abbott they go you stay she looks back cronin shakes his head no pamela yes now they reluctantly obey the door clicking shut behind them abbott sit down pamela id rather stand if its all the same to you abbott i dont exactly know what to say im sorry pamela why would be enough for me abbott im not a traitor ive served my country pamela and pocketed a fair amount of change while doing it abbott why not it was just money pamela and danny zorn what was that abbott had to be done pamela no good options left abbott shrugs in the end honestly its hubris simple hubris you reach a point in this game when the only satisfaction left is to see how clever you are pamela no you lost your way abbott well youre probably right i guess thats all that hubris is he raises the gun pamela presses her lips together closes her eyes boom she opens them and as cronin flies back through the door theres abbott dead at the desk hes shot himself also in a way with some help from bourne ', ' the train easing to a stop the platform busy with people waiting and passengers disembarking bourne among them unremarkable in the crowd and ', ' bourne on the move welcome to the whole mad moscow scene a jumble of faces and voices travellers arrivals and departures families beggars drunk war vets hawkers ', ' there in the plaza bourne hobbling across the street when suddenly a car horn he turns and look out a big black bmw speeding past followed by two more all three cars with blue lights strobing on the dashboards a convoy whipping by like they own the place and taxi driver os gangster bastards dont care what they do bourne turns a grizzled taxi driver right beside him bourne pulls a slip of paper from his pocket bourne his russian is basic you know this address the taxi driver squints finally grunts affirmative he motions to his cab as they get in and pull away ', ' lots of cars no people but someone running its kirill pulling his keys as he sprints past and ', ' bourne and the taxi driver looking over as three moscow police cars speed by sirens wailing taxi driver its always something right bourne just nods as we ', ' kirill at the wheel a guy in a hurry who knows what hes doing one more thing on the passenger seat two big automatic pistols ', ' moscow cops fanning through the crowd showing bournes interpol picture have you seen him ', ' moscow cops with the picture flashing it around until young cabby the moment he sees it he was just here they just left ', ' theyve stopped bourne flashes a fifty dollar bill bourne you wait you understand stay taxi driver happy to pocket the cash sure no problem i sit ', ' old moscow but not for long theres new construction metastasizing all around it bourne crosses the street and his pov an abandoned wooden house windows shattered and boarded up paint all but gone roof and gables all failing back to bourne crestfallen checking the address this is it ', ' more cops everything focused on another taxi driver whos making a call on a cell phone everybody waiting on it ', ' bourne off the sidewalk now peering around the side trying to see if theres anything around back and over there an old woman on the steps next door watching him bourne starts over finding the sweetest smile hes got ', ' the taxi driver still parked there his pov bourne and the old lady shes pointing like shes giving directions when suddenly the drivers cell phone rings taxi driverphone hello ', ' bourne and the old lady his russian is limited but shes charmed nonetheless bourne a pento writeone minute searching his pockets ', ' the taxi driver on the phone not so happy anymore taxi driver im looking at him american hes right here ', ' the old lady scribbling on a piece of paper bourne reacting as the taxi drops into gear pulls away bourne wait hey but the taxi only speeds up and ', ' moscow police cars tearing away and ', ' kirill driving reaching for his ringing phone and ', ' the black bmw a moment later slamming on the brakes fishtailing a uturn and ', ' bourne hustling past all the new construction glancing back as police sirens start rising behind him and ', ' kirill skidding around another corner and ', ' two police cars just stopped there cops the old lady pointing everyone turning as the red lexus speeds past them and ', ' bourne coming down as fast as he can just ahead theres a footpath beneath a four lane overpass a neighborhood on the other side he could disappear there ', ' kirill driving and scanning there as he passes it the overpass slamming on the brakes and ', ' bourne hobbling out in the open twenty yards to go ', ' kirill jumping out of the lexus with a pistol in hand and ', ' bourne no clue bang his shoulder hes hit he throws himself forward and ', ' kirill shifting for a better second shot and ', ' bourne hes diving rolling pure instinct back under the embankment and ', ' kirill with no shot suddenly leaning over the rail just as the two moscow police cars come screaming up moscow cops jumping out with guns drawn and ', ' bourne hes up hes bleeding hes moving and ', ' chaos kirill with his hands in the air moscow cops coming toward him everyone screaming moscow cops mockbourne up hands up keep im kgb assholes them up drop the gun were chasing the same guy drop it hes getting away they let kirill go he looks back at the footpath bourne is gone as ', ' a gretkov strolls along suddenly two black sedans pull up and he is arrested ', ' a bourne hurriedly makes his way to the other end a few beats later kirill on the hunt ', ' a labyrinth of stalls food hardware clothes and crowded even this hardtoimpress crowd noticing bourne hobbling through nothing like a limping madman with a fresh gunshot wound to get attention people back off pull their kids out of the way some woman starts screaming and ', ' a security guard hears the commotion jogs out and ', ' kirill running toward the market five moscow cops behind him cant keep up and ', ' the security guard coming up fast behind bourne security guard hey hey you stop bourne turns the security guard right behind him and bourne no warning his good arm smash right into the security guards face and bourne takes his pistol and the crowd they jump holy shit ', ' crazy kirill sprinting through where did bourne go ', ' bourne back on the march except now hes shopping grabbing a bundle of tube socks and ', ' kirill sprinting out toward the stalls and ', ' bourne there a roll of duct tape and a bottle of vodka and ', ' kirill fighting his way through the fleeing crowd ', ' pt bourne leaving the market taking a swig of vodka and continues knows there are two new cops on his ass ', ' pt another cab stand cabbie by a yellow cab looks up to see bourne coming toward him and also the two cops as bourne nears the cabbie shakes his head bourne pivots casually like he doesnt know theyre coming until he spits vodka into one of the cops face blinded as bourne takes him and his partner out the cabbie raises his hands in surrender steps aside as bourne takes his car ', ' pt bourne in the yellow cab starting the engine peeling away careening into the street and kirill sprinting into the parking lot just in time to see ', ' pt bourne concentrating away the pain trying to drive ', ' two ladies ducked behind a big black gwagon freaked out as kirill grabs their keys and ', ' the cab speeding across a boulevard into an older neighborhood of rising narrow streets and two moscow police cars pulling uturns on the boulevard whipping around to give chase and the gwagon in full pursuit now and bourne driving up this curving little hill and the two moscow police cars starting to climb and kirill driving and hes on the hill now bourne bad hand on the wheel holding on trying to find something in passenger seat tube socks the two moscow police cars splitting up one on bournes ass the other cutting hard into a side street flanking him and bourne topping the hill two choices right or left right no wrong because down the hill theres a police car just about to angle in from the sidestreet and bourne no choice flooring it the cab its a whale slam knifing the front end of the police car and the police car spun back crashing against a building on the corner and kirill right behind that guy swerving onto the sidewalk sparks from the wall as he scrapes hanging in skidding into a turn down the hill and just missing the first police car bombing right past him bourne in pain as he packs his shoulder wound with the socks ahead the street banks downhill to left and there a boulevard wide ride lots of traffic and the cab rocketing into the flow and behind him police car with the gwagon right on his ass and bourne wrists flicking the wheel the cab screaming through the slower traffic and kirill totally on it pedal down passenger window open wind blowing hes got the pistol in his hand closing the gap and the black gwagon blowing past police car and bourne steering barely as he tears a few strips of duct tape to finish his triage blam blam the gwagon right beside him bourne reacting what the fuck thats not a cop but no time to clock kirill because kirill shit cant keep shooting into the oncoming lanes swinging wide a truck swerving again and the cab wavering again rallying and up ahead the boulevard opens into the river beltway big wide fast kremlin in the bg and four new police cars screaming down from red square and bourne skidding onto the beltway looking for room finding it open road kirill back in the hunt and the river beltway cab screaming past then one two three four police cars now the black gwagon and bourne both hands on the wheel hes already forgotten about his shoulder the beltway up ahead another choice right takes you up to the city left is a transit tunnel and bourne checking his rearview starting right and the two lead police cars right on his ass and bourne fake out veering left last second into the tunnel and the two lead police cars wrong and worse trying to change crash spinning and its not just them a third police car caught in the clutter not to mention the commuters crash the police are out of the race kirill not fooled threading the needle through the carnage and into ', ' four lanes two way and long theres the cab squibbing past slower cars and kirill on him move for move follow the leader and bourne checks the rearview hes lost them all but the gwagon who the hell is that the heavyweights world championship belt up for grabs kirill gaining nearly pulling level bourne nowhere to go thats never stopped him before he carves a path turns two lanes into three as sparks his way through a lane split the gwagon roaring after him bourne checks the mirror closer who the hell is that guy kirill gaining firing through his passenger window bourne brakes tunnel as the two vehicles scrape along each other kirill firing back odd angle bourne ducking for meager cover as bullets stitch through the roof tunnel the gwagon crushes the cab against the wall sparks showering the windshield finally the cab shoots ahead kirill in a controlled fury the suv jerking hard and right into the rear of the cab bourne trying to keep control spots a maintenance truck up ahead kirill banging away as his quarry straightens maintenance truck looming bourne a hard left tunnel the cab wrapping around the front of the suv wham pushing it to the right the cab continues spinning around the gwagon details front bumpers locking on rear fenders as tunnel the gwagon hurtling forward the cab ass end first locked together kirill firing into the cab really unloading now bourne down on the floor a tornado overhead kirill slaps in a new clip intense bourne gun against his door just below the window knob whumpwhumpwhump suv tire shredding kirill fights the wheel another truck looming large bourne looking between the seats out the rear window a lane dividing pillar ahead cab as bourne sits up jerks the wheel to the right tunnel the cars unlock spin away from each other kirill focused taking deadly aim bourne staring back at him calm i know something you dont know kirill frowns the truck swerves to reveal the pillar to kirills pov kirill eyes go wide whallop steel vs concrete concrete victorious a bone compressing truly horrendous impact bourne whipping the wheel cab spinning to a stop out of harms way door opening ', ' gun ready bourne heads over ahead spam in a can bourne crouches down looks in kirill bloody beattocrap barely alive but trapped entombed alive by the metal crushed around him bourne watches not here to help kirill looks over calms a moment as the two men consider each other bourne looks at him long and hard kirill dies and bourne stands and just walks away ', ' a snow swirls pamela disembarks from the g or us military plane she is met by russian officials ', ' huge awful sovietera housing towers fill the horizon a city bus grinds to a stop people trundle off working people at the end of their day tired cold a girl trudging a manmade wasteland twenty a proud little waif sad eyes home from some job irena ', ' grimmer up close rusted steel mesh over the windows drunk teenagers a haze of cigarette smoke irena pushing through doesnt want to talk to anyone ', ' irena climbing a junkie here flickering light there ', ' irena her key at the door domestic disturbance playing across the hall she opens up and ', ' its dark and shes barely through the door when irena jumps chokes back a cry bourne is standing there propped there actually behind her gun in hand motioning for her to be quiet bourne his shabby russian quiet silence okay irena nods scared gun in hand bourne pushes the door the last few inches so its fully closed irena i have no money no drugs is that what you want and now she can really see him hes a disaster shivering bloody eyes more hollow than hers are bourne sit can you trying to conjure the russian the chair have the chair irena accented i speak english bourne staring at her nods gestures for her to sit bourne please so she does and here they are bourne contd contd of all the people in the world youre the only one i have anything to offer hesitating thats why i came here irena shes terrified okay hes got something beside him something hes taken off the wall its the photograph the neski family same as the one that was in the hotel brecker mom dad and irena arms around each other in front of the house before it was abandoned happy smiling perfect bourne its nice a beat does this picture mean anything to you no answer hmm irena its nothing its just a picture bourne no its because you dont know how they died irena he couldnt understand no i do a change in bourne as he studies her measures her some moment of truth is here irena braces unsure bourne i would want to know beat i would want to know that my mother didnt kill my father i would want to know that she didnt kill herself irena what she really looks at him now fear overwhelmed by curiosity bourne i would grow up thinking that they didnt love me if they just left me like that irena making sure her eyes dont leave his they dont bourne contd contd it changes things that knowledge doesnt it irena wary yes bourne thats not what happened to your parents irena then what bourne i killed them body blows but he has her attention she wipes a tear bourne contd it was my job my first time your father was supposed to be alone but then your mother she came out of nowhere a little shrug i had to change my plan beat you understand me does she you dont have to live like that anymore thinking that irena you killed them bourne nods thats right bourne they loved you beat and i killed them irena howhow canhow can you be here and say this bourne i dont want you to forgive me she stands suddenly stands because if she doesnt shell burst into tears because she knows if she starts crying she wont be able to make sense of this irena for who he doesnt answer killed for who bourne pushes himself to his feet a real effort bourne it doesnt matter your life is hard enough irena youre a liar bourne you know im not irena youre a liar bourne look at me there they are two people standing in a room squared off and now she starts crying really crying and hes taking it irena i should kill youif its true you should diei should kill you now bourne i cant let you do that either irena because youre afraid bourne no starting for the door because you dont want to know how it feels she hesitates stunned hes leaving hes opening the door bourne contd i have to go now irena is this really happening bourne empty im sorry and she sags back into the chair as the photograph on the table the sound of the door closing and irena crying as ', ' bourne trudging along across the snow hes done it and he really cant take another step theres a bench he sits down out of gas he just might die here we slowly tilt up to the multi colored moscow tenements fade out ', ' bourne waking up sitting up where is he trying to get his bearings but its so bright white walls sheets sunshine through clean windows and pamela os hello david there she is standing at the foot of his bed bourne where am i pamela ramstein air base germany smiles before the wall fell you would have woken up in a russian prison hospital he looks around tries to move hammered by pain bourne oh shit pamela careful long moment hes taking it in trying to bourne why am i alive pamela are you disappointed they study each other a beat bourne i know who you are pamela nods very calm here no sudden movements pamela thank you for your gift im sorry about marie bourne whats that pamela do you think you can read are you well enough she has a folder a photograph bournes face stapled to the cover pamela contd its all in here treadstone a summary of your life all of it he waves it off bourne dont need it i remember everything pamela smiles again sounds like a threat bourne you didnt answer my question pamela why youre alive beat youre alive because youre special because she kept you alive she smiles because we want you back on our side bourne silent but hearing it pamela leaves the file pamela contd contd take a look at it well talk later bourne watching her back away as she exits into ', ' long sterile hallway cronin and nicky standing there with an air force sentry assigned to guard the room cronin and nicky trying to play it cool but now as they get some distance down the hallway pamela to the sentry lets give him half an hour nicky quietly so pamela felt promising its a start a chill in the air both of them going quiet because theres a nurse carrying a tray of food shes coming toward us theyre walking away staying with the nurse now coming up the hall the sentry smiles opens the door and she enters ', ' empty bed open window bourne is gone as the music starts pumping and we ', ' off he goes disappearing into thin air fade out the end '] (2) BoW (Bag of Words) 벡터 생성 123456789from sklearn.feature_extraction.text import CountVectorizer# filter stop wordsvect = CountVectorizer(tokenizer=None, stop_words='english', analyzer='word').fit(corpus)# tokenize: 문장을 단어로 나누는 기준; stop_words: 불용어 설정bow_vect = vect.fit_transform(corpus) # BoW 벡터 생성word_list = vect.get_feature_names()count_list = bow_vect.toarray().sum(axis=0) 123# 등장한 단어 listword_list ['aa', 'ab', 'abandoned', 'abandons', 'abbott', 'abbottnow', 'abbottphone', 'abbotts', 'abend', 'able', 'aboott', 'aboutfaces', 'absolutely', 'abyss', 'accelerating', 'accented', 'accepting', 'accepts', 'access', 'accompanying', 'accomplished', 'account', 'acknowledged', 'act', 'activity', 'actually', 'address', 'adjust', 'adrenaline', 'affirmative', 'afford', 'afraid', 'afternoon', 'againi', 'agencies', 'agency', 'agent', 'agents', 'agitated', 'ago', 'agreement', 'agrees', 'ah', 'ahead', 'aim', 'aimed', 'air', 'airport', 'alarm', 'alert', 'alexanderplatz', 'alive', 'alley', 'alleys', 'allocation', 'allpoints', 'alongside', 'alps', 'alright', 'alrighti', 'alrighttake', 'american', 'ammo', 'amnesia', 'amused', 'anger', 'angle', 'ankle', 'anonymous', 'answer', 'answering', 'answers', 'anymore', 'anythings', 'apology', 'appealing', 'appear', 'appearing', 'appears', 'approached', 'approaches', 'approaching', 'archive', 'archives', 'area', 'arm', 'armed', 'arms', 'army', 'arrested', 'arrivals', 'arrived', 'arrives', 'arriving', 'article', 'asap', 'ashes', 'aside', 'ask', 'asked', 'asking', 'asks', 'asleep', 'ass', 'assassinated', 'assholes', 'assigned', 'assignment', 'assistant', 'associated', 'attempt', 'attention', 'autobahn', 'automatic', 'available', 'aware', 'away', 'awful', 'awhile', 'ba', 'backhanding', 'backing', 'backpack', 'backpacks', 'backs', 'backseat', 'backyard', 'bad', 'bag', 'bags', 'bail', 'bailing', 'bakery', 'balance', 'ball', 'balling', 'band', 'bang', 'banging', 'bank', 'banking', 'banks', 'bar', 'barely', 'bargain', 'barge', 'barn', 'base', 'basement', 'basic', 'basically', 'bastards', 'bathroom', 'battery', 'bb', 'bc', 'beach', 'bearing', 'bearings', 'beat', 'beats', 'beattocrap', 'bed', 'bedroom', 'beep', 'beeping', 'beggars', 'begging', 'begin', 'begins', 'behavior', 'behaviors', 'believe', 'believed', 'belongings', 'belt', 'beltway', 'bench', 'bends', 'beneath', 'berlin', 'better', 'bg', 'big', 'bigger', 'binders', 'binocular', 'birch', 'bit', 'bits', 'black', 'blade', 'blades', 'blam', 'blaming', 'blamm', 'blank', 'bleeding', 'blending', 'blinded', 'blindsided', 'blinking', 'blinks', 'block', 'blocked', 'blocking', 'blocks', 'blonde', 'blood', 'bloody', 'blow', 'blowing', 'blown', 'blows', 'blue', 'blueprint', 'blur', 'blurry', 'bmw', 'board', 'boarded', 'body', 'bogus', 'bomb', 'bombing', 'bone', 'book', 'boom', 'booooomm', 'booth', 'border', 'boss', 'bothering', 'bottle', 'boulevard', 'bouncing', 'bound', 'bourne', 'bourneabbott', 'bournephone', 'bournes', 'box', 'boxed', 'boxes', 'braced', 'braces', 'bracing', 'brakes', 'brandenburg', 'brass', 'breakdown', 'breaker', 'breaking', 'breaks', 'breath', 'breathe', 'breathing', 'breathless', 'brecker', 'bridge', 'briefcase', 'briefed', 'briefing', 'bright', 'bring', 'briskly', 'bristles', 'broadcoasting', 'bruise', 'budget', 'building', 'bulge', 'bulging', 'bulkhead', 'bullet', 'bulletin', 'bullets', 'bullpen', 'bumpers', 'bunch', 'bundle', 'burly', 'burn', 'burning', 'burst', 'bus', 'business', 'bust', 'busted', 'busy', 'button', 'buttoning', 'buy', 'buying', 'buzzkill', 'cab', 'cabbie', 'cabby', 'cabin', 'cabinet', 'cable', 'cabled', 'caffeine', 'calculated', 'calendar', 'caliber', 'called', 'calling', 'calls', 'calm', 'calmly', 'calms', 'came', 'camera', 'cameras', 'campground', 'canhow', 'canvas', 'cap', 'captain', 'caption', 'car', 'carabinieri', 'carabinieris', 'card', 'cards', 'care', 'careening', 'careful', 'carefully', 'careless', 'carnage', 'carries', 'carrying', 'cars', 'carves', 'cascading', 'case', 'cash', 'caspian', 'caspiexpetroleum', 'cast', 'casual', 'casually', 'catches', 'catching', 'caught', 'cause', 'caution', 'caves', 'cd', 'cell', 'cellphone', 'cement', 'center', 'ceo', 'certainly', 'chair', 'chairs', 'chalkboard', 'championed', 'championship', 'chance', 'change', 'changed', 'changes', 'chaos', 'charge', 'charges', 'charmed', 'chase', 'chasing', 'chatter', 'chatting', 'check', 'checked', 'checking', 'checkoff', 'checks', 'cherbourg', 'childlike', 'chill', 'chilly', 'chinese', 'chirping', 'choice', 'choices', 'chokehold', 'chokes', 'chop', 'choreographed', 'christ', 'chucked', 'chugging', 'ci', 'cia', 'cigarette', 'cigarettes', 'cinch', 'circles', 'city', 'civvies', 'claimed', 'clean', 'cleaning', 'clear', 'clearance', 'clearing', 'clearly', 'clears', 'clenching', 'clerk', 'clerks', 'clever', 'click', 'clicking', 'clicks', 'cliff', 'climb', 'climbing', 'clip', 'clipping', 'clock', 'clogging', 'cloned', 'close', 'closed', 'closequarter', 'closer', 'closes', 'closing', 'clothes', 'club', 'clubhouse', 'clue', 'cluster', 'clutter', 'cluttered', 'coal', 'coat', 'code', 'coding', 'coffee', 'cold', 'colonial', 'colored', 'come', 'comes', 'comfortable', 'coming', 'comm', 'command', 'commanders', 'common', 'commotion', 'communications', 'commuters', 'companies', 'company', 'comparison', 'complaining', 'compressing', 'compulsive', 'computer', 'computers', 'comrade', 'concentrating', 'concentric', 'concerned', 'concerning', 'concierge', 'concrete', 'condition', 'conditions', 'conductors', 'conferring', 'confidentially', 'confirm', 'confusion', 'conjunction', 'conjure', 'conklin', 'conklins', 'connections', 'consider', 'considering', 'consist', 'console', 'construction', 'consulate', 'contact', 'contd', 'continents', 'continues', 'continuing', 'contract', 'control', 'controlled', 'converge', 'conversation', 'convinced', 'convoy', 'coo', 'cool', 'cooly', 'coordinate', 'cop', 'cops', 'corner', 'corral', 'corridor', 'cots', 'cottage', 'coughing', 'counter', 'countering', 'counterintelligence', 'counting', 'country', 'countryside', 'couple', 'course', 'courtesy', 'cover', 'covered', 'covering', 'coworkers', 'cranking', 'cranks', 'crap', 'crash', 'crashes', 'crashing', 'crazy', 'credentials', 'credit', 'creepy', 'crestfallen', 'crewcut', 'crime', 'crinkles', 'crisp', 'crissake', 'cronin', 'croninradio', 'cross', 'crosses', 'crossing', 'crouches', 'crowd', 'crowded', 'cruising', 'crush', 'crushed', 'crushes', 'crying', 'cuffed', 'cuffs', 'cup', 'curb', 'curiosity', 'curious', 'curtains', 'curving', 'customs', 'cut', 'cuts', 'cutting', 'cyrillic', 'da', 'dad', 'damn', 'dangerous', 'dangle', 'daniel', 'danka', 'danny', 'dark', 'darkened', 'darkness', 'dash', 'dashboards', 'data', 'database', 'date', 'david', 'day', 'days', 'dead', 'deadly', 'deal', 'dealing', 'death', 'debrief', 'debriefed', 'decent', 'decide', 'decided', 'decision', 'decives', 'deck', 'deep', 'defensive', 'defiant', 'definitely', 'definitive', 'delta', 'deltas', 'departure', 'departures', 'depression', 'deputy', 'descend', 'deserted', 'desk', 'desolate', 'desperation', 'destiny', 'destroy', 'destroys', 'detailed', 'details', 'detained', 'determined', 'detonation', 'device', 'diagnosis', 'diagnostic', 'dial', 'dialed', 'did', 'didi', 'didjason', 'didnt', 'die', 'died', 'diei', 'dies', 'different', 'digital', 'digs', 'direct', 'directions', 'directly', 'director', 'disappear', 'disappearing', 'disappears', 'disappointed', 'disaster', 'discreet', 'discreetly', 'disembark', 'disembarking', 'disembarks', 'disgusted', 'dishes', 'disputing', 'distance', 'distinctive', 'distribution', 'disturbance', 'ditch', 'dividing', 'diving', 'dobermans', 'doctor', 'document', 'dod', 'dodging', 'dods', 'does', 'doesnt', 'doing', 'dollar', 'dollars', 'domestic', 'dominant', 'dominates', 'donnie', 'dont', 'door', 'doorbell', 'doorman', 'doors', 'doorway', 'double', 'doublecrossed', 'doubt', 'downhill', 'downs', 'dozens', 'drab', 'drawn', 'dread', 'dream', 'dresser', 'drifting', 'drill', 'drills', 'drink', 'drinks', 'drive', 'driver', 'driverphone', 'drivers', 'drives', 'driving', 'drone', 'drop', 'dropping', 'drops', 'drugs', 'drunk', 'ducked', 'ducking', 'duct', 'dude', 'dudes', 'duffel', 'duffle', 'dumping', 'dunk', 'ear', 'earlier', 'early', 'earpiece', 'ears', 'easing', 'east', 'easy', 'eat', 'edge', 'edges', 'ef', 'effective', 'effort', 'effortless', 'electric', 'electrical', 'element', 'elevator', 'eluded', 'embankment', 'embarrassed', 'emerge', 'emergency', 'emerges', 'emerging', 'emphatic', 'emptied', 'end', 'ends', 'energy', 'engine', 'engines', 'english', 'enjoy', 'enter', 'entering', 'enters', 'entombed', 'entrance', 'entrances', 'equal', 'equally', 'escape', 'escort', 'ether', 'europe', 'european', 'euros', 'evac', 'event', 'everybody', 'everyday', 'evidence', 'ex', 'exactly', 'exceptionally', 'excited', 'excuse', 'exfil', 'exit', 'exiting', 'exits', 'exnavyseal', 'expensive', 'expert', 'explosion', 'explosive', 'express', 'extreme', 'extremely', 'eye', 'eyes', 'facade', 'facades', 'face', 'faces', 'fact', 'factories', 'factoring', 'fade', 'fading', 'fail', 'failed', 'failing', 'fair', 'fake', 'fakes', 'faking', 'fall', 'fallen', 'falling', 'falls', 'familiar', 'families', 'family', 'fan', 'fanning', 'far', 'fast', 'faster', 'father', 'fatherly', 'fault', 'faux', 'favorite', 'fax', 'fear', 'feed', 'feeding', 'feel', 'feels', 'feet', 'fell', 'felt', 'fender', 'fenders', 'fernsehturm', 'ferry', 'field', 'fiftyeuro', 'fighting', 'fights', 'figure', 'file', 'filei', 'files', 'fileyour', 'filing', 'filling', 'fills', 'final', 'finally', 'financial', 'finding', 'finds', 'fine', 'finger', 'fingerprint', 'fingers', 'finish', 'finished', 'finishes', 'finishing', 'fired', 'fires', 'firing', 'firmly', 'fishing', 'fishtailing', 'fix', 'fixed', 'flag', 'flames', 'flanking', 'flash', 'flashback', 'flashes', 'flashing', 'flat', 'flatout', 'fleeing', 'flexcuffs', 'flicker', 'flickering', 'flicking', 'flies', 'flight', 'flights', 'flimsy', 'flips', 'floated', 'flood', 'flooding', 'floor', 'flooring', 'floors', 'flow', 'fly', 'flying', 'focused', 'focusing', 'foggy', 'folder', 'folding', 'folks', 'follow', 'followed', 'following', 'follows', 'food', 'fooled', 'foot', 'footing', 'footlocker', 'footpath', 'footstep', 'footsteps', 'force', 'foreboding', 'forehead', 'forest', 'forever', 'forget', 'forging', 'forgive', 'forgotten', 'fork', 'forlorn', 'forties', 'fortune', 'forward', 'fourgam', 'fourth', 'frantic', 'freaked', 'free', 'freezes', 'freezing', 'frequency', 'fresh', 'fridge', 'friendly', 'friends', 'frowns', 'frozen', 'frustration', 'fry', 'fuck', 'fucking', 'fully', 'fumbling', 'funky', 'furious', 'fury', 'fusty', 'futile', 'gables', 'gadgetry', 'gaining', 'game', 'gangster', 'gap', 'gas', 'gasolinestoked', 'gasping', 'gassoaked', 'gate', 'gathered', 'gathering', 'gauge', 'gaze', 'gear', 'gears', 'geneva', 'genevai', 'genoa', 'gentlemen', 'german', 'germans', 'germany', 'gestures', 'gets', 'getting', 'gift', 'gimme', 'girl', 'girlfriend', 'girls', 'given', 'gives', 'giving', 'glacial', 'glance', 'glanced', 'glances', 'glancing', ...] 123# 각 단어의 씬별 등장 횟수bow_vect.toarray() array([[0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], ..., [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0], [0, 0, 0, ..., 0, 0, 0]], dtype=int64) 1bow_vect.shape (320, 2850) 123# 각 단어의 총 등장 횟수 (모든 씬에서의 등장 횟수의 합)count_list # BoW array의 각 column에 대해서 모든 row의 합을 구하기 array([ 3, 3, 2, ..., 1, 42, 3], dtype=int64) 1234# \"단어\" - \"총 등장 횟수\" Matchingword_count_dict = dict(zip(word_list, count_list))word_count_dict {'aa': 3, 'ab': 3, 'abandoned': 2, 'abandons': 1, 'abbott': 128, 'abbottnow': 1, 'abbottphone': 4, 'abbotts': 3, 'abend': 2, 'able': 1, 'aboott': 1, 'aboutfaces': 1, 'absolutely': 1, 'abyss': 1, 'accelerating': 1, 'accented': 1, 'accepting': 1, 'accepts': 1, 'access': 3, 'accompanying': 1, 'accomplished': 1, 'account': 3, 'acknowledged': 1, 'act': 1, 'activity': 2, 'actually': 3, 'address': 3, 'adjust': 1, 'adrenaline': 1, 'affirmative': 1, 'afford': 1, 'afraid': 1, 'afternoon': 1, 'againi': 1, 'agencies': 1, 'agency': 5, 'agent': 2, 'agents': 2, 'agitated': 1, 'ago': 10, 'agreement': 2, 'agrees': 1, 'ah': 1, 'ahead': 17, 'aim': 1, 'aimed': 1, 'air': 9, 'airport': 2, 'alarm': 3, 'alert': 1, 'alexanderplatz': 3, 'alive': 9, 'alley': 2, 'alleys': 1, 'allocation': 1, 'allpoints': 1, 'alongside': 1, 'alps': 1, 'alright': 2, 'alrighti': 1, 'alrighttake': 1, 'american': 4, 'ammo': 1, 'amnesia': 5, 'amused': 1, 'anger': 1, 'angle': 2, 'ankle': 1, 'anonymous': 3, 'answer': 8, 'answering': 1, 'answers': 7, 'anymore': 3, 'anythings': 1, 'apology': 2, 'appealing': 1, 'appear': 1, 'appearing': 1, 'appears': 1, 'approached': 1, 'approaches': 2, 'approaching': 1, 'archive': 1, 'archives': 2, 'area': 5, 'arm': 2, 'armed': 2, 'arms': 3, 'army': 1, 'arrested': 1, 'arrivals': 1, 'arrived': 3, 'arrives': 8, 'arriving': 3, 'article': 1, 'asap': 1, 'ashes': 1, 'aside': 2, 'ask': 1, 'asked': 1, 'asking': 2, 'asks': 1, 'asleep': 1, 'ass': 7, 'assassinated': 2, 'assholes': 1, 'assigned': 1, 'assignment': 1, 'assistant': 1, 'associated': 1, 'attempt': 1, 'attention': 3, 'autobahn': 1, 'automatic': 3, 'available': 1, 'aware': 1, 'away': 48, 'awful': 3, 'awhile': 2, 'ba': 2, 'backhanding': 1, 'backing': 5, 'backpack': 4, 'backpacks': 2, 'backs': 2, 'backseat': 4, 'backyard': 1, 'bad': 5, 'bag': 18, 'bags': 2, 'bail': 1, 'bailing': 2, 'bakery': 1, 'balance': 2, 'ball': 1, 'balling': 1, 'band': 1, 'bang': 1, 'banging': 1, 'bank': 3, 'banking': 1, 'banks': 1, 'bar': 1, 'barely': 8, 'bargain': 1, 'barge': 9, 'barn': 1, 'base': 2, 'basement': 2, 'basic': 1, 'basically': 1, 'bastards': 1, 'bathroom': 7, 'battery': 1, 'bb': 2, 'bc': 1, 'beach': 10, 'bearing': 1, 'bearings': 1, 'beat': 22, 'beats': 2, 'beattocrap': 1, 'bed': 9, 'bedroom': 2, 'beep': 2, 'beeping': 2, 'beggars': 1, 'begging': 4, 'begin': 2, 'begins': 9, 'behavior': 1, 'behaviors': 1, 'believe': 4, 'believed': 6, 'belongings': 1, 'belt': 1, 'beltway': 4, 'bench': 1, 'bends': 1, 'beneath': 1, 'berlin': 37, 'better': 7, 'bg': 1, 'big': 17, 'bigger': 3, 'binders': 1, 'binocular': 1, 'birch': 1, 'bit': 6, 'bits': 1, 'black': 15, 'blade': 1, 'blades': 1, 'blam': 2, 'blaming': 1, 'blamm': 1, 'blank': 2, 'bleeding': 1, 'blending': 1, 'blinded': 1, 'blindsided': 1, 'blinking': 2, 'blinks': 2, 'block': 3, 'blocked': 2, 'blocking': 2, 'blocks': 1, 'blonde': 1, 'blood': 6, 'bloody': 2, 'blow': 1, 'blowing': 4, 'blown': 3, 'blows': 4, 'blue': 3, 'blueprint': 2, 'blur': 3, 'blurry': 1, 'bmw': 4, 'board': 2, 'boarded': 1, 'body': 9, 'bogus': 1, 'bomb': 1, 'bombing': 1, 'bone': 1, 'book': 2, 'boom': 1, 'booooomm': 1, 'booth': 3, 'border': 2, 'boss': 2, 'bothering': 1, 'bottle': 3, 'boulevard': 4, 'bouncing': 1, 'bound': 1, 'bourne': 455, 'bourneabbott': 1, 'bournephone': 5, 'bournes': 29, 'box': 5, 'boxed': 1, 'boxes': 1, 'braced': 1, 'braces': 1, 'bracing': 2, 'brakes': 3, 'brandenburg': 1, 'brass': 1, 'breakdown': 1, 'breaker': 1, 'breaking': 1, 'breaks': 1, 'breath': 2, 'breathe': 1, 'breathing': 1, 'breathless': 1, 'brecker': 9, 'bridge': 13, 'briefcase': 8, 'briefed': 1, 'briefing': 1, 'bright': 2, 'bring': 2, 'briskly': 2, 'bristles': 1, 'broadcoasting': 1, 'bruise': 1, 'budget': 1, 'building': 20, 'bulge': 1, 'bulging': 1, 'bulkhead': 2, 'bullet': 1, 'bulletin': 1, 'bullets': 2, 'bullpen': 5, 'bumpers': 1, 'bunch': 1, 'bundle': 1, 'burly': 1, 'burn': 1, 'burning': 2, 'burst': 1, 'bus': 3, 'business': 3, 'bust': 1, 'busted': 1, 'busy': 7, 'button': 1, 'buttoning': 1, 'buy': 7, 'buying': 2, 'buzzkill': 1, 'cab': 24, 'cabbie': 3, 'cabby': 1, 'cabin': 1, 'cabinet': 3, 'cable': 1, 'cabled': 1, 'caffeine': 1, 'calculated': 1, 'calendar': 1, 'caliber': 1, 'called': 3, 'calling': 1, 'calls': 1, 'calm': 4, 'calmly': 2, 'calms': 1, 'came': 10, 'camera': 3, 'cameras': 1, 'campground': 1, 'canhow': 1, 'canvas': 1, 'cap': 1, 'captain': 2, 'caption': 1, 'car': 51, 'carabinieri': 5, 'carabinieris': 1, 'card': 1, 'cards': 2, 'care': 3, 'careening': 1, 'careful': 2, 'carefully': 2, 'careless': 1, 'carnage': 1, 'carries': 1, 'carrying': 6, 'cars': 20, 'carves': 1, 'cascading': 1, 'case': 7, 'cash': 6, 'caspian': 1, 'caspiexpetroleum': 1, 'cast': 1, 'casual': 2, 'casually': 1, 'catches': 1, 'catching': 3, 'caught': 2, 'cause': 1, 'caution': 1, 'caves': 1, 'cd': 1, 'cell': 7, 'cellphone': 2, 'cement': 1, 'center': 3, 'ceo': 1, 'certainly': 1, 'chair': 9, 'chairs': 1, 'chalkboard': 1, 'championed': 1, 'championship': 1, 'chance': 1, 'change': 4, 'changed': 3, 'changes': 2, 'chaos': 2, 'charge': 7, 'charges': 2, 'charmed': 1, 'chase': 2, 'chasing': 1, 'chatter': 1, 'chatting': 1, 'check': 6, 'checked': 2, 'checking': 13, 'checkoff': 1, 'checks': 12, 'cherbourg': 1, 'childlike': 1, 'chill': 1, 'chilly': 1, 'chinese': 2, 'chirping': 1, 'choice': 5, 'choices': 1, 'chokehold': 1, 'chokes': 1, 'chop': 2, 'choreographed': 1, 'christ': 2, 'chucked': 1, 'chugging': 2, 'ci': 2, 'cia': 7, 'cigarette': 1, 'cigarettes': 1, 'cinch': 1, 'circles': 2, 'city': 4, 'civvies': 1, 'claimed': 1, 'clean': 7, 'cleaning': 1, 'clear': 9, 'clearance': 1, 'clearing': 1, 'clearly': 5, 'clears': 2, 'clenching': 1, 'clerk': 8, 'clerks': 1, 'clever': 1, 'click': 6, 'clicking': 1, 'clicks': 1, 'cliff': 1, 'climb': 1, 'climbing': 4, 'clip': 3, 'clipping': 1, 'clock': 4, 'clogging': 1, 'cloned': 2, 'close': 13, 'closed': 3, 'closequarter': 1, 'closer': 4, 'closes': 2, 'closing': 3, 'clothes': 7, 'club': 3, 'clubhouse': 1, 'clue': 1, 'cluster': 1, 'clutter': 1, 'cluttered': 1, 'coal': 2, 'coat': 7, 'code': 2, 'coding': 1, 'coffee': 5, 'cold': 4, 'colonial': 1, 'colored': 1, 'come': 18, 'comes': 10, 'comfortable': 1, 'coming': 30, 'comm': 2, 'command': 1, 'commanders': 1, 'common': 1, 'commotion': 1, 'communications': 2, 'commuters': 1, 'companies': 1, 'company': 3, 'comparison': 1, 'complaining': 1, 'compressing': 1, 'compulsive': 1, 'computer': 7, 'computers': 2, 'comrade': 1, 'concentrating': 1, 'concentric': 1, 'concerned': 2, 'concerning': 1, 'concierge': 3, 'concrete': 3, 'condition': 1, 'conditions': 1, 'conductors': 1, 'conferring': 2, 'confidentially': 1, 'confirm': 1, 'confusion': 3, 'conjunction': 1, 'conjure': 1, 'conklin': 29, 'conklins': 4, 'connections': 1, 'consider': 1, 'considering': 1, 'consist': 1, 'console': 1, 'construction': 2, 'consulate': 2, 'contact': 3, 'contd': 63, 'continents': 1, 'continues': 3, 'continuing': 8, 'contract': 1, 'control': 2, 'controlled': 1, 'converge': 1, 'conversation': 3, 'convinced': 1, 'convoy': 1, 'coo': 1, 'cool': 3, 'cooly': 1, 'coordinate': 1, 'cop': 5, 'cops': 22, 'corner': 13, 'corral': 1, 'corridor': 1, 'cots': 1, 'cottage': 1, 'coughing': 1, 'counter': 2, 'countering': 1, 'counterintelligence': 2, 'counting': 1, 'country': 1, 'countryside': 1, 'couple': 4, 'course': 1, 'courtesy': 1, 'cover': 9, 'covered': 2, 'covering': 1, 'coworkers': 1, 'cranking': 1, 'cranks': 1, 'crap': 2, 'crash': 2, 'crashes': 1, 'crashing': 2, 'crazy': 4, 'credentials': 1, 'credit': 1, 'creepy': 1, 'crestfallen': 1, 'crewcut': 1, 'crime': 2, 'crinkles': 1, 'crisp': 1, 'crissake': 1, 'cronin': 81, 'croninradio': 1, 'cross': 2, 'crosses': 3, 'crossing': 2, 'crouches': 1, 'crowd': 7, 'crowded': 2, 'cruising': 1, 'crush': 1, 'crushed': 1, 'crushes': 1, 'crying': 4, 'cuffed': 2, 'cuffs': 2, 'cup': 2, 'curb': 3, 'curiosity': 1, 'curious': 1, 'curtains': 2, 'curving': 1, 'customs': 1, 'cut': 2, 'cuts': 2, 'cutting': 3, 'cyrillic': 2, 'da': 1, 'dad': 1, 'damn': 2, 'dangerous': 3, 'dangle': 1, 'daniel': 1, 'danka': 1, 'danny': 8, 'dark': 16, 'darkened': 1, 'darkness': 2, 'dash': 2, 'dashboards': 1, 'data': 3, 'database': 1, 'date': 2, 'david': 1, 'day': 4, 'days': 2, 'dead': 22, 'deadly': 1, 'deal': 3, 'dealing': 1, 'death': 4, 'debrief': 2, 'debriefed': 1, 'decent': 1, 'decide': 2, 'decided': 1, 'decision': 1, 'decives': 1, 'deck': 2, 'deep': 2, 'defensive': 2, 'defiant': 1, 'definitely': 1, 'definitive': 3, 'delta': 12, 'deltas': 1, 'departure': 2, 'departures': 1, 'depression': 1, 'deputy': 2, 'descend': 1, 'deserted': 2, 'desk': 17, 'desolate': 2, 'desperation': 2, 'destiny': 1, 'destroy': 1, 'destroys': 1, 'detailed': 1, 'details': 2, 'detained': 1, 'determined': 1, 'detonation': 1, 'device': 2, 'diagnosis': 1, 'diagnostic': 1, 'dial': 1, 'dialed': 1, 'did': 15, 'didi': 1, 'didjason': 1, 'didnt': 11, 'die': 1, 'died': 3, 'diei': 1, 'dies': 1, 'different': 2, 'digital': 1, 'digs': 1, 'direct': 1, 'directions': 1, 'directly': 1, 'director': 2, 'disappear': 6, 'disappearing': 1, 'disappears': 3, 'disappointed': 1, 'disaster': 3, 'discreet': 2, 'discreetly': 2, 'disembark': 1, 'disembarking': 2, 'disembarks': 1, 'disgusted': 1, 'dishes': 1, 'disputing': 1, 'distance': 4, 'distinctive': 1, 'distribution': 1, 'disturbance': 1, 'ditch': 1, 'dividing': 1, 'diving': 1, 'dobermans': 2, 'doctor': 1, 'document': 1, 'dod': 3, 'dodging': 1, 'dods': 1, 'does': 9, 'doesnt': 11, 'doing': 20, 'dollar': 2, 'dollars': 4, 'domestic': 1, 'dominant': 1, 'dominates': 1, 'donnie': 1, 'dont': 42, 'door': 31, 'doorbell': 1, 'doorman': 2, 'doors': 9, 'doorway': 3, 'double': 1, 'doublecrossed': 1, 'doubt': 1, 'downhill': 1, 'downs': 1, 'dozens': 1, 'drab': 1, 'drawn': 4, 'dread': 2, 'dream': 4, 'dresser': 1, 'drifting': 2, 'drill': 3, 'drills': 2, 'drink': 1, 'drinks': 1, 'drive': 3, 'driver': 20, 'driverphone': 1, 'drivers': 3, 'drives': 4, 'driving': 12, 'drone': 1, 'drop': 4, 'dropping': 3, 'drops': 3, 'drugs': 1, 'drunk': 4, 'ducked': 1, 'ducking': 1, 'duct': 2, 'dude': 2, 'dudes': 6, 'duffel': 1, 'duffle': 3, 'dumping': 1, 'dunk': 1, 'ear': 1, 'earlier': 1, 'early': 5, 'earpiece': 3, 'ears': 1, 'easing': 1, 'east': 2, 'easy': 2, 'eat': 1, 'edge': 2, 'edges': 1, 'ef': 1, 'effective': 1, 'effort': 1, 'effortless': 1, 'electric': 1, 'electrical': 3, 'element': 1, 'elevator': 8, 'eluded': 1, 'embankment': 1, 'embarrassed': 2, 'emerge': 1, 'emergency': 1, 'emerges': 1, 'emerging': 2, 'emphatic': 1, 'emptied': 1, 'end': 10, 'ends': 2, 'energy': 1, 'engine': 1, 'engines': 1, 'english': 2, 'enjoy': 1, 'enter': 2, 'entering': 1, 'enters': 10, 'entombed': 1, 'entrance': 2, 'entrances': 1, 'equal': 1, 'equally': 1, 'escape': 1, 'escort': 3, 'ether': 1, 'europe': 2, 'european': 1, 'euros': 1, 'evac': 2, 'event': 1, 'everybody': 3, 'everyday': 1, 'evidence': 1, 'ex': 1, 'exactly': 7, 'exceptionally': 1, 'excited': 2, 'excuse': 1, 'exfil': 6, 'exit': 2, 'exiting': 1, 'exits': 3, 'exnavyseal': 1, 'expensive': 1, 'expert': 1, 'explosion': 1, 'explosive': 3, 'express': 1, 'extreme': 1, 'extremely': 2, 'eye': 6, 'eyes': 25, 'facade': 2, 'facades': 1, 'face': 22, 'faces': 6, 'fact': 2, 'factories': 1, 'factoring': 1, 'fade': 2, 'fading': 1, 'fail': 1, 'failed': 1, 'failing': 1, 'fair': 1, 'fake': 1, 'fakes': 1, 'faking': 1, 'fall': 3, 'fallen': 1, 'falling': 2, 'falls': 1, 'familiar': 2, 'families': 1, 'family': 5, 'fan': 1, 'fanning': 1, 'far': 7, 'fast': 13, 'faster': 1, 'father': 3, 'fatherly': 1, 'fault': 1, 'faux': 1, 'favorite': 1, 'fax': 2, 'fear': 4, 'feed': 2, 'feeding': 1, 'feel': 4, 'feels': 1, 'feet': 3, 'fell': 3, 'felt': 4, 'fender': 1, 'fenders': 1, 'fernsehturm': 1, 'ferry': 2, 'field': 6, 'fiftyeuro': 1, 'fighting': 1, 'fights': 1, 'figure': 3, 'file': 8, 'filei': 1, 'files': 11, 'fileyour': 1, 'filing': 1, 'filling': 1, 'fills': 1, 'final': 5, 'finally': 11, 'financial': 2, 'finding': 3, 'finds': 1, 'fine': 2, 'finger': 4, 'fingerprint': 3, 'fingers': 1, 'finish': 2, 'finished': 1, 'finishes': 1, 'finishing': 1, 'fired': 1, 'fires': 1, 'firing': 4, 'firmly': 1, 'fishing': 2, 'fishtailing': 1, 'fix': 2, 'fixed': 3, 'flag': 2, 'flames': 1, 'flanking': 1, 'flash': 2, 'flashback': 7, 'flashes': 3, 'flashing': 2, 'flat': 2, 'flatout': 1, 'fleeing': 1, 'flexcuffs': 2, 'flicker': 3, 'flickering': 1, 'flicking': 1, 'flies': 1, 'flight': 1, 'flights': 1, 'flimsy': 1, 'flips': 2, 'floated': 1, 'flood': 1, 'flooding': 1, 'floor': 10, 'flooring': 1, 'floors': 1, 'flow': 1, 'fly': 1, 'flying': 2, 'focused': 3, 'focusing': 1, 'foggy': 1, 'folder': 1, 'folding': 2, 'folks': 1, 'follow': 3, 'followed': 1, 'following': 2, 'follows': 3, 'food': 4, 'fooled': 2, 'foot': 4, 'footing': 1, 'footlocker': 2, 'footpath': 2, 'footstep': 1, 'footsteps': 1, 'force': 2, 'foreboding': 1, 'forehead': 1, 'forest': 1, 'forever': 1, 'forget': 3, 'forging': 1, 'forgive': 1, 'forgotten': 2, 'fork': 2, 'forlorn': 1, 'forties': 1, 'fortune': 1, 'forward': 6, 'fourgam': 1, 'fourth': 1, 'frantic': 1, 'freaked': 3, 'free': 4, 'freezes': 1, 'freezing': 2, 'frequency': 1, 'fresh': 4, 'fridge': 1, 'friendly': 1, 'friends': 2, 'frowns': 1, 'frozen': 2, 'frustration': 1, 'fry': 1, 'fuck': 7, 'fucking': 1, 'fully': 3, 'fumbling': 1, 'funky': 1, 'furious': 1, 'fury': 2, 'fusty': 1, 'futile': 1, 'gables': 1, 'gadgetry': 1, 'gaining': 2, 'game': 4, 'gangster': 1, 'gap': 1, 'gas': 5, 'gasolinestoked': 1, 'gasping': 1, 'gassoaked': 1, 'gate': 1, 'gathered': 2, 'gathering': 1, 'gauge': 1, 'gaze': 2, 'gear': 9, 'gears': 1, 'geneva': 1, 'genevai': 1, 'genoa': 1, 'gentlemen': 1, 'german': 7, 'germans': 1, 'germany': 2, 'gestures': 3, 'gets': 7, 'getting': 16, 'gift': 1, 'gimme': 1, 'girl': 6, 'girlfriend': 1, 'girls': 1, 'given': 1, 'gives': 4, 'giving': 3, 'glacial': 1, 'glance': 1, 'glanced': 1, 'glances': 1, 'glancing': 8, ...} 12345# 등장 횟수 (count) 순으로 정렬import operatorsorted(word_count_dict.items(), key = operator.itemgetter(1), reverse = True)[:5] [('bourne', 455), ('pamela', 199), ('abbott', 128), ('hes', 100), ('kirill', 93)] (3) 단어 분포 탐색 12plt.hist(list(word_count_dict.values()), bins=150)plt.show() 대부분의 단어가 0번~50번 사이에 등장했고, 일부 소수의 단어들이 100번 이상 등장한 것을 확인할 수 있습니다. 4. 택스트 마이닝 4-1. 단어별 빈도 분석 (+ Word Cloud) (1) 상위 빈도수 단어 출력 1234# word_count_dict중 상위 25 tags 확인해보기ranked_tags = Counter(word_count_dict).most_common(25)ranked_tags [('bourne', 455), ('pamela', 199), ('abbott', 128), ('hes', 100), ('kirill', 93), ('nicky', 90), ('cronin', 81), ('just', 80), ('marie', 67), ('contd', 63), ('know', 61), ('car', 51), ('away', 48), ('room', 44), ('jarda', 43), ('looks', 43), ('dont', 42), ('zorn', 42), ('phone', 40), ('right', 39), ('theres', 39), ('police', 38), ('want', 38), ('berlin', 37), ('teddy', 35)] (2) Word Cloud 시각화 1!pip install pytagcloud pygame simplejson Collecting pytagcloud Downloading pytagcloud-0.3.5.tar.gz (754 kB) Collecting pygame Downloading pygame-1.9.6-cp37-cp37m-win_amd64.whl (4.3 MB) Collecting simplejson Downloading simplejson-3.17.2-cp37-cp37m-win_amd64.whl (73 kB) Building wheels for collected packages: pytagcloud Building wheel for pytagcloud (setup.py): started Building wheel for pytagcloud (setup.py): finished with status 'done' Created wheel for pytagcloud: filename=pytagcloud-0.3.5-py3-none-any.whl size=759873 sha256=0c740b8c183f3dd04c6b6353e75f2307bdcc7855bb0ce66f4caa3ed352b6e8cc Stored in directory: c:\\users\\kimsu\\appdata\\local\\pip\\cache\\wheels\\fc\\fd\\aa\\86956a295a7c9205bafd518ef4b6d489e51d2d476990c18238 Successfully built pytagcloud Installing collected packages: pytagcloud, pygame, simplejson Successfully installed pygame-1.9.6 pytagcloud-0.3.5 simplejson-3.17.2 12345from collections import Counterimport randomimport pytagcloudimport webbrowser pygame 1.9.6 Hello from the pygame community. https://www.pygame.org/contribute.html 내림순으로 상위 N개를 추출하는 두가지 방법: sorted(dict .items(), key = operator.itemgetter(col_index), reverse=True) [:N] Counter(dict .most_common(N)) 1234567# Top 40 단어로 word cloud 생성하기taglist = pytagcloud.make_tags(sorted(word_count_dict.items(), key = operator.itemgetter(1), reverse=True)[:40], maxsize=60) # 빈도수(itemgetter(1)) 내림차순(reverse=True)으로 정렬, maxsize: 글자 크기# taglist = pytagcloud.make_tages(Counter(word_count_dict).most_common(40), maxsize=60)pytagcloud.create_tag_image(taglist, 'movie_wordcloud.jpg', rectangular=False)from IPython.display import ImageImage(filename='movie_wordcloud.jpg') ​ 4-2. 장면별 중요 단어 시각화 (TF-IDF) (1) TF-IDF 변환 Bag of Words 벡터에 대해서 TF-IDF변환 진행합니다. 123456from sklearn.feature_extraction.text import TfidfTransformertfidf_vectorizer = TfidfTransformer()tf_idf_vect = tfidf_vectorizer.fit_transform(bow_vect)print(tf_idf_vect.shape) # 320*2850 vector: 320 scenes, 2850 sentences (320, 2850) 변환 후 320*2850 matrix가 출력됩니다. 여기서 한 행(row)은 한 씬을 의미하고 한 열(column)은 한 단어를 의미합니다. 12# 첫번째 행 출력 (0이 아닌것 만) -- 즉 첫 씬에서 모든 단어의 TF-IDF 값print(tf_idf_vect[0]) (320, 2850) (0, 2788) 0.19578974958217082 (0, 2763) 0.27550455848587985 (0, 2412) 0.1838379942679887 (0, 2387) 0.3109660261831164 (0, 1984) 0.2902223973596984 (0, 1978) 0.3109660261831164 (0, 1898) 0.27550455848587985 (0, 1673) 0.2902223973596984 (0, 1366) 0.21520447034992146 (0, 1251) 0.19855583314180728 (0, 1001) 0.2340173008390438 (0, 974) 0.2902223973596984 (0, 874) 0.27550455848587985 (0, 798) 0.1906694714764746 (0, 237) 0.08646242181596513 (0, 125) 0.26408851574819875 123# (0을 포함한) 실제 vector의 모습 출력해보기print(tf_idf_vect[0].toarray().shape)print(tf_idf_vect[0].toarray()) (1, 2850) [[0. 0. 0. ... 0. 0. 0.]] (2) “벡터” - “단어” mapping 길이가 2850인 단어 벡터의 각 위치가 어떤 단어를 상징하는지를 알아내기 위해 단어 벡터에 대해서 “단어” - “index No.” Mapping 을 진행합니다. 1vect.vocabulary_ {'raining': 1898, 'light': 1366, 'strobes': 2387, 'wet': 2763, 'glass': 1001, 'rhythmic': 1978, 'pace': 1673, 'suddenly': 2412, 'window': 2788, 'face': 798, 'jason': 1251, 'bourne': 237, 'riding': 1984, 'backseat': 125, 'gaze': 974, 'fixed': 874, 'knee': 1297, 'syringe': 2459, 'gun': 1055, 'eyes': 795, 'driver': 703, 'jarda': 1248, 'watching': 2741, 'bournes': 240, 'pov': 1817, 'passenger': 1710, 'head': 1097, 'cell': 351, 'phone': 1747, 'rings': 1990, 'turns': 2626, 'conklin': 481, 'returns': 1971, 'stare': 2332, 'open': 1649, 'panicked': 1693, 'gasping': 968, 'trying': 2615, 'stay': 2347, 'quiet': 1886, 'marie': 1454, 'sleeps': 2221, 'moving': 1556, 'medicine': 1482, 'cabinet': 299, 'digs': 640, 'downs': 690, 'specific': 2283, 'minute': 1515, 'later': 1333, 'moves': 1555, 'veranda': 2679, 'pads': 1681, 'moment': 1537, 'concerned': 468, 'clearly': 408, 'time': 2542, 'happened': 1082, 'look': 1405, 'different': 638, 'saw': 2044, 'hair': 1065, 'longer': 1404, 'shes': 2137, 'blonde': 207, 'hippie': 1138, 'travelers': 2592, 'cottage': 512, 'humble': 1174, 'sweet': 2445, 'bedroom': 163, 'opens': 1652, 'beach': 156, 'town': 2570, 'just': 1272, 'hill': 1135, 'club': 432, 'music': 1566, 'night': 1602, 'rave': 1909, 'wafting': 2708, 'far': 821, 'distance': 658, 'car': 321, 'ill': 1193, 'book': 226, 'theres': 2513, 'new': 1595, 'youre': 2844, 'sure': 2428, 'nods': 1607, 'write': 2823, 'years': 2834, 'scribbling': 2070, 'notebook': 1615, 'bad': 127, 'bits': 189, 'pieces': 1760, 'gone': 1012, 'think': 2521, 'maybe': 1470, 'making': 1442, 'worse': 2816, 'dont': 680, 'wonder': 2800, 'lays': 1337, 'hands': 1077, 'shoulders': 2157, 'steadies': 2351, 'sooner': 2268, 'going': 1011, 'remember': 1951, 'good': 1014, 'softens': 2260, 'smiles': 2241, 'kisses': 1293, 'leads': 1342, 'getting': 986, 'bed': 162, 'turning': 2625, 'settled': 2110, 'waiting': 2713, 'pill': 1763, 'kick': 1281, 'im': 1194, 'okay': 1641, 'worry': 2815, 'like': 1369, 'nightmare': 1603, 'mean': 1473, 'try': 2614, 'ignore': 1190, 'hesitates': 1124, 'gets': 985, 'knows': 1310, 'right': 1987, 'opening': 1651, 'hes': 1123, 'letting': 1359, 'resistance': 1963, 'folding': 907, 'childlike': 380, 'gathering': 972, 'contd': 491, 'sleep': 2218, 'better': 181, 'memories': 1487, 'dream': 695, 'having': 1094, 'ends': 752, 'day': 586, 'takes': 2464, 'beat': 159, 'make': 1440, 'silence': 2182, 'strokes': 2389, 'gives': 993, 'tenderness': 2499, 'fading': 804, 'waifs': 2710, 'dark': 577, 'running': 2022, 'sun': 2418, 'punishing': 1865, 'sand': 2038, 'strong': 2391, 'effortless': 737, 'deep': 601, 'focused': 903, 'stunning': 2400, 'conjunction': 479, 'scenery': 2055, 'lost': 1414, 'busy': 289, 'market': 1457, 'fishing': 871, 'lots': 1416, 'young': 2842, 'western': 2761, 'faces': 799, 'rundown': 2021, 'happening': 1083, 'shopping': 2152, 'filling': 852, 'bag': 128, 'local': 1391, 'produce': 1841, 'leaving': 1352, 'putting': 1875, 'groceries': 1040, 'away': 116, 'stops': 2369, 'photograph': 1753, 'windowsill': 2790, 'snapshot': 2250, 'arms': 87, 'protector': 1853, 'big': 183, 'alive': 51, 'love': 1419, 'funky': 955, 'colonial': 444, 'facades': 797, 'vivid': 2698, 'subcontinental': 2404, 'technicolor': 2483, 'loud': 1417, 'morning': 1545, 'traffic': 2576, 'camera': 313, 'finds': 858, 'coming': 449, 'store': 2370, 'bottle': 233, 'water': 2742, 'finished': 864, 'run': 2020, 'standing': 2329, 'chugging': 393, 'checking': 376, 'scene': 2054, 'catches': 344, 'eye': 794, 'street': 2380, 'silver': 2188, 'newish': 1596, 'pulling': 1861, 'block': 203, 'quite': 1888, 'whos': 2779, 'driving': 707, 'casual': 342, 'passing': 1714, 'notice': 1616, 'alert': 49, 'follows': 912, 'foot': 915, 'natural': 1575, 'cruising': 551, 'sidewalk': 2174, 'blending': 198, 'mix': 1525, 'ahead': 43, 'corner': 508, 'slowing': 2233, 'reaches': 1912, 'parked': 1700, 'guy': 1059, 'welldressed': 2757, 'physical': 1755, 'sunglasses': 2420, 'kirill': 1291, 'heading': 1100, 'building': 270, 'telegraph': 2491, 'office': 1632, 'watch': 2739, 'perimeter': 1739, 'mr': 1557, 'mohan': 1534, 'desk': 614, 'crisp': 541, 'proper': 1849, 'man': 1443, 'handed': 1074, 'old': 1642, 'passport': 1715, 'picture': 1758, 'question': 1879, 'sir': 2197, 'sister': 2200, 'death': 592, 'family': 818, 'place': 1772, 'know': 1307, 'called': 306, 'note': 1614, 'table': 2460, 'come': 446, 'read': 1917, 'balling': 135, 'quickly': 1884, 'fact': 800, 'bailing': 131, 'fast': 822, 'calm': 309, 'methodical': 1501, 'exfil': 782, 'procedure': 1839, 'honed': 1150, 'choreographed': 390, 'packing': 1678, 'machine': 1432, 'rapid': 1908, 'cuts': 566, 'backpacks': 123, 'thrown': 2534, 'house': 1163, 'cash': 338, 'pulled': 1860, 'lamp': 1318, 'base': 147, 'credit': 535, 'cards': 325, 'taped': 2470, 'counter': 514, 'bank': 139, 'mission': 1521, 'accomplished': 20, 'starting': 2338, 'glancing': 999, 'nice': 1599, 'easy': 730, 'cool': 503, 'gear': 975, 'makes': 1441, 'slow': 2231, 'pass': 1707, 'marketplace': 1458, 'stripped': 2384, 'thing': 2519, 'shit': 2143, 'missed': 1519, 'looking': 1406, 'earlier': 724, 'jamming': 1246, 'pocket': 1793, 'begins': 169, 'sweep': 2444, 'jogging': 1259, 'keeping': 1273, 'low': 1422, 'neighborhood': 1587, 'alleys': 53, 'random': 1905, 'worked': 2807, 'crowded': 550, 'tourists': 2566, 'sunbathers': 2419, 'favorite': 828, 'spot': 2298, 'talking': 2467, 'women': 2799, 'laughing': 1335, 'happy': 1085, 'burly': 281, 'jeep': 1252, 'comes': 447, 'roaring': 2003, 'spots': 2300, 'parks': 1702, 'end': 751, 'methodically': 1502, 'way': 2746, 'blue': 214, 'tent': 2503, 'towel': 2567, 'opposite': 1657, 'arrives': 92, 'looks': 1407, 'sees': 2089, 'yards': 2831, 'hard': 1086, 'bends': 178, 'gotta': 1018, 'tone': 2552, 'voice': 2702, 'grabs': 1020, 'quick': 1883, 'goodbye': 1015, 'friends': 946, 'hurry': 1177, 'uses': 2667, 'cover': 523, 'retreats': 1969, 'reach': 1911, 'drill': 698, 'tossed': 2559, 'pulls': 1862, 'blown': 212, 'ago': 39, 'fine': 859, 'careful': 328, 'pushed': 1871, 'got': 1017, 'lazy': 1338, 'following': 911, 'main': 1437, 'blocked': 204, 'huge': 1172, 'automatic': 113, 'pistol': 1768, 'travel': 2591, 'narrow': 1573, 'little': 1385, 'passageway': 1708, 'windshield': 2791, 'packed': 1677, 'liking': 1370, 'decide': 596, 'campground': 315, 'yesterday': 2838, 'wrong': 2827, 'rental': 1953, 'dollar': 674, 'sneakers': 2251, 'pull': 1859, 'thats': 2511, 'crazy': 533, 'real': 1921, 'throwing': 2533, 'reverse': 1974, 'hyundai': 1183, 'trapped': 2589, 'gridlock': 1036, 'freezing': 941, 'alley': 52, 'disappear': 645, 'backing': 121, 'came': 312, 'blowing': 211, 'horn': 1156, 'van': 2672, 'blocks': 206, 'leaning': 1344, 'theyve': 2517, 'wait': 2712, 'want': 2726, 'againi': 33, 'clear': 405, 'shack': 2117, 'safe': 2031, 'hang': 1078, 'awhile': 118, 'check': 374, 'wheres': 2773, 'left': 1353, 'places': 1774, 'afford': 30, 'possessed': 1809, 'familiar': 816, 'tactical': 2462, 'patience': 1720, 'doesnt': 672, 'sense': 2098, 'checks': 378, 'rearview': 1927, 'fuck': 951, 'taking': 2465, 'hell': 1117, 'forward': 934, 'blocking': 205, 'drive': 702, 'squeezing': 2313, 'switch': 2455, 'bridge': 259, 'scrambling': 2061, 'seat': 2078, 'squirts': 2316, 'wheel': 2771, 'adrenaline': 28, 'pumping': 1864, 'thirty': 2524, 'skidding': 2208, 'turn': 2624, 'clipping': 421, 'vehicle': 2677, 'mirror': 1517, 'shattering': 2130, 'speeding': 2285, 'scanning': 2050, 'veering': 2676, 'oncoming': 1645, 'bus': 285, 'jesus': 1256, 'yeah': 2832, 'ready': 1920, 'bearing': 157, 'smile': 2240, 'knowing': 1308, 'stopping': 2368, 'short': 2153, 'rise': 1995, 'bit': 188, 'view': 2692, 'half': 1067, 'headed': 1099, 'gonna': 1013, 'lose': 1412, 'kirills': 1292, 'mind': 1513, 'racing': 1890, 'duffle': 720, 'abandons': 3, 'preps': 1825, 'meet': 1484, 'hour': 1161, 'bail': 130, 'follow': 909, 'crosses': 546, 'warned': 2731, 'told': 2551, 'leave': 1350, 'thisit': 2526, 'wont': 2801, 'choice': 385, 'concrete': 471, 'slams': 2216, 'precise': 1819, 'sniper': 2252, 'rifle': 1985, 'hand': 1073, 'spare': 2276, 'clip': 420, 'roll': 2007, 'tell': 2496, 'scope': 2059, 'rumbling': 2019, 'target': 2472, 'drivers': 705, 'headrest': 1103, 'finger': 860, 'firing': 869, 'jerking': 1254, 'fender': 838, 'tearing': 2480, 'guard': 1045, 'rail': 1895, 'cement': 353, 'shards': 2126, 'air': 46, 'reaching': 1913, 'late': 1332, 'finally': 855, 'crashes': 531, 'flimsy': 892, 'guardrail': 1046, 'plummets': 1791, 'splashes': 2295, 'sink': 2194, 'sight': 2177, 'lowers': 1425, 'basically': 150, 'unnoticed': 2646, 'nook': 1611, 'silenced': 2183, 'people': 1737, 'rushing': 2026, 'woman': 2797, 'directly': 643, 'doorway': 685, 'indian': 1211, 'goa': 1006, 'drills': 699, 'sinks': 2195, 'inside': 1215, 'swallowed': 2439, 'scans': 2051, 'surface': 2429, 'river': 2000, 'mud': 1559, 'plumes': 1790, 'settles': 2111, 'tries': 2599, 'urge': 2661, 'killers': 1287, 'unbroken': 2634, 'woodwork': 2803, 'breaks': 253, 'moments': 1538, 'goes': 1010, 'held': 1116, 'jeeps': 1253, 'canvas': 317, 'gulp': 1054, 'frantic': 937, 'unclip': 2636, 'seatbelt': 2079, 'jammed': 1245, 'chucked': 392, 'drifting': 697, 'disappears': 647, 'red': 1935, 'halo': 1071, 'growing': 1043, 'bigger': 184, 'blood': 208, 'pauses': 1723, 'maries': 1455, 'blank': 196, 'dead': 588, 'realizing': 1924, 'pick': 1756, 'briefcase': 260, 'telephoto': 2492, 'lens': 1356, 'teddyradio': 2486, 'vo': 2700, 'seller': 2093, 'arrived': 91, 'berlin': 180, 'chinese': 383, 'restaurant': 1966, 'squarely': 2312, 'seen': 2088, 'enters': 760, 'stark': 2335, 'men': 1489, 'cross': 545, 'square': 2310, 'vic': 2686, 'steelass': 2354, 'intel': 1220, 'operator': 1655, 'carries': 332, 'large': 1330, 'samples': 2037, 'case': 337, 'mike': 1509, 'younger': 2843, 'exnavyseal': 786, 'hub': 1169, 'secure': 2083, 'anonymous': 68, 'space': 2274, 'city': 400, 'shades': 2118, 'drawn': 693, 'cabled': 301, 'stale': 2325, 'improvised': 1203, 'feel': 833, 'temporary': 2498, 'outpost': 1664, 'room': 2014, 'pamela': 1687, 'landy': 1322, 'senior': 2097, 'cia': 395, 'counterintelligence': 516, 'officer': 1633, 'hovering': 1165, 'communications': 455, 'console': 487, 'cronin': 543, 'pamelas': 1689, 'early': 725, 'forties': 932, 'stonecold': 2365, 'facade': 796, 'quarterbacking': 1878, 'operation': 1653, 'radio': 1893, 'kurt': 1312, 'kim': 1289, 'techs': 2484, 'headphones': 1101, 'ruggedized': 2017, 'laptops': 1329, 'comm': 450, 'spread': 2301, 'survey': 2434, 'teddy': 2485, 'military': 1511, 'rig': 1986, 'mobile': 1527, 'motion': 1548, 'shake': 2121, 'tired': 2549, 'coworkers': 526, 'parting': 1704, 'ways': 2747, 'walking': 2720, 'entering': 759, 'doors': 684, 'smiling': 2242, 'approached': 79, 'shift': 2139, 'security': 2085, 'hear': 1107, 'mikeradio': 1510, 'sleeve': 2222, 'earpiece': 726, 'escort': 767, 'command': 451, 'post': 1812, 'works': 2811, 'board': 219, 'teams': 2478, 'listen': 1381, 'final': 854, 'green': 1031, 'listening': 1382, 'word': 2804, 'raises': 1901, 'langley': 1326, 'patched': 1718, 'surprised': 2431, 'martin': 1461, 'mandarins': 1448, 'sit': 2201, 'round': 2016, 'marshall': 1460, 'deputy': 611, 'vicedirector': 2687, 'charge': 367, 'tense': 2501, 'donnie': 679, 'jack': 1241, 'weller': 2758, 'understand': 2638, 'using': 2668, 'allocation': 54, 'buy': 292, 'lot': 1415, 'money': 1540, 'pam': 1686, 'raw': 1910, 'unprocessed': 2649, 'kgb': 1280, 'files': 849, 'comparison': 459, 'shop': 2151, 'thief': 2518, 'mole': 1535, 'vetted': 2683, 'source': 2272, 'marty': 1462, 'does': 671, 'list': 1380, 'suspects': 2436, 'bargain': 144, 'times': 2544, 'price': 1829, 'mandarin': 1447, 'quality': 1876, 'issue': 1236, 'yes': 2837, 'total': 2562, 'agreement': 40, 'theyre': 2516, 'fakes': 810, 'expensive': 787, 'furious': 956, 'impatient': 1200, 'gentlemen': 980, 'ive': 1240, 'site': 2202, 'play': 1784, 'honestly': 1151, 'talk': 2466, 'mandarians': 1446, 'convinced': 500, 'opportunity': 1656, 'wash': 2736, 'game': 963, 'puts': 1874, 'nodding': 1606, 'croninradio': 544, 'repeat': 1957, 'passed': 1709, 'muster': 1567, 'elevator': 741, 'vicradio': 2688, 'waits': 2714, 'small': 2237, 'wiring': 2794, 'infrastructure': 1214, 'lit': 1384, 'glare': 1000, 'someones': 2264, 'maglight': 1436, 'gloved': 1005, 'racks': 1892, 'electrical': 739, 'risers': 1997, 'carefully': 329, 'explosive': 790, 'device': 625, 'pack': 1675, 'cigarettes': 397, 'riser': 1996, 'second': 2081, 'ones': 1646, 'special': 2282, 'taken': 2463, 'plastic': 1781, 'mounted': 1551, 'floor': 897, 'subpanel': 2406, 'hold': 1143, 'piece': 1759, 'tape': 2469, 'transferring': 2583, 'pressing': 1827, 'button': 290, 'close': 425, 'rises': 1998, 'bracing': 246, 'door': 681, 'ivan': 1238, 'russian': 2027, 'outside': 1665, 'darkened': 578, 'hallway': 1070, 'holding': 1144, 'flips': 893, 'million': 1512, 'dollars': 675, 'suite': 2416, 'offices': 1634, 'clean': 403, 'caspiexpetroleum': 340, 'cherbourg': 379, 'moscow': 1546, 'rome': 2009, 'tehran': 2490, 'curtains': 562, 'lights': 1368, 'sitting': 2204, 'counting': 517, 'poring': 1806, 'document': 667, 'dozens': 691, 'sheets': 2134, 'financial': 856, 'data': 582, 'incomprehensibly': 1208, 'cyrillic': 568, 'marked': 1456, 'judging': 1265, 'seals': 2074, 'clearance': 406, 'sign': 2178, 'offs': 1637, 'topsecret': 2557, 'tinny': 2546, 'pop': 1805, 'tune': 2620, 'started': 2337, 'playing': 1786, 'hall': 1069, 'said': 2033, 'doublecrossed': 687, 'ankle': 67, 'shut': 2170, 'freaked': 938, 'feet': 835, 'pushing': 1873, 'rushes': 2025, 'past': 1716, 'sample': 2036, 'spilling': 2290, 'snapph': 2248, 'suppressed': 2427, 'caliber': 305, 'shots': 2155, 'falls': 815, 'crashing': 532, 'bullets': 276, 'tear': 2479, 'hit': 1139, 'unscrewing': 2652, 'silencer': 2184, 'tucking': 2619, 'weapon': 2748, 'whats': 2770, 'climbing': 419, 'duffel': 719, 'stuffing': 2398, 'ivans': 1239, 'file': 847, 'backpack': 122, 'remove': 1952, 'single': 2193, 'sheet': 2133, 'paper': 1694, 'exactly': 778, 'stuff': 2397, 'tucked': 2618, 'page': 1682, 'blur': 216, 'slipping': 2229, 'underneath': 2637, 'tossing': 2561, 'fell': 836, 'struggle': 2392, 'detonation': 624, 'decives': 599, 'blows': 213, 'tidy': 2538, 'selfcontained': 2091, 'explosion': 789, 'flicker': 886, 'fail': 805, 'cast': 341, 'darkness': 579, 'sudden': 2411, 'urgent': 2662, 'power': 1818, 'went': 2759, 'whiff': 2774, 'dread': 694, 'location': 1392, 'voices': 2703, 'piling': 1762, 'confusion': 478, 'cascading': 336, 'ab': 1, 'drone': 708, 'barn': 146, 'stepping': 2357, 'carrying': 333, 'gretkov': 1033, 'professional': 1842, 'trim': 2601, 'polished': 1802, 'dominant': 677, 'complaining': 460, 'bring': 264, 'tosses': 2560, 'photocopy': 1752, 'doing': 673, 'stripping': 2385, 'shower': 2164, 'long': 1403, 'plane': 1779, 'dumping': 721, 'sheds': 2132, 'clothes': 431, 'workmen': 2810, 'cluster': 435, 'cable': 300, 'winches': 2786, 'raised': 1900, 'pours': 1816, 'crime': 539, 'police': 1801, 'workers': 2808, 'media': 1479, 'vans': 2673, 'clogging': 423, 'mood': 1543, 'black': 190, 'ashes': 96, 'need': 1582, 'working': 2809, 'stands': 2330, 'silent': 2186, 'staring': 2334, 'disaster': 649, 'heartbroken': 1112, 'footlocker': 917, 'stash': 2340, 'setting': 2108, 'aside': 97, 'work': 2806, 'things': 2520, 'needs': 1586, 'separate': 2103, 'pile': 1761, 'phony': 1750, 'student': 2394, 'ids': 1188, 'loose': 1411, 'photos': 1754, 'hairdos': 1066, 'vacuumpacked': 2671, 'bags': 129, 'shoes': 2147, 'gasolinestoked': 967, 'burning': 283, 'rocklined': 2006, 'pit': 1770, 'feeding': 832, 'papers': 1695, 'belongings': 174, 'crinkles': 540, 'reveal': 1973, 'photo': 1751, 'burn': 282, 'gassoaked': 969, 'holds': 1145, 'flames': 876, 'rules': 2018, 'say': 2045, 'drop': 709, 'sticks': 2360, 'hefting': 1115, 'strides': 2382, 'covered': 524, 'xeroxed': 2829, 'paperwork': 1696, 'showandtell': 2162, 'charges': 368, 'placed': 1773, 'lines': 1376, 'failed': 806, 'fingerprint': 861, 'didnt': 633, ...} 123# Mapping: 단어 &lt;-&gt; 벡터안의 index no. invert_index_vectorizer = {v: k for k, v in vect.vocabulary_.items()} # value : keyprint(str(invert_index_vectorizer)[:100]+'...') {1898: 'raining', 1366: 'light', 2387: 'strobes', 2763: 'wet', 1001: 'glass', 1978: 'rhythmic', 1673... (3) 중요 단어 추출 - Top 3 TF-IDF 먼저 TF-IDF Matrix 첫번째 행 (첫 씬)의 Top 3 단어의 index을 출력해보겠습니다. 1np.argsort(tf_idf_vect[0].toarray())[0][-3:] array([1984, 2387, 1978], dtype=int64) 즉 단어 벡터중의 1984번(0.2902), 2387번(0.3109), 1978번째(0.3109) 단어가 첫 씬에서 제일 중요한 단어로 뽑혔습니다. 이제 전체 TF-IDF matrix 에 적용해볼게요. 1np.argsort(tf_idf_vect.toarray())[:, -3:] array([[1984, 2387, 1978], [1297, 1971, 1097], [1693, 2221, 968], [ 690, 299, 1482], [2823, 1951, 1454], [2218, 2815, 1454], [2038, 737, 2418], [ 852, 2761, 2570], [2022, 156, 1352], [2250, 2241, 1454], [ 342, 321, 2188], [ 614, 1557, 1534], [ 535, 1884, 1614], [2188, 139, 20], [ 503, 730, 1458], [2790, 2384, 724], [ 169, 915, 2444], [1905, 1259, 53], [2566, 1335, 828], [2300, 281, 1702], [2503, 1502, 2567], [ 794, 1454, 1018], [ 698, 2559, 1252], [1871, 237, 1454], [ 204, 911, 2591], [ 237, 596, 1454], [ 52, 941, 1036], [ 211, 1156, 206], [1193, 2712, 1454], [ 52, 1809, 2462], [ 237, 1454, 702], [2130, 237, 1454], [1995, 1890, 321], [1011, 259, 1454], [1985, 2216, 1819], [ 420, 2276, 1454], [2019, 1103, 2059], [2177, 353, 1252], [1642, 1291, 2797], [1454, 1012, 2439], [2000, 2429, 2051], [2111, 1559, 2661], [1737, 1291, 2429], [1116, 2079, 46], [2634, 697, 392], [1723, 1015, 1071], [1443, 2700, 2486], [ 332, 2354, 786], [1165, 543, 975], [1169, 2434, 1986], [1509, 2486, 2335], [1001, 2686, 1509], [1289, 854, 219], [2758, 1687, 1460], [ 544, 1031, 854], [2686, 741, 726], [ 790, 625, 2794], [ 955, 367, 2583], [ 337, 1238, 2686], [ 340, 1634, 2490], [1238, 2248, 2686], [ 624, 789, 2538], [ 579, 341, 805], [ 543, 270, 577], [ 68, 146, 708], [1291, 1100, 1069], [ 162, 1291, 1033], [ 300, 2786, 1900], [ 543, 1687, 2380], [ 431, 782, 917], [2006, 128, 1751], [1687, 543, 2485], [ 552, 1866, 235], [2695, 762, 1102], [ 265, 2641, 56], [ 612, 1691, 441], [1654, 692, 1363], [2136, 243, 1688], [ 7, 2848, 6], [2596, 1687, 4], [2635, 1483, 841], [ 653, 2650, 1882], [1687, 481, 4], [1715, 1198, 1633], [2219, 2482, 169], [1541, 2423, 538], [ 322, 1633, 1198], [1460, 4, 414], [1307, 270, 1593], [1407, 1687, 543], [ 237, 491, 1593], [ 792, 348, 2665], [1055, 1747, 1593], [2010, 1868, 1403], [ 80, 2415, 2611], [2361, 1747, 1593], [1687, 1594, 1688], [1310, 1593, 143], [2825, 1688, 1594], [1460, 4, 1687], [ 4, 508, 2848], [1745, 983, 1612], [ 180, 491, 1690], [1496, 132, 1600], [1687, 1105, 1600], [2849, 2211, 2378], [ 173, 1687, 1600], [1757, 2379, 652], [2368, 2086, 1609], [ 4, 1312, 1572], [1725, 1863, 1418], [1873, 1274, 270], [1291, 2718, 683], [ 108, 1033, 2421], [1104, 650, 382], [ 491, 237, 1248], [2768, 1561, 1247], [ 939, 237, 1248], [1561, 2008, 1721], [ 883, 623, 1248], [ 944, 1561, 1246], [ 855, 1248, 1055], [ 458, 1914, 1250], [ 930, 966, 2550], [2380, 2516, 2625], [ 670, 228, 81], [2660, 1780, 902], [2371, 2553, 2515], [1716, 706, 93], [ 926, 780, 2848], [1585, 659, 1118], [1967, 1180, 208], [1992, 268, 2741], [ 237, 1521, 2377], [2178, 2003, 1296], [ 608, 2504, 970], [2849, 237, 706], [1655, 1049, 2700], [1160, 1322, 2197], [2375, 2223, 1776], [2475, 725, 2381], [ 703, 258, 481], [2646, 2229, 467], [ 237, 1059, 2067], [1828, 1669, 2112], [ 741, 1390, 783], [1562, 2407, 543], [ 295, 1269, 1906], [2437, 771, 703], [1291, 2245, 260], [2368, 2008, 2437], [ 891, 1400, 1960], [ 62, 2185, 1676], [1465, 919, 241], [2658, 1358, 1582], [1091, 595, 1002], [ 738, 1424, 1600], [2726, 1600, 1687], [2451, 2787, 273], [ 4, 680, 1687], [ 755, 401, 155], [1593, 4, 1413], [ 607, 1600, 1817], [2329, 1144, 254], [ 80, 1601, 2582], [ 606, 1600, 2582], [1434, 630, 1381], [2551, 1350, 173], [ 727, 2137, 2702], [1931, 1600, 1307], [1692, 372, 1893], [1830, 237, 1600], [ 504, 2344, 606], [2408, 819, 763], [2623, 1342, 1228], [1033, 1319, 890], [ 521, 481, 293], [ 10, 826, 2586], [ 167, 237, 1600], [2014, 1687, 2137], [1700, 218, 2120], [1225, 2750, 942], [ 442, 2848, 4], [ 981, 258, 1918], [2323, 2355, 2848], [ 221, 4, 2848], [ 1, 0, 1160], [ 8, 2014, 411], [1984, 694, 1552], [1775, 2133, 829], [1441, 2053, 2205], [ 55, 275, 267], [1647, 1306, 2014], [2415, 2416, 878], [2780, 650, 1171], [2329, 673, 256], [ 833, 1111, 1813], [ 366, 543, 2485], [1896, 2495, 1196], [2604, 651, 1389], [1344, 1272, 882], [1558, 1517, 1590], [1697, 1661, 2192], [1444, 319, 2507], [2615, 2318, 255], [2746, 2477, 2441], [1730, 2014, 1988], [ 124, 133, 2435], [1439, 1712, 1700], [1282, 1137, 896], [2788, 1548, 152], [1659, 1340, 2015], [1486, 2441, 2011], [1555, 2767, 349], [ 204, 762, 784], [1894, 407, 2014], [ 796, 88, 2077], [2728, 2323, 2659], [1291, 2011, 1110], [ 577, 374, 2485], [2300, 1830, 11], [1160, 2485, 4], [1147, 2777, 954], [2284, 973, 823], [ 116, 1548, 2480], [2235, 334, 1721], [2207, 1801, 2000], [ 684, 1895, 2582], [2149, 1321, 1354], [1056, 580, 45], [2424, 1346, 145], [2159, 145, 2582], [ 752, 498, 2246], [2014, 1687, 543], [1687, 1590, 543], [1193, 1033, 4], [1333, 2234, 2082], [2230, 1291, 1033], [ 238, 870, 4], [ 543, 1687, 2485], [1372, 493, 91], [1396, 1970, 2341], [1301, 318, 2236], [1506, 791, 2577], [1687, 2460, 2485], [ 615, 230, 1800], [2537, 474, 2696], [1490, 1312, 543], [ 357, 237, 1454], [ 187, 2244, 2597], [ 543, 1687, 4], [ 741, 1999, 1201], [1685, 1747, 1033], [2588, 543, 1747], [1305, 1033, 4], [1938, 925, 924], [1305, 543, 2485], [1170, 1687, 4], [ 653, 728, 1782], [1266, 90, 817], [2626, 703, 2475], [1416, 1279, 2305], [2711, 703, 2475], [ 113, 1177, 1769], [1225, 2166, 820], [1272, 881, 297], [2638, 880, 674], [2129, 960, 1500], [ 351, 903, 774], [1731, 2240, 2446], [ 642, 2137, 2475], [2076, 1371, 369], [ 72, 703, 2475], [1915, 2070, 2475], [1546, 334, 2480], [ 707, 1913, 1989], [2215, 872, 2669], [1999, 488, 1182], [1291, 508, 2208], [2367, 1361, 2286], [ 918, 1670, 179], [2215, 1713, 1670], [1649, 2831, 1142], [1768, 1268, 1361], [ 434, 137, 2535], [2081, 181, 2140], [1867, 664, 1219], [1344, 1056, 1546], [1556, 197, 1123], [1077, 1546, 709], [2086, 2390, 89], [1175, 160, 1176], [1057, 1315, 1088], [1110, 1260, 454], [1546, 2022, 1457], [1127, 1045, 2085], [ 630, 2304, 533], [1019, 280, 1453], [1291, 2304, 2327], [2469, 716, 233], [ 549, 884, 844], [2701, 493, 2449], [ 237, 295, 296], [ 754, 327, 1729], [1683, 702, 466], [1061, 1316, 714], [ 334, 1987, 1801], [2622, 1291, 295], [ 237, 1407, 51], [ 654, 1636, 2453], [1155, 2569, 1737], [1037, 1494, 2488], [ 419, 887, 1271], [1277, 676, 661], [ 555, 237, 1232], [ 445, 177, 1560], [ 237, 51, 1687], [1600, 1621, 2102], [ 162, 1566, 1864], [ 46, 803, 646]], dtype=int64) 이를 변수로 저장해서 원본 데이터셋에 추가하면 다음와 같습니다. 123top_3_words = np.argsort(tf_idf_vect.toarray())[:, -3:]df['important_word_index'] = pd.Series(top_3_words.tolist())df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } page_no scene_title text processed_text important_word_index 0 1 1 EXT. MERCEDES WINDSHIELD -- DUSK 1 It's raining... ... its raining light strobes across the wet glas... [1984, 2387, 1978] 1 1 A1 INT. MERCEDES -- NIGHT A1 On his knee -- a syringe an... a on his knee a syringe and a gun the eyes of... [1297, 1971, 1097] 2 1 2 INT. COTTAGE BEDROOM -- NIGHT 2 BOURNE'S EYES OPEN! -- panic... bournes eyes open panicked gasping trying to ... [1693, 2221, 968] 3 1 A2 INT. COTTAGE LIVING AREA/BATHROOM ... A2 BOURNE moving for the medic... a bourne moving for the medicine cabinet digs... [690, 299, 1482] 4 2 3 INT./EXT. COTTAGE LIVING ROOM/VERA... 3 One minute later. BOURNE mo... one minute later bourne moves out onto the ve... [2823, 1951, 1454] 하지만 지금 중요한 단어의 index만 표시 되고, 과연 어떤 단어인지를 모릅니다. 그래서 우리는 방금 추출한 “벡터”-“단어” Mapping 결과를 이용해 index에 해당하는 단어들을 추출하여 데이터셋에 저장하겠습니다. 1234567# index -&gt; word 변환함수 만들기def convert_to_word(x): word_list = [] for index in x: word_list.append(invert_index_vectorizer[index]) return word_list 12df['important_words'] = df['important_word_index'].apply(lambda x: convert_to_word(x))df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } page_no scene_title text processed_text important_word_index important_words 0 1 1 EXT. MERCEDES WINDSHIELD -- DUSK 1 It's raining... ... its raining light strobes across the wet glas... [1984, 2387, 1978] [riding, strobes, rhythmic] 1 1 A1 INT. MERCEDES -- NIGHT A1 On his knee -- a syringe an... a on his knee a syringe and a gun the eyes of... [1297, 1971, 1097] [knee, returns, head] 2 1 2 INT. COTTAGE BEDROOM -- NIGHT 2 BOURNE'S EYES OPEN! -- panic... bournes eyes open panicked gasping trying to ... [1693, 2221, 968] [panicked, sleeps, gasping] 3 1 A2 INT. COTTAGE LIVING AREA/BATHROOM ... A2 BOURNE moving for the medic... a bourne moving for the medicine cabinet digs... [690, 299, 1482] [downs, cabinet, medicine] 4 2 3 INT./EXT. COTTAGE LIVING ROOM/VERA... 3 One minute later. BOURNE mo... one minute later bourne moves out onto the ve... [2823, 1951, 1454] [write, remember, marie] 이제 장면별 중요한 단어 Top 3가 모두 출력됐습니다. document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Text Mining","slug":"Text-Mining","permalink":"https://hyemin-kim.github.io/tags/Text-Mining/"}]},{"title":"Python >> 텍스트 마이닝 (Text Mining) 소개","slug":"S-Python-TextMining1","date":"2020-08-19T11:10:26.000Z","updated":"2020-08-20T13:13:27.283Z","comments":true,"path":"2020/08/19/S-Python-TextMining1/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/19/S-Python-TextMining1/","excerpt":"","text":"텍스트 마이닝 (Text Mining) 소개 1. 텍스트 마이닝의 개념 2. 텍스트 마이닝 응용분야 3. 텍스트 데이터의 처리 방법 3-1. BoW (Bag of Words) 3-2. 문서 단어 행렬 (Document-Term Matrix, DTM) 3-3. 단어의 중요도를 계산하는 방법 (TF-IDF) 1. 텍스트 마이닝의 개념 텍스트 마이닝은 비정형 및 반정형 텍스트 데이터에 대하여 자연어 처리(Natural Langrage Precessing) 기술과 문서 처리 기술을 적용하여 가치와 의미가 있는 정보를 찾아내는(Mining) 기술입니다. 2. 텍스트 마이닝 응용분야 단어의 빈도수 기반 Word Cloud: 텍스트 데이터에서의 단어 등장 빈도수 시각화 문서 분류: 감성 분류 Topic Modeling: 텍스트 데이터를 분석하여 여러 Topic으로 Clustering 하는 직업 단어의 의미 기반 Semantic Analysis: 사람처럼 자연어를 이해하기 3. 텍스트 데이터의 처리 방법 3-1. BoW (Bag of Words) 단어 가방(Bag of Words) 모델은 문장의 문법 및 단어 순서를 무시하고 텍스트 문서를 \"단어\"로 변환한 후 다양한 측정 값을 계산할 수 있도록 \"가방\"형식으로 저장해놓는 겁니다. 단어 가방 모델에서 계산 된 가장 일반적인 유형의 특성 또는 기능은 용어 빈도, 즉 용어가 텍스트에 나타나는 횟수입니다. 《기생충》중의 한 대사로 예를 들어 볼게요. 이 문장에서 “그”, “을”, \"듯\"와 같이 실질적인 의미가 없는 \"불용어\"를 제외하고 의미 있는 “형태소” 단어와 해당 형태소의 등장 횟수을 추출합니다. 그럼 다음과 같은 표로 요약할 수 있겠습니다. 이것이 바로 \"Bag of Words 모델\"입니다. 3-2. 문서 단어 행렬 (Document-Term Matrix, DTM) 위에 설명드린 Bag of Words는 한 문장에 대해 적용하는 것이고, 문장이 여러 개가 있을 때는 (DataFrame 형태) 문서 단어 행렬 (Document-Term Matrix) 로 표현됩니다. 똑같이 《기생충》중의 대사들로 예를 들어 볼게요. 이처럼 여러 문장의 경우에 \"문서 단어 행렬\"은 위와 같이 표현 됩니다. 3-3. 단어의 중요도를 계산하는 방법 (TF-IDF) 문서 단어 행렬은 그저 단어의 등장 횟수를 단순히 세는 겁니다. 각 문장에서 어떤 단어가 중요한지 알 수 없습니다. 이를 알아내기 위해 우리는 “TF-IDF (Term Frequency-Inverse Document Frequency)” 라는 지표를 사용합니다. TF (Term Frequency): 특정 문서에서 특정 단어의 등장 횟수 DF (Document Frequency): 특정 단어가 등장한 문서의 수 IDF (Inverse Document Frequency): DF와 반비례 값을 가지는 수식 IDF(d,t)=ln⁡(n1+DF(t))IDF(d,t) = \\ln ( \\frac{n}{1+DF(t)} )IDF(d,t)=ln(1+DF(t)n​) TF-IDF (Term Frequency-Inverse Document Frequency): TF와 IDF를 곱한 값 TF-IDF로 특정 문서 안의 특정 단어의 중요도를 나타나는 원리는: 특정 문서에서는 많이 등장했으면서 다른 문서에서 잘 등장하지 않은 단어가 결국 이 문서에서 가장 중요한 단어가 될것이다라는 가설입니다. [예] 문서1에서 \"아들\"와 “계획” 이 두 단어의 TF-IDF를 한번 계산해봅시다. Step 1. TF A: 1 B: 1 Step 2. DF A: 1 B: 3 Step 3. IDF A: ln⁡(41+1)=ln⁡2≈0.6931\\ln( \\frac{4}{1+1} ) = \\ln 2 \\approx 0.6931ln(1+14​)=ln2≈0.6931 B: ln⁡(41+3)=0\\ln( \\frac{4}{1+3} ) = 0ln(1+34​)=0 Step 4. TF-IDF A: 1 * 0.6931 = 0.6931 B: 1 * 0 = 0 혜석: \"계획\"이라는 단어가 《기생충》의 문장들에서 너무 많이 등장해서 문서1에서 특별히 중요한 단어라고 볼 수 없다. 하지만 \"아들\"이라는 단어가 다른 문장에서 한번도 나타나지 않았기 때문에 문장1에서는 매우 중요하다고 볼 수 있다 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Text Mining","slug":"Text-Mining","permalink":"https://hyemin-kim.github.io/tags/Text-Mining/"}]},{"title":"【실습】 Python >> Classification -- 포켓몬 데이터셋","slug":"E-Python-Classification-1","date":"2020-08-13T14:00:08.000Z","updated":"2020-08-29T09:31:46.360Z","comments":true,"path":"2020/08/13/E-Python-Classification-1/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/13/E-Python-Classification-1/","excerpt":"","text":"【Classification 실습】 – 포켓몬 데이터셋 0. 개요 1. Library &amp; Data Import 2. EDA (Exploratoty Data Analysis: 탐색적 데이터 분석) 2-1. 데이터셋 기본 정보 탐색 2-2. 변수(Feature) 특징 탐색 (1) 각 능력치 분포 (2) 총 능력치 (Total) 분포 (3) 포켓몬 타입 (Type 1 &amp; Type 2) 분포 (4) 포켓몬 세대(Generation) 분포 3. 지도 학습 기반 분류 분석 – Logistic Regression 3-1. 데이터 전처리 (1) 데이터 타입 변경 (2) One-Hot Encoding (3) Feature 포준화 (4) Training set / Test set 나누기 3-2. Logistic Regression 모델 학습 (1) 모델 학습 (2) 모델 평가 3-3. 클래스 불균형 조정 4. 비지도 학습 기반 군집 분류 분석 – K-Means Clustering 4-1. K-Means 군집 분류 (1) 2차원 군집 분석 (2) 다차원 군집 분석 0. 개요 포켓몬 데이터셋을 이용해 분류 분석을 진행합니다. 지도 학습 (Logistic Regression): “전설의 포켓몬” 여부 예측 – “Legendary” = 0/1 비지도 학습 (K-Means Clustering): 포켓몬 분류 1. Library &amp; Data Import &gt;&gt; 사용할 Library 123456789%matplotlib inlineimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport warningswarnings.filterwarnings(\"ignore\") 1plt.rcParams['font.family'] = 'Malgun Gothic' # 한글 깨짐 방지 1plt.rcParams['figure.figsize'] = (10, 8) # figsize 설정 &gt;&gt; 사용할 데이터셋 - Pokemon Dataset 1df = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/Pokemon.csv\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } # Name Type 1 Type 2 Total HP Attack Defense Sp. Atk Sp. Def Speed Generation Legendary 0 1 Bulbasaur Grass Poison 318 45 49 49 65 65 45 1 False 1 2 Ivysaur Grass Poison 405 60 62 63 80 80 60 1 False 2 3 Venusaur Grass Poison 525 80 82 83 100 100 80 1 False 3 3 VenusaurMega Venusaur Grass Poison 625 80 100 123 122 120 80 1 False 4 4 Charmander Fire NaN 309 39 52 43 60 50 65 1 False &gt;&gt; Feature Description Name: 포켓몬 이름 Type 1: 포켓몬 타입 1 Type 2: 포켓몬 타입 2 Total: 포켓몬 총 능력치 (Sum of ‘HP’, ‘Attack’, ‘Defense’, ‘Sp.Atk’, ‘Sp.Def’ and ‘Speed’) HP: 포켓몬 HP 능력치 Attack: 포켓몬 Attack 능력치 Defense: 포켓몬 Defense 능력치 Sp.Atk: 포켓몬 Sp.Atk 능력치 Sp.Def: 포켓몬 Sp.Def 능력치 Speed: 포켓몬 Speed 능력치 Generation: 포켓몬 세대 Legendary: 전설의 포켓몬 여부 2. EDA (Exploratoty Data Analysis: 탐색적 데이터 분석) 12# 그래프 배경 설정sns.set_style('darkgrid') 2-1. 데이터셋 기본 정보 탐색 &gt;&gt; 전체 데이터셋 12# demensiondf.shape (800, 13) 12# information (data type)df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 800 entries, 0 to 799 Data columns (total 13 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 # 800 non-null int64 1 Name 800 non-null object 2 Type 1 800 non-null object 3 Type 2 414 non-null object 4 Total 800 non-null int64 5 HP 800 non-null int64 6 Attack 800 non-null int64 7 Defense 800 non-null int64 8 Sp. Atk 800 non-null int64 9 Sp. Def 800 non-null int64 10 Speed 800 non-null int64 11 Generation 800 non-null int64 12 Legendary 800 non-null bool dtypes: bool(1), int64(9), object(3) memory usage: 75.9+ KB 12# 결측치df.isnull().sum() # 0 Name 0 Type 1 0 Type 2 386 Total 0 HP 0 Attack 0 Defense 0 Sp. Atk 0 Sp. Def 0 Speed 0 Generation 0 Legendary 0 dtype: int64 &gt;&gt; 개별 Feature 탐색 분류할 목표 Feature: “Legendary” (전설의 포켓몬 여부) 12# class 별 데이터 수 확인df['Legendary'].value_counts() False 735 True 65 Name: Legendary, dtype: int64 “Generation” (포켓몬 세대) 12# 세대별 데이터 수 확인df['Generation'].value_counts() 1 166 5 165 3 160 4 121 2 106 6 82 Name: Generation, dtype: int64 12345# 세대 순서로 데이터 갯수 시각화fig = plt.figure(figsize=(8, 6))df['Generation'].value_counts().sort_index().plot()plt.title(\"'Generation 별 데이터 갯수'\")plt.show() “Type 1” &amp; “Type 2” (포켓몬 타입) 12# unique value of \"Type 1\"df['Type 1'].unique() array(['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Poison', 'Electric', 'Ground', 'Fairy', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Ice', 'Dragon', 'Dark', 'Steel', 'Flying'], dtype=object) 12# No. of unique value for \"Type 1\"len(df['Type 1'].unique()) 18 12# unique value of \"Type 2\" (exclude \"NaN\")df[df['Type 2'].notnull()]['Type 2'].unique() array(['Poison', 'Flying', 'Dragon', 'Ground', 'Fairy', 'Grass', 'Fighting', 'Psychic', 'Steel', 'Ice', 'Rock', 'Dark', 'Water', 'Electric', 'Fire', 'Ghost', 'Bug', 'Normal'], dtype=object) 12# No. of unique value for \"Type 2\"len(df[df['Type 2'].notnull()]['Type 2'].unique()) 18 2-2. 변수(Feature) 특징 탐색 각 변수(Feature)의 분포를 관찰함으로써, 변수들의 특징을 알아보도록 하겠습니다. 특히, 저희가 분류할 목표 Feature가 \"Legendary\"이므로, 각 변수의 분포를 탐색 시: 각 항목(feature)에서 전체 데이터의 분포 뿐만 아닌 \"Legendary\"변수 class 별의 데이터 분포도 함께 살펴볼게요. GUIDE 【전체 데이터 탐색】 &amp; 【“Legendary” class별 탐색】 각 능력치 분포 총 능력치 (Toal) 분포 포켓몬 타입 (Type 1 &amp; Type 2) 분포 포켓몬 세대 (Generation) 분포 (1) 각 능력치 분포 123456# 전체 포켓몬의 각 능력치 분포stats = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed'] # 능력치 변수 집합sns.boxplot(data = df[stats])plt.title('각 능력치 분포')plt.show() 12345678910111213# \"전설의 포켓몬\" 여부에 따른 능력치 분포fig = plt.figure(figsize=(16, 8))plt.subplot(1,2,1)sns.boxplot(data = df[df['Legendary']==1][stats])plt.title('Legendary = True')plt.subplot(1,2,2)sns.boxplot(data = df[df['Legendary']==0][stats])plt.title('Legendary = False')plt.show() \"전설의 포켓몬\"은 전체적으로 더 높은 능력치를 보유하고 있으며, Attack와 Sp.Atk가 특히 높은 것으로 보입니다. (2) 총 능력치 (Total) 분포 12345# 전체 포켓몬의 총 능력치 분포df['Total'].hist(bins=50)plt.title('총 능력치 (Total) 분포')plt.show() 1234# 세대별 총 능력치 분포sns.boxplot(data = df, x = \"Generation\", y=\"Total\")plt.title(\"세대별 총 능력치 분포\")plt.show() 1234# 각 세대 \"전설의 포켓몬\" 여부에 따른 총 능력치 분포sns.boxplot(data = df, x = \"Generation\", y=\"Total\", hue=\"Legendary\")plt.title(\"각 세대 '전설의 포켓몬' 여부에 따른 총 능력치 분포\")plt.show() 1234# 타입(Type 1)별 총 능력치 분포sns.boxplot(data = df, x = 'Type 1', y = 'Total')plt.title(\"타입(Type 1)별 총 능력치 분포\")plt.show() (3) 포켓몬 타입 (Type 1 &amp; Type 2) 분포 123# 전체 포켓몬 -- Type 1 분포df['Type 1'].value_counts(sort=False).sort_index().plot.barh() &lt;matplotlib.axes._subplots.AxesSubplot at 0x2e92fab51c8&gt; 12345678# \"전설의 포켓몬\" 여부에 따른 Type 1 분포T1_Total = pd.DataFrame(df['Type 1'].value_counts().sort_index())T1_NotLeg = pd.DataFrame(df[df['Legendary']==0].groupby('Type 1').size())T1_count = pd.concat([T1_Total, T1_NotLeg], axis = 1)T1_count.columns = ['Total', 'Not Legend']T1_count['Legend'] = T1_count['Total'] - T1_count['Not Legend']T1_count .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total Not Legend Legend Type 1 Bug 69 69 0 Dark 31 29 2 Dragon 32 20 12 Electric 44 40 4 Fairy 17 16 1 Fighting 27 27 0 Fire 52 47 5 Flying 4 2 2 Ghost 32 30 2 Grass 70 67 3 Ground 32 28 4 Ice 24 22 2 Normal 98 96 2 Poison 28 28 0 Psychic 57 43 14 Rock 44 40 4 Steel 27 23 4 Water 112 108 4 1T1_count[['Not Legend', 'Legend']].plot.barh(width=0.7) &lt;matplotlib.axes._subplots.AxesSubplot at 0x2e92ff18b88&gt; 123456# 전체 포켓몬 -- Type 2 분포df['Type 2'].value_counts(sort=False).sort_index().plot.barh()plt.title('\"전설의 포켓몬\" 여부에 따른 Type 1 분포')plt.show() 12345678# \"전설의 포켓몬\" 여부에 따른 Type 2 분포T2_Total = pd.DataFrame(df['Type 2'].value_counts().sort_index())T2_NotLeg = pd.DataFrame(df[df['Legendary']==0].groupby('Type 2').size())T2_count = pd.concat([T2_Total, T2_NotLeg], axis = 1)T2_count.columns = ['Total', 'Not Legend']T2_count['Legend'] = T2_count['Total'] - T2_count['Not Legend']T2_count .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total Not Legend Legend Type 2 Bug 3 3 0 Dark 20 19 1 Dragon 18 14 4 Electric 6 5 1 Fairy 23 21 2 Fighting 26 22 4 Fire 12 9 3 Flying 97 84 13 Ghost 14 13 1 Grass 25 25 0 Ground 35 34 1 Ice 14 11 3 Normal 4 4 0 Poison 34 34 0 Psychic 33 28 5 Rock 14 14 0 Steel 22 21 1 Water 14 13 1 1234T2_count[['Not Legend', 'Legend']].plot.barh(width=0.7)plt.title('\"전설의 포켓몬\" 여부에 따른 Type 2 분포')plt.show() (4) 포켓몬 세대(Generation) 분포 123# 전체 포켓몬 -- 세대 분포df['Generation'].value_counts().sort_index().plot.bar() &lt;matplotlib.axes._subplots.AxesSubplot at 0x2e930887d08&gt; 1234567# \"전설의 포켓몬\" 여부에 따른 세대 분포gene_Leg = pd.DataFrame(df[df['Legendary']==1].groupby('Generation').size())gene_NotLeg = pd.DataFrame(df[df['Legendary']==0].groupby('Generation').size())gene_count = pd.concat([gene_Leg, gene_NotLeg], axis=1)gene_count.columns = ['Legend', 'Not Legend']gene_count .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Legend Not Legend Generation 1 6 160 2 5 101 3 18 142 4 13 108 5 15 150 6 8 74 123gene_count.plot.bar()plt.title('\"전설의 포켓몬\" 여부에 따른 세대 분포')plt.show() 3. 지도 학습 기반 분류 분석 – Logistic Regression 3-1. 데이터 전처리 (1) 데이터 타입 변경 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } # Name Type 1 Type 2 Total HP Attack Defense Sp. Atk Sp. Def Speed Generation Legendary 0 1 Bulbasaur Grass Poison 318 45 49 49 65 65 45 1 False 1 2 Ivysaur Grass Poison 405 60 62 63 80 80 60 1 False 2 3 Venusaur Grass Poison 525 80 82 83 100 100 80 1 False 3 3 VenusaurMega Venusaur Grass Poison 625 80 100 123 122 120 80 1 False 4 4 Charmander Fire NaN 309 39 52 43 60 50 65 1 False 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 800 entries, 0 to 799 Data columns (total 13 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 # 800 non-null int64 1 Name 800 non-null object 2 Type 1 800 non-null object 3 Type 2 414 non-null object 4 Total 800 non-null int64 5 HP 800 non-null int64 6 Attack 800 non-null int64 7 Defense 800 non-null int64 8 Sp. Atk 800 non-null int64 9 Sp. Def 800 non-null int64 10 Speed 800 non-null int64 11 Generation 800 non-null int64 12 Legendary 800 non-null bool dtypes: bool(1), int64(9), object(3) memory usage: 75.9+ KB 분류예측 목표 Feature인 \"Lengendary\"의 값은 현재 “True”/\"False\"로 구성되어있습니다. 예측 모델에 적용하기 위해 “1”/\"0\"으로 바꾸겠습니다. 포켓몬의 세대를 나타나는 Feature인 \"Generation\"의 타입은 지금 \"int\"로 되어있지만, Feature의 의미상 해당 숫자는 분류 역할을 하고 있으므로 \"str\"타입으로 변환시키겠습니다. 분류 예측 시 이름 데이터가 예측에 도움이 없으므로 \"Name\"을 빼고 데이터셋을 제구성하겠습니다. 12345df['Legendary'] = df['Legendary'].astype(int)df['Generation'] = df['Generation'].astype(str)preprocessed_df = df[['Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation', 'Legendary']]preprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Type 1 Type 2 Total HP Attack Defense Sp. Atk Sp. Def Speed Generation Legendary 0 Grass Poison 318 45 49 49 65 65 45 1 0 1 Grass Poison 405 60 62 63 80 80 60 1 0 2 Grass Poison 525 80 82 83 100 100 80 1 0 3 Grass Poison 625 80 100 123 122 120 80 1 0 4 Fire NaN 309 39 52 43 60 50 65 1 0 (2) One-Hot Encoding Categorical Variable에 대해서 dummy화 작업을 진행하겠습니다. 1 data one-label: One-hot Encoding 1 data multi-label: Multi-label Encoding &gt;&gt; 타입 (Type) – Multi-label Encoding 먼저 Type 1과 Type 2를 하나의 변수(Type)로 묶는다. 그 다음 1~2개의 label를 가진 Type변수에 대해서 Multi-label Encoding을 진행한다. 12345678910# pokemon type list 생성def make_list(x1, x2): type_list = [] type_list.append(x1) if x2 is not np.nan: type_list.append(x2) return type_listpreprocessed_df['Type'] = preprocessed_df.apply(lambda x: make_list(x['Type 1'], x['Type 2']), axis=1)preprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Type 1 Type 2 Total HP Attack Defense Sp. Atk Sp. Def Speed Generation Legendary Type 0 Grass Poison 318 45 49 49 65 65 45 1 0 [Grass, Poison] 1 Grass Poison 405 60 62 63 80 80 60 1 0 [Grass, Poison] 2 Grass Poison 525 80 82 83 100 100 80 1 0 [Grass, Poison] 3 Grass Poison 625 80 100 123 122 120 80 1 0 [Grass, Poison] 4 Fire NaN 309 39 52 43 60 50 65 1 0 [Fire] 123del preprocessed_df['Type 1']del preprocessed_df['Type 2']preprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total HP Attack Defense Sp. Atk Sp. Def Speed Generation Legendary Type 0 318 45 49 49 65 65 45 1 0 [Grass, Poison] 1 405 60 62 63 80 80 60 1 0 [Grass, Poison] 2 525 80 82 83 100 100 80 1 0 [Grass, Poison] 3 625 80 100 123 122 120 80 1 0 [Grass, Poison] 4 309 39 52 43 60 50 65 1 0 [Fire] 123456# multi-lacel encodingfrom sklearn.preprocessing import MultiLabelBinarizerml = MultiLabelBinarizer()preprocessed_df = preprocessed_df.join(pd.DataFrame(ml.fit_transform(preprocessed_df.pop('Type')), columns = ml.classes_)) [pandas.DataFrame.join]: Join columns of another DataFrame [pandas.DataFrame.pop (item) ]: Return item and drop from frame 1preprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total HP Attack Defense Sp. Atk Sp. Def Speed Generation Legendary Bug ... Ghost Grass Ground Ice Normal Poison Psychic Rock Steel Water 0 318 45 49 49 65 65 45 1 0 0 ... 0 1 0 0 0 1 0 0 0 0 1 405 60 62 63 80 80 60 1 0 0 ... 0 1 0 0 0 1 0 0 0 0 2 525 80 82 83 100 100 80 1 0 0 ... 0 1 0 0 0 1 0 0 0 0 3 625 80 100 123 122 120 80 1 0 0 ... 0 1 0 0 0 1 0 0 0 0 4 309 39 52 43 60 50 65 1 0 0 ... 0 0 0 0 0 0 0 0 0 0 5 rows × 27 columns &gt;&gt; 세대 (Generation) – One-hot Encoding 1234# apply one-hot encoding to 'Generation'preprocessed_df = pd.get_dummies(preprocessed_df) # df name입력하면 str var를 자동 식별하여 encoding 진행함# preprocessed_ddf = pd.get_dummies(preprocessed_df['Generation']) # 작업할 var 지정preprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total HP Attack Defense Sp. Atk Sp. Def Speed Legendary Bug Dark ... Psychic Rock Steel Water Generation_1 Generation_2 Generation_3 Generation_4 Generation_5 Generation_6 0 318 45 49 49 65 65 45 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 1 405 60 62 63 80 80 60 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 2 525 80 82 83 100 100 80 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 3 625 80 100 123 122 120 80 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 4 309 39 52 43 60 50 65 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 5 rows × 32 columns (3) Feature 포준화 Numerical Feature간의 Scale차이를 없애기 위해 feature 표준화를 진행합니다. 1preprocessed_df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 800 entries, 0 to 799 Data columns (total 32 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Total 800 non-null int64 1 HP 800 non-null int64 2 Attack 800 non-null int64 3 Defense 800 non-null int64 4 Sp. Atk 800 non-null int64 5 Sp. Def 800 non-null int64 6 Speed 800 non-null int64 7 Legendary 800 non-null int32 8 Bug 800 non-null int32 9 Dark 800 non-null int32 10 Dragon 800 non-null int32 11 Electric 800 non-null int32 12 Fairy 800 non-null int32 13 Fighting 800 non-null int32 14 Fire 800 non-null int32 15 Flying 800 non-null int32 16 Ghost 800 non-null int32 17 Grass 800 non-null int32 18 Ground 800 non-null int32 19 Ice 800 non-null int32 20 Normal 800 non-null int32 21 Poison 800 non-null int32 22 Psychic 800 non-null int32 23 Rock 800 non-null int32 24 Steel 800 non-null int32 25 Water 800 non-null int32 26 Generation_1 800 non-null uint8 27 Generation_2 800 non-null uint8 28 Generation_3 800 non-null uint8 29 Generation_4 800 non-null uint8 30 Generation_5 800 non-null uint8 31 Generation_6 800 non-null uint8 dtypes: int32(19), int64(7), uint8(6) memory usage: 107.9 KB 1234567from sklearn.preprocessing import StandardScaler# feature standardizationscaler = StandardScaler()scale_columns = ['Total', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']preprocessed_df[scale_columns] = scaler.fit_transform(preprocessed_df[scale_columns])preprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total HP Attack Defense Sp. Atk Sp. Def Speed Legendary Bug Dark ... Psychic Rock Steel Water Generation_1 Generation_2 Generation_3 Generation_4 Generation_5 Generation_6 0 -0.976765 -0.950626 -0.924906 -0.797154 -0.239130 -0.248189 -0.801503 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 1 -0.251088 -0.362822 -0.524130 -0.347917 0.219560 0.291156 -0.285015 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 2 0.749845 0.420917 0.092448 0.293849 0.831146 1.010283 0.403635 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 3 1.583957 0.420917 0.647369 1.577381 1.503891 1.729409 0.403635 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 4 -1.051836 -1.185748 -0.832419 -0.989683 -0.392027 -0.787533 -0.112853 0 0 0 ... 0 0 0 0 1 0 0 0 0 0 5 rows × 32 columns (4) Training set / Test set 나누기 12345from sklearn.model_selection import train_test_splitX = preprocessed_df.loc[:, preprocessed_df.columns != 'Legendary']y = preprocessed_df['Legendary']x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1) 1x_train.shape, y_train.shape ((600, 31), (600,)) 1x_test.shape, y_test.shape ((200, 31), (200,)) 3-2. Logistic Regression 모델 학습 (1) 모델 학습 123456789from sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score# Fit in Training setlogit = LogisticRegression(random_state=0)logit.fit(x_train, y_train)# Predict in Test sety_pred = logit.predict(x_test) (2) 모델 평가 123456# classification result for test setprint(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred))print(\"Precision: %.3f\" % precision_score(y_test, y_pred))print(\"Recall: %.3f\" % recall_score(y_test, y_pred))print(\"F1: %.3f\" % f1_score(y_test, y_pred)) accuracy: 0.93 Precision: 0.615 Recall: 0.471 F1: 0.533 위 모델 평가 결과를 확인해보면, 해당 모델은 정확도(accuracy) 만 높고, 정밀도(Precision), 재현율(Recall), F1 score 등 모두 낮습니다. 이는 학습 데이터의 클래스 불균형으로 인한 정확도 함정 문제일 가능성이 높습니다. (참고: [Python &gt;&gt; sklearn - (2) 분류] 4-2. !!정확도 함정!!) 추가 확인을 위해 Confusion Matrix를 출력해 봅니다. 1np.set_printoptions(suppress=True) 123456789from sklearn.metrics import confusion_matrix# print confusion matrixconfu = confusion_matrix(y_true = y_test, y_pred = y_pred)plt.figure(figsize=(4, 3))sns.heatmap(confu, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')plt.title('Confusion Matrix')plt.show() Positive Condition ( “Legendary” = True/1 ) &lt;17&gt; 대비 Negative Condition ( “Legendary” = False/0 ) &lt;183&gt;인 케이스가 훨씬 많다는 것을 볼 수 있습니다. 따라서, 클래스 불균형으로 인한 정확도 함정 문제가 맞으며, 클래스 불균형을 조정한 후 다시 학습 시키도록 하겠습니다. 3-3. 클래스 불균형 조정 1preprocessed_df['Legendary'].value_counts() 0 735 1 65 Name: Legendary, dtype: int64 &gt;&gt; 1:1 샘플링 Positive Condition 케이스와 Negative Condition 케이스를 1:1비율로 샘플링 합니다. 12positive_random_idx = preprocessed_df[preprocessed_df['Legendary']==1].sample(65, random_state=12).index.tolist()negative_random_idx = preprocessed_df[preprocessed_df['Legendary']==0].sample(65, random_state=12).index.tolist() &gt;&gt; Training set / Test set 나누기 1234random_idx = positive_random_idx + negative_random_idxX = preprocessed_df.loc[random_idx, preprocessed_df.columns != 'Legendary']y = preprocessed_df['Legendary'][random_idx]x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1) 1x_train.shape, y_train.shape ((97, 31), (97,)) 1x_test.shape, y_test.shape ((33, 31), (33,)) &gt;&gt; 모델 재학습 123456# Fit in Training setlogit2 = LogisticRegression(random_state=0)logit2.fit(x_train, y_train)# Predict in Test sety_pred2 = logit2.predict(x_test) &gt;&gt; 모델 재평가 123456# clssification result for test setprint(\"accuracy: %.2f\" % accuracy_score(y_test, y_pred2))print(\"Precision: %.3f\" % precision_score(y_test, y_pred2))print(\"Recall: %.3f\" % recall_score(y_test, y_pred2))print(\"F1: %.3f\" % f1_score(y_test, y_pred2)) accuracy: 1.00 Precision: 1.000 Recall: 1.000 F1: 1.000 12345678# confusion matrixconfu2 = confusion_matrix(y_true=y_test, y_pred = y_pred2)plt.figure(figsize=(4, 3))sns.heatmap(confu2, annot=True, annot_kws={'size':15}, cmap='OrRd', fmt='.10g')plt.title('Confusion Matrix')plt.show() 클래스 불균형을 조정한 후, 새롭게 학습된 모델의 performance가 많이 좋아졌습니다. 4. 비지도 학습 기반 군집 분류 분석 – K-Means Clustering 4-1. K-Means 군집 분류 (1) 2차원 군집 분석 12345678910111213141516from sklearn.cluster import KMeans# K-means train &amp; Elbow methodX = preprocessed_df[['Attack', 'Defense']]k_list = []cost_list = []for k in range (1, 8): kmeans = KMeans(n_clusters=k).fit(X) interia = kmeans.inertia_ # inertia: Sum of squared distances of samples to their closest cluster center. print(\"k:\", k, \"| cost:\", interia) k_list.append(k) cost_list.append(interia)plt.figure(figsize=(8, 6))plt.plot(k_list, cost_list) k: 1 | cost: 1600.0 k: 2 | cost: 853.3477298974242 k: 3 | cost: 642.3911470107209 k: 4 | cost: 480.49450250321513 k: 5 | cost: 403.97191765107124 k: 6 | cost: 343.98696660525184 k: 7 | cost: 295.56093457429847 [&lt;matplotlib.lines.Line2D at 0x2e930467c48&gt;] 추세를 봤을 때, 4 clusters가 제일 적당한 것으로 보입니다. 따라서, cluster를 4로 지정한 후 다시 학습시킨 뒤, 각 데이터가 분류된 cluster 결과를 원 데이터셋에 추가합니다. 12345# k-means fitting and predictkmeans = KMeans(n_clusters=4).fit(X)cluster_num = pd.Series(kmeans.predict(X))preprocessed_df['cluster_num'] = cluster_num.valuespreprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total HP Attack Defense Sp. Atk Sp. Def Speed Legendary Bug Dark ... Rock Steel Water Generation_1 Generation_2 Generation_3 Generation_4 Generation_5 Generation_6 cluster_num 0 -0.976765 -0.950626 -0.924906 -0.797154 -0.239130 -0.248189 -0.801503 0 0 0 ... 0 0 0 1 0 0 0 0 0 0 1 -0.251088 -0.362822 -0.524130 -0.347917 0.219560 0.291156 -0.285015 0 0 0 ... 0 0 0 1 0 0 0 0 0 2 2 0.749845 0.420917 0.092448 0.293849 0.831146 1.010283 0.403635 0 0 0 ... 0 0 0 1 0 0 0 0 0 2 3 1.583957 0.420917 0.647369 1.577381 1.503891 1.729409 0.403635 0 0 0 ... 0 0 0 1 0 0 0 0 0 1 4 -1.051836 -1.185748 -0.832419 -0.989683 -0.392027 -0.787533 -0.112853 0 0 0 ... 0 0 0 1 0 0 0 0 0 0 5 rows × 33 columns 1print(preprocessed_df['cluster_num'].value_counts()) 2 309 0 253 3 128 1 110 Name: cluster_num, dtype: int64 &gt;&gt; 군집 시각화 1234567891011121314151617181920# Visualizationplt.scatter(preprocessed_df[preprocessed_df['cluster_num'] == 0]['Attack'], preprocessed_df[preprocessed_df['cluster_num'] == 0]['Defense'], s = 50, c = 'red', alpha = 0.5, label = 'Pokemon Group 1')plt.scatter(preprocessed_df[preprocessed_df['cluster_num'] == 1]['Attack'], preprocessed_df[preprocessed_df['cluster_num'] == 1]['Defense'], s = 50, c = 'green', alpha = 0.7, label = 'Pokemon Group 2')plt.scatter(preprocessed_df[preprocessed_df['cluster_num'] == 2]['Attack'], preprocessed_df[preprocessed_df['cluster_num'] == 2]['Defense'], s = 50, c = 'blue', alpha = 0.5, label = 'Pokemon Group 3')plt.scatter(preprocessed_df[preprocessed_df['cluster_num'] == 3]['Attack'], preprocessed_df[preprocessed_df['cluster_num'] == 3]['Defense'], s = 50, c = 'yellow', alpha = 0.8, label = 'Pokemon Group 4')plt.title('Pokemon Cluster by \"Attack\" &amp; \"Defense\"')plt.xlabel('Attack')plt.ylabel('Defense')plt.legend()plt.show() (2) 다차원 군집 분석 12345678910111213141516from sklearn.cluster import KMeans# K-Means train &amp; Elbow methodX = preprocessed_df[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']]k_list = []cost_list = []for k in range (1, 15): kmeans = KMeans(n_clusters=k).fit(X) interia = kmeans.inertia_ # inertia: Sum of squared distances of samples to their closest cluster center. print(\"k:\", k, \"| cost:\", interia) k_list.append(k) cost_list.append(interia)plt.figure(figsize=(8, 6))plt.plot(k_list, cost_list) k: 1 | cost: 4800.0 k: 2 | cost: 3275.3812330305977 k: 3 | cost: 2862.057922495397 k: 4 | cost: 2566.5807792995274 k: 5 | cost: 2328.0706840275643 k: 6 | cost: 2182.759972635841 k: 7 | cost: 2070.734327066247 k: 8 | cost: 1957.5240844927844 k: 9 | cost: 1854.3770148227836 k: 10 | cost: 1778.3178764912984 k: 11 | cost: 1721.845255688537 k: 12 | cost: 1644.3967658442484 k: 13 | cost: 1579.4938049394318 k: 14 | cost: 1536.785887021493 [&lt;matplotlib.lines.Line2D at 0x2e930efbb88&gt;] 이 경우에는 cluster가 5일 때가 제일 적당해 보입니다. 12345# k-means fitting and predictkmeans = KMeans(n_clusters=5).fit(X)cluster_num = pd.Series(kmeans.predict(X))preprocessed_df['cluster_num'] = cluster_num.valuespreprocessed_df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Total HP Attack Defense Sp. Atk Sp. Def Speed Legendary Bug Dark ... Rock Steel Water Generation_1 Generation_2 Generation_3 Generation_4 Generation_5 Generation_6 cluster_num 0 -0.976765 -0.950626 -0.924906 -0.797154 -0.239130 -0.248189 -0.801503 0 0 0 ... 0 0 0 1 0 0 0 0 0 4 1 -0.251088 -0.362822 -0.524130 -0.347917 0.219560 0.291156 -0.285015 0 0 0 ... 0 0 0 1 0 0 0 0 0 1 2 0.749845 0.420917 0.092448 0.293849 0.831146 1.010283 0.403635 0 0 0 ... 0 0 0 1 0 0 0 0 0 1 3 1.583957 0.420917 0.647369 1.577381 1.503891 1.729409 0.403635 0 0 0 ... 0 0 0 1 0 0 0 0 0 0 4 -1.051836 -1.185748 -0.832419 -0.989683 -0.392027 -0.787533 -0.112853 0 0 0 ... 0 0 0 1 0 0 0 0 0 4 5 rows × 33 columns &gt;&gt; 군집별 특성 시각화 2차원이 아니기 때문에 위와 같이 군집 결과를 시각화하기 어렵습니다. 군집화 결과를 확인하기 위해 각 Feature의 군집별 특성을 시각화하도록 하겠습니다. 1234# HPsns.boxplot(x = \"cluster_num\", y = \"HP\", data = preprocessed_df)plt.title('군집별 \"HP\" 분포')plt.show() 1234# Attacksns.boxplot(x = 'cluster_num', y = 'Attack', data = preprocessed_df)plt.title('군집별 \"Attack\" 분포')plt.show() 1234# Defensesns.boxplot(x = 'cluster_num', y = 'Defense', data = preprocessed_df)plt.title('군집별 \"Defense\" 분포')plt.show() 1234# Sp. Atksns.boxplot(x = 'cluster_num', y = 'Sp. Atk', data = preprocessed_df)plt.title('군집별 \"Sp. Atk\" 분포')plt.show() 1234# Sp. Defsns.boxplot(x = 'cluster_num', y = 'Sp. Def', data = preprocessed_df)plt.title('군집별 \"Sp. Def\" 분포')plt.show() 1234# Speedsns.boxplot(x = 'cluster_num', y = 'Speed', data = preprocessed_df)plt.title('군집별 \"Speed\" 분포')plt.show() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"분류","slug":"분류","permalink":"https://hyemin-kim.github.io/tags/%EB%B6%84%EB%A5%98/"}]},{"title":"【실습】 Python >> EDA & Linear Regression -- 부동산 데이터","slug":"E-Python-LinearRegression-1","date":"2020-08-10T15:42:27.000Z","updated":"2020-08-29T09:32:07.036Z","comments":true,"path":"2020/08/11/E-Python-LinearRegression-1/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/11/E-Python-LinearRegression-1/","excerpt":"","text":"【EDA &amp; Regression 실습】 – 부동산 데이터 0. 개요 1. Library &amp; Data Import 2. EDA (Exploratory Data Analysis: 탐색적 데이터 분석) 2-1. 데이터셋 기본 정보 탐색 2-2. 회귀 분석 종속(목표) 변수 탐색 2-3. 회귀 분석 설명 변수 탐색 &gt;&gt; 설명 변수들의 분포 탐색 &gt;&gt; 설명 변수들의 상관관계 탐색 (with target variable “CMEDV”) &gt;&gt; 설명 변수와 종속 변수의 관계 탐색 &gt;&gt; 지역별 차이 탐색 3. 집값 예측 분석: 회귀분석 3-1. 데이터 전처리 &gt;&gt; feature 표준화 &gt;&gt; Training set / Test set 나누기 &gt;&gt; 다중 공선성 3-2. 회귀 분석 모델 학습 및 예측 &gt;&gt; coefficients 확인하기 &gt;&gt; feature 유의성 검정 &gt;&gt; 예측 결과 및 모델 성능 확인 0. 개요 Boston 지역의 부동산 데이터를 이용하여 선형 집값 예측 모델을 만듭니다. 사용 방법: 지도학습 — Linear Regression 1. Library &amp; Data Import &gt;&gt; 사용할 Library 123456789%matplotlib inlineimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport warningswarnings.filterwarnings('ignore') &gt;&gt; 사용할 데이터셋 – Boston Housing Dataset Original Data Source: http://lib.stat.cmu.edu/datasets/boston_corrected.txt Dataset Introduction: Boston Housing 1970 1df = pd.read_csv(\"https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/BostonHousing2.csv\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TOWN LON LAT CMEDV CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 Nahant -70.955 42.2550 24.0 0.00632 18.0 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 4.98 1 Swampscott -70.950 42.2875 21.6 0.02731 0.0 7.07 0 0.469 6.421 78.9 4.9671 2 242 17.8 396.90 9.14 2 Swampscott -70.936 42.2830 34.7 0.02729 0.0 7.07 0 0.469 7.185 61.1 4.9671 2 242 17.8 392.83 4.03 3 Marblehead -70.928 42.2930 33.4 0.03237 0.0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 2.94 4 Marblehead -70.922 42.2980 36.2 0.06905 0.0 2.18 0 0.458 7.147 54.2 6.0622 3 222 18.7 396.90 5.33 &gt;&gt; Feature Description TOWN: 지역 이름 LON, LAT: 경도(Longitudes) 위도(Latitudes) 정보 CMEDV: 해당 지역의 집값 (중앙값) (corrected median values of housing in USD 1000) CRIM: 근방 범죄율 per capita crime ZN: 주택지 비율 INDUS: 상업적 비즈니스에 활용되지 않는 농지 면적 CHAS: 경계선에 강에 있는지 여부 (dummy variable) NOX: 산화질소 농도 RM: 자택당 평균 방 갯수 AGE: 1940년 이전에 건설된 비율 DIS: 5개의 보스턴 고용 센터와의 거리레 따른 가중치 부여 RAD: radial 고속도로와의 접근성 지수 TAX: 10000달러당 재산세 PTRATIO: 지역별 학생-교사 비율 B: 지역의 흑인 지수 (1000(Bk - 0.63)^2), Bk는 흑인의 비율 LSTAT: 빈곤층의 비율 2. EDA (Exploratory Data Analysis: 탐색적 데이터 분석) 12# 그래프 배경 설정sns.set_style('darkgrid') 2-1. 데이터셋 기본 정보 탐색 12# shape (dimension)df.shape (506, 17) 12# 결측치df.isnull().sum() TOWN 0 LON 0 LAT 0 CMEDV 0 CRIM 0 ZN 0 INDUS 0 CHAS 0 NOX 0 RM 0 AGE 0 DIS 0 RAD 0 TAX 0 PTRATIO 0 B 0 LSTAT 0 dtype: int64 12# information (data type)df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 506 entries, 0 to 505 Data columns (total 17 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 TOWN 506 non-null object 1 LON 506 non-null float64 2 LAT 506 non-null float64 3 CMEDV 506 non-null float64 4 CRIM 506 non-null float64 5 ZN 506 non-null float64 6 INDUS 506 non-null float64 7 CHAS 506 non-null int64 8 NOX 506 non-null float64 9 RM 506 non-null float64 10 AGE 506 non-null float64 11 DIS 506 non-null float64 12 RAD 506 non-null int64 13 TAX 506 non-null int64 14 PTRATIO 506 non-null float64 15 B 506 non-null float64 16 LSTAT 506 non-null float64 dtypes: float64(13), int64(3), object(1) memory usage: 67.3+ KB 2-2. 회귀 분석 종속(목표) 변수 탐색 &gt;&gt; Target Variable: ‘CMEDV’(집값) 탐색 1df['CMEDV'].describe() count 506.000000 mean 22.528854 std 9.182176 min 5.000000 25% 17.025000 50% 21.200000 75% 25.000000 max 50.000000 Name: CMEDV, dtype: float64 12# 분포df['CMEDV'].hist(bins=50) &lt;matplotlib.axes._subplots.AxesSubplot at 0x23cf30df388&gt; boxplot: Pandas Function (pandas.DataFrame.boxplot) Matplotlib Function (matplotlib.pyplot.boxplot) 12# boxplot - Pandasdf.boxplot(column=['CMEDV']) &lt;matplotlib.axes._subplots.AxesSubplot at 0x23cf38c44c8&gt; 123# boxplot - matplotlibplt.boxplot(df['CMEDV'])plt.show() 2-3. 회귀 분석 설명 변수 탐색 &gt;&gt; 설명 변수들의 분포 탐색 12345678# numerical features (except \"LON\" &amp; \"LAT\")numerical_columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']fig = plt.figure(figsize = (16, 20))ax = fig.gca() # Axes 생성df[numerical_columns].hist(ax=ax)plt.show() &gt;&gt; 설명 변수들의 상관관계 탐색 (with target variable “CMEDV”) 12345# Person 상관계수cols = ['CMEDV', 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']corr = df[cols].corr(method = 'pearson')corr .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CMEDV CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT CMEDV 1.000000 -0.389582 0.360386 -0.484754 0.175663 -0.429300 0.696304 -0.377999 0.249315 -0.384766 -0.471979 -0.505655 0.334861 -0.740836 CRIM -0.389582 1.000000 -0.200469 0.406583 -0.055892 0.420972 -0.219247 0.352734 -0.379670 0.625505 0.582764 0.289946 -0.385064 0.455621 ZN 0.360386 -0.200469 1.000000 -0.533828 -0.042697 -0.516604 0.311991 -0.569537 0.664408 -0.311948 -0.314563 -0.391679 0.175520 -0.412995 INDUS -0.484754 0.406583 -0.533828 1.000000 0.062938 0.763651 -0.391676 0.644779 -0.708027 0.595129 0.720760 0.383248 -0.356977 0.603800 CHAS 0.175663 -0.055892 -0.042697 0.062938 1.000000 0.091203 0.091251 0.086518 -0.099176 -0.007368 -0.035587 -0.121515 0.048788 -0.053929 NOX -0.429300 0.420972 -0.516604 0.763651 0.091203 1.000000 -0.302188 0.731470 -0.769230 0.611441 0.668023 0.188933 -0.380051 0.590879 RM 0.696304 -0.219247 0.311991 -0.391676 0.091251 -0.302188 1.000000 -0.240265 0.205246 -0.209847 -0.292048 -0.355501 0.128069 -0.613808 AGE -0.377999 0.352734 -0.569537 0.644779 0.086518 0.731470 -0.240265 1.000000 -0.747881 0.456022 0.506456 0.261515 -0.273534 0.602339 DIS 0.249315 -0.379670 0.664408 -0.708027 -0.099176 -0.769230 0.205246 -0.747881 1.000000 -0.494588 -0.534432 -0.232471 0.291512 -0.496996 RAD -0.384766 0.625505 -0.311948 0.595129 -0.007368 0.611441 -0.209847 0.456022 -0.494588 1.000000 0.910228 0.464741 -0.444413 0.488676 TAX -0.471979 0.582764 -0.314563 0.720760 -0.035587 0.668023 -0.292048 0.506456 -0.534432 0.910228 1.000000 0.460853 -0.441808 0.543993 PTRATIO -0.505655 0.289946 -0.391679 0.383248 -0.121515 0.188933 -0.355501 0.261515 -0.232471 0.464741 0.460853 1.000000 -0.177383 0.374044 B 0.334861 -0.385064 0.175520 -0.356977 0.048788 -0.380051 0.128069 -0.273534 0.291512 -0.444413 -0.441808 -0.177383 1.000000 -0.366087 LSTAT -0.740836 0.455621 -0.412995 0.603800 -0.053929 0.590879 -0.613808 0.602339 -0.496996 0.488676 0.543993 0.374044 -0.366087 1.000000 123456789# heatmap (seaborn)fig = plt.figure(figsize = (16, 12))ax = fig.gca()sns.set(font_scale = 1.5) # heatmap 안의 font-size 설정heatmap = sns.heatmap(corr.values, annot = True, fmt='.2f', annot_kws={'size':15}, yticklabels = cols, xticklabels = cols, ax=ax)plt.tight_layout()plt.show() 우리의 관심사인 target variable **“CMEDV”**가 다른 feature간의 상관관계를 살펴보면, 이는 “RM - 자택당 평균 방 갯수”(0.7) 및 **“LSTAT - 빈곤층의 비율”(-0.74)**과 강한 상관관계를 보이고 있다는 것을 알 수 있다. 이 두 변수와의 관계를 좀 더 자세히 살펴볼게요. &gt;&gt; 설명 변수와 종속 변수의 관계 탐색 집값 ( “CMEDV” ) ~ 방 갯수 ( “RM” ) 1234# scatter plotsns.scatterplot(data=df, x='RM', y='CMEDV', markers='o', color='blue', alpha=0.6)plt.title('Scatter Plot')plt.show() 집값은 방 갯수와 양의 상관관계(positive correlation)를 갖는다. 즉, 방 갯수가 많을 수록 집값이 높을 경향이 있다 집값(“CMEDV”) ~ 빈곤층의 비율(“LSTAT”) 1234# scatter plotsns.scatterplot(data=df, x='LSTAT', y='CMEDV', markers='o', color='blue', alpha=0.6)plt.title('Scatter Plot')plt.show() 집값은 빈곤층의 비율과 음의 상관관계(negative correlation)를 갖는다. 즉, 빈곤층의 비율이 높을 수록 집값이 낮은 경향이 있다. &gt;&gt; 지역별 차이 탐색 12# 지역 데이터 - \"TOWN\"df['TOWN'].value_counts() Cambridge 30 Boston Savin Hill 23 Lynn 22 Boston Roxbury 19 Newton 18 .. Hanover 1 Hull 1 Sherborn 1 Hamilton 1 Dover 1 Name: TOWN, Length: 92, dtype: int64 12# 지역별 데이터 갯수df['TOWN'].value_counts().hist(bins=50) &lt;matplotlib.axes._subplots.AxesSubplot at 0x23cf3fb4b08&gt; 123# 지역별 집값 특징 (boxplot 이용)fig = plt.figure(figsize = (12, 20))sns.boxplot(x='CMEDV', y='TOWN', data=df) &lt;matplotlib.axes._subplots.AxesSubplot at 0x23cf3ff9ec8&gt; 123# 지역별 범죄율 특징fig = plt.figure(figsize = (12, 20))sns.boxplot(x='CRIM', y='TOWN', data=df) &lt;matplotlib.axes._subplots.AxesSubplot at 0x23cf407fec8&gt; 3. 집값 예측 분석: 회귀분석 3-1. 데이터 전처리 &gt;&gt; feature 표준화 Feature 들의 scale 차이를 없애기 위해 먼저 Feature 표준화를 진행한다. 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TOWN LON LAT CMEDV CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 Nahant -70.955 42.2550 24.0 0.00632 18.0 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 4.98 1 Swampscott -70.950 42.2875 21.6 0.02731 0.0 7.07 0 0.469 6.421 78.9 4.9671 2 242 17.8 396.90 9.14 2 Swampscott -70.936 42.2830 34.7 0.02729 0.0 7.07 0 0.469 7.185 61.1 4.9671 2 242 17.8 392.83 4.03 3 Marblehead -70.928 42.2930 33.4 0.03237 0.0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 2.94 4 Marblehead -70.922 42.2980 36.2 0.06905 0.0 2.18 0 0.458 7.147 54.2 6.0622 3 222 18.7 396.90 5.33 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 506 entries, 0 to 505 Data columns (total 17 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 TOWN 506 non-null object 1 LON 506 non-null float64 2 LAT 506 non-null float64 3 CMEDV 506 non-null float64 4 CRIM 506 non-null float64 5 ZN 506 non-null float64 6 INDUS 506 non-null float64 7 CHAS 506 non-null int64 8 NOX 506 non-null float64 9 RM 506 non-null float64 10 AGE 506 non-null float64 11 DIS 506 non-null float64 12 RAD 506 non-null int64 13 TAX 506 non-null int64 14 PTRATIO 506 non-null float64 15 B 506 non-null float64 16 LSTAT 506 non-null float64 dtypes: float64(13), int64(3), object(1) memory usage: 67.3+ KB Dummy Variable을 제외한 Numerical Variable 들을 표준화 함. 123456from sklearn.preprocessing import StandardScaler# feature standardization (numerical_columns except dummy var.-\"CHAS\")scaler = StandardScaler() # 평균 0, 표준편차 1scale_columns = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']df[scale_columns] = scaler.fit_transform(df[scale_columns]) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } TOWN LON LAT CMEDV CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 Nahant -70.955 42.2550 24.0 -0.419782 0.284830 -1.287909 0 -0.144217 0.413672 -0.120013 0.140214 -0.982843 -0.666608 -1.459000 0.441052 -1.075562 1 Swampscott -70.950 42.2875 21.6 -0.417339 -0.487722 -0.593381 0 -0.740262 0.194274 0.367166 0.557160 -0.867883 -0.987329 -0.303094 0.441052 -0.492439 2 Swampscott -70.936 42.2830 34.7 -0.417342 -0.487722 -0.593381 0 -0.740262 1.282714 -0.265812 0.557160 -0.867883 -0.987329 -0.303094 0.396427 -1.208727 3 Marblehead -70.928 42.2930 33.4 -0.416750 -0.487722 -1.306878 0 -0.835284 1.016303 -0.809889 1.077737 -0.752922 -1.106115 0.113032 0.416163 -1.361517 4 Marblehead -70.922 42.2980 36.2 -0.412482 -0.487722 -1.306878 0 -0.835284 1.228577 -0.511180 1.077737 -0.752922 -1.106115 0.113032 0.441052 -1.026501 &gt;&gt; Training set / Test set 나누기 12# features for linear regression modeldf[numerical_columns].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 -0.419782 0.284830 -1.287909 0 -0.144217 0.413672 -0.120013 0.140214 -0.982843 -0.666608 -1.459000 0.441052 -1.075562 1 -0.417339 -0.487722 -0.593381 0 -0.740262 0.194274 0.367166 0.557160 -0.867883 -0.987329 -0.303094 0.441052 -0.492439 2 -0.417342 -0.487722 -0.593381 0 -0.740262 1.282714 -0.265812 0.557160 -0.867883 -0.987329 -0.303094 0.396427 -1.208727 3 -0.416750 -0.487722 -1.306878 0 -0.835284 1.016303 -0.809889 1.077737 -0.752922 -1.106115 0.113032 0.416163 -1.361517 4 -0.412482 -0.487722 -1.306878 0 -0.835284 1.228577 -0.511180 1.077737 -0.752922 -1.106115 0.113032 0.441052 -1.026501 123456from sklearn.model_selection import train_test_split# split dataset into training &amp; testX = df[numerical_columns]y = df['CMEDV']X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) 1X_train.shape, y_train.shape ((404, 13), (404,)) 1X_test.shape, y_test.shape ((102, 13), (102,)) &gt;&gt; 다중 공선성 다중 공선성을 판단할 때 보통 VIF값을 본다. 일반적으로, VIF &gt; 10인 feature들은 다른 변수와 상관관계가 높아, 다중 공선성이 존재하는 것으로 판단한다. 123456from statsmodels.stats.outliers_influence import variance_inflation_factorvif = pd.DataFrame()vif['features'] = X_train.columnsvif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]vif.round(1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } features VIF Factor 0 CRIM 1.7 1 ZN 2.5 2 INDUS 3.8 3 CHAS 1.1 4 NOX 4.4 5 RM 1.9 6 AGE 3.2 7 DIS 4.2 8 RAD 8.1 9 TAX 9.8 10 PTRATIO 1.9 11 B 1.4 12 LSTAT 3.0 3-2. 회귀 분석 모델 학습 및 예측 12345678from sklearn import linear_model# fit regression model in training setlr = linear_model.LinearRegression()model = lr.fit(X_train, y_train)# predict in test setpred_test = lr.predict(X_test) &gt;&gt; coefficients 확인하기 12# print coefprint(lr.coef_) [-0.9479409 1.39796831 0.14786968 2.13469673 -2.25995614 2.15879342 0.12103297 -3.23121173 2.63662665 -1.95959865 -2.05639351 0.65670428 -3.93702535] 123# \"feature - coefficients\" DataFrame 만들기coefs = pd.DataFrame(zip(df[numerical_columns].columns, lr.coef_), columns = ['feature', 'coefficients'])coefs .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } feature coefficients 0 CRIM -0.947941 1 ZN 1.397968 2 INDUS 0.147870 3 CHAS 2.134697 4 NOX -2.259956 5 RM 2.158793 6 AGE 0.121033 7 DIS -3.231212 8 RAD 2.636627 9 TAX -1.959599 10 PTRATIO -2.056394 11 B 0.656704 12 LSTAT -3.937025 12# 크기 순서로 나열coefs.reindex(coefs.coefficients.abs().sort_values(ascending=False).index) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } feature coefficients 12 LSTAT -3.937025 7 DIS -3.231212 8 RAD 2.636627 4 NOX -2.259956 5 RM 2.158793 3 CHAS 2.134697 10 PTRATIO -2.056394 9 TAX -1.959599 1 ZN 1.397968 0 CRIM -0.947941 11 B 0.656704 2 INDUS 0.147870 6 AGE 0.121033 1234567891011## coefficients 시각화# figure sizeplt.figure(figsize = (8, 8))# bar plotplt.barh(coefs['feature'], coefs['coefficients'])plt.title('\"feature - coefficient\" Graph')plt.xlabel('coefficients')plt.ylabel('features')plt.show() &gt;&gt; feature 유의성 검정 12345import statsmodels.api as smX_train2 = sm.add_constant(X_train)model2 = sm.OLS(y_train, X_train2).fit()model2.summary() OLS Regression Results Dep. Variable: CMEDV R-squared: 0.734 Model: OLS Adj. R-squared: 0.725 Method: Least Squares F-statistic: 82.86 Date: Tue, 11 Aug 2020 Prob (F-statistic): 1.72e-103 Time: 00:22:07 Log-Likelihood: -1191.9 No. Observations: 404 AIC: 2412. Df Residuals: 390 BIC: 2468. Df Model: 13 Covariance Type: nonrobust coef std err t P&gt;|t| [0.025 0.975] const 22.4313 0.245 91.399 0.000 21.949 22.914 CRIM -0.9479 0.290 -3.263 0.001 -1.519 -0.377 ZN 1.3980 0.372 3.758 0.000 0.667 2.129 INDUS 0.1479 0.458 0.323 0.747 -0.753 1.049 CHAS 2.1347 0.899 2.375 0.018 0.367 3.902 NOX -2.2600 0.490 -4.617 0.000 -3.222 -1.298 RM 2.1588 0.332 6.495 0.000 1.505 2.812 AGE 0.1210 0.415 0.292 0.771 -0.695 0.937 DIS -3.2312 0.477 -6.774 0.000 -4.169 -2.293 RAD 2.6366 0.671 3.931 0.000 1.318 3.955 TAX -1.9596 0.731 -2.679 0.008 -3.398 -0.522 PTRATIO -2.0564 0.319 -6.446 0.000 -2.684 -1.429 B 0.6567 0.272 2.414 0.016 0.122 1.191 LSTAT -3.9370 0.405 -9.723 0.000 -4.733 -3.141 Omnibus: 169.952 Durbin-Watson: 1.935 Prob(Omnibus): 0.000 Jarque-Bera (JB): 859.012 Skew: 1.762 Prob(JB): 2.94e-187 Kurtosis: 9.213 Cond. No. 10.7 Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. t검정 결과를 확인해보면, INDUS(상업적 비즈니스에 활용되지 않는 농지 면적)과 AGE(1940 년 이전에 건설된 비율) 두 변수가 유의하지 않다는 것을 확인할 수 있다. &gt;&gt; 예측 결과 및 모델 성능 확인 예측 결과 시각화 12345678910# 예측 결과 시각화 (test set)df = pd.DataFrame({'actual': y_test, 'prediction': pred_test})df = df.sort_values(by='actual').reset_index(drop=True)plt.figure(figsize=(12, 9))plt.scatter(df.index, df['prediction'], marker='x', color='r')plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black')plt.title(\"Prediction Result in Test Set\", fontsize=20)plt.legend(['prediction', 'actual'], fontsize=12)plt.show() R square 123# R squareprint(model.score(X_train, y_train)) # training setprint(model.score(X_test, y_test)) # test set 0.7341832055169144 0.7639579157366423 RMSE 12345678910# RMSEfrom sklearn.metrics import mean_squared_errorfrom math import sqrt# training setpred_train = lr.predict(X_train)print(sqrt(mean_squared_error(y_train, pred_train)))# test setprint(sqrt(mean_squared_error(y_test, pred_test))) 4.624051760840334 4.829847098176557 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"회귀","slug":"회귀","permalink":"https://hyemin-kim.github.io/tags/%ED%9A%8C%EA%B7%80/"}]},{"title":"Python >> sklearn - (5) 비지도 학습 (Unsupervised Learning)","slug":"S-Python-sklearn5","date":"2020-08-06T04:57:29.000Z","updated":"2020-08-13T12:47:41.657Z","comments":true,"path":"2020/08/06/S-Python-sklearn5/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/06/S-Python-sklearn5/","excerpt":"","text":"비지도 학습 (Unsupervised Learning) 1. 비지도 학습의 개요 2. 차원 축소 2-1. 데이터 로드 (iris 데이터) 2-2. PCA 차원 축소 2-3. LDA 차원 축소 2-4. SVD (특이값 분해) 3. 군집화 3-1. K-Means Clustering 3-2. DBSCAN 3-3. 실루엣 스코어 (군집화 평가) 1from IPython.display import Image 1. 비지도 학습의 개요 비지도 학습 (Unsupervised Learning)은 기계 학습의 일종으로, 데이터가 어떻게 구성되어 있는지를 알아내는 문제의 범주에 속한다. 이 방법은 지도 학습 (Supervised Learning) 혹은 강화 학습 (Reinforcement Learning)과는 달리 입력값에 대한 목표치가 주어지지 않는다 차원 축소: PCA, LDA, SVD 군집화: KMeans Clustering, DBSCAN 군집화 평가 2. 차원 축소 feature의 갯수를 줄이는 것을 뛰어 넘어, 특징을 추출하는 역할응 하기도 함 계산 비용을 감소하는 효과 전반적인 데이터에 대한 이해도를 높이는 효과 1234from sklearn.preprocessing import StandardScalerfrom sklearn.decomposition import PCAfrom sklearn import datasetsimport pandas as pd 2-1. 데이터 로드 (iris 데이터) 1iris = datasets.load_iris() 1data = iris['data'] 1data[:5] array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5. , 3.6, 1.4, 0.2]]) 1df = pd.DataFrame(data, columns = iris['feature_names']) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 1df['target'] = iris['target'] 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 2-2. PCA 차원 축소 참고: PCA 원리 관련 블로그 주성분 분석 (PCA, Principal Component Analysis) 는 선형 차원 축소 기법이다. 매우 인기 있게 사용되는 차원 축소 기법중 하나다. PCA는 먼저 데이터에 가장 가까운 초평면(hyperplane)을 구한 다음, 데이터를 이 초평면에 투영(projection)시킨다. 주요 특징 중의 하나는 분산(variance)을 촤대한 보존한다는 점이다. 분산 보존 PCA는 데이터의 분산이 최대가 되는 축을 찾는다. 즉, 원본 데이터셋과 투영된 데이터셋 간의 평균제곱거리를 최소화하는 축을 찾는다. PCA 실현 과정 학습 데이터셋에서 분산이 최대인 축(axis)을 찾는다 이렇게 찾은 첫 번째 축과 직교(orthogonal)하면서 분산이 최대인 두 번째 축을 찾는다 첫 번째 축과 두 번째 축에 직교하고 분산을 최대한 보존하는 세 번째 축을 찾는다 1~3과 같은 방법으로 데이터셋의 차원(특성 수)만큼의 축을 찾는다 이렇게 i-번째 축을 정의하는 **단위 벡터(unit vector)**를 i-번째 주성분(PC, Principle Component)이라고 한다. &gt;&gt; sklearn에서 실현 [sklearn.decomposition.PCA] Documnet n_components에 1보다 작은 값을 넣으면, 분산을 기준으로 차원 축소 n_components에 1보다 큰 값을 넣으면, 해당 값을 기준으로 feature를 축소 (1) 주성분 2개로 지정 (n_components = 2) 1from sklearn.decomposition import PCA 12345678# 모델 선언pca = PCA(n_components=2)# data scalingdata_scaled = StandardScaler().fit_transform(df.loc[:, 'sepal length (cm)' : 'petal width (cm)'])# PCA 실행pca_data = pca.fit_transform(data_scaled) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 1data_scaled[:5] array([[-0.90068117, 1.01900435, -1.34022653, -1.3154443 ], [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ], [-1.38535265, 0.32841405, -1.39706395, -1.3154443 ], [-1.50652052, 0.09821729, -1.2833891 , -1.3154443 ], [-1.02184904, 1.24920112, -1.34022653, -1.3154443 ]]) 1pca_data[:5] array([[-2.26470281, 0.4800266 ], [-2.08096115, -0.67413356], [-2.36422905, -0.34190802], [-2.29938422, -0.59739451], [-2.38984217, 0.64683538]]) 주성분에 따른 데이터 시각화 12345import matplotlib.pyplot as pltfrom matplotlib import cmimport seaborn as sns%matplotlib inline 1plt.scatter(pca_data[:, 0], pca_data[:, 1], c=df['target']) # c: color 기준 &lt;matplotlib.collections.PathCollection at 0x201028bf148&gt; (2) 분산을 기준으로 차원축소 (n_components &lt; 1) 123pca2 = PCA(n_components=0.99)pca_data2 = pca2.fit_transform(data_scaled)pca_data2[:5] array([[-2.26470281, 0.4800266 , -0.12770602], [-2.08096115, -0.67413356, -0.23460885], [-2.36422905, -0.34190802, 0.04420148], [-2.29938422, -0.59739451, 0.09129011], [-2.38984217, 0.64683538, 0.0157382 ]]) 1234567891011from mpl_toolkits.mplot3d import Axes3Dimport numpy as npfig = plt.figure(figsize=(10, 5))ax = fig.add_subplot(111, projection='3d') # Axe3D objectsample_size = 50ax.scatter(pca_data2[:,0], pca_data2[:,1], pca_data2[:,2], alpha=0.6, c=df['target'])plt.savefig('./tmp.svg')plt.title('ax.plot')plt.show() 2-3. LDA 차원 축소 참고 블로그: 차원 축소 - LDA(Linear Discriminant Analysis) 개요 머신러닝 기초9 - LDA (Linear Discriminant Analysis) LDA (Linear Discriminant Analysis): 선형 판별 분석법 (PCA와 유사) LDA는 클래스(Class)분리를 최대화하는 축을 찾기 위해 클래스 간 분산(between-class scatter)과 내분 분산(within-class scatter)의 비율을 최대화하는 방식으로 차원을 축소함. 즉, 클래스 간 분산은 최대한 크게 가져가고, 클래스 내부의 분산은 최대한 작게 가져가는 방식이다. &gt;&gt; sklearn에서 실현 12from sklearn.discriminant_analysis import LinearDiscriminantAnalysisfrom sklearn.preprocessing import StandardScaler 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 12345678# 모델 선언lda = LinearDiscriminantAnalysis(n_components=2)# data scalingdata_scaled = StandardScaler().fit_transform(df.loc[:, 'sepal length (cm)' : 'petal width (cm)'])# LDA 실행lda_data = lda.fit_transform(data_scaled, df['target']) 1lda_data[:5] array([[-8.06179978, 0.30042062], [-7.12868772, -0.78666043], [-7.48982797, -0.26538449], [-6.81320057, -0.67063107], [-8.13230933, 0.51446253]]) 시각화 12# LDAplt.scatter(lda_data[:,0], lda_data[:,1], c=df['target']) &lt;matplotlib.collections.PathCollection at 0x20102cd5608&gt; PCA 결과와 비교 12# PCAplt.scatter(pca_data[:,0], pca_data[:,1], c=df['target']) &lt;matplotlib.collections.PathCollection at 0x20102ba6908&gt; 2-4. SVD (특이값 분해) 위키문서 SVD (Singular Value Decomposition): 특이값 분해 기법이다 PCA와 유사한 차원 축소 기법이다 scikit-learn 패키지에서는 truncated SVD (aka LSA)을 사용한다 상품의 추천 시스템에도 활용되어지는 알고리즘 (추천시스템) 1from sklearn.decomposition import TruncatedSVD 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 123svd = TruncatedSVD(n_components = 2)data_scaled = StandardScaler().fit_transform(df.loc[:, 'sepal length (cm)' : 'petal width (cm)'])svd_data = svd.fit_transform(data_scaled) 1svd_data[:5] array([[-2.26470281, 0.4800266 ], [-2.08096115, -0.67413356], [-2.36422905, -0.34190802], [-2.29938422, -0.59739451], [-2.38984217, 0.64683538]]) 시각화 12# SVDplt.scatter(svd_data[:,0], svd_data[:,1], c=df['target']) &lt;matplotlib.collections.PathCollection at 0x20102b2ed08&gt; PCA &amp; LDA와 비교 12# PCAplt.scatter(pca_data[:,0], pca_data[:,1], c=df['target']) &lt;matplotlib.collections.PathCollection at 0x20102ad7d88&gt; 12# LDAplt.scatter(lda_data[:,0], lda_data[:,1], c=df['target']) &lt;matplotlib.collections.PathCollection at 0x20102d43e08&gt; 3. 군집화 3-1. K-Means Clustering 위키문서 군집화에서 가장 대중적으로 사용되는 알고리즘이다. centroid라는 중점을 기준으로 가강 가까운 포인트를 선택하는 군집화 기법이다 원리: 주어진 데이터를 k개의 cluster로 묶는 방식, 거리 차이의 분산을 최소화하는 방식으로 동작. 1Image('https://image.slidesharecdn.com/patternrecognitionbinoy-06-kmeansclustering-160317135729/95/pattern-recognition-binoy-k-means-clustering-13-638.jpg') 사용되는 예제 스팸 문자 분류 뉴스 기사 분류 [sklearn.cluster.KMeans] Document 1from sklearn.cluster import KMeans 123kmeans = KMeans(n_clusters=3)data_scaled = StandardScaler().fit_transform(df.loc[:, 'sepal length (cm)' : 'petal width (cm)'])cluster_data = kmeans.fit_transform(data_scaled) 1cluster_data[:5] array([[3.12119834, 0.21295824, 3.98940603], [2.6755083 , 0.99604549, 4.01793312], [2.97416665, 0.65198444, 4.19343668], [2.88014429, 0.9034561 , 4.19784749], [3.30022609, 0.40215457, 4.11157152]]) 1kmeans.labels_ array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0]) 1sns.countplot(kmeans.labels_) &lt;matplotlib.axes._subplots.AxesSubplot at 0x201043c7fc8&gt; 1sns.countplot(df['target']) &lt;matplotlib.axes._subplots.AxesSubplot at 0x2010301bec8&gt; Hyper-parameter Tuning 1kmeans KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300, n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto', random_state=None, tol=0.0001, verbose=0) 1234# max_iter: maximum number of iterations for a single runkmeans2 = KMeans(n_clusters=3, max_iter=500)data_scaled = StandardScaler().fit_transform(df.loc[:, 'sepal length (cm)' : 'petal width (cm)'])cluster_data2 = kmeans2.fit_transform(data_scaled) 1sns.countplot(kmeans2.labels_) &lt;matplotlib.axes._subplots.AxesSubplot at 0x20105525688&gt; 3-2. DBSCAN 밀도 기반 클러스터링 (DBSCAN: Dencity-Based Spatial Clustering of Applications with Noise) 밀도가 높은 부분을 클러스터링 하는 방식 어느 점을 기준으로 반경 x내에 점이 n개 이상 있으면 하나의 군집으로 인식하는 방식 KMeans 에서는 n_cluster의 갯수를 반드시 지정해 주어야 하나, DBSCAN에서는 필요없음 기하학적인 clustering도 잘 찾아냄 1Image('https://image.slidesharecdn.com/pydatanyc2015-151119175854-lva1-app6891/95/pydata-nyc-2015-automatically-detecting-outliers-with-datadog-26-638.jpg') [sklearn.cluster.DBSCAN] Document 주의: 변환 시 fit_transform()대신 fit_predict() 를 쓴다 1from sklearn.cluster import DBSCAN 12345# eps: The maximum distance between two samples for one to be considered as in the neighborhoood of the otherdbscan = DBSCAN(eps=0.7, min_samples=2)data_scaled = StandardScaler().fit_transform(df.loc[:, 'sepal length (cm)' : 'petal width (cm)'])dbscan_data = dbscan.fit_predict(data_scaled)dbscan_data array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64) 3-3. 실루엣 스코어 (군집화 평가) 클러스터링의 품질을 정량적으로 평가해 주는 지표 1: 클러스터링의 품질이 좋다 0: 클러스터링의 품질이 안좋다 (클러스터링의 의미 없음) 음수: 잘못 분류됨 1from sklearn.metrics import silhouette_samples, silhouette_score 123data_scaled = StandardScaler().fit_transform(df.loc[:, 'sepal length (cm)' : 'petal width (cm)'])score = silhouette_score(data_scaled, kmeans.labels_)score 0.45994823920518635 12samples = silhouette_samples(data_scaled, kmeans.labels_)samples[:5] array([0.73419485, 0.56827391, 0.67754724, 0.62050159, 0.72847412]) silhouette analysis 시각화 Document 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586def plot_silhouette(X, num_cluesters): for n_clusters in num_cluesters: # Create a subplot with 1 row and 2 columns fig, (ax1, ax2) = plt.subplots(1, 2) fig.set_size_inches(18, 7) # The 1st subplot is the silhouette plot # The silhouette coefficient can range from -1, 1 but in this example all # lie within [-0.1, 1] ax1.set_xlim([-0.1, 1]) # The (n_clusters+1)*10 is for inserting blank space between silhouette # plots of individual clusters, to demarcate them clearly. ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10]) # Initialize the clusterer with n_clusters value and a random generator # seed of 10 for reproducibility. clusterer = KMeans(n_clusters=n_clusters, random_state=10) cluster_labels = clusterer.fit_predict(X) # The silhouette_score gives the average value for all the samples. # This gives a perspective into the density and separation of the formed # clusters silhouette_avg = silhouette_score(X, cluster_labels) print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is :\", silhouette_avg) # Compute the silhouette scores for each sample sample_silhouette_values = silhouette_samples(X, cluster_labels) y_lower = 10 for i in range(n_clusters): # Aggregate the silhouette scores for samples belonging to # cluster i, and sort them ith_cluster_silhouette_values = \\ sample_silhouette_values[cluster_labels == i] ith_cluster_silhouette_values.sort() size_cluster_i = ith_cluster_silhouette_values.shape[0] y_upper = y_lower + size_cluster_i color = cm.nipy_spectral(float(i) / n_clusters) ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7) # Label the silhouette plots with their cluster numbers at the middle ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i)) # Compute the new y_lower for next plot y_lower = y_upper + 10 # 10 for the 0 samples ax1.set_title(\"The silhouette plot for the various clusters.\") ax1.set_xlabel(\"The silhouette coefficient values\") ax1.set_ylabel(\"Cluster label\") # The vertical line for average silhouette score of all the values ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\") ax1.set_yticks([]) # Clear the yaxis labels / ticks ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1]) # 2nd Plot showing the actual clusters formed colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters) ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=colors, edgecolor='k') # Labeling the clusters centers = clusterer.cluster_centers_ # Draw white circles at cluster centers ax2.scatter(centers[:, 0], centers[:, 1], marker='o', c=\"white\", alpha=1, s=200, edgecolor='k') for i, c in enumerate(centers): ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k') ax2.set_title(\"The visualization of the clustered data.\") ax2.set_xlabel(\"Feature space for the 1st feature\") ax2.set_ylabel(\"Feature space for the 2nd feature\") plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \" \"with n_clusters = %d\" % n_clusters), fontsize=14, fontweight='bold') plt.show() 1plot_silhouette(data_scaled, [2, 3, 4, 5]) For n_clusters = 2 The average silhouette_score is : 0.5817500491982808 For n_clusters = 3 The average silhouette_score is : 0.45994823920518635 For n_clusters = 4 The average silhouette_score is : 0.4188923398171004 For n_clusters = 5 The average silhouette_score is : 0.34551099599809465 빨간 점선은 평균 실루엣 계수를 의미함 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"비지도 학습","slug":"비지도-학습","permalink":"https://hyemin-kim.github.io/tags/%EB%B9%84%EC%A7%80%EB%8F%84-%ED%95%99%EC%8A%B5/"}]},{"title":"Python >> sklearn - (4) 앙상블 (Ensemble)","slug":"S-Python-sklearn4","date":"2020-08-04T11:40:35.000Z","updated":"2020-08-04T12:31:24.820Z","comments":true,"path":"2020/08/04/S-Python-sklearn4/","link":"","permalink":"https://hyemin-kim.github.io/2020/08/04/S-Python-sklearn4/","excerpt":"","text":"앙상블 (Ensemble) 0. 데이터 셋 0-1. 데이터 로드 0-2. 데이터프레임 만들기 1. Training set / Test set 나누기 2. 평가 지표 만들기 2-1. 평가 지표 2-2. 모델 성능 확인을 위한 함수 3. 단일 회귀 모델 (지난 시간) (1) Linear Regression (2) Ridge (3) LASSO (4) ElasticNet (5) With Standard Scaling (6) Polynomial Features 4. 앙상블 (Ensemble) 알고리즘 4-1. 보팅 (Voting) &gt;&gt; 회귀 (Regression) &gt;&gt; 분류 (Classification) 4-2. 배깅 (Bagging) &gt;&gt; Random Forest 4-3. 부스팅 (Boosting) 4-3-1. Gradient Boost 4-3-2. XGBoost 4-3-3. LightGBM 4-4. 스태킹 (Stacking) 4-5. Weighted Blending 4-6. 앙상블 모델 정리 5. Cross Validation 5-1. Cross Validation 소개 5-2. Hyper-parameter 튜닝 (1) RandomizedSearchCV (2) GridSerchCV 머신러닝 앙상블이란 여러 개의 머신러닝 모델을 이용해 최적의 답을 찾아내는 기법이다. (여러 모델을 이용하여 데이터를 학습하고, 모든 모델의 예측결과를 평균하여 예측) 앙상블 기법의 종류 보팅 (Voting): 투표를 통해 결과 도출 배깅 (Bagging): 샘플 중복 생성을 통해 결과 도출 부스팅 (Boosting): 이전 오차를 보완하면서 가중치 부여 스태킹 (Stacking): 여러 모델을 기반으로 예측된 결과를 통해 meta 모델이 다시 한번 예측 참고자료 (블로그) 보팅 (Voting) 배경 (Bagging) 부스팅 (Boosting) 0. 데이터 셋 12345import pandas as pdimport numpy as npfrom IPython.display import Imagenp.set_printoptions(suppress=True) # If True, print floating point numbers instead of scientific notation 1from sklearn.datasets import load_boston 0-1. 데이터 로드 1data = load_boston() 1print(data['DESCR']) .. _boston_dataset: Boston house prices dataset --------------------------- **Data Set Characteristics:** :Number of Instances: 506 :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target. :Attribute Information (in order): - CRIM per capita crime rate by town - ZN proportion of residential land zoned for lots over 25,000 sq.ft. - INDUS proportion of non-retail business acres per town - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) - NOX nitric oxides concentration (parts per 10 million) - RM average number of rooms per dwelling - AGE proportion of owner-occupied units built prior to 1940 - DIS weighted distances to five Boston employment centres - RAD index of accessibility to radial highways - TAX full-value property-tax rate per $10,000 - PTRATIO pupil-teacher ratio by town - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town - LSTAT % lower status of the population - MEDV Median value of owner-occupied homes in $1000's :Missing Attribute Values: None :Creator: Harrison, D. and Rubinfeld, D.L. This is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/machine-learning-databases/housing/ ​ This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics &amp; Management, vol.5, 81-102, 1978. Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics ...', Wiley, 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter. The Boston house-price data has been used in many machine learning papers that address regression problems. .. topic:: References - Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261. - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann. ​ 0-2. 데이터프레임 만들기 12df = pd.DataFrame(data['data'], columns = data['feature_names'])df['MEDV'] = data['target'] 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 36.2 컬럼 소게 (feature 13 + target 1): CRIM: 범죄율 ZN: 25,000 square feet 당 주거용 토지의 비율 INDUS: 비소매(non-retail) 비즈니스 면적 비율 CHAS: 찰스 강 더미 변수 (통로가 하천을 향하면 1; 그렇지 않으면 0) NOX: 산화 질소 농도 (천만 분의 1) RM:주거 당 평균 객실 수 AGE: 1940 년 이전에 건축된 자가 소유 점유 비율 DIS: 5 개의 보스턴 고용 센터까지의 가중 거리 RAD: 고속도로 접근성 지수 TAX: 10,000 달러 당 전체 가치 재산 세율 PTRATIO 도시 별 학생-교사 비율 B: 1000 (Bk-0.63) ^ 2 여기서 Bk는 도시 별 검정 비율입니다. LSTAT: 인구의 낮은 지위 MEDV: 자가 주택의 중앙값 (1,000 달러 단위) 1. Training set / Test set 나누기 1from sklearn.model_selection import train_test_split 1x_train, x_test, y_train, y_test = train_test_split(df.drop('MEDV', 1), df['MEDV'], random_state=23) 1x_train.shape, y_train.shape ((379, 13), (379,)) 1x_test.shape, y_test.shape ((127, 13), (127,)) 2. 평가 지표 만들기 2-1. 평가 지표 (1) MAE (Mean Absolute Error) MAE (평균 절대 오차): 에측값과 실제값의 차이의 절대값에 대하여 평균을 낸 것 MAE=1n∑i=1n∣yi−yi^∣MAE = \\frac{1}{n} \\sum_{i=1}^n \\left\\vert y_i - \\widehat{y_i} \\right\\vert MAE=n1​i=1∑n​∣yi​−yi​​∣ (2) MSE (Mean Squared Error) MSE (평균 제곱 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 것 MSE=1n∑i=1n(yi−yi^)2MSE = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2 MSE=n1​i=1∑n​(yi​−yi​​)2 (3) RMSE (Root Mean Squared Error) RMSE (평균 제곱근 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 뒤 루트를 씌운 것 RMSE=1n∑i=1n(yi−yi^)2RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2} RMSE=n1​i=1∑n​(yi​−yi​​)2​ 2-2. 모델 성능 확인을 위한 함수 12# sklearn 평가지표 활용from sklearn.metrics import mean_absolute_error, mean_squared_error 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import matplotlib.pyplot as pltimport seaborn as snsmy_predictions = {}colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown', 'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick', 'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', 'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate', 'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', 'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato' ]# prediction plotdef plot_predictions(name_, actual, pred): df = pd.DataFrame({'actual': y_test, 'prediction': pred}) df = df.sort_values(by='actual').reset_index(drop=True) plt.figure(figsize=(12, 9)) plt.scatter(df.index, df['prediction'], marker='x', color='r') plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black') plt.title(name_, fontsize=15) plt.legend(['prediction', 'actual'], fontsize=12) plt.show()# evaluation plotdef mse_eval(name_, actual, pred): global predictions global colors plot_predictions(name_, actual, pred) mse = mean_squared_error(actual, pred) my_predictions[name_] = mse y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True) df = pd.DataFrame(y_value, columns=['model', 'mse']) print(df) min_ = df['mse'].min() - 10 max_ = df['mse'].max() + 10 length = len(df) plt.figure(figsize=(10, length)) ax = plt.subplot() ax.set_yticks(np.arange(len(df))) ax.set_yticklabels(df['model'], fontsize=15) bars = ax.barh(np.arange(len(df)), df['mse']) for i, v in enumerate(df['mse']): idx = np.random.choice(len(colors)) bars[i].set_color(colors[idx]) ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold') plt.title('MSE Error', fontsize=18) plt.xlim(min_, max_) plt.show()# remove modeldef remove_model(name_): global my_predictions try: del my_predictions[name_] except KeyError: return False return True# coefficients visulizationdef plot_coef(columns, coef): coef_df = pd.DataFrame(list(zip(columns, coef))) coef_df.columns=['feature', 'coef'] coef_df = coef_df.sort_values('coef', ascending=False).reset_index(drop=True) fig, ax = plt.subplots(figsize=(9, 7)) ax.barh(np.arange(len(coef_df)), coef_df['coef']) idx = np.arange(len(coef_df)) ax.set_yticks(idx) ax.set_yticklabels(coef_df['feature']) fig.tight_layout() plt.show() 3. 단일 회귀 모델 (지난 시간) 1234567from sklearn.linear_model import LinearRegressionfrom sklearn.linear_model import Ridgefrom sklearn.linear_model import Lassofrom sklearn.linear_model import ElasticNetfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScalerfrom sklearn.pipeline import make_pipelinefrom sklearn.preprocessing import PolynomialFeatures (1) Linear Regression 1234linear_reg = LinearRegression(n_jobs=-1)linear_reg.fit(x_train, y_train)linear_pred = linear_reg.predict(x_test)mse_eval('LinearRegression', y_test, linear_pred) model mse 0 LinearRegression 22.770784 (2) Ridge 1234ridge = Ridge(alpha=1)ridge.fit(x_train, y_train)ridge_pred = ridge.predict(x_test)mse_eval('Ridge(alpha=1)', y_test, ridge_pred) model mse 0 LinearRegression 22.770784 1 Ridge(alpha=1) 22.690411 (3) LASSO 1234lasso = Lasso(alpha=0.01)lasso.fit(x_train, y_train)lasso_pred = lasso.predict(x_test)mse_eval('Lasso(alpha=0.01)', y_test, lasso_pred) model mse 0 LinearRegression 22.770784 1 Ridge(alpha=1) 22.690411 2 Lasso(alpha=0.01) 22.635614 (4) ElasticNet 1234elasticnet = ElasticNet(alpha=0.5, l1_ratio=0.2)elasticnet.fit(x_train, y_train)elas_pred = elasticnet.predict(x_test)mse_eval('ElasticNet(l1_ratio=0.2)', y_test, elas_pred) model mse 0 ElasticNet(l1_ratio=0.2) 24.481069 1 LinearRegression 22.770784 2 Ridge(alpha=1) 22.690411 3 Lasso(alpha=0.01) 22.635614 (5) With Standard Scaling 1234567standard_elasticnet = make_pipeline( StandardScaler(), ElasticNet(alpha=0.5, l1_ratio=0.2))elas_scaled_pred = standard_elasticnet.fit(x_train, y_train).predict(x_test)mse_eval('Standard ElasticNet', y_test, elas_scaled_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 (6) Polynomial Features 123456789# 2-Degree Polynomial Features + Standard Scalingpoly_elasticnet = make_pipeline( PolynomialFeatures(degree=2, include_bias=False), StandardScaler(), ElasticNet(alpha=0.5, l1_ratio=0.2))poly_pred = poly_elasticnet.fit(x_train, y_train).predict(x_test)mse_eval('Poly ElasticNet', y_test, poly_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Poly ElasticNet 20.805986 4. 앙상블 (Ensemble) 알고리즘 [sklearn.ensemble] Document 앙상블 기법의 종류 보팅 (Voting): 투표를 통해 결과 도출 배깅 (Bagging): 샘플 중복 생성을 통해 결과 도출 부스팅 (Boosting): 이전 오차를 보완하면서 가중치 부여 스태킹 (Stacking): 여러 모델을 기반으로 예측된 결과를 통해 meta 모델이 다시 한번 예측 4-1. 보팅 (Voting) &gt;&gt; 회귀 (Regression) Voting은 단어 뜻 그대로 투표를 통해 최종 결과를 결정하는 방식이다. Voting과 Bagging은 모두 투표방식이지만, 다음과 같은 큰 차이점이 있다: Voting은 다른 알고리즘 model을 조합해서 사용함 Bagging은 같은 알고리즘 내에서 다른 sample 조합을 사용함 1from sklearn.ensemble import VotingRegressor 반드시, Tuple 형태로 모델을 정의해야 한다. 123456789# 보팅에 참여한 single models 지정single_models = [ ('linear_reg', linear_reg), ('ridge', ridge), ('lasso', lasso), ('elasticnet', elasticnet), ('standard_elasticnet', standard_elasticnet), ('poly_elasticnet', poly_elasticnet)] 12# voting regressor 만들기voting_regressor = VotingRegressor(single_models, n_jobs=-1) 1voting_regressor.fit(x_train, y_train) VotingRegressor(estimators=[('linear_reg', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)), ('ridge', Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=None, solver='auto', tol=0.001)), ('lasso', Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False, positive=False, pr... interaction_only=False, order='C')), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=0.5, copy_X=True, fit_intercept=True, l1_ratio=0.2, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=None, selection='cyclic', tol=0.0001, warm_start=False))], verbose=False))], n_jobs=-1, weights=None) 12voting_pred = voting_regressor.predict(x_test)mse_eval('Voting Ensemble', y_test, voting_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 &gt;&gt; 분류 (Classification) 참고 자료 (Blog) 분류기 모델을 만들때, Voting 앙상블은 1가지의 중요한 parameter가 있다: voting = {‘hard’, ‘soft’} class를 0, 1로 분류 예측을 하는 이진 분류를 예로 들어 보자. (1) hard 로 설정한 경우 Hard Voting 방식에서는 결과 값에 대한 다수 class를 사용한다. 분류를 예측한 값이 1, 0, 0, 1, 1 이었다고 가정한다면 1이 3표, 0이 2표를 받았기 때문에 Hard Voting 방식에서는 1이 최종 값으로 예측을 하게 된다. (2) soft 로 설정한 경우 soft voting 방식은 각각의 확률의 평균 값을 계산한다음에 가장 확률이 높은 값으로 확정짓게 된다. 가령 class 0이 나올 확률이 (0.4, 0.9, 0.9, 0.4, 0.4)이었고, class 1이 나올 확률이 (0.6, 0.1, 0.1, 0.6, 0.6) 이었다면, class 0이 나올 최종 확률은 (0.4+0.9+0.9+0.4+0.4) / 5 = 0.44, class 1이 나올 최종 확률은 (0.6+0.1+0.1+0.6+0.6) / 5 = 0.4 가 되기 때문에 앞선 Hard Voting의 결과와는 다른 결과 값이 최종으로 선출되게 된다. 12from sklearn.ensemble import VotingClassifierfrom sklearn.linear_model import LogisticRegression, RidgeClassifier 1234models = [ ('Logit', LogisticRegression()), ('ridge', RidgeClassifier())] voting 옵션 지정 1vc = VotingClassifier(models, voting='soft') 4-2. 배깅 (Bagging) 참고 자료 (Blog) Bagging은 Bootstrap Aggregating의 줄임말이다. Bootstrap은 여러 개의 dataset을 중첩을 허용하게 하여 샘플링하여 분할하는 방식. 데이터 셋의 구성이 [1, 2, 3, 4, 5]로 되어 있다면, group 1 = [1, 2, 3] group 2 = [1, 3, 4] group 3 = [2, 3, 5] 1Image('https://teddylee777.github.io/images/2019-12-17/image-20191217015537872.png') Voting VS Bagging Voting은 여러 알고리즘의 조합에 대한 앙상블 Bagging은 하나의 단일 알고리즘에 대하여 여러 개의 샘플 조합으로 앙상블 대표적인 Bagging 앙상블 Random Forest Bagging &gt;&gt; Random Forest Decision Tree 기반 Bagging 앙상블 굉장히 인기있는 앙상블 모델 사용성이 쉽고, 성능도 우수함 [sklearn.ensemble.RandomForestRegressor] Document [sklearn.ensemble.RandomForestClassifier] Document 회귀 (Regression) Hyper-parameter의 default value로 모델 학습 1from sklearn.ensemble import RandomForestRegressor 12rfr = RandomForestRegressor(random_state=1)rfr.fit(x_train, y_train) RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse', max_depth=None, max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None, oob_score=False, random_state=1, verbose=0, warm_start=False) 12rfr_pred = rfr.predict(x_test)mse_eval('RandomForest Ensemble', y_test, rfr_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 7 RandomForest Ensemble 13.781191 주요 Hyper-parameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 max_depth: 깊어질 수 있는 최대 깊이. 과대적합 방지용 n_estimators: 암상블하는 트리의 갯수 max_features: best split을 판단할 때 최대로 사용할 feature의 갯수 {‘auto’, ‘sqrt’, ‘log2’}. 과대적합 방지용 min_samples_split: 트리가 분할할 때 최소 샘플의 갯수. default=2. 과대적합 방지용 1Image('https://teddylee777.github.io/images/2020-01-09/decistion-tree.png', width=600) With Hyper-parameter Tuning 1234rfr_t = RandomForestRegressor(random_state=1, n_estimators=500, max_depth=7, max_features='sqrt')rfr_t.fit(x_train, y_train)rfr_t_pred = rfr_t.predict(x_test)mse_eval('RandomForest Ensemble w/ Tuning', y_test, rfr_t_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 7 RandomForest Ensemble 13.781191 8 RandomForest Ensemble w/ Tuning 11.481491 4-3. 부스팅 (Boosting) 참고 자료 (Blog) 악한 학습기를 순차적으로 학습을 하되, 이전 학습에 대하여 잘멋 예측된 데이터에 가중치를 부여해 오차를 보완해 나가는 방식이다. 장점 성능이 매우 우수하다 (LightGBM, XGBoost) 단점 부스팅 알고리즘의 특성상 계속 약점(오분류/잔차)을 보완하려고 하기 때문에 잘못된 레이블링이나 아웃라이어에 필요 이상으로 민감할 수 있다 다른 앙상블 대비 학습 시간이 오래걸린다는 단점이 존재 1Image('https://keras.io/img/graph-kaggle-1.jpeg', width=800) 대표적인 Boosting 앙상블 AdaBoost GradientBoost LightGBM (LGBM) XGBoost 4-3-1. Gradient Boost 장점: 성능이 우수함 단점: 학습 시간이 너무 오래 걸린다 [sklearn.ensemble.GradientBoostingRegressor] Document 1from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier 123# default value로 학습gbr = GradientBoostingRegressor(random_state=1)gbr.fit(x_train, y_train) GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse', init=None, learning_rate=0.1, loss='ls', max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_iter_no_change=None, presort='deprecated', random_state=1, subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0, warm_start=False) 12gbr_pred = gbr.predict(x_test)mse_eval('GradientBoost Ensemble', y_test, gbr_pred) model mse 0 Standard ElasticNet 26.010756 1 ElasticNet(l1_ratio=0.2) 24.481069 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 4 Lasso(alpha=0.01) 22.635614 5 Voting Ensemble 22.092158 6 Poly ElasticNet 20.805986 7 RandomForest Ensemble 13.781191 8 GradientBoost Ensemble 13.451877 9 RandomForest Ensemble w/ Tuning 11.481491 주요 Hyper-parameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. default=0.1 (n_estimators와 같이 튜닝해야 함) n_estimators: 부스팅 스테이지 수. default=100 (Random Forest 트리의 갯수 설정과 비슷) subsample: 샘플 사용 비율 (max_features와 비슷). 과대적합 방지용 min_samples_split: 노드 분할시 최소 샘플의 갯수. default=2. 과대적합 방지용 There’s a trade-off between learning_rate and n_estimators. 둘의 곱을 유지하는 것이 좋다 123456# with hyper-parameter tuning# learning_rate=0.01 (without tuning n_estimators together)gbr_t = GradientBoostingRegressor(random_state=1, learning_rate=0.01)gbr_t.fit(x_train, y_train)gbr_t_pred = gbr_t.predict(x_test)mse_eval('GradientBoost Ensemble w/ tuning (lr=0.01)', y_test, gbr_t_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 RandomForest Ensemble 13.781191 9 GradientBoost Ensemble 13.451877 10 RandomForest Ensemble w/ Tuning 11.481491 12345# tuning: learning_rate=0.01, n_estimators=1000gbr_t2 = GradientBoostingRegressor(random_state=1, learning_rate=0.01, n_estimators=1000)gbr_t2.fit(x_train, y_train)gbr_t2_pred = gbr_t2.predict(x_test)mse_eval('GradientBoost Ensemble w/ tuning (lr=0.01, est=1000)', y_test, gbr_t2_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 RandomForest Ensemble 13.781191 9 GradientBoost Ensemble 13.451877 10 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 11 RandomForest Ensemble w/ Tuning 11.481491 12345# tuning: learning_rate=0.01, n_estimators=1000, subsample=0.8gbr_t3 = GradientBoostingRegressor(random_state=42, learning_rate=0.01, n_estimators=1000, subsample=0.7)gbr_t3.fit(x_train, y_train)gbr_t3_pred = gbr_t3.predict(x_test)mse_eval('GradientBoost Ensemble w/ tuning (lr=0.01, est=1000, subsample=0.7)', y_test, gbr_t3_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 RandomForest Ensemble 13.781191 9 GradientBoost Ensemble 13.451877 10 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 12 RandomForest Ensemble w/ Tuning 11.481491 4-3-2. XGBoost eXtreme Gradient Boosting [XGBoost] Document 주요 특징 scikit-learn 패키지 아님 성능이 우수함 GBM보다는 빠르고 성능도 향상됨 여전히 학습 속도가 느림 1pip install xgboost Requirement already satisfied: xgboost in d:\\anaconda\\lib\\site-packages (1.1.1) Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.4.1) Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.18.1) Note: you may need to restart the kernel to use updated packages. 1from xgboost import XGBRegressor, XGBClassifier 123# default value로 학습xgb = XGBRegressor(random_state=1)xgb.fit(x_train, y_train) XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1, importance_type='gain', interaction_constraints='', learning_rate=0.300000012, max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0, num_parallel_tree=1, objective='reg:squarederror', random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact', validate_parameters=1, verbosity=None) 12xgb_pred = xgb.predict(x_test)mse_eval('XGBoost', y_test, xgb_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 13 RandomForest Ensemble w/ Tuning 11.481491 주요 Hyper-parameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1 n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 max_depth: 트리의 깊이. 과대적합 방지용. default=3. subsample: 샘플 사용 비율. 과대적합 방지용. default=1.0 max_features: 최대로 사용할 feature의 비율. 과대적합 방지용. default=1.0 12345# with hyeper-parameter tuningxgb_t = XGBRegressor(random_state=1, learning_rate=0.01, n_estimators=1000, subsample=0.7, max_features=0.8, max_depth=7)xgb_t.fit(x_train, y_train)xgb_t_pred = xgb_t.predict(x_test)mse_eval('XGBoost w/ Tuning', y_test, xgb_t_pred) [16:55:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: Parameters: { max_features } might not be used. This may not be accurate due to some parameters are only used in language bindings but passed down to XGBoost core. Or some parameters are not used but slip through this verification. Please open an issue if you find above cases. ​ ​ model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 13 XGBoost w/ Tuning 11.987602 14 RandomForest Ensemble w/ Tuning 11.481491 4-3-3. LightGBM [LightGBM] Document 주요 특징 scikit-learn 패키지가 아님 성능이 우수함 속도도 매우 빠름 1pip install lightgbm Requirement already satisfied: lightgbm in d:\\anaconda\\lib\\site-packages (2.3.1) Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.4.1) Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.18.1) Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (from lightgbm) (0.22.1) Requirement already satisfied: joblib&gt;=0.11 in d:\\anaconda\\lib\\site-packages (from scikit-learn-&gt;lightgbm) (0.14.1) Note: you may need to restart the kernel to use updated packages. 1from lightgbm import LGBMRegressor, LGBMClassifier 123# default value 로 학습lgbm = LGBMRegressor(random_state=1)lgbm.fit(x_train, y_train) LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, importance_type='split', learning_rate=0.1, max_depth=-1, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31, objective=None, random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0) 12lgbm_pred = lgbm.predict(x_test)mse_eval('LightGBM', y_test, lgbm_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 LightGBM 12.882170 13 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 14 XGBoost w/ Tuning 11.987602 15 RandomForest Ensemble w/ Tuning 11.481491 주요 Hyperparameter random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1 n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 max_depth: 트리의 깊이. 과대적합 방지용. default=3. colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0 12345# with hyper-parameter tuninglgbm_t = LGBMRegressor(random_state=1, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.9, subsample=0.7, max_depth=5)lgbm_t.fit(x_train, y_train)lgbm_t_pred = lgbm_t.predict(x_test)mse_eval('LightGBM w/ Tuning', y_test, lgbm_t_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 XGBoost 13.841454 9 RandomForest Ensemble 13.781191 10 GradientBoost Ensemble 13.451877 11 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 12 LightGBM 12.882170 13 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 14 LightGBM w/ Tuning 12.200040 15 XGBoost w/ Tuning 11.987602 16 RandomForest Ensemble w/ Tuning 11.481491 4-4. 스태킹 (Stacking) 개별 모델이 예측한 데이터를 기반으로 final_estimators 종합하여 예측을 수행 성능을 극으로 끌오올릴 때 활용하기도 함 과대적합을 유발할 수 있다. (특히, 데이터셋이 적은 경우) [sklearn.ensemble.StackingRegressor] Document 1from sklearn.ensemble import StackingRegressor 12345stack_models = [ ('elasticnet', poly_elasticnet), ('randomforest', rfr_t), ('lgbm', lgbm_t)] 1234stack_reg = StackingRegressor(stack_models, final_estimator=xgb, n_jobs=-1)stack_reg.fit(x_train, y_train)stack_pred = stack_reg.predict(x_test)mse_eval('Stacking Ensemble', y_test, stack_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 15 LightGBM w/ Tuning 12.200040 16 XGBoost w/ Tuning 11.987602 17 RandomForest Ensemble w/ Tuning 11.481491 4-5. Weighted Blending 각 모델의 예측값에 대하여 weight를 곱해혀 최종 output 산출 모델에 대한 가중치를 조절하여, 최종 output을 산출함 가중치의 합은 1.0이 되도록 설정 12345final_outputs = { 'randomforest': rfr_t_pred, 'xgboost': xgb_t_pred, 'lgbm': lgbm_t_pred} 1234final_prediction=\\final_outputs['randomforest'] * 0.5\\+final_outputs['xgboost'] * 0.3\\+final_outputs['lgbm'] * 0.2\\ 1mse_eval('Weighted Blending', y_test, final_prediction) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 15 LightGBM w/ Tuning 12.200040 16 XGBoost w/ Tuning 11.987602 17 RandomForest Ensemble w/ Tuning 11.481491 18 Weighted Blending 10.585610 4-6. 앙상블 모델 정리 앙상블은 대체적으로 단일 모델 대비 성능이 좋다 앙상블을 앙상블하는 기법인 Stacking과 Weighted Blending도 참고해 볼만 하다 앙상블 모델은 적절한 Hyper-parameter Tuning이 중요하다 앙상블 모델은 대체적으로 학습시간이 더 오래 걸린다 따라서, 모델 튜닝을 하는 데에 시간이 오래 소유된다 5. Cross Validation 5-1. Cross Validation 소개 Cross Validation 알아보기 참고 자료: 딥러닝 모델의 K-겹 교차검증 (K-fold Cross Validation) 전에 진행했던 실습에서도 보였듯이, Hyper-parameter의 값은 모델의 성능을 좌우한다. 그러므로 예측 모델의 성능을 높이기 위해, Hyper-parameter Tuning이 매우 중요하다. 이를 실현하기 위해 저희는 Training data을 다시 Training set과 Validation set으로 나눈다. Trainging set에서 Hyper-parameter값을 바뀌가면서 모델 학습하고, Validation set에서 모델의 성능을 평가하여, 모델 성능을 제일 높일 수 있는 Hyper-parameter값을 선택한다 하지만, 데이터의 일부만 Validation set으로 사용해 모델 성능을 평가하게 되면, 훈련된 모델이 Test set에 대한 성능 평가의 신뢰성이 떨어질 수 있다. 이를 방지하기 위해 **K-fold Cross Validation (K-겹 교차검증)**을 많이 활용한다 K겹 교차 검증은 모든 데이터가 최소 한 번은 validation set으로 쓰이도록 한다 (아래의 그림을 보면, 데이터를 5개로 쪼개 매번 validation set을 바꿔나가는 것을 볼 수 있다) K번 검증을 통해 구한 K 개의 평가지표 값을 평균 내어 모델 성능을 평가한다 [예시] Estimation 1일 때, Training set: [2, 3, 4, 5] / Validation set: [1] Estimation 2일 때, Training set: [1, 3, 4, 5] / Validation set: [2] 1from sklearn.model_selection import KFold 12n_splits = 5kfold = KFold(n_splits=n_splits, random_state=1, shuffle = True) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 36.2 12X = np.array(df.drop('MEDV', 1))Y = np.array(df['MEDV']) 1lgbm_fold = LGBMRegressor(random_state=1) 123456789101112i = 1total_error = 0for train_index, test_index in kfold.split(X): x_train_fold, x_test_fold = X[train_index], X[test_index] y_train_fold, y_test_fold = Y[train_index], Y[test_index] lgbm_fold_pred = lgbm_fold.fit(x_train_fold, y_train_fold).predict(x_test_fold) error = mean_squared_error(y_test_fold, lgbm_fold_pred) print('Fold = {}, prediction score = {:.2f}'.format(i, error)) total_error += error i+=1print('---'*10)print('Average Error: %s' % (total_error / n_splits)) Fold = 1, prediction score = 9.76 Fold = 2, prediction score = 20.58 Fold = 3, prediction score = 6.95 Fold = 4, prediction score = 12.18 Fold = 5, prediction score = 10.87 ------------------------------ Average Error: 12.06743160435072 5-2. Hyper-parameter 튜닝 Hyper-parameter 튜닝 시 경우의 수가 너무 많으므로 우리는 자동화할 틸요가 있다 sklearn 패키지에서 자주 사용되는 hyper-parameter 튜닝을 돕는 클래스는 다음 2가지가 있다: RandomizedSerchCV GridSerchCV 적용하는 방법 사용할 Search 방법을 선택한다 hyper-parameter 도메인(값의 범위)을 설정한다 (max_depth, n_estimators… 등등) 학습을 시킨 후, 기다린다 도출된 결과 값을 모델에 적용하고 성능을 비교한다 (1) RandomizedSearchCV 모든 매개 변수 값이 시도되는 것이 아니라 지정된 분포에서 고정 된 수의 매개 변수 설정이 샘플링된다. 시도 된 매개 변수 설정의 수는 n_iter에 의해 제공됨. 주요 Hyper-parameter (LGBM) random_state: random seed 고정 값 n_jobs: CPU 사용 갯수 learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1 n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 max_depth: 트리의 깊이. 과대적합 방지용. default=3. colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0 1234567params = { 'learning_rate': [0.005, 0.01, 0.03, 0.05], 'n_estimators': [500, 1000, 2000, 3000], 'max_depth': [3, 5, 7], 'colsample_bytree': [0.8, 0.9, 1.0], 'subsample': [0.7, 0.8, 0.9, 1.0],} 1from sklearn.model_selection import RandomizedSearchCV 조절하여, 총 몇 회의 시도를 진행할 것인자 정의한다 12345(회수가 늘어나면, 더 좋은 parameter를 찾을 확률은 올라가지만, 그만큼 시간이 오래걸린다.)```pythonrcv_lgbm = RandomizedSearchCV(LGBMRegressor(), params, random_state=1, cv=5, n_iter=100, scoring='neg_mean_squared_error') 1rcv_lgbm.fit(x_train, y_train) RandomizedSearchCV(cv=5, error_score=nan, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, importance_type='split', learning_rate=0.1, max_depth=-1, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31, objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silen... subsample_freq=0), iid='deprecated', n_iter=100, n_jobs=None, param_distributions={'colsample_bytree': [0.8, 0.9, 1.0], 'learning_rate': [0.005, 0.01, 0.03, 0.05], 'max_depth': [3, 5, 7], 'n_estimators': [500, 1000, 2000, 3000], 'subsample': [0.7, 0.8, 0.9, 1.0]}, pre_dispatch='2*n_jobs', random_state=1, refit=True, return_train_score=False, scoring='neg_mean_squared_error', verbose=0) 1rcv_lgbm.best_score_ -11.132039701508374 1rcv_lgbm.best_params_ {'subsample': 0.8, 'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.9} 123lgbm_best = LGBMRegressor(learning_rate=0.05, n_estimators=1000, subsample=0.8, max_depth=3, colsample_bytree=0.9)lgbm_best_pred = lgbm_best.fit(x_train, y_train).predict(x_test)mse_eval('RandomSearch LGBM', y_test, lgbm_best_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 RandomSearch LGBM 12.661917 15 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 16 LightGBM w/ Tuning 12.200040 17 XGBoost w/ Tuning 11.987602 18 RandomForest Ensemble w/ Tuning 11.481491 19 Weighted Blending 10.585610 (2) GridSerchCV 모든 매개 변수 값에 대하여 완전 탐색을 시도한다 따라서, 최적화할 parameter가 많다면, 시간이 매우 오래걸린다 1234567params = { 'learning_rate': [0.04, 0.05, 0.06], 'n_estimators': [800, 1000, 1200], 'max_depth': [3, 4, 5], 'colsample_bytree': [0.8, 0.85, 0.9], 'subsample': [0.8, 0.85, 0.9],} 1from sklearn.model_selection import GridSearchCV 1grid_search = GridSearchCV(LGBMRegressor(), params, cv=5, n_jobs=-1, scoring='neg_mean_squared_error') 1grid_search.fit(x_train, y_train) GridSearchCV(cv=5, error_score=nan, estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, importance_type='split', learning_rate=0.1, max_depth=-1, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31, objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0), iid='deprecated', n_jobs=-1, param_grid={'colsample_bytree': [0.8, 0.85, 0.9], 'learning_rate': [0.04, 0.05, 0.06], 'max_depth': [3, 4, 5], 'n_estimators': [800, 1000, 1200], 'subsample': [0.8, 0.85, 0.9]}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='neg_mean_squared_error', verbose=0) 1grid_search.best_score_ -11.10039780445118 1grid_search.best_params_ {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 800, 'subsample': 0.8} 123lgbm_best = LGBMRegressor(learning_rate=0.05, n_estimators=800, subsample=0.8, max_depth=3, colsample_bytree=0.9)lgbm_best_pred = lgbm_best.fit(x_train, y_train).predict(x_test)mse_eval('GridSearch LGBM', y_test, lgbm_best_pred) model mse 0 Standard ElasticNet 26.010756 1 GradientBoost Ensemble w/ tuning (lr=0.01) 24.599441 2 ElasticNet(l1_ratio=0.2) 24.481069 3 LinearRegression 22.770784 4 Ridge(alpha=1) 22.690411 5 Lasso(alpha=0.01) 22.635614 6 Voting Ensemble 22.092158 7 Poly ElasticNet 20.805986 8 Stacking Ensemble 16.906090 9 XGBoost 13.841454 10 RandomForest Ensemble 13.781191 11 GradientBoost Ensemble 13.451877 12 GradientBoost Ensemble w/ tuning (lr=0.01, est... 13.002472 13 LightGBM 12.882170 14 GridSearch LGBM 12.794172 15 RandomSearch LGBM 12.661917 16 GradientBoost Ensemble w/ tuning (lr=0.01, est... 12.607717 17 LightGBM w/ Tuning 12.200040 18 XGBoost w/ Tuning 11.987602 19 RandomForest Ensemble w/ Tuning 11.481491 20 Weighted Blending 10.585610 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"앙상블","slug":"앙상블","permalink":"https://hyemin-kim.github.io/tags/%EC%95%99%EC%83%81%EB%B8%94/"}]},{"title":"Python >> sklearn - (3) 회귀 (Regression)","slug":"S-Python-sklearn3","date":"2020-07-29T09:53:05.000Z","updated":"2020-07-29T10:16:41.634Z","comments":true,"path":"2020/07/29/S-Python-sklearn3/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/29/S-Python-sklearn3/","excerpt":"","text":"회귀 (Regression) 예측 0. 데이터 셋 0-1. 데이터 로드 0-2. 데이터프레임 만들기 1. Training set / Test set 나누기 2. 평가 지표 만들기 2-1. 평가 지표 계산식 2-2. 코딩으로 평가 지표 만들어 보기 2-3. sklearn의 평가 지표 활용하기 2-4. 모델 성능 확인을 위한 함수 3. 회귀 알고리즘 3-1. Linear Regression 3-2. Ridge &amp; LASSO &amp; ElasticNet (1) 개념 (2) 실습 4. Scaling 4-1. Scaler 소개 4-2. Scaling 후 모델 학습 – 파이프라인 활용 5. Polynomial Features [Supervised Learning] Document 특성: 수치형 값을 예측 (Y의 값이 연속형 수치로 표현) 예시: 주택 가격 예측 매출앵 예측 0. 데이터 셋 1234import pandas as pdimport numpy as npnp.set_printoptions(suppress=True) # If True, print floating point numbers instead of scientific notation 1from sklearn.datasets import load_boston [Boston Dataset] 0-1. 데이터 로드 1data = load_boston() 1print(data['DESCR']) # data description .. _boston_dataset: Boston house prices dataset --------------------------- **Data Set Characteristics:** :Number of Instances: 506 :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target. :Attribute Information (in order): - CRIM per capita crime rate by town - ZN proportion of residential land zoned for lots over 25,000 sq.ft. - INDUS proportion of non-retail business acres per town - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) - NOX nitric oxides concentration (parts per 10 million) - RM average number of rooms per dwelling - AGE proportion of owner-occupied units built prior to 1940 - DIS weighted distances to five Boston employment centres - RAD index of accessibility to radial highways - TAX full-value property-tax rate per $10,000 - PTRATIO pupil-teacher ratio by town - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town - LSTAT % lower status of the population - MEDV Median value of owner-occupied homes in $1000's :Missing Attribute Values: None :Creator: Harrison, D. and Rubinfeld, D.L. This is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/machine-learning-databases/housing/ ​ This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics &amp; Management, vol.5, 81-102, 1978. Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics ...', Wiley, 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter. The Boston house-price data has been used in many machine learning papers that address regression problems. .. topic:: References - Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261. - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann. ​ 0-2. 데이터프레임 만들기 1234567# step 1. features (X)# data['data'] - feature data; data['feature_names'] - feature column namesdf = pd.DataFrame(data['data'], columns = data['feature_names'])# step 2. target (y) 추가 df['MEDV'] = data['target'] 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 24.0 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 21.6 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 34.7 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 33.4 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 36.2 컬럼 소게 (feature 13 + target 1): CRIM: 범죄율 ZN: 25,000 square feet 당 주거용 토지의 비율 INDUS: 비소매(non-retail) 비즈니스 면적 비율 CHAS: 찰스 강 더미 변수 (통로가 하천을 향하면 1; 그렇지 않으면 0) NOX: 산화 질소 농도 (천만 분의 1) RM:주거 당 평균 객실 수 AGE: 1940 년 이전에 건축된 자가 소유 점유 비율 DIS: 5 개의 보스턴 고용 센터까지의 가중 거리 RAD: 고속도로 접근성 지수 TAX: 10,000 달러 당 전체 가치 재산 세율 PTRATIO 도시 별 학생-교사 비율 B: 1000 (Bk-0.63) ^ 2 여기서 Bk는 도시 별 검정 비율입니다. LSTAT: 인구의 낮은 지위 MEDV: 자가 주택의 중앙값 (1,000 달러 단위) 1. Training set / Test set 나누기 1from sklearn.model_selection import train_test_split 1x_train, x_test, y_train, y_test = train_test_split(df.drop('MEDV', 1), df['MEDV'], random_state=23) 1x_train.shape, y_train.shape ((379, 13), (379,)) 1x_test.shape, y_test.shape ((127, 13), (127,)) 1x_train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 112 0.12329 0.0 10.01 0.0 0.547 5.913 92.9 2.3534 6.0 432.0 17.8 394.95 16.21 301 0.03537 34.0 6.09 0.0 0.433 6.590 40.4 5.4917 7.0 329.0 16.1 395.75 9.50 401 14.23620 0.0 18.10 0.0 0.693 6.343 100.0 1.5741 24.0 666.0 20.2 396.90 20.32 177 0.05425 0.0 4.05 0.0 0.510 6.315 73.4 3.3175 5.0 296.0 16.6 395.60 6.29 69 0.12816 12.5 6.07 0.0 0.409 5.885 33.0 6.4980 4.0 345.0 18.9 396.90 8.79 1y_train.head() 112 18.8 301 22.0 401 7.2 177 24.6 69 20.9 Name: MEDV, dtype: float64 2. 평가 지표 만들기 2-1. 평가 지표 계산식 (1) MAE (Mean Absolute Error) MAE (평균 절대 오차): 에측값과 실제값의 차이의 절대값에 대하여 평균을 낸 것 MAE=1n∑i=1n∣yi−yi^∣MAE = \\frac{1}{n} \\sum_{i=1}^n \\left\\vert y_i - \\widehat{y_i} \\right\\vert MAE=n1​i=1∑n​∣yi​−yi​​∣ (2) MSE (Mean Squared Error) MSE (평균 제곱 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 것 MSE=1n∑i=1n(yi−yi^)2MSE = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2 MSE=n1​i=1∑n​(yi​−yi​​)2 (3) RMSE (Root Mean Squared Error) RMSE (평균 제곱근 오차): 예측값과 실제값의 차이의 제곱에 대하여 평균을 낸 뒤 루트를 씌운 것 RMSE=1n∑i=1n(yi−yi^)2RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\widehat{y_i} \\right)^2} RMSE=n1​i=1∑n​(yi​−yi​​)2​ 2-2. 코딩으로 평가 지표 만들어 보기 1import numpy as np 12actual = np.array([1, 2, 3])pred = np.array([3, 4, 5]) 12345# MAEdef my_mae(actual, pred): return np.abs(actual - pred).mean()my_mae(actual, pred) 2.0 12345# MSEdef my_mse(actual, pred): return ((actual - pred)**2).mean()my_mse(actual, pred) 4.0 12345# RMSEdef my_rmse(actual, pred): return np.sqrt(my_mse(actual, pred))my_rmse(actual, pred) 2.0 2-3. sklearn의 평가 지표 활용하기 1from sklearn.metrics import mean_absolute_error, mean_squared_error [sklearn.metrics.mean_absolute_error] [sklearn.metrics.mean_squared_error] 12# MAE (my_mae VS sklearn_mae)my_mae(actual, pred), mean_absolute_error(actual, pred) (2.0, 2.0) 12# MSE (my_mse VS sklearn_mse)my_mse(actual, pred), mean_squared_error(actual, pred) (4.0, 4.0) 2-4. 모델 성능 확인을 위한 함수 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import matplotlib.pyplot as pltimport seaborn as snsmy_predictions = {}colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown', 'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick', 'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', 'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate', 'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', 'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato' ]# prediction plotdef plot_predictions(name_, actual, pred): df = pd.DataFrame({'actual': y_test, 'prediction': pred}) df = df.sort_values(by='actual').reset_index(drop=True) plt.figure(figsize=(12, 9)) plt.scatter(df.index, df['prediction'], marker='x', color='r') plt.scatter(df.index, df['actual'], alpha=0.7, marker='o', color='black') plt.title(name_, fontsize=15) plt.legend(['prediction', 'actual'], fontsize=12) plt.show()# evaluation plotdef mse_eval(name_, actual, pred): global predictions global colors plot_predictions(name_, actual, pred) mse = mean_squared_error(actual, pred) my_predictions[name_] = mse y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True) df = pd.DataFrame(y_value, columns=['model', 'mse']) print(df) min_ = df['mse'].min() - 10 max_ = df['mse'].max() + 10 length = len(df) plt.figure(figsize=(10, length)) ax = plt.subplot() ax.set_yticks(np.arange(len(df))) ax.set_yticklabels(df['model'], fontsize=15) bars = ax.barh(np.arange(len(df)), df['mse']) for i, v in enumerate(df['mse']): idx = np.random.choice(len(colors)) bars[i].set_color(colors[idx]) ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold') plt.title('MSE Error', fontsize=18) plt.xlim(min_, max_) plt.show()# remove modeldef remove_model(name_): global my_predictions try: del my_predictions[name_] except KeyError: return False return True 3. 회귀 알고리즘 3-1. Linear Regression [sklearn.linear_model.LinearRegression] Document 1from sklearn.linear_model import LinearRegression 123model = LinearRegression(n_jobs=-1) # n_jobs: CPU코어의 사용model.fit(x_train, y_train)pred = model.predict(x_test) 1mse_eval('LinearRegression', y_test, pred) model mse 0 LinearRegression 22.770784 3-2. Ridge &amp; LASSO &amp; ElasticNet (1) 개념 참고 규제(Regularization): 학습이 과적합 되는 것을 방지하고자 일종의 penalty를 부여하는 것. [원리] penalty를 부여하여 가중치(β\\betaβ)를 축소함으로써 학습 모델의 예측 variance를 감소 시키는 것 &gt;&gt; L2 규제 &amp; Ridge (릿지) L2 규제 (L2 Regularization): 각 가중치 제곱의 합에 규제 강도 (Regularization Strength) λ\\lambdaλ 를 곱한다 L2&nbsp;규제=λ∑j=1pβj2=λ&nbsp;∥β∥22L2 \\ 규제 = \\lambda \\sum_{j=1}^p \\beta_j^2 = \\lambda\\ \\lVert \\beta \\rVert_2^2 L2&nbsp;규제=λj=1∑p​βj2​=λ&nbsp;∥β∥22​ l2&nbsp;norm:∥β∥2=∑j=1pβj2l_2 \\ norm: \\lVert \\beta \\rVert_2 = \\sqrt{\\sum_{j=1}^p \\beta_j^2} l2​&nbsp;norm:∥β∥2​=j=1∑p​βj2​​ Ridge: Loss Function에 L2 규제를 더한 값을 최소화 시키는 것 min⁡βj&nbsp;[∑i=1n(yi−β0−∑j=1pβjxij)+λ&nbsp;∑j=1pβj2]=min⁡βj&nbsp;[RSS+λ&nbsp;∑j=1pβj2]\\min_{\\beta_j} \\ \\left[ \\sum_{i=1}^n \\left( y_i-\\beta_0-\\sum_{j=1}^p\\beta_jx_{ij} \\right) + \\lambda\\ \\sum_{j=1}^p\\beta_j^2 \\right]= \\min_{\\beta_j} \\ \\left[ RSS + \\lambda\\ \\sum_{j=1}^p\\beta_j^2 \\right] βj​min​&nbsp;[i=1∑n​(yi​−β0​−j=1∑p​βj​xij​)+λ&nbsp;j=1∑p​βj2​]=βj​min​&nbsp;[RSS+λ&nbsp;j=1∑p​βj2​] λ\\lambdaλ 를 크게 하면 가중치(β\\betaβ) 가 더 많이 감소되고(규제를 중요시 함), λ\\lambdaλ 를 작게 하면 가중치(β\\betaβ) 가 증가한다(규제를 중요시하지 않음) &gt;&gt; L1 규제 &amp; LASSO (라쏘) L1 규제 (L1 Regularization): 각 가중치 절대값의 합에 규제 강도 (Regularization Strength) λ\\lambdaλ 를 곱한다 L1&nbsp;규제=λ∑j=1p∣βj∣=λ&nbsp;∥β∥1L1\\ 규제 = \\lambda \\sum_{j=1}^p \\left| \\beta_j \\right| = \\lambda \\ \\lVert \\beta \\rVert_1 L1&nbsp;규제=λj=1∑p​∣βj​∣=λ&nbsp;∥β∥1​ l1&nbsp;norm:∥β∥1=∑j=1p∣βj∣l1\\ norm: \\lVert \\beta \\rVert_1 = \\sum_{j=1}^p \\left| \\beta_j \\right| l1&nbsp;norm:∥β∥1​=j=1∑p​∣βj​∣ LASSO: Loss Function에 L1 규제를 더한 값을 최소화 시키는 것 min⁡βj&nbsp;[∑i=1n(yi−β0−∑j=1pβjxij)+λ∑j=1p∣βj∣]=min⁡βj&nbsp;[RSS+λ∑j=1p∣βj∣]\\min_{\\beta_j} \\ \\left[ \\sum_{i=1}^n \\left( y_i-\\beta_0-\\sum_{j=1}^p\\beta_jx_{ij} \\right) + \\lambda \\sum_{j=1}^p \\left| \\beta_j \\right| \\right]= \\min_{\\beta_j} \\ \\left[ RSS + \\lambda \\sum_{j=1}^p \\left| \\beta_j \\right| \\right] βj​min​&nbsp;[i=1∑n​(yi​−β0​−j=1∑p​βj​xij​)+λj=1∑p​∣βj​∣]=βj​min​&nbsp;[RSS+λj=1∑p​∣βj​∣] 어떤 가중치(β\\betaβ) 는 실제로 0이 된다. 즉, 모델에서 완전히 제외되는 특성이 생기는 것이다 &gt;&gt; ElasticNet l1_ratio (default=0.5) l1_ratio = 0 (L2 규제만 사용) l1_ratio = 1 (L1 규제만 사용) 0 &lt; l1_ratio &lt;1 (L1 and L2 규제 혼합사용) (2) 실습 &gt;&gt; Ridge [Document] 1from sklearn.linear_model import Ridge 예측 결과 확인 123456789# lambda (규제강도) 범위 설정alphas = [100, 10, 1, 0.1, 0.01, 0.001]# 모델 학습for alpha in alphas: ridge = Ridge(alpha = alpha) ridge.fit(x_train, y_train) ridge_pred = ridge.predict(x_test) mse_eval('Ridge(alpha={})'.format(alpha), y_test, ridge_pred) model mse 0 Ridge(alpha=100) 23.487453 1 LinearRegression 22.770784 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=1) 22.690411 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=0.1) 22.718126 4 Ridge(alpha=1) 22.690411 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=0.01) 22.764254 4 Ridge(alpha=0.1) 22.718126 5 Ridge(alpha=1) 22.690411 model mse 0 Ridge(alpha=100) 23.487453 1 Ridge(alpha=10) 22.793119 2 LinearRegression 22.770784 3 Ridge(alpha=0.001) 22.770117 4 Ridge(alpha=0.01) 22.764254 5 Ridge(alpha=0.1) 22.718126 6 Ridge(alpha=1) 22.690411 coefficents 값 확인 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1ridge.coef_ # for the last alpha in 'alphas' array([ -0.09608448, 0.04753482, 0.0259022 , 3.24479273, -18.89579975, 4.06725732, 0.0020486 , -1.46883742, 0.28149275, -0.0094656 , -0.87454099, 0.01240815, -0.52406249]) 1234567891011121314# coefficients visulizationdef plot_coef(columns, coef): coef_df = pd.DataFrame(list(zip(columns, coef))) coef_df.columns=['feature', 'coef'] coef_df = coef_df.sort_values('coef', ascending=False).reset_index(drop=True) fig, ax = plt.subplots(figsize=(9, 7)) ax.barh(np.arange(len(coef_df)), coef_df['coef']) idx = np.arange(len(coef_df)) ax.set_yticks(idx) ax.set_yticklabels(coef_df['feature']) fig.tight_layout() plt.show() 1plot_coef(x_train.columns, ridge.coef_) # alpha = 0.001 alpha 값에 따른 coef의 차이 1234567ridge_1 = Ridge(alpha=1)ridge_1.fit(x_train, y_train)ridge_pred_1 = ridge_1.predict(x_test)ridge_100 = Ridge(alpha=100)ridge_100.fit(x_train, y_train)ridge_pred_100 = ridge_100.predict(x_test) 1plot_coef(x_train.columns, ridge_1.coef_) # alpha = 1 1plot_coef(x_train.columns, ridge_100.coef_) # alpha = 100 &gt;&gt; LASSO [Document] 1from sklearn.linear_model import Lasso 예측 결과 확인 123456789# lambda (규제강도) 범위 설정alphas = [100, 10, 1, 0.1, 0.01, 0.001]# 모델 학습for alpha in alphas: lasso = Lasso(alpha=alpha) lasso.fit(x_train, y_train) lasso_pred = lasso.predict(x_test) mse_eval('Lasso(alpha={})'.format(alpha), y_test, lasso_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Ridge(alpha=100) 23.487453 2 Ridge(alpha=10) 22.793119 3 LinearRegression 22.770784 4 Ridge(alpha=0.001) 22.770117 5 Ridge(alpha=0.01) 22.764254 6 Ridge(alpha=0.1) 22.718126 7 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Ridge(alpha=100) 23.487453 3 Ridge(alpha=10) 22.793119 4 LinearRegression 22.770784 5 Ridge(alpha=0.001) 22.770117 6 Ridge(alpha=0.01) 22.764254 7 Ridge(alpha=0.1) 22.718126 8 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Ridge(alpha=10) 22.793119 5 LinearRegression 22.770784 6 Ridge(alpha=0.001) 22.770117 7 Ridge(alpha=0.01) 22.764254 8 Ridge(alpha=0.1) 22.718126 9 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Ridge(alpha=0.1) 22.718126 10 Ridge(alpha=1) 22.690411 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Ridge(alpha=0.1) 22.718126 10 Ridge(alpha=1) 22.690411 11 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Lasso(alpha=0.001) 22.753017 10 Ridge(alpha=0.1) 22.718126 11 Ridge(alpha=1) 22.690411 12 Lasso(alpha=0.01) 22.635614 coefficients 값 확인 123456789# alpha = 0.01lasso_01 = Lasso(alpha=0.01)lasso_01.fit(x_train, y_train)lasso_pred_01 = lasso_01.predict(x_test)# alpha = 100lasso_100 = Lasso(alpha=100)lasso_100.fit(x_train, y_train)lasso_pred_100 = lasso_100.predict(x_test) [alpha = 0.01] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1lasso_01.coef_ array([ -0.09427142, 0.04759954, 0.01255668, 3.08256139, -15.36800113, 4.07373679, -0.00100439, -1.40819927, 0.27152905, -0.0097157 , -0.84377679, 0.01249204, -0.52790174]) 1plot_coef(x_train.columns, lasso_01.coef_) [alpha = 100] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1lasso_100.coef_ array([-0. , 0. , -0. , 0. , -0. , 0. , -0. , 0. , -0. , -0.02078349, -0. , 0.00644409, -0. ]) 1plot_coef(x_train.columns, lasso_100.coef_) &gt;&gt; ElasticNet [Document] 1from sklearn.linear_model import ElasticNet 예측 결과 확인 1ratios = [0.2, 0.5, 0.8] 1234567# alpha = 0.5 로 고정for ratio in ratios: elasticnet = ElasticNet(alpha=0.1, l1_ratio=ratio) elasticnet.fit(x_train, y_train) elas_pred = elasticnet.predict(x_test) mse_eval('ElasticNet(l1_ratio={})'.format(ratio), y_test, elas_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 LinearRegression 22.770784 7 Ridge(alpha=0.001) 22.770117 8 Ridge(alpha=0.01) 22.764254 9 Lasso(alpha=0.001) 22.753017 10 ElasticNet(l1_ratio=0.2) 22.749018 11 Ridge(alpha=0.1) 22.718126 12 Ridge(alpha=1) 22.690411 13 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 Ridge(alpha=10) 22.793119 6 ElasticNet(l1_ratio=0.5) 22.787269 7 LinearRegression 22.770784 8 Ridge(alpha=0.001) 22.770117 9 Ridge(alpha=0.01) 22.764254 10 Lasso(alpha=0.001) 22.753017 11 ElasticNet(l1_ratio=0.2) 22.749018 12 Ridge(alpha=0.1) 22.718126 13 Ridge(alpha=1) 22.690411 14 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 ElasticNet(l1_ratio=0.8) 22.865628 6 Ridge(alpha=10) 22.793119 7 ElasticNet(l1_ratio=0.5) 22.787269 8 LinearRegression 22.770784 9 Ridge(alpha=0.001) 22.770117 10 Ridge(alpha=0.01) 22.764254 11 Lasso(alpha=0.001) 22.753017 12 ElasticNet(l1_ratio=0.2) 22.749018 13 Ridge(alpha=0.1) 22.718126 14 Ridge(alpha=1) 22.690411 15 Lasso(alpha=0.01) 22.635614 coefficients 값 확인 123456789# ㅣ1_ratio = 0.2elasticnet_2 = ElasticNet(alpha = 0.1, l1_ratio = 0.2)elasticnet_2.fit(x_train, y_train)elast_pred_2 = elasticnet_2.predict(x_test)# l1_ratio = 0.8elasticnet_8 = ElasticNet(alpha=0.1, l1_ratio = 0.8)elasticnet_8.fit(x_train, y_train)elast_pred_8 = elasticnet_8.predict(x_test) [ l1_ratio = 0.2 ] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1elasticnet_2.coef_ array([-0.09297585, 0.05293361, -0.03950412, 1.30126199, -0.41996826, 3.15838796, -0.00644646, -1.15290012, 0.25973467, -0.01231233, -0.77186571, 0.01201684, -0.60780037]) 1plot_coef(x_train.columns, elasticnet_2.coef_) [ l1_ratio = 0.8 ] 1x_train.columns Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='object') 1elasticnet_8.coef_ array([-0.08797633, 0.05035601, -0.03058513, 1.51071961, -0. , 3.70247373, -0.01017259, -1.12431077, 0.24389841, -0.01189981, -0.73481448, 0.01259147, -0.573733 ]) 1plot_coef(x_train.columns, elasticnet_8.coef_) 4. Scaling 4-1. Scaler 소개 StandardScaler MinMaxScaler RobustScaler 1from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler 1x_train.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT count 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 379.000000 mean 3.512192 11.779683 10.995013 0.076517 0.548712 6.266953 67.223483 3.917811 9.282322 404.680739 18.448549 357.048100 12.633773 std 8.338717 23.492842 6.792065 0.266175 0.115006 0.681796 28.563787 2.084167 8.583051 166.813256 2.154917 92.745266 7.259213 min 0.006320 0.000000 0.460000 0.000000 0.385000 3.561000 2.900000 1.129600 1.000000 188.000000 12.600000 2.520000 1.730000 25% 0.078910 0.000000 5.190000 0.000000 0.445000 5.876500 42.250000 2.150900 4.000000 278.000000 17.150000 375.425000 6.910000 50% 0.228760 0.000000 9.690000 0.000000 0.532000 6.208000 74.400000 3.414500 5.000000 330.000000 19.000000 392.110000 11.380000 75% 2.756855 19.000000 18.100000 0.000000 0.624000 6.611000 93.850000 5.400900 8.000000 666.000000 20.200000 396.260000 16.580000 max 73.534100 100.000000 27.740000 1.000000 0.871000 8.398000 100.000000 10.585700 24.000000 711.000000 22.000000 396.900000 37.970000 &gt;&gt; StandardScaler 평균(mean)을 0, 표준편차(std)를 1로 만들어 주는 scaler 123std_scaler = StandardScaler()std_scaled = std_scaler.fit_transform(x_train)round(pd.DataFrame(std_scaled).describe(), 2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 8 9 10 11 12 count 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 mean -0.00 0.00 0.00 -0.00 -0.00 -0.00 -0.00 0.00 -0.00 0.00 0.00 0.00 0.00 std 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 min -0.42 -0.50 -1.55 -0.29 -1.43 -3.97 -2.25 -1.34 -0.97 -1.30 -2.72 -3.83 -1.50 25% -0.41 -0.50 -0.86 -0.29 -0.90 -0.57 -0.88 -0.85 -0.62 -0.76 -0.60 0.20 -0.79 50% -0.39 -0.50 -0.19 -0.29 -0.15 -0.09 0.25 -0.24 -0.50 -0.45 0.26 0.38 -0.17 75% -0.09 0.31 1.05 -0.29 0.66 0.51 0.93 0.71 -0.15 1.57 0.81 0.42 0.54 max 8.41 3.76 2.47 3.47 2.81 3.13 1.15 3.20 1.72 1.84 1.65 0.43 3.49 &gt;&gt; MinMaxScaler min값과 max값을 0~1사이로 정규화 (Normalize) 123minmax_scaler = MinMaxScaler()minmax_scaled = minmax_scaler.fit_transform(x_train)round(pd.DataFrame(minmax_scaled).describe(), 2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 8 9 10 11 12 count 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 379.00 mean 0.05 0.12 0.39 0.08 0.34 0.56 0.66 0.29 0.36 0.41 0.62 0.90 0.30 std 0.11 0.23 0.25 0.27 0.24 0.14 0.29 0.22 0.37 0.32 0.23 0.24 0.20 min 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 25% 0.00 0.00 0.17 0.00 0.12 0.48 0.41 0.11 0.13 0.17 0.48 0.95 0.14 50% 0.00 0.00 0.34 0.00 0.30 0.55 0.74 0.24 0.17 0.27 0.68 0.99 0.27 75% 0.04 0.19 0.65 0.00 0.49 0.63 0.94 0.45 0.30 0.91 0.81 1.00 0.41 max 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 &gt;&gt; RobustScaler 중앙값(median)이 0, IQR(interquartile rage)이 1이 되도록 변환 outlier 처리에 유용 123robust_scaler = RobustScaler()robust_scaled = robust_scaler.fit_transform(x_train)round(pd.DataFrame(robust_scaled).median(), 2) 0 0.0 1 0.0 2 0.0 3 0.0 4 0.0 5 0.0 6 0.0 7 0.0 8 0.0 9 0.0 10 0.0 11 0.0 12 0.0 dtype: float64 4-2. Scaling 후 모델 학습 – 파이프라인 활용 1from sklearn.pipeline import make_pipeline 1234567891011121314# elasticnet(alpha=0.1, l1_ratio=0.2) &lt; without standard scaling &gt;elasticnet_no_scale = ElasticNet(alpha=0.1, l1_ratio=0.2)no_scale_pred = elasticnet_no_scale.fit(x_train, y_train).predict(x_test)mse_eval('No Standard ElasticNet', y_test, no_scale_pred)# elasticnet(alpha=0.1, l1_ratio=0.2) &lt; with standard scaling &gt;elasticnet_pipeline = make_pipeline( StandardScaler(), ElasticNet(alpha=0.1, l1_ratio=0.2))with_scale_pred = elasticnet_pipeline.fit(x_train, y_train).predict(x_test)mse_eval('With Standard ElasticNet', y_test, with_scale_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 Lasso(alpha=0.1) 22.979708 5 ElasticNet(l1_ratio=0.8) 22.865628 6 Ridge(alpha=10) 22.793119 7 ElasticNet(l1_ratio=0.5) 22.787269 8 LinearRegression 22.770784 9 Ridge(alpha=0.001) 22.770117 10 Ridge(alpha=0.01) 22.764254 11 Lasso(alpha=0.001) 22.753017 12 ElasticNet(l1_ratio=0.2) 22.749018 13 No Standard ElasticNet 22.749018 14 Ridge(alpha=0.1) 22.718126 15 Ridge(alpha=1) 22.690411 16 Lasso(alpha=0.01) 22.635614 model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 With Standard ElasticNet 23.230164 5 Lasso(alpha=0.1) 22.979708 6 ElasticNet(l1_ratio=0.8) 22.865628 7 Ridge(alpha=10) 22.793119 8 ElasticNet(l1_ratio=0.5) 22.787269 9 LinearRegression 22.770784 10 Ridge(alpha=0.001) 22.770117 11 Ridge(alpha=0.01) 22.764254 12 Lasso(alpha=0.001) 22.753017 13 ElasticNet(l1_ratio=0.2) 22.749018 14 No Standard ElasticNet 22.749018 15 Ridge(alpha=0.1) 22.718126 16 Ridge(alpha=1) 22.690411 17 Lasso(alpha=0.01) 22.635614 5. Polynomial Features [Document] 다항식의 계수간 상호작용을 통해 새로운 feature를 생성한다. 예를 들면, [a, b] 2개의 feature가 존재한다고 가정하고, degree=2로 설정한다면, polynomial features 는 [1, a, b, a^2, ab, b^2]가 돤다 1from sklearn.preprocessing import PolynomialFeatures Polynomial Features 생성 1poly = PolynomialFeatures(degree=2, include_bias=False) 12poly_features = poly.fit_transform(x_train)[0]poly_features array([ 0.12329 , 0. , 10.01 , 0. , 0.547 , 5.913 , 92.9 , 2.3534 , 6. , 432. , 17.8 , 394.95 , 16.21 , 0.01520042, 0. , 1.2341329 , 0. , 0.06743963, 0.72901377, 11.453641 , 0.29015069, 0.73974 , 53.26128 , 2.194562 , 48.6933855 , 1.9985309 , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 100.2001 , 0. , 5.47547 , 59.18913 , 929.929 , 23.557534 , 60.06 , 4324.32 , 178.178 , 3953.4495 , 162.2621 , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.299209 , 3.234411 , 50.8163 , 1.2873098 , 3.282 , 236.304 , 9.7366 , 216.03765 , 8.86687 , 34.963569 , 549.3177 , 13.9156542 , 35.478 , 2554.416 , 105.2514 , 2335.33935 , 95.84973 , 8630.41 , 218.63086 , 557.4 , 40132.8 , 1653.62 , 36690.855 , 1505.909 , 5.53849156, 14.1204 , 1016.6688 , 41.89052 , 929.47533 , 38.148614 , 36. , 2592. , 106.8 , 2369.7 , 97.26 , 186624. , 7689.6 , 170618.4 , 7002.72 , 316.84 , 7030.11 , 288.538 , 155985.5025 , 6402.1395 , 262.7641 ]) 1x_train.iloc[0] CRIM 0.12329 ZN 0.00000 INDUS 10.01000 CHAS 0.00000 NOX 0.54700 RM 5.91300 AGE 92.90000 DIS 2.35340 RAD 6.00000 TAX 432.00000 PTRATIO 17.80000 B 394.95000 LSTAT 16.21000 Name: 112, dtype: float64 Polynomial Features + Standard Scaling 후 모델 학습 12345poly_pipeline = make_pipeline( PolynomialFeatures(degree=2, include_bias=False), StandardScaler(), ElasticNet(alpha=0.1, l1_ratio=0.2)) 1poly_pred = poly_pipeline.fit(x_train, y_train).predict(x_test) D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.61172784964583, tolerance: 3.2374824854881266 positive) 1mse_eval('Poly ElasticNet', y_test, poly_pred) model mse 0 Lasso(alpha=100) 63.348818 1 Lasso(alpha=10) 42.436622 2 Lasso(alpha=1) 27.493672 3 Ridge(alpha=100) 23.487453 4 With Standard ElasticNet 23.230164 5 Lasso(alpha=0.1) 22.979708 6 ElasticNet(l1_ratio=0.8) 22.865628 7 Ridge(alpha=10) 22.793119 8 ElasticNet(l1_ratio=0.5) 22.787269 9 LinearRegression 22.770784 10 Ridge(alpha=0.001) 22.770117 11 Ridge(alpha=0.01) 22.764254 12 Lasso(alpha=0.001) 22.753017 13 ElasticNet(l1_ratio=0.2) 22.749018 14 No Standard ElasticNet 22.749018 15 Ridge(alpha=0.1) 22.718126 16 Ridge(alpha=1) 22.690411 17 Lasso(alpha=0.01) 22.635614 18 Poly ElasticNet 17.526214 2차 Polynomial Features 추가 후 학습된 모델의 성능이 많이 향상 된것을 확인할 수 있다 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"회귀","slug":"회귀","permalink":"https://hyemin-kim.github.io/tags/%ED%9A%8C%EA%B7%80/"}]},{"title":"Python >> sklearn - (2) 분류 (Classification)","slug":"S-Python-sklearn2","date":"2020-07-26T11:23:49.000Z","updated":"2020-07-30T07:54:02.033Z","comments":true,"path":"2020/07/26/S-Python-sklearn2/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/26/S-Python-sklearn2/","excerpt":"","text":"분류 (Classification) 0. 데이터 셋 0-1. iris 데이터 셋 0-2. 데이터프레임 만들기 0-3. 시각화로 데이터셋 파악하기 1. training set / validation set 나누기 2. 하이퍼 파라미터 (hyper-parameter) 튜닝 3. 분류 알고리즘 3-1. Logistic Regression 3-2. SGD (SGDClassifier) 3-3. KNN (KNeighborsClassifier) 3-4. SVM (SVC) 3-5. Decision Tree (DecisionTreeClassifier) 1. Decision Tree (의사 결정 나무): 나무 가지치기를 통해 소그룹으로 나누어 판별하는것 2. Decision Tree 분류 결과 시각화 3. 가지 치기 (pruning) 4. 모델 성능 평가 지표 4-1. 오차 행렬 (Confusion Matrix) 4-2. 정확도 (Accuracy) 4-3. 정밀도 (Precision) 4-4. 민감도 (Sensitivity) / 재현율 (Recall) 4-5. 특이도 (Specificity) 4-6. F1 Score 12import warningswarnings.filterwarnings('ignore') # 불필요한 경고 출력을 방지함 1import pandas as pd 0. 데이터 셋 sklearn.dataset 에서 제공해주는 다양한 샘플 데이터를 활용한다 여기서는 iris 데이터 셋을 활용한다 0-1. iris 데이터 셋 Mission: 꽃 종류 분류하기 iris 데이터 셋 1from sklearn.datasets import load_iris 12# iris 데이터 셋 로드iris = load_iris() iris 데이터 셋 구성 (key values): DESCR: 데이터 셋의 정보를 보여줌 data: feature data feature_names: feature data의 컬럼 이름 target: label data (수치형) target_names: label data의 value 이름 (문자형) 12# 데이터 셋 정보 확인하기print(iris['DESCR']) .. _iris_dataset: Iris plants dataset -------------------- **Data Set Characteristics:** :Number of Instances: 150 (50 in each of three classes) :Number of Attributes: 4 numeric, predictive attributes and the class :Attribute Information: - sepal length in cm - sepal width in cm - petal length in cm - petal width in cm - class: - Iris-Setosa - Iris-Versicolour - Iris-Virginica :Summary Statistics: ============== ==== ==== ======= ===== ==================== Min Max Mean SD Class Correlation ============== ==== ==== ======= ===== ==================== sepal length: 4.3 7.9 5.84 0.83 0.7826 sepal width: 2.0 4.4 3.05 0.43 -0.4194 petal length: 1.0 6.9 3.76 1.76 0.9490 (high!) petal width: 0.1 2.5 1.20 0.76 0.9565 (high!) ============== ==== ==== ======= ===== ==================== :Missing Attribute Values: None :Class Distribution: 33.3% for each of 3 classes. :Creator: R.A. Fisher :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov) :Date: July, 1988 The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken from Fisher's paper. Note that it's the same as in R, but not as in the UCI Machine Learning Repository, which has two wrong data points. This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda &amp; Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. .. topic:: References - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950). - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis. (Q327.D83) John Wiley &amp; Sons. ISBN 0-471-22361-1. See page 218. - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System Structure and Classification Rule for Recognition in Partially Exposed Environments\". IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. PAMI-2, No. 1, 67-71. - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\". IEEE Transactions on Information Theory, May 1972, 431-433. - See also: 1988 MLC Proceedings, 54-64. Cheeseman et al\"s AUTOCLASS II conceptual clustering system finds 3 classes in the data. - Many, many more ... 123# data 불러오기data = iris['data']data[:5] array([[5.1, 3.5, 1.4, 0.2], [4.9, 3. , 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5. , 3.6, 1.4, 0.2]]) 123# feature names 확인하기feature_names = iris['feature_names']feature_names ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] [해석] sepal: 꽃 받침; petal: 꽃잎 123# label data 확인하기target = iris['target']target[:5] array([0, 0, 0, 0, 0]) 12# target names 확인하기iris['target_names'] array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10') 0-2. 데이터프레임 만들기 123# feature data 먼저 생성하기df_iris = pd.DataFrame(data, columns = feature_names)df_iris.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) 0 5.1 3.5 1.4 0.2 1 4.9 3.0 1.4 0.2 2 4.7 3.2 1.3 0.2 3 4.6 3.1 1.5 0.2 4 5.0 3.6 1.4 0.2 123# target column 추가하기df_iris['target'] = targetdf_iris.head() # 최종 dataframe .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target 0 5.1 3.5 1.4 0.2 0 1 4.9 3.0 1.4 0.2 0 2 4.7 3.2 1.3 0.2 0 3 4.6 3.1 1.5 0.2 0 4 5.0 3.6 1.4 0.2 0 0-3. 시각화로 데이터셋 파악하기 12import matplotlib.pyplot as pltimport seaborn as sns 1. Sepal data로 보는 꽃 종류 1df_iris.columns Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target'], dtype='object') 123sns.scatterplot('sepal width (cm)', 'sepal length (cm)', hue='target', palette='muted', data=df_iris)plt.title('Sepal')plt.show() 2. petal data로 보는 꽃 종류 123sns.scatterplot('petal width (cm)', 'petal length (cm)', hue='target', palette='muted', data=df_iris)plt.title('Petal')plt.show() 3. 3D plot로 보는 꽃 종류 (PCA 이용) 1234567891011121314151617from mpl_toolkits.mplot3d import Axes3Dfrom sklearn.decomposition import PCAfig = plt.figure(figsize=(8, 6))ax = Axes3D(fig, elev=-150, azim=110)X_reduced = PCA(n_components=3).fit_transform(df_iris.drop('target', 1))ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=df_iris['target'], cmap=plt.cm.Set1, edgecolor='k', s=40)ax.set_title(\"Iris 3D\")ax.set_xlabel(\"x\")ax.w_xaxis.set_ticklabels([])ax.set_ylabel(\"y\")ax.w_yaxis.set_ticklabels([])ax.set_zlabel(\"z\")ax.w_zaxis.set_ticklabels([])plt.show() 1. training set / validation set 나누기 1from sklearn.model_selection import train_test_split 1x_train, x_valid, y_train, y_valid = train_test_split(df_iris.drop('target', 1), df_iris['target']) 1x_train.shape, y_train.shape ((112, 4), (112,)) 1x_valid.shape, y_valid.shape ((38, 4), (38,)) 1sns.countplot(y_train) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1cb7aaaeec8&gt; 'target’값이 0, 1, 2인 데이터가 Original dataset으로 부터 랜덤으로 뽑히기 때문에 비율의 차이가 존재할 수 있다. 따라서 기계학습할 때 sample size가 큰 데이터 위주로 학습하여 모델의 예측성능이 떨어질 수 있다. (위 상황에서, 학습된 머신러닝 모델이 sample size가 큰 target=1인 경우를 좀 더 잘 예측하고, target=2에 대한 예측도가 떨어질 수 있다) 이를 방지하기 위해 우리는 stratify옵션을 이용하여 label의 class 분포를 균등하게 배분한다. 1x_train, x_valid, y_train, y_valid = train_test_split(df_iris.drop('target', 1), df_iris['target'], stratify=df_iris['target']) 1sns.countplot(y_train) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1cb7b17b508&gt; 1x_train.shape, y_train.shape ((112, 4), (112,)) 1x_valid.shape, y_valid.shape ((38, 4), (38,)) 2. 하이퍼 파라미터 (hyper-parameter) 튜닝 모델 학습할 때 설정 한 옵션들은 **하이퍼 파라미터 (hyper-parameter)**라고 한다. 설정한 값에 따라 모델 성능도 달라질 수 있다. 각 알고리즘 별, hyper-parameter의 종류가 매우 다양하다. 다음 두 가지 parameter는 기본적으로 설정해주는 것이 좋다: random_state: sampling seed 설정 (항상 동일하게 sampling 하기) n_jobs=-1: CPU를 모두 사용 (학습속도가 빠름) 3. 분류 알고리즘 3-1. Logistic Regression [sklearn.linear_model.LogisticRegression] Document Logistic Regression, SVM(Support Vector Machine)과 같은 알고리즘은 이진(Binary Class) 분류만 가능한다. (2개의 클래스 판별만 가능한다.) 하지만, 3개 이상의 클래스에 대한 판별 **[다중 클래스(Multi-Class) 분류]**을 진행하는 경우, 다음과 같은 전략으로 판별한다. one-vs-one (OvO): K 개의 클래스가 존재할 때, 이 중 2개의 클래스 조합을 선택하여 K(K−1)/2 개의 이진 클래스 분류 문제를 풀고 이진판별을 통해 가장 많은 판별값을 얻은 클래스를 선택하는 방법이다. one-vs-rest (OvR): K 개의 클래스가 존재할 때, 클래스들을 “k번째 클래스(one)” &amp; \"나머지(rest)\"로 나누어서 K개의 개별 이진 분류 문제를 푼다. 즉, 각각의 클래스에 대해 표본이 속하는지(y=1) 속하지 않는지(y=0)의 이진 분류 문제를 푸는 것이다. OvO와 달리 클래스 수만큼의 이진 분류 문제를 풀면 된다. 대부분 OvsR 전략을 선호합니다. 1from sklearn.linear_model import LogisticRegression step 1: 모델 선언 1lr = LogisticRegression(random_state=0) step 2: 모델 학습 1lr.fit(x_train, y_train) LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=0, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False) step 3: 예측 1prediction = lr.predict(x_valid) 1prediction[:5] array([0, 1, 2, 2, 0]) step 4: 평가 1(prediction == y_valid).mean() # 정확도 0.9473684210526315 3-2. SGD (SGDClassifier) [sklearn.linear_model.SGDClassifier] Document stochastic gradient descent (SGD): 확률적 경사 하강법 1from IPython.display import Image 12# 출처: https://machinelearningnotepad.wordpress.com/Image('https://machinelearningnotepad.files.wordpress.com/2018/04/yk1mk.png', width=500) 1from sklearn.linear_model import SGDClassifier step 1: 모델 선언 1sgd = SGDClassifier(random_state=0) step 2: 모델 학습 1sgd.fit(x_train, y_train) SGDClassifier(alpha=0.0001, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5, random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False) step 3: 예측 1prediction = sgd.predict(x_valid) step 4: 평가 1(prediction == y_valid).mean() 0.9473684210526315 Change hyper-parameter values: e.g.: penalty = ‘l1’, random_state = 1, n_jobs = -1 1sgd2 = SGDClassifier(penalty='l1', random_state=1, n_jobs=-1) 1sgd2.fit(x_train, y_train) SGDClassifier(alpha=0.0001, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l1', power_t=0.5, random_state=1, shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False) 1prediction2 = sgd2.predict(x_valid) 1(prediction2 == y_valid).mean() 1.0 3-3. KNN (KNeighborsClassifier) [sklearn.neighbors.KNeighborsClassifier] Document KNN (K Nearest Neighbors): K 최근접 이웃 알고리즘 새로운 데이터의 분류 결과가 K 개 최근접 이웃의 클래스에 의해서 결정되며, 데이터는 가장 많이 할당되는 클래스로 분류하게 된다. 12# 출처: 데이터 캠프Image('https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/KNN_final_a1mrv9.png') 1from sklearn.neighbors import KNeighborsClassifier 12# 1. 모델 선언knn = KNeighborsClassifier() 12# 2. 모델 학습knn.fit(x_train, y_train) # default: n_neighbors=5 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform') 12# 3. 예측prediction = knn.predict(x_valid) 12# 4. 평가(prediction == y_valid).mean() 0.9210526315789473 n_neighnors를 9개로 설정하여 다시 예측해본다: 123knn2 = KNeighborsClassifier(n_neighbors=9)knn2.fit(x_train, y_train)knn2_pred = knn2.predict(x_valid) 1(knn2_pred == y_valid).mean() 0.9473684210526315 3-4. SVM (SVC) [sklearn.svm.SVC] Document 새로운 데이터가 어느 카테고리에 속할지 판단하는 비확률적 이진 선형 분류 모델을 만듦. 경계로 표현되는 데이터들 중 가장 큰 폭을 가진 경계를 찾는 알고리즘. 1Image('https://csstudy.files.wordpress.com/2011/03/screen-shot-2011-02-28-at-5-53-26-pm.png') SVM은 Logistic Regression과 같이 이진 분류만 가능하다. (2개의 클래스 판별만 가능) 3개 이상의 클래스인 경우: OvsR 전략 사용 1from sklearn.svm import SVC # SVC: Support Vector Classification 123svc = SVC(random_state=0)svc.fit(x_train, y_train)svc_pred = svc.predict(x_valid) 1svc # hyper-parameter 확인 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf', max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001, verbose=False) 1(svc_pred == y_valid).mean() 0.9473684210526315 각 클래스 별 확률값을 return해주는 decision_function() 1svc.decision_function(x_valid)[:5] array([[ 2.22273426, 1.18194657, -0.25426485], [-0.22060229, 2.23192595, 0.91725911], [-0.23638817, 1.18969144, 2.17593611], [-0.23457057, 1.07146337, 2.22588253], [ 2.22808358, 1.16872302, -0.25381783]]) 1svc_pred[:5] array([0, 1, 2, 2, 0]) 확률값이 제일 높은 클래스로 분류(예측) 된 것을 확인하실 수 있다 3-5. Decision Tree (DecisionTreeClassifier) [sklearn.tree.DecisionTreeClassifier] Document 1. Decision Tree (의사 결정 나무): 나무 가지치기를 통해 소그룹으로 나누어 판별하는것 1Image('https://www.researchgate.net/profile/Ludmila_Aleksejeva/publication/293194222/figure/fig1/AS:669028842487827@1536520314657/Decision-tree-for-Iris-dataset.png', width=500) 1from sklearn.tree import DecisionTreeClassifier 1dt = DecisionTreeClassifier(random_state=0) 1dt.fit(x_train, y_train) DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=0, splitter='best') 1dt_pred = dt.predict(x_valid) 1(dt_pred == y_valid).mean() 0.9210526315789473 2. Decision Tree 분류 결과 시각화 123from sklearn.tree import export_graphvizfrom IPython.display import Imageimport numpy as np 방법 1: pydot을 사용하여 \"dot 파일\"을 \"png 이미지\"로 전환 (참고) 1pip install pydot Collecting pydotNote: you may need to restart the kernel to use updated packages. Downloading pydot-1.4.1-py2.py3-none-any.whl (19 kB) Requirement already satisfied: pyparsing&gt;=2.1.4 in d:\\anaconda\\lib\\site-packages (from pydot) (2.4.6) Installing collected packages: pydot Successfully installed pydot-1.4.1 ​ 12345678910111213# 참고: https://niceman.tistory.com/169import pydot# .dot결과 생성export_graphviz(dt, out_file='tree.dot', feature_names=feature_names, class_names=np.unique(iris['target_names']))# Encoding(graph,) = pydot.graph_from_dot_file('tree.dot', encoding='utf8')# .dot파일을 .png이미지로 저장graph.write_png('tree.png')Image(filename = 'tree.png', width=600) 방법 2: graphviz.Source이용 (참고) 1pip install -U graphviz Requirement already up-to-date: graphviz in d:\\anaconda\\lib\\site-packages (0.14.1) Note: you may need to restart the kernel to use updated packages. 1import graphviz 123456# 참고: https://www.kaggle.com/vaishvik25/titanic-eda-fe-3-model-decision-tree-vizfrom sklearn.tree import DecisionTreeClassifier, export_graphviztree_dot = export_graphviz(dt,out_file=None, feature_names=feature_names, class_names=np.unique(iris['target_names']))tree = graphviz.Source(tree_dot)tree gini계수: 불순도를 의미함. gini계수가 높을 수록 엔트로피(Entropy)가 큼. 즉, 클래스가 혼잡하게 섞여 있음. 3. 가지 치기 (pruning) Overfitting을 방지하기 위해 적당히 가지 치기를 진행한다. 1234# 수동으로 max_depth 설정dt2 = DecisionTreeClassifier(max_depth=2)dt2.fit(x_train, y_train)dt2_pred = dt2.predict(x_valid) 1(dt2_pred == y_valid).mean() 0.9210526315789473 123tree2_dot = export_graphviz(dt2,out_file=None, feature_names=feature_names, class_names=np.unique(iris['target_names']))tree2 = graphviz.Source(tree2_dot)tree2 4. 모델 성능 평가 지표 참고자료: 분류성능평가지표 - Precision(정밀도), Recall(재현율) and Accuracy(정확도) 4-1. 오차 행렬 (Confusion Matrix) 4-2. 정확도 (Accuracy) 정확도 (Accuracy): 모델이 샘플을 올바르게 예측하는 비율 Accuracy=TP+TNTP+FP+TN+FNAccuracy = \\frac{TP+TN}{TP+FP+TN+FN} Accuracy=TP+FP+TN+FNTP+TN​ !!정확도의 함정!! 정확도는 모델의 성능을 가장 지관적으로 나타낼 수 있는 평가 지표다. 하지만, 만약 Actual positive sample과 Actual negative sample의 비율이 차이가 많이 나면 정확도의 함정에 빠질 수 있다. 즉, 모두 positive / negative로 예측 했을 때 모델의 정확도가 매우 높은 경우다. 이 경우에 예측 정확도가 높지만, 모델의 예측 성능이 좋다라고 말할 수는 없다. 유방암 환자 데이터셋을 이용하여 한번 이해해 볼게요. 123from sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_splitimport numpy as np 1cancer = load_breast_cancer(유방암 환자 데이터셋) 1print(cancer['DESCR']) # describe .. _breast_cancer_dataset: Breast cancer wisconsin (diagnostic) dataset -------------------------------------------- **Data Set Characteristics:** :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.0) - concavity (severity of concave portions of the contour) - concave points (number of concave portions of the contour) - symmetry - fractal dimension (\"coastline approximation\" - 1) The mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius. - class: - WDBC-Malignant - WDBC-Benign :Summary Statistics: ===================================== ====== ====== Min Max ===================================== ====== ====== radius (mean): 6.981 28.11 texture (mean): 9.71 39.28 perimeter (mean): 43.79 188.5 area (mean): 143.5 2501.0 smoothness (mean): 0.053 0.163 compactness (mean): 0.019 0.345 concavity (mean): 0.0 0.427 concave points (mean): 0.0 0.201 symmetry (mean): 0.106 0.304 fractal dimension (mean): 0.05 0.097 radius (standard error): 0.112 2.873 texture (standard error): 0.36 4.885 perimeter (standard error): 0.757 21.98 area (standard error): 6.802 542.2 smoothness (standard error): 0.002 0.031 compactness (standard error): 0.002 0.135 concavity (standard error): 0.0 0.396 concave points (standard error): 0.0 0.053 symmetry (standard error): 0.008 0.079 fractal dimension (standard error): 0.001 0.03 radius (worst): 7.93 36.04 texture (worst): 12.02 49.54 perimeter (worst): 50.41 251.2 area (worst): 185.2 4254.0 smoothness (worst): 0.071 0.223 compactness (worst): 0.027 1.058 concavity (worst): 0.0 1.252 concave points (worst): 0.0 0.291 symmetry (worst): 0.156 0.664 fractal dimension (worst): 0.055 0.208 ===================================== ====== ====== :Missing Attribute Values: None :Class Distribution: 212 - Malignant, 357 - Benign :Creator: Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian :Donor: Nick Street :Date: November, 1995 This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2 Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/ .. topic:: References - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995. - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171. 123data = cancer['data']target = cancer['target']feature_names = cancer['feature_names'] 123# 데이터 프레임 생성df = pd.DataFrame(data = data, columns = feature_names)df['target'] = target 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean radius mean texture mean perimeter mean area mean smoothness mean compactness mean concavity mean concave points mean symmetry mean fractal dimension ... worst texture worst perimeter worst area worst smoothness worst compactness worst concavity worst concave points worst symmetry worst fractal dimension target 0 17.99 10.38 122.80 1001.0 0.11840 0.27760 0.3001 0.14710 0.2419 0.07871 ... 17.33 184.60 2019.0 0.1622 0.6656 0.7119 0.2654 0.4601 0.11890 0 1 20.57 17.77 132.90 1326.0 0.08474 0.07864 0.0869 0.07017 0.1812 0.05667 ... 23.41 158.80 1956.0 0.1238 0.1866 0.2416 0.1860 0.2750 0.08902 0 2 19.69 21.25 130.00 1203.0 0.10960 0.15990 0.1974 0.12790 0.2069 0.05999 ... 25.53 152.50 1709.0 0.1444 0.4245 0.4504 0.2430 0.3613 0.08758 0 3 11.42 20.38 77.58 386.1 0.14250 0.28390 0.2414 0.10520 0.2597 0.09744 ... 26.50 98.87 567.7 0.2098 0.8663 0.6869 0.2575 0.6638 0.17300 0 4 20.29 14.34 135.10 1297.0 0.10030 0.13280 0.1980 0.10430 0.1809 0.05883 ... 16.67 152.20 1575.0 0.1374 0.2050 0.4000 0.1625 0.2364 0.07678 0 5 rows × 31 columns target: 0: Malignant (악성종양); 1: Benign (양성종양) 12pos = df.loc[df['target'] == 1] # 앙성 sampleneg = df.loc[df['target'] == 0] # 음성 sample 1pos.shape, neg.shape ((357, 31), (212, 31)) 시범용 sample data를 생성: 양성 환자 357 + 음성 환자 5 1sample = pd.concat([pos, neg[:5]], sort=True) 1x_train, x_test, y_train, y_test = train_test_split(sample.drop('target',1), sample['target'], random_state=42) 1x_train.shape, y_train.shape ((271, 30), (271,)) 1x_test.shape, y_test.shape ((91, 30), (91,)) 1234# 모델 정의 및 학습model = LogisticRegression()model.fit(x_train, y_train)model_pred = model.predict(x_test) Confusion Matrix 1from sklearn.metrics import confusion_matrix 1confusion_matrix(y_test, model_pred) array([[ 1, 0], [ 2, 88]], dtype=int64) 1234sns.heatmap(confusion_matrix(y_test, model_pred), annot=True, cmap='Reds')plt.xlabel('Predict')plt.ylabel('Actual')plt.show() 정확도 (Accuracy) 12# logistic 모델 정확도(model_pred == y_test).mean() 0.978021978021978 12345# 모두 양성으로 예측한 경우my_pred = np.ones(shape=y_test.shape)# 정확도(my_pred == y_test).mean() 0.989010989010989 정확도만 놓고 본다면, 무조건 양성 환자로 예측하는 분류기가 성능이 더 좋다. 하지만 무조건 양성 환자로 예측해서 예측율이 98.9%로 말하는 의사는 당영히 자질이 좋은 의사라고 볼 수 없다 정확도(Accuracy)만 보고 분류기의 성능을 판별하는 것은 위와 같은 오류에 빠질 수 있다. 이를 보완하기 위해 다음과 같은 지표들도 같이 활용하게 된다 4-3. 정밀도 (Precision) 정밀도 (Precision): 양성 예측의 정확도. 즉, Positive Prediction 중에서 올바르게 예측되는 비율 Precision=TPTP+FPPrecision=\\frac{TP}{TP+FP} Precision=TP+FPTP​ 1from sklearn.metrics import precision_score 1precision_score(y_test, model_pred) 1.0 4-4. 민감도 (Sensitivity) / 재현율 (Recall) 민감도 (Sensitivity) / 재현율 (Recall): 분류기가 양성 샘플에 대한 식별력을 나타남. 즉, Positive Condition 중에서 올바르게 예측되는 비율. True Positive Rate (TPR) 이라고도 불린다. Sensitivity/Recall=TPTP+FNSensitivity / Recall = \\frac{TP}{TP+FN} Sensitivity/Recall=TP+FNTP​ 1from sklearn.metrics import recall_score 1recall_score(y_test, model_pred) 0.9777777777777777 4-5. 특이도 (Specificity) 특이도 (Specificity): 분류기가 음성 샘플에 대한 식별력을 나타남. 즉, Negative Condition 중에서 올바르게 예측되는 비율. True Negative Rate (TNR) 이라고도 불린다. Specificity=TNTN+FPSpecificity = \\frac{TN}{TN+FP} Specificity=TN+FPTN​ 4-6. F1 Score F1 Score: 정밀도(Precision)와 재현율(Recall)의 조화 평균을 나타나는 지표임. 데이터 label이 불균형 구조일 때, 모델의 성능을 정확하게 평가할 수 있으며, 성능을 하나의 숫자로 표현할 수 있다. F1&nbsp;Score=2∗Precision∗RecallPrecision+Recall=TPTP+FN+FP2F1\\ Score = 2*\\frac{Precision * Recall}{Precision + Recall}=\\frac{TP}{TP+\\frac{FN+FP}{2}} F1&nbsp;Score=2∗Precision+RecallPrecision∗Recall​=TP+2FN+FP​TP​ 1from sklearn.metrics import f1_score 1f1_score(y_test, model_pred) 0.9887640449438202 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"분류","slug":"분류","permalink":"https://hyemin-kim.github.io/tags/%EB%B6%84%EB%A5%98/"}]},{"title":"Python >> sklearn - (1) 전처리","slug":"S-Python-sklearn1","date":"2020-07-17T07:37:50.000Z","updated":"2020-07-17T09:02:10.992Z","comments":true,"path":"2020/07/17/S-Python-sklearn1/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/17/S-Python-sklearn1/","excerpt":"","text":"전처리 (Pre-Processing) 개요 1. 전처리의 정의 2. 전처리의 종류 실습 – Titanic 0. 데이터 셋 파악 1. train / validation 셋 나누기 2. 결측치 처리 2-0. 결측치 확인 2-1. Numerical Column의 결측치 처리 2-2. Categorical Column의 결측치 처리 3. Label Encoding: 문자(categorivcal)를 수치(numerical)로 변환 4. 원 핫 인코딩 (One Hot Encoding) 5. Normalize (정규화) 6. Standard Scaling (표준화) 개요 1. 전처리의 정의 데이터 전처리는 데이터 분석에 적합하게 데이터를 가공/ 변경/ 처리/ 클리닝하는 과정이다 2. 전처리의 종류 결측치 - Imputer 이상치 정규화 (Normalization) 0~1사이의 분포로 조정 xnew=x−xminxmax−xminx_{new} = \\frac{x-x_{min}}{x_{max}-x_{min}}xnew​=xmax​−xmin​x−xmin​​ 표준화 (Standardization) 평균을 0, 표준편차를 1로 맞춤 xnew=x−μσx_{new} = \\frac{x-\\mu}{\\sigma}xnew​=σx−μ​ 샘플링 (over/under sampling) 피처 공학 (Feature Engineering) feature 생성/ 연산 구간 생성, 스케일 변경 실습 – Titanic 12import numpy as npimport pandas as pd 12train = pd.read_csv('train.csv')test = pd.read_csv('test.csv') 0. 데이터 셋 파악 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S PassengerId: 승객 아이디 Survived: 생존 여부, 1: 생존, 0: 사망 Pclass: 등급 Name: 성함 Sex: 성별 Age: 나이 SibSp: 형제, 자매, 배우자 수 Parch: 부모, 자식 수 Ticket: 티켓번호 Fare: 요즘 Cabin: 좌석번호 Embarked: 탑승 항구 1. train / validation 셋 나누기 STEP 1. feature &amp; label 정의하기 123feature = [ 'Pclass', 'Sex', 'Age', 'Fare'] 123label = [ 'Survived'] 1train[feature].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Pclass Sex Age Fare 0 3 male 22.0 7.2500 1 1 female 38.0 71.2833 2 3 female 26.0 7.9250 3 1 female 35.0 53.1000 4 3 male 35.0 8.0500 1train[label].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Survived 0 0 1 1 2 1 3 1 4 0 STEP 2. 적절한 비율로 train / validation set 나누기 1from sklearn.model_selection import train_test_split reference: &lt; train_test_split &gt; Document train_test_split ( X, y, test_size=…, random_state=…, shuffle=True ) test_size: validation set에 할당할 비율 (20% -&gt; 0.2) random_state: random seed 설정 shuffle: 기본 True: shuffle the data before splitting 1x_train, x_valid, y_train, y_valid = train_test_split(train[feature], train[label], test_size=0.2, random_state=30, shuffle=True) 1x_train.shape, y_train.shape ((712, 4), (712, 1)) 1x_valid.shape, y_valid.shape ((179, 4), (179, 1)) 2. 결측치 처리 2-0. 결측치 확인 방법 1. pandas의 info() 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 방법 2. pandas의 isnull() 합계를 구하는 sum()을 통해 한 눈에 확인할 수 있다 1train.isnull().sum() PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 개별 column의 결측치 확인하기 1train['Age'].isnull().sum() 177 2-1. Numerical Column의 결측치 처리 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 1. Pandas의 \"fillna()\"를 사용: 1개의 column을 처리할 때 a. 숫자\"0\"으로 채우기 1train['Age'].fillna(0).describe() count 891.000000 mean 23.799293 std 17.596074 min 0.000000 25% 6.000000 50% 24.000000 75% 35.000000 max 80.000000 Name: Age, dtype: float64 b. 통계값(평균)으로 채우기 1train['Age'].fillna(train['Age'].mean()).describe() count 891.000000 mean 29.699118 std 13.002015 min 0.420000 25% 22.000000 50% 29.699118 75% 35.000000 max 80.000000 Name: Age, dtype: float64 2. sklearn의 \"SimpleImputer\"를 사용: 2개 이상의 column을 한 번에 처리할 때 reference: Impute 도큐먼트 SimplrImputer 도큐먼트 SimpleImputer( *, missing_values=nan, strategy=‘mean’, fill_value=None, verbose=0, copy=True, add_indicator=False ) strategy: “mean” / “median” / “most_frequent” / “constant” 1from sklearn.impute import SimpleImputer a. 숫자\"0\"으로 채우기 12# STEP 1. imputer 만들기imputer = SimpleImputer(strategy='constant', fill_value=0) 12# STEP 2. fit() 을 통해 결측치에 대한 학습을 진행하기imputer.fit(train[['Age', 'Pclass']]) SimpleImputer(add_indicator=False, copy=True, fill_value=0, missing_values=nan, strategy='constant', verbose=0) 123# STEP 3. transform() 을 통해 실제 결측치에 대해 처리하기result = imputer.transform(train[['Age', 'Pclass']])result array([[22., 3.], [38., 1.], [26., 3.], ..., [ 0., 3.], [26., 1.], [32., 3.]]) 12# STEP 4. 처리 결과를 original data에 대입train[['Age', 'Pclass']] = result 1train[['Age', 'Pclass']].isnull().sum() Age 0 Pclass 0 dtype: int64 fit_transform() 은 fit()과 transform()을 한 번에 해주는 합수다. 1train = pd.read_csv('train.csv') 1train[['Age', 'Pclass']].isnull().sum() Age 177 Pclass 0 dtype: int64 12# STEP 1. imputer 만들기imputer = SimpleImputer(strategy='constant', fill_value=0) 12# STEP 2. fit and transformresult = imputer.fit_transform(train[['Age', 'Pclass']]) 12# STEP 3. 결과 대입train[['Age', 'Pclass']] = result 1train[['Age', 'Pclass']].isnull().sum() Age 0 Pclass 0 dtype: int64 1train[['Age', 'Pclass']].describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age Pclass count 891.000000 891.000000 mean 23.799293 2.308642 std 17.596074 0.836071 min 0.000000 1.000000 25% 6.000000 2.000000 50% 24.000000 3.000000 75% 35.000000 3.000000 max 80.000000 3.000000 b. 통계값(평균)으로 채우기 1train = pd.read_csv('train.csv') 1train[['Age', 'Pclass']].isnull().sum() Age 177 Pclass 0 dtype: int64 123imputer = SimpleImputer(strategy='mean')result = imputer.fit_transform(train[['Age', 'Pclass']])train[['Age', 'Pclass']] = result 1train[['Age', 'Pclass']].isnull().sum() Age 0 Pclass 0 dtype: int64 1train[['Age', 'Pclass']].describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Age Pclass count 891.000000 891.000000 mean 29.699118 2.308642 std 13.002015 0.836071 min 0.420000 1.000000 25% 22.000000 2.000000 50% 29.699118 3.000000 75% 35.000000 3.000000 max 80.000000 3.000000 2-2. Categorical Column의 결측치 처리 1train = pd.read_csv('train.csv') 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 1. Pandas의 \"fillna()\"를 사용: 1개의 column을 처리할 때 1train['Embarked'].fillna('S') 0 S 1 C 2 S 3 S 4 S .. 886 S 887 S 888 S 889 C 890 Q Name: Embarked, Length: 891, dtype: object 2. sklearn의 \"SimpleImputer\"를 사용: 2개 이상의 column을 한 번에 처리할 때 123imputer = SimpleImputer(strategy = 'most_frequent')result = imputer.fit_transform(train[['Embarked', 'Cabin']])train[['Embarked', 'Cabin']] = result 1train[['Embarked', 'Cabin']].isnull().sum() Embarked 0 Cabin 0 dtype: int64 3. Label Encoding: 문자(categorivcal)를 수치(numerical)로 변환 기계학습을 위해서 모든 문자로된 데이터는 수치로 변환해야 한다 12train = pd.read_csv('train.csv')train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 1train['Sex'] 0 male 1 female 2 female 3 female 4 male ... 886 male 887 female 888 female 889 male 890 male Name: Sex, Length: 891, dtype: object 방법 1: convert함수를 직접 정의하기 1train['Sex'].value_counts() male 577 female 314 Name: Sex, dtype: int64 123456# STEP 1. 함수 정의def convert(data): if data == 'female': return 1 elif data == 'male': return 0 12# STEP 2. 함수 applytrain['Sex'].apply(convert) 0 0 1 1 2 1 3 1 4 0 .. 886 0 887 1 888 1 889 0 890 0 Name: Sex, Length: 891, dtype: int64 방법 2: sklearn의 “LabelEncoder” 사용 변환 규칙: value name의 alphabet 순서대로 0, 1, 2… 숫자를 부여 1from sklearn.preprocessing import LabelEncoder 1train['Sex'].value_counts() male 577 female 314 Name: Sex, dtype: int64 1le = LabelEncoder() 1train['Sex_num'] = le.fit_transform(train['Sex']) 1train['Sex_num'].value_counts() 1 577 0 314 Name: Sex_num, dtype: int64 12# class 확인le.classes_ array(['female', 'male'], dtype=object) 12# 숫자 -&gt; 문자le.inverse_transform([0, 1, 1, 0, 0, 1, 1]) array(['female', 'male', 'male', 'female', 'female', 'male', 'male'], dtype=object) NaN 값이 포함되어 있으면, LabeEncoder가 정상 동작하지 않음 1train['Embarked'] 0 S 1 C 2 S 3 S 4 S .. 886 S 887 S 888 S 889 C 890 Q Name: Embarked, Length: 891, dtype: object 1train['Embarked'].value_counts() S 644 C 168 Q 77 Name: Embarked, dtype: int64 1le.fit_transform(train['Embarked']) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in _encode(values, uniques, encode, check_unknown) 111 try: --&gt; 112 res = _encode_python(values, uniques, encode) 113 except TypeError: D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in _encode_python(values, uniques, encode) 59 if uniques is None: ---&gt; 60 uniques = sorted(set(values)) 61 uniques = np.array(uniques, dtype=values.dtype) TypeError: '&lt;' not supported between instances of 'float' and 'str' ​ During handling of the above exception, another exception occurred: TypeError Traceback (most recent call last) &lt;ipython-input-38-86525b1fc929&gt; in &lt;module&gt; ----&gt; 1 le.fit_transform(train['Embarked']) D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in fit_transform(self, y) 250 \"\"\" 251 y = column_or_1d(y, warn=True) --&gt; 252 self.classes_, y = _encode(y, encode=True) 253 return y 254 D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py in _encode(values, uniques, encode, check_unknown) 112 res = _encode_python(values, uniques, encode) 113 except TypeError: --&gt; 114 raise TypeError(\"argument must be a string or number\") 115 return res 116 else: TypeError: argument must be a string or number 1train['Embarked'] = train['Embarked'].fillna('S') 1train['Embarked'] = le.fit_transform(train['Embarked']) 1train['Embarked'] 0 2 1 0 2 2 3 2 4 2 .. 886 2 887 2 888 2 889 0 890 1 Name: Embarked, Length: 891, dtype: int32 1train['Embarked'].value_counts() 2 646 0 168 1 77 Name: Embarked, dtype: int64 4. 원 핫 인코딩 (One Hot Encoding) pd.get_dummies ( df_name [ ‘col_name’ ] ) 1train = pd.read_csv('train.csv') 1train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 1train.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB \"Embarked\"를 살펴보기 12# Unique Value 확인하기train['Embarked'].value_counts() S 644 C 168 Q 77 Name: Embarked, dtype: int64 123# NA 채우기train['Embarked'] = train['Embarked'].fillna('S')train['Embarked'].value_counts() S 646 C 168 Q 77 Name: Embarked, dtype: int64 123# Label Encoding (문자 to 숫자)train['Embarked_num'] = LabelEncoder().fit_transform(train['Embarked'])train['Embarked_num'].value_counts() 2 646 0 168 1 77 Name: Embarked_num, dtype: int64 Embarked는 탑승 항구의 이니셜을 나타낸다. 우리는 LabelEncoder를 통해서 값을 수치형으로 변환해주었다, 하지만 이대로 데이터를 기계학습 시키면, 기계는 데이터 안에서 관계를 학습한다. 예를 들면, ‘S’= 2, ‘Q’= 1 이라고 되어 있는데, Q+Q=S가 된다라고 학습해버린다 그렇기 때문에, 우리는 각 unique value를 별도의 column으로 분리하고, 값에 해당하는 column는 True (1), 나머지 column는 False (0) 를 갖게 한다.이것이 바로 원 핫 인코딩 이다. 1train['Embarked'][:6] 0 S 1 C 2 S 3 S 4 S 5 Q Name: Embarked, dtype: object 1train['Embarked_num'][:6] 0 2 1 0 2 2 3 2 4 2 5 1 Name: Embarked_num, dtype: int32 12one_hot = pd.get_dummies(train['Embarked_num'][:6])one_hot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 0 0 1 1 1 0 0 2 0 0 1 3 0 0 1 4 0 0 1 5 0 1 0 12one_hot.columns = ['C', 'Q', 'S']one_hot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } C Q S 0 0 0 1 1 1 0 0 2 0 0 1 3 0 0 1 4 0 0 1 5 0 1 0 원핫인코딩은 카테고리의 특성을(계절, 항구, 성별, 종류…) 가지는 column에 대해서 적용한다 5. Normalize (정규화) 정규화: column간에 다른 min,max 값을 가지는 경우, 정규화를 통해 min / max 의 척도를 맞추어 주는 작업이다 sklearn.preprocessing --&gt; MinMaxScaler() 예: 영화평점 네이버 영화평점 (0점 ~ 10점): [2, 4, 6, 8, 10] 넷플릭스 영화평점 (0점 ~ 5점): [1, 2, 3, 4, 5] 123movie = {'naver': [2, 4, 6, 8, 10], 'netflix': [1, 2, 3, 4, 5] } 12movie = pd.DataFrame(data=movie)movie .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } naver netflix 0 2 1 1 4 2 2 6 3 3 8 4 4 10 5 1from sklearn.preprocessing import MinMaxScaler 1min_max_scaler = MinMaxScaler() 1min_max_movie = min_max_scaler.fit_transform(movie) 1pd.DataFrame(min_max_movie, columns = ['naver', 'netfllix']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } naver netfllix 0 0.00 0.00 1 0.25 0.25 2 0.50 0.50 3 0.75 0.75 4 1.00 1.00 6. Standard Scaling (표준화) 표준화: 평균이 0, 표준편차가 1이 되도록 변환해주는 작업 sklearn.preprocessing --&gt; StandardScaler() 12from sklearn.preprocessing import StandardScalerstandard_scaler = StandardScaler() 123# 샘플데이터 생성x = np.arange(10)x[9] = 1000 # oulier 추가 1x.mean(), x.std() (103.6, 298.8100399919654) 12# 원본 데이터 표준화하기scaled = standard_scaler.fit_transform(x.reshape(-1, 1)) 1scaled.mean(), scaled.std() (4.4408920985006264e-17, 1.0) 1round(scaled.mean(), 2), scaled.std() # mean값 반올림 (0.0, 1.0) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"}]},{"title":"Python >> sklearn -(0) sklearn 개요","slug":"S-Python-sklearn0","date":"2020-07-17T07:36:59.000Z","updated":"2020-07-17T08:23:44.120Z","comments":true,"path":"2020/07/17/S-Python-sklearn0/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/17/S-Python-sklearn0/","excerpt":"","text":"scikit-learn 개요 Install Package Import Functions from Sub-packages 3 Steps to Fit Model and Do Prediction &lt; scikit-learn &gt; Homepage scikit-learn 패키지는 지도학습, 비지도학습 등 대부분의 머신러닝 알고리즘을 제공하고 있으며, Python에서 머신러닝을 수행할 때 굉장히 많이 쓰이는 패키지 중의 하나다 Install Package 1pip install -U scikit-learn # -U: Update Note: you may need to restart the kernel to use updated packages. ​ Usage: D:\\Anaconda\\python.exe -m pip install [options] &lt;requirement specifier&gt; [package-index-options] ... D:\\Anaconda\\python.exe -m pip install [options] -r &lt;requirements file&gt; [package-index-options] ... D:\\Anaconda\\python.exe -m pip install [options] [-e] &lt;vcs project url&gt; ... D:\\Anaconda\\python.exe -m pip install [options] [-e] &lt;local project path&gt; ... D:\\Anaconda\\python.exe -m pip install [options] &lt;archive url/path&gt; ... no such option: -: Import Functions from Sub-packages 12from sklearn.linear_model import LinearRegressionfrom sklearn.model_selection import train_test_split 3 Steps to Fit Model and Do Prediction STEP 1. 모델 정의 12from sklearn.linear_model import LinearRegressionmodel = LinearRegression() STEP 2. 학습 (Fit in Training set) 명령어: model_name .fit 1model.fit(x_train, y_train) STEP 3. 예측 (Predict in Test set) 명령어: model_name .predict 1prediction = model.predict(x_test) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"}]},{"title":"Python >> Seaborn - (2) 통계 기반의 시각화","slug":"S-Python-Seaborn2","date":"2020-07-03T10:18:20.000Z","updated":"2020-07-03T13:19:50.303Z","comments":true,"path":"2020/07/03/S-Python-Seaborn2/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/03/S-Python-Seaborn2/","excerpt":"","text":"통계 기반의 시각화 0. 통계 기반의 시각화를 제공해주는 Seaborn 1. countplot 1-1. 세로로 그리기 1-2. 가로로 그리기 1-3. 색상 팔레트 설정 2. distplot 2-1. 기본 displot 2-2. 데이터가 Series일 경우 2-3. rugplot 2-4. kde (kernel density) 2-5. 가로로 표현하기 2-6. 컬러 바꾸기 3. heatmap 3-1. 기본 heatmap 3-2. pivot table을 활용하여 그리기 3-3. correlation(상관관계)를 시각화 4. pairplot 4-1. 기본 pairplot 그리기 4-2. hue 옵션으로 특성 구분 4-3. 컬러 팔레트 적용 4-4. 사이즈 적용 5. violinplot 5-1. 기본 violinplot 그리기 5-2. 비교 분포 확인 5-3. 가로로 뉘인 violinplot 5-4. hue 옵션으로 분포 비교 6. lmplot 6-1. 기본 lmplot 6-2. hue 옵션으로 다중 선형관계 그리기 6-3. col 옵션을 추가하여 그래프를 별도로 그려볼 수 있다 7. relplot 7-1. 기본 relplot 7-2. col 옵션으로 그래프 분할 7-3. row와 column에 표기할 데이터 column 선택 7-4. 컬러 팔레트 적용 8. jointplot 8-1. 기본 jointplot 그리기 8-2. 선형관계를 표현하는 regression 라인 그리기 8-3. hex 밀도 보기 8-4. 등고선 모양으로 밀집도 확인하기 1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns 12plt.rcParams[\"figure.figsize\"] = (9, 6) # figure size 설정plt.rcParams[\"font.size\"] = 14 # fontsize 설정 0. 통계 기반의 시각화를 제공해주는 Seaborn reference: Seaborn 공식 도큐먼트 seaborn 라이브러리가 매력적인 이유는 바로 통계 차트다. 이번 실습에서는 seaborn의 다양한 통계 차트 중 대표적인 차트 몇 개를 뽑아서 다뤄볼 예정이다. 그럼 먼저 실습에 사용되는 Dataset을 한번 살펴볼게요. Dataset — \"Titanic\" 12titanic = sns.load_dataset('titanic')titanic .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone 0 0 3 male 22.0 1 0 7.2500 S Third man True NaN Southampton no False 1 1 1 female 38.0 1 0 71.2833 C First woman False C Cherbourg yes False 2 1 3 female 26.0 0 0 7.9250 S Third woman False NaN Southampton yes True 3 1 1 female 35.0 1 0 53.1000 S First woman False C Southampton yes False 4 0 3 male 35.0 0 0 8.0500 S Third man True NaN Southampton no True ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 886 0 2 male 27.0 0 0 13.0000 S Second man True NaN Southampton no True 887 1 1 female 19.0 0 0 30.0000 S First woman False B Southampton yes True 888 0 3 female NaN 1 2 23.4500 S Third woman False NaN Southampton no False 889 1 1 male 26.0 0 0 30.0000 C First man True C Cherbourg yes True 890 0 3 male 32.0 0 0 7.7500 Q Third man True NaN Queenstown no True 891 rows × 15 columns survived: 생존여부 pclass: 좌석등급 (숫자) sex: 성별 age: 나이 sibsp: 형제자매 + 배우자 숫자 parch: 부모 + 자식 숫자 fare: 요금 embarked: 탑승 항구 class: 좌석등급 (영문) who: 사람 구분 deck: 데크 embark_town: 탑승 항구 (영문) alive: 생존여부 (영문) alone: 혼자인지 여부 Dataset — \"tips\" 12tips = sns.load_dataset('tips')tips .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 ... ... ... ... ... ... ... ... 239 29.03 5.92 Male No Sat Dinner 3 240 27.18 2.00 Female Yes Sat Dinner 2 241 22.67 2.00 Male Yes Sat Dinner 2 242 17.82 1.75 Male No Sat Dinner 2 243 18.78 3.00 Female No Thur Dinner 2 244 rows × 7 columns total_bill: 총 합계 요금표 tip: 팁 sex: 성별 smoker: 흡연자 여부 day: 요일 time: 식사 시간 size: 식사 인원 12# 배경 설정sns.set(style='darkgrid') 1. countplot 항목별 갯수를 세어주는 countplot 해당 column을 구성하고 있는 value들을 자동으로 구분하여 보여준다 reference: &lt;sns.countplot&gt; Document sns.countplot ( x=None, y=None, hue=None, data=None, color=None, palette=None ) 1-1. 세로로 그리기 12sns.countplot(x='class', hue='who', data=titanic)plt.show() 1-2. 가로로 그리기 12sns.countplot(y='class', hue='who', data=titanic)plt.show() 1-3. 색상 팔레트 설정 12sns.countplot(x='class', hue='who', palette='copper', data= titanic)plt.show() 2. distplot matplotlib의 hist그래프와 kdeplot을 통합한 그래프다. 분포와 밀도를 확인할 수 있음 reference: &lt;sns.distplot&gt; Document sns.displot ( a, hist=True, kde=True, rug=False, vertical=False, color=None ) hist: histogram kde: kernel density estimate rug: rugplot vertical: If True, observed values are on y-axis 123# 샘플 데이터 생성x = np.random.randn(100)x array([-3.39765920e-01, -1.48664049e+00, -5.57926444e-01, 3.25206560e-01, -7.46665762e-01, -3.10926812e-01, -2.14536012e+00, 1.25905620e+00, -2.07806423e-01, 5.56377038e-01, -2.20574498e+00, -1.15138577e-01, -3.32417471e-01, 1.13927613e-01, -7.29559442e-01, -1.31243715e+00, -8.27477111e-01, -1.24455099e+00, -5.44035731e-02, -1.85399773e+00, -1.62571613e+00, 3.89312791e-01, 1.26815698e+00, -7.43355761e-01, -1.34113997e+00, 2.67291801e-02, -4.74142344e-01, -1.07662894e+00, -2.35607451e+00, 1.90337236e-01, -1.18577255e+00, -1.23238300e+00, 9.39298755e-01, -2.69078751e-01, -3.50418097e-01, 1.92109121e+00, -1.46520490e-01, 3.90810577e-01, -6.60511307e-01, -1.46288431e+00, 1.26314685e+00, 2.38384651e-01, 8.03730080e-01, 2.83340226e-01, -1.24219159e+00, -1.50458389e+00, -1.60213592e-01, 3.97086657e-01, 1.27321390e-01, -1.13722876e+00, -1.48448425e+00, 1.36136226e+00, -2.34669327e-01, -1.32679409e+00, 1.59032718e+00, 7.53779845e-01, -7.48815568e-01, 7.34822673e-03, 5.57358372e-01, 1.78429993e+00, -1.50510591e+00, -3.87983571e-01, -7.57372493e-01, 6.25354827e-01, 1.44857563e-01, 7.78608476e-01, -6.61441801e-02, -1.24836018e+00, 1.77522984e+00, 1.60497019e-01, -1.18893624e+00, 1.93951152e+00, -9.34504796e-01, 1.82000588e+00, -1.91594654e+00, -1.13118210e+00, -4.13371342e-01, -5.07021131e-01, 1.57792370e+00, -2.52509848e+00, 1.86695906e-01, -1.18412859e+00, 1.49572473e-01, -3.53669860e-01, 1.38877682e+00, 2.53212949e-02, 7.79387552e-01, -7.41508306e-01, 4.10007279e-01, 1.96517288e-02, -5.69215198e-01, 1.45113980e+00, -8.80722624e-01, 1.35468793e+00, -1.67677998e-03, -1.14952039e+00, 8.90718244e-01, -4.10411520e-01, 6.17620908e-01, 2.96993057e-01]) 2-1. 기본 displot 12sns.distplot(x) # x: numpy arrayplt.show() 2-2. 데이터가 Series일 경우 12x = pd.Series(x, name='x variable')x 0 -0.339766 1 -1.486640 2 -0.557926 3 0.325207 4 -0.746666 ... 95 -1.149520 96 0.890718 97 -0.410412 98 0.617621 99 0.296993 Name: x variable, Length: 100, dtype: float64 12sns.distplot(x) # x: Seriesplt.show() x가 Seires일 때는: 그래프에서 x label이 자동으로 Series 이름(column name) 으로 나타남 2-3. rugplot 데이터 위치를 x축 위에 작은 선분(rug)으로 나타내어 데이터들의 위치 밒 분포를 보여준다 12sns.distplot(x, rug=True, hist=False, kde=True)plt.show() 2-4. kde (kernel density) kde 는 histogram보다 부드러운 형태의 분포 곧선을 보여주는 방법 12sns.distplot(x, rug=False, hist=False, kde=True)plt.show() 2-5. 가로로 표현하기 12sns.distplot(x, vertical=True)plt.show() 2-6. 컬러 바꾸기 12sns.distplot(x, color='r')plt.show() 3. heatmap 색상으로 표현할 수 있는 다양한 정보를 일정한 이미지위에 열분포 형태의 비쥬얼한 그래픽으로 출력하는 것이 특정이다 주로 활용되는 경우: pivot table의 데이터를 시각화할 때 데이터의 상관관계를 살펴볼 때 reference: &lt;sns.heatmap&gt; Document sns.heatmap ( data, annot=None, cmap=None ) annot: If True, write the data value in each cell 3-1. 기본 heatmap 123uniform_data = np.random.rand(10, 12)sns.heatmap(uniform_data, annot=True)plt.show() 컬러가 진할수록 숫자가 0에 가깝고, 연할수록 1에 가깝다 3-2. pivot table을 활용하여 그리기 1tips .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 ... ... ... ... ... ... ... ... 239 29.03 5.92 Male No Sat Dinner 3 240 27.18 2.00 Female Yes Sat Dinner 2 241 22.67 2.00 Male Yes Sat Dinner 2 242 17.82 1.75 Male No Sat Dinner 2 243 18.78 3.00 Female No Thur Dinner 2 244 rows × 7 columns 12pivot = tips.pivot_table(index='day', columns='size', values='tip')pivot .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } size 1 2 3 4 5 6 day Thur 1.83 2.442500 2.692500 4.218000 5.000000 5.3 Fri 1.92 2.644375 3.000000 4.730000 NaN NaN Sat 1.00 2.517547 3.797778 4.123846 3.000000 NaN Sun NaN 2.816923 3.120667 4.087778 4.046667 5.0 12sns.heatmap(pivot, cmap='Blues', annot=True)plt.show() 3-3. correlation(상관관계)를 시각화 corr() 함수는 데이터의 상관관계를 보여줌 1titanic.corr() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass age sibsp parch fare adult_male alone survived 1.000000 -0.338481 -0.077221 -0.035322 0.081629 0.257307 -0.557080 -0.203367 pclass -0.338481 1.000000 -0.369226 0.083081 0.018443 -0.549500 0.094035 0.135207 age -0.077221 -0.369226 1.000000 -0.308247 -0.189119 0.096067 0.280328 0.198270 sibsp -0.035322 0.083081 -0.308247 1.000000 0.414838 0.159651 -0.253586 -0.584471 parch 0.081629 0.018443 -0.189119 0.414838 1.000000 0.216225 -0.349943 -0.583398 fare 0.257307 -0.549500 0.096067 0.159651 0.216225 1.000000 -0.182024 -0.271832 adult_male -0.557080 0.094035 0.280328 -0.253586 -0.349943 -0.182024 1.000000 0.404744 alone -0.203367 0.135207 0.198270 -0.584471 -0.583398 -0.271832 0.404744 1.000000 12sns.heatmap(titanic.corr(), annot=True, cmap='YlGnBu')plt.show() 4. pairplot pairplot은 grid 형태로 각 집합의 조합에 대해 히스토그램과 분포도를 그린다. (숫자형 column에 대해서만 그려줌) reference: &lt;sns.pairplot&gt; Document sns.pairplot ( data, hue=None, palette=None, height=2.5 ) 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 4-1. 기본 pairplot 그리기 12sns.pairplot(tips)plt.show() 4-2. hue 옵션으로 특성 구분 12sns.pairplot(tips, hue='size')plt.show() 4-3. 컬러 팔레트 적용 12sns.pairplot(tips, hue='size', palette='rainbow')plt.show() 4-4. 사이즈 적용 12sns.pairplot(tips, hue='size', palette='rainbow', height=4)plt.show() 5. violinplot 마이올린처럼 생긴 violinplot다. column에 대한 데이터의 비교 분포도를 확인할 수 있다. 곡선형 부분 (뚱뚱한 부분)은 데이터의 분포를 나타냄 양쪽 끝 뾰족한 부분은 데이터의 최소값과 최대값을 나타냄 reference: &lt;sns.violinplot&gt; Document sns.violinplot ( x=None. y=None, hue=None, data=None, split=False ) split: When using hue nesting with a variable that takes two levels, setting split to True will draw half of a violin for each level. This can make it easier to directly compare the distributions. 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 5-1. 기본 violinplot 그리기 12sns.violinplot(x=tips['total_bill'])plt.show() 5-2. 비교 분포 확인 x, y축을 지정해줌으로써 바이올린을 분할하여 비교 분포를 볼 수 있다 12sns.violinplot(x='day', y='total_bill', data=tips)plt.show() 5-3. 가로로 뉘인 violinplot x축, y축 변경 12sns.violinplot(y='day', x='total_bill', data=tips)plt.show() 5-4. hue 옵션으로 분포 비교 사실 hue옵션을 사용하지 않으면 바이올린이 대칭이기 때문에 분포의 큰 의미는 없다. 하지만, hue옵션을 주면, 단일 column에 대한 바이올린 모양의 비교를 할 수 있다. 12sns.violinplot(x='day', y='total_bill', hue='smoker', data=tips, palette='muted')plt.show() split 옵션으로 바이올린을 합쳐서 볼 수 있다 12sns.violinplot(x='day', y='total_bill', hue='smoker', data=tips, palette='muted', split=True)plt.show() violinplot은 이런 경우에 많이 활용된다 6. lmplot lmport (initial: 소문자 L) 은 column간의 선형관계를 확인하기에 용이한 차트임. 또한, outlier도 같이 짐작해 볼 수 있다. reference: &lt;sns.lmplot&gt; Document sns.lmplot ( x, y, data, hue=None, col=None, col_wrap=None, row=None, height=5 ) 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 6-1. 기본 lmplot 12sns.lmplot(x='total_bill', y='tip', data=tips, height=6)plt.show() 6-2. hue 옵션으로 다중 선형관계 그리기 아래의 그래프를 통하여 비흡연자가, 흡연자 대비 좀 더 가파른 선형관계를 가지는 것을 볼 수 있다 12sns.lmplot(x='total_bill', y='tip', hue='smoker', data=tips, height=6)plt.show() 6-3. col 옵션을 추가하여 그래프를 별도로 그려볼 수 있다 또한, col_wrap으로 한 줄에 표기할 column의 갯수를 명시할 수 있다 12sns.lmplot(x='total_bill', y='tip', hue='smoker', col='day', col_wrap=2, data=tips, height=6)plt.show() 7. relplot 두 column간 상관관계를 보지만 lmport처럼 선형관계를 따로 그려주지 않다 reference: &lt;sns.replot&gt; Document sns.relplot ( x, y, data, hue=None, col=None, row=None, height=5, palette=None ) 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 7-1. 기본 relplot 12sns.relplot(x='total_bill', y='tip', hue='day', data=tips)plt.show() 7-2. col 옵션으로 그래프 분할 12sns.relplot(x='total_bill', y='tip', hue='day', col='time', data=tips)plt.show() 7-3. row와 column에 표기할 데이터 column 선택 12sns.relplot(x='total_bill', y='tip',hue='day', col='time', row='sex', data=tips)plt.show() 7-4. 컬러 팔레트 적용 12sns.relplot(x='total_bill', y='tip', hue='day', col='time', row='sex', data=tips, palette='CMRmap_r')plt.show() 8. jointplot jointplot은 scatter(산점도)와 histogram(분포)을 동시에 그려줌.(숫자형 데이터만) reference: &lt;sns.jointplot&gt; Document sns.jointplot ( x, y, data=None, kind=‘scatter’, height=6 ) kind: kind of plot to draw. {‘scatter’, ‘reg’, ‘resid’, ‘kde’, ‘hex’} 1tips.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 8-1. 기본 jointplot 그리기 default 로 \"scatter plot\"을 그린다 (kind=‘scatter’) 12sns.jointplot(x='total_bill', y='tip', data=tips)plt.show() 8-2. 선형관계를 표현하는 regression 라인 그리기 옵션: kind='reg’ 12sns.jointplot('total_bill', 'tip', data=tips, kind='reg')plt.show() 8-3. hex 밀도 보기 옵션: kind='hex’ 12sns.jointplot('total_bill', 'tip', data=tips, kind='hex')plt.show() 8-4. 등고선 모양으로 밀집도 확인하기 kind=‘kde’ 옵션으로 데이터의 밀집도를 보다 부드러운 선으로 확인할 수 있다 12iris = sns.load_dataset('iris')iris .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sepal_length sepal_width petal_length petal_width species 0 5.1 3.5 1.4 0.2 setosa 1 4.9 3.0 1.4 0.2 setosa 2 4.7 3.2 1.3 0.2 setosa 3 4.6 3.1 1.5 0.2 setosa 4 5.0 3.6 1.4 0.2 setosa ... ... ... ... ... ... 145 6.7 3.0 5.2 2.3 virginica 146 6.3 2.5 5.0 1.9 virginica 147 6.5 3.0 5.2 2.0 virginica 148 6.2 3.4 5.4 2.3 virginica 149 5.9 3.0 5.1 1.8 virginica 150 rows × 5 columns 12sns.jointplot('sepal_width', 'petal_length', data=iris, kind='kde', color='g')plt.show() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Seaborn","slug":"Seaborn","permalink":"https://hyemin-kim.github.io/tags/Seaborn/"}]},{"title":"Python >> Seaborn - (1) Seaborn을 활용한 다양한 그래프 그리기","slug":"S-Python-Seaborn1","date":"2020-07-03T10:14:58.000Z","updated":"2020-08-12T05:28:21.438Z","comments":true,"path":"2020/07/03/S-Python-Seaborn1/","link":"","permalink":"https://hyemin-kim.github.io/2020/07/03/S-Python-Seaborn1/","excerpt":"","text":"Seaborn을 활용한 다양한 그래프 그리기 0. Seaborn 개요 0-1. seaborn 에서만 제공되는 통계 기반 plot 0-2. 아름다운 스타일링 0-3. 컬러 팔레트 0-4. pandas 데이터프레임과 높은 호환성 1. Scatterplot 1-1. x, y, color, area 설정하기 1-2. cmap과 alpha 2. Barplot, Barhplot 2-1. 기본 Barplot 그리기 2-2. 기본 Barhplot 그리기 2-3. Barplot에서 비교 그래프 그리기 3. Line Plot 3-1. 기본 lineplot 그리기 3-2. 2개 이상의 그래프 그리기 3-3. 마커 스타일링 3-4. 라인 스타일 변경하기 4. Areaplot (Filled Area) 5.Histogram 5-1. 기본 Histogram 그리기 5-2. 다중 Histogram 그리기 6. Pie Chart 7. Box Plot 7-1. 기본 박스플롯 생성 7-2. 다중 박스플롯 생성 7-3. Box Plot 축 바꾸기 7-4. Outlier 마커 심볼과 컬러 변경 reference: pyplot 공식 도튜먼트 살펴보기 seaborn 공식 도큐먼트 살펴보기 1234567import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom IPython.display import Image# seabornimport seaborn as sns 12plt.rcParams[\"figure.figsize\"] = (9, 6) # figure size 설정plt.rcParams[\"font.size\"] = 14 # fontsize 설정 0. Seaborn 개요 seaborn은 matplotlib을 더 사용하게 쉽게 해주는 라이브러리다. matplotlib으로 대부분의 시각화는 가능하지만, 다음과 같은 이유로 많은 사람들이 seaborn을 선호한다. 비교: matplotlib을 활용한 다양한 그래프 그리기 0-1. seaborn 에서만 제공되는 통계 기반 plot 1tips = sns.load_dataset(\"tips\") (1) violinplot 123sns.violinplot(x=\"day\", y=\"total_bill\", data=tips)plt.title('violin plot')plt.show() (2) countplot 123sns.countplot(tips['day'])plt.title('countplot')plt.show() (3) relplot 123sns.relplot(x='tip', y='total_bill', data=tips)plt.title('relplot')plt.show() (4) lmplot 123sns.lmplot(x='tip', y='total_bill', data=tips)plt.title('lmplot')plt.show() (5) heatmap 123plt.title('heatmap')sns.heatmap(tips.corr(), annot=True, linewidths=1)plt.show() 0-2. 아름다운 스타일링 (1) default color의 예쁜 조합 seaborn의 최대 장점 중의 하나가 아름다운 컬러팔레트다. 스타일링에 크게 신경 쓰지 않아도 default 컬러가 예쁘게 조합해준다. matplotlib VS seaborn 12plt.bar(tips['day'], tips['total_bill'])plt.show() 12sns.barplot(x=\"day\", y=\"total_bill\", data=tips, palette=\"colorblind\")plt.show() (2) 그래프 배경 설정 그래프의 배경 (grid 스타일)을 설정할 수 있음. sns.set_style(’…’) whitegrid: white background + grid darkgrid: dark background + grid white: white background (without grid) dark: dark background (without grid) 123sns.set_style('darkgrid')sns.barplot(x=\"day\", y=\"total_bill\", data=tips, palette=\"colorblind\")plt.show() 123sns.set_style('white')sns.barplot(x=\"day\", y=\"total_bill\", data=tips, palette=\"colorblind\")plt.show() 0-3. 컬러 팔레트 자세한 컬러팔레트는 공식 도큐먼트를 참고 123456sns.palplot(sns.light_palette((210, 90, 60), input=\"husl\"))sns.palplot(sns.dark_palette(\"muted purple\", input=\"xkcd\"))sns.palplot(sns.color_palette(\"BrBG\", 10))sns.palplot(sns.color_palette(\"BrBG_r\", 10))sns.palplot(sns.color_palette(\"coolwarm\", 10))sns.palplot(sns.diverging_palette(255, 133, l=60, n=10, center=\"dark\")) 1sns.barplot(x=\"tip\", y=\"total_bill\", data=tips, palette='coolwarm') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5bf62888&gt; 1sns.barplot(x=\"tip\", y=\"total_bill\", data=tips, palette='Reds') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba59e40988&gt; 0-4. pandas 데이터프레임과 높은 호환성 1tips .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } total_bill tip sex smoker day time size 0 16.99 1.01 Female No Sun Dinner 2 1 10.34 1.66 Male No Sun Dinner 3 2 21.01 3.50 Male No Sun Dinner 3 3 23.68 3.31 Male No Sun Dinner 2 4 24.59 3.61 Female No Sun Dinner 4 ... ... ... ... ... ... ... ... 239 29.03 5.92 Male No Sat Dinner 3 240 27.18 2.00 Female Yes Sat Dinner 2 241 22.67 2.00 Male Yes Sat Dinner 2 242 17.82 1.75 Male No Sat Dinner 2 243 18.78 3.00 Female No Thur Dinner 2 244 rows × 7 columns 1234sns.catplot(x=\"sex\", y=\"total_bill\", data=tips, kind=\"bar\")plt.show() hue옵션: bar를 새로운 기준으로 분할 12345sns.catplot(x=\"sex\", y=\"total_bill\", hue=\"smoker\", data=tips, kind=\"bar\")plt.show() col / row 옵션: 그래프 자체를 새로운 기준으로 분할 123456sns.catplot(x=\"sex\", y=\"total_bill\", hue=\"smoker\", col=\"time\", data=tips, kind=\"bar\")plt.show() xtick, ytick, xlabel, ylabel을 알아서 생성해 줌 legend까지 자동으로 생성해 줌 뿐만 아니라, 신뢰 구간도 알아서 계산하여 생성함 1. Scatterplot reference: &lt;sns.scatterplot&gt; Document sns.scatterplot ( x, y, size=None, sizes=None, hue=None, palette=None, color=‘auto’, alpha=‘auto’… ) sizes 옵션: size의 선택범위를 설정. (사아즈의 min, max를 설정) hue 옵션: 컬러의 구별 기준이 되는 grouping variable 설정 color 옵션: cmap에 컬러를 지정하면, 컬러 값을 모두 같게 가겨갈 수 있음 alpha 옵션: 투명도 (0~1) 1sns.set_style('darkgrid') 1-1. x, y, color, area 설정하기 12345# 데이터 생성x = np.random.rand(50)y = np.random.rand(50)colors = np.arange(50)area = x * y * 1000 (1) matplotlib 12plt.scatter(x, y, s=area, c=colors)plt.show() (2) seaborn 12sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), hue=area, palette='coolwarm')plt.show() [Tip] Palette 이름이 생각안나면: palette 값을 임의로 주고 실행하여 오류 경고창에 정확한 palette 이름을 보여줌 12sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), hue=area, palette='coolwarm111')plt.show() --------------------------------------------------------------------------- ValueError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\seaborn\\relational.py in numeric_to_palette(self, data, order, palette, norm) 248 try: --&gt; 249 cmap = mpl.cm.get_cmap(palette) 250 except (ValueError, TypeError): D:\\Anaconda\\lib\\site-packages\\matplotlib\\cm.py in get_cmap(name, lut) 182 \"Colormap %s is not recognized. Possible values are: %s\" --&gt; 183 % (name, ', '.join(sorted(cmap_d)))) 184 ValueError: Colormap coolwarm111 is not recognized. Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, twilight, twilight_r, twilight_shifted, twilight_shifted_r, viridis, viridis_r, vlag, vlag_r, winter, winter_r 1-2. cmap과 alpha (1) matplotlib 12345678910111213plt.figure(figsize=(12, 6))plt.subplot(131)plt.scatter(x, y, s=area, c='blue', alpha=0.1)plt.title('alpha=0.1')plt.subplot(132)plt.title('alpha=0.5')plt.scatter(x, y, s=area, c='red', alpha=0.5)plt.subplot(133)plt.title('alpha=1.0')plt.scatter(x, y, s=area, c='green', alpha=1.0)plt.show() (2) seaborn 123456789101112131415plt.figure(figsize=(12, 6))plt.subplot(131)sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), color='blue', alpha=0.1)plt.title('alpha=0.1')plt.subplot(132)plt.title('alpha=0.5')sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), color='red', alpha=0.5)plt.subplot(133)plt.title('alpha=1.0')sns.scatterplot(x, y, size=area, sizes=(area.min(), area.max()), color='green', alpha=0.9)plt.show() 2. Barplot, Barhplot reference: &lt;sns.barplot&gt; Document sns.boxplot ( x, y, hue=None, data=None, alpha=‘auto’, palette=None / color=None ) 2-1. 기본 Barplot 그리기 (1) matplotlib 12345678910111213x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,4))plt.bar(x, y, alpha = 0.7, color = 'red')plt.title('Subjects')plt.xticks(rotation=20)plt.ylabel('Grades')plt.show() (2) seaborn 12345678910111213x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,4))sns.barplot(x, y, alpha=0.8, palette='YlGnBu')plt.title('Subjects')plt.xticks(rotation=20)plt.ylabel('Grades')plt.show() 2-2. 기본 Barhplot 그리기 (1) matplotlib plt.barh 함수 사용 bar 함수에서 xticks / ylabel 로 설정했던 부분이 barh 함수에서 yticks / xlabel 로 변경함 12345678910111213x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,5))plt.barh(x, y, alpha = 0.7, color = 'red')plt.title('Subjects')plt.yticks(x)plt.xlabel('Grades')plt.show() (2) seaborn sns.barplot 함수를 그대로 사용 barplot함수 안에 x와 y의 위치를 교환 xticks설정이 변경 불필요; 하지만 ylabel설정은 xlable로 변경 필요 1234567891011x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]plt.figure(figsize = (7,5))sns.barplot(y, x, alpha=0.9, palette=\"YlOrRd\")plt.xlabel('Grades')plt.title('Subjects')plt.show() 2-3. Barplot에서 비교 그래프 그리기 (1) matplotlib 12345678910111213141516171819202122232425262728x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.bar(x - width/2, y_1, width, alpha = 0.5)axes.bar(x + width/2, y_2, width, alpha = 0.8)# ticks &amp; label 설정plt.xticks(x)axes.set_xticklabels(x_label)plt.ylabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() 123456789101112131415161718192021222324252627x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.barh(x - width/2, y_1, width, alpha = 0.5, color = \"green\")axes.barh(x + width/2, y_2, width, alpha = 0.5, color = \"blue\")# ticks &amp; label 설정plt.yticks(x)axes.set_yticklabels(x_label)plt.xlabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() (2) seaborn Seaborn에서는 위의 matplotlib과 조금 다른 방식을 취한다. seaborn에서 hue옵션으로 매우 쉽게 비교 barplot을 그릴 수 있음. sns.barplot ( x, y, hue=…, data=…, palette=… ) 실전 tip. 그래프를 임의로 그려야 하는 경우 -&gt; matplotlib DataFrame을 가지고 그리는 경우 -&gt; seaborn 12titanic = sns.load_dataset('titanic')titanic.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone 0 0 3 male 22.0 1 0 7.2500 S Third man True NaN Southampton no False 1 1 1 female 38.0 1 0 71.2833 C First woman False C Cherbourg yes False 2 1 3 female 26.0 0 0 7.9250 S Third woman False NaN Southampton yes True 3 1 1 female 35.0 1 0 53.1000 S First woman False C Southampton yes False 4 0 3 male 35.0 0 0 8.0500 S Third man True NaN Southampton no True 12sns.barplot(x='sex', y='survived', hue='pclass', data=titanic, palette='muted')plt.show() 3. Line Plot reference: &lt;sns.lineplot&gt; Document sns.lineplot ( x, y, label=…, color=None, alpha=‘auto’, marker=None, linestyle=None ) 기본 옵션은 matplotlib의 plt.plot과 비슷 함수만 plt.plot에서 sns.lineplot로 바꾸면 됨 plt.legend() 명령어 따로 쓸 필요없음 배경이 whitegrid / darkgrid 로 설정되어 있을 시 plt.grid() 명령어 불필요 3-1. 기본 lineplot 그리기 (1) matplotlib 12345678910x = np.arange(0, 10, 0.1)y = 1 + np.sin(x)plt.plot(x, y)plt.xlabel('x value')plt.ylabel('y value')plt.title('sin graph', fontsize=16)plt.show() (2) seaborn 1234567sns.lineplot(x, y) # 함수만 변경하면 됨 (plt.plot -&gt; sns.lineplot)plt.xlabel('x value')plt.ylabel('y value')plt.title('sin graph', fontsize=16)plt.show() 3-2. 2개 이상의 그래프 그리기 12345678910111213x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1 + np.cos(x)sns.lineplot(x, y_1,label='1+sin', color='blue', alpha = 0.3) # label 설정값을 legend에 나타날 수 있음sns.lineplot(x, y_2, label='1+cos', color='red', alpha = 0.7)plt.xlabel(\"x value\")plt.ylabel(\"y value\")plt.title(\"sin and cos graph\", fontsize = 18)plt.show() 3-3. 마커 스타일링 marker: 마커 옵션 12345678910111213x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)sns.lineplot(x, y_1, label='1+sin', color='blue', alpha=0.3, marker='o')sns.lineplot(x, y_2, label='1+cos', color='red', alpha=0.7, marker='+')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.show() 3-4. 라인 스타일 변경하기 linestyle: 라인 스타일 변경하기 12345678910111213x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)sns.lineplot(x, y_1, label='1+sin', color='blue', linestyle=':')sns.lineplot(x, y_2, label='1+cos', color='red', linestyle='-.')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.show() 4. Areaplot (Filled Area) Seaborn에서는 areaplot을 지원하지 않음 matplotlib을 활용하여 구현해야 함 5.Histogram reference: &lt;sns.distplot&gt; Document sns.distplot ( x, bins=None, hist=True, kde=True, vertical=False ) bins: hist bins 갯수 설정 hist: Whether to plot a (normed) histogram kde: Whether to plot a gaussian kernel density estimate vertical: If True, observed values are on y-axis 5-1. 기본 Histogram 그리기 (1) matplotlib 12345678N = 100000bins = 30x = np.random.randn(N)plt.hist(x, bins=bins)plt.show() (2) seaborn Histogram + Density Function (default) 123456N = 100000bins = 30x = np.random.randn(N)sns.distplot(x, bins=bins) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5cc800c8&gt; Histogram Only 1sns.distplot(x, bins=bins, hist=True, kde=False, color='g') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5cd09788&gt; Density Function Only 1sns.distplot(x, bins=bins, hist=False, kde=True, color='g') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5c7cc208&gt; 수평 그래프 1sns.distplot(x, bins=bins, vertical=True, color='r') &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5c250108&gt; 5-2. 다중 Histogram 그리기 matplotlib 에서의 방법을 사용 12345678910111213141516N = 100000bins = 30x = np.random.randn(N)fig, axes = plt.subplots(1, 3, sharey = True, tight_layout = True)fig.set_size_inches(12, 5)axes[0].hist(x, bins = bins)axes[1].hist(x, bins = bins*2)axes[2].hist(x, bins = bins*4)plt.show() 6. Pie Chart Seaborn에서는 pie plot을 지원하지 않음 matplotlib을 활용하여 구현해야 함 7. Box Plot reference: &lt;sns.boxplot&gt; Document sns.baxplot ( x=None, y=None, hue=None, data=None, orient=None, width=0.8 ) hue: 비교 그래프를 그릴 때 나눔 기준이 되는 Variable 설정 orient: “v” / “h”. Orientation of the plot (vertical or horizontal) width: box의 넓이 7-1. 기본 박스플롯 생성 샘플 데이터 생성 123456# DGPspread = np.random.rand(50) * 100center = np.ones(25) * 50flier_high = np.random.rand(10) * 100 + 100flier_low = np.random.rand(10) * -100data = np.concatenate((spread, center, flier_high, flier_low)) (1) matplotlib 12plt.boxplot(data)plt.show() (2) seaborn 12sns.boxplot(data, orient='v', width=0.2)plt.show() 7-2. 다중 박스플롯 생성 seaborn에서는 hue옵션으로 매우 쉽게 비교 boxplot을 그릴 수 있으며 주로 DataFrame을 가지고 그릴 때 활용한다. barplot과 마찬가지로, 용도에 따라 적절한 library를 사용한다 실전 Tip. 그래프를 임의로 그려야 하는 경우 -&gt; matplotlit DataFrame을 가지고 그리는 경우 -&gt; seaborn (1) matplotlib 1234567891011121314151617# DGPspread1 = np.random.rand(50) * 100center1 = np.ones(25) * 50flier_high1 = np.random.rand(10) * 100 + 100flier_low1 = np.random.rand(10) * -100data1 = np.concatenate((spread1, center1, flier_high1, flier_low1))spread2 = np.random.rand(50) * 100center2 = np.ones(25) * 40flier_high2 = np.random.rand(10) * 100 + 100flier_low2 = np.random.rand(10) * -100data2 = np.concatenate((spread2, center2, flier_high2, flier_low2))data1.shape = (-1, 1)data2.shape = (-1, 1)data = [data1, data2, data2[::2, 0]] 12plt.boxplot(data)plt.show() (2) seaborn 12titanic = sns.load_dataset('titanic')titanic.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } survived pclass sex age sibsp parch fare embarked class who adult_male deck embark_town alive alone 0 0 3 male 22.0 1 0 7.2500 S Third man True NaN Southampton no False 1 1 1 female 38.0 1 0 71.2833 C First woman False C Cherbourg yes False 2 1 3 female 26.0 0 0 7.9250 S Third woman False NaN Southampton yes True 3 1 1 female 35.0 1 0 53.1000 S First woman False C Southampton yes False 4 0 3 male 35.0 0 0 8.0500 S Third man True NaN Southampton no True 12sns.boxplot(x='pclass', y='age', hue='survived', data=titanic)plt.show() 7-3. Box Plot 축 바꾸기 (1) 단일 boxplot orient옵션: orient = \"h\"로 설정 123456# DGPspread = np.random.rand(50) * 100center = np.ones(25) * 50flier_high = np.random.rand(10) * 100 + 100flier_low = np.random.rand(10) * -100data = np.concatenate((spread, center, flier_high, flier_low)) 1sns.boxplot(data, orient='h', width=0.3) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1ba5e866188&gt; (2) 다중 boxplot x, y 변수 교환 orient = “h” 12sns.boxplot(y='pclass', x='age', hue='survived', data=titanic, orient='h')plt.show() 7-4. Outlier 마커 심볼과 컬러 변경 flierprops = … 옵션 사용 (matplotlib과 동일) 123456outlier_marker = dict(markerfacecolor='r', marker='D')plt.title('Changed Outlier Symbols', fontsize=15)sns.boxplot(data, orient='v', width=0.2, flierprops=outlier_marker)plt.show() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Seaborn","slug":"Seaborn","permalink":"https://hyemin-kim.github.io/tags/Seaborn/"}]},{"title":"Python >> Matplotlib - (2) 다양한 그래프 그리기","slug":"S-Python-Matplotlib2","date":"2020-06-28T05:12:32.000Z","updated":"2020-07-03T12:52:46.206Z","comments":true,"path":"2020/06/28/S-Python-Matplotlib2/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/28/S-Python-Matplotlib2/","excerpt":"","text":"matplotlib을 활용한 다양한 그래프 그리기 1. Scatterplot 1-1. x, y, colors, area 설정하기 1-2. cmap과 alpha 2. Barplot, Barhplot 2-1. 기본 barplot 그리기 2-2. 기본 Barhplot 그리기 2-3. Barplot에서 비교 그래프 그리기 3. Line Plot 3-1. 기본 lineplot 그리기 3-2. 2개 이상의 그래프 그리기 3-3. 마커 스타일링 3-4. 라인 스타일링 4. Areaplot (Filled Area) 4-1. 기본 areaplot 그리기 4-2. 경계선을 굵게 그리고 area는 옅게 그리는 효과 적용 4-3. 여러 그래프를 겹쳐서 표현 5. Histogram 5-1. 기본 Histogram 그리기 5-2. 다중 Histogram 그리기 5-3. Y축에 Density 표기 6. Pie Chart 7. Box Plot 7-1. 기본 박스플롯 생성 7-2. 다중 박스플롯 생성 7-3. Box Plot 축 바꾸기 7-4. Outlier 마커 심볼과 컬러 변경 8. 3D 그래프 그리기 8-1. 밑그림 그리기 (canvas) 8-2. 3D plot 그리기 8-3. 3d-scatter 그리기 8-4. contour3D 그리기 (등고선) 9. imshow 123import matplotlib.pyplot as pltimport pandas as pdimport numpy as np 12plt.rcParams[\"figure.figsize\"] = (9, 6) # figure size 설정plt.rcParams[\"font.size\"] = 14 # fontsize 설정 1. Scatterplot reference: &lt;plt.scatter&gt; Document plt.scatter( x, y, s=None, c=None, cmap=None, alpha=None ) s: marker size c: color cmap: colormap alpha: between 0 and 1 Data 생성 12# 0~1 사이의 random value 50 개 생성np.random.rand(50) array([0.65532609, 0.19008877, 0.72343673, 0.63981883, 0.07531076, 0.67080518, 0.93282479, 0.04750706, 0.81240348, 0.40032198, 0.59662026, 0.25797641, 0.37315105, 0.6266855 , 0.50732916, 0.55803591, 0.63610033, 0.88673444, 0.99751021, 0.03723629, 0.07695327, 0.44247 , 0.5245731 , 0.41263818, 0.8009583 , 0.57238283, 0.58647938, 0.9882001 , 0.88993497, 0.5396632 , 0.24683042, 0.0838774 , 0.0826096 , 0.89701004, 0.78305308, 0.21027637, 0.93441558, 0.05756907, 0.6299839 , 0.05833447, 0.24247082, 0.9057054 , 0.1585265 , 0.45569918, 0.85597115, 0.43875418, 0.96962923, 0.17476189, 0.68713067, 0.832518 ]) 12# 0 부터 50 개의 value 생성np.arange(50) array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]) 1-1. x, y, colors, area 설정하기 plt.scatter ( x, y, s = , c = ) s: 점의 넓이. area 값이 커지면 넓이도 커진다 c: 임의 값을 color 값으로 변환 1234567x = np.random.rand(50)y = np.random.rand(50)colors = np.arange(50)area = x * y * 1000plt.scatter(x, y, s = area, c = colors)plt.show() 1-2. cmap과 alpha cmap에 컬러를 지정하면, 컬러 값을 모두 같게 가져갈 수도 있다 alpha값은 투명도를 나타내며 0~1 사이의 값을 지정해 둘 수 있으며, 0에 가까울 수록 투명한 값을 가진다 123456789101112131415plt.figure(figsize=(12 ,6))plt.subplot(131)plt.scatter(x, y, s = area, cmap = 'blue', alpha = 0.1)plt.title('alpha = 0.1') plt.subplot(132)plt.scatter(x, y, s = area, cmap = 'blue', alpha = 0.5)plt.title('alpha = 0.5') plt.subplot(133)plt.scatter(x, y, s = area, cmap = 'blue', alpha = 1.0)plt.title('alpha = 1.0')plt.show() 2. Barplot, Barhplot reference: &lt;plt.bar&gt; Document plt.bar(x, height, width = 0.8, align = ‘center’, alpha = …, color = … ) x: The x coordinates of the bars height: The height(s) of the bars width: The width(s) of the bars (default: 0.8) align: Alignment of the bars to the x coordinates: {‘center’, ‘edge’} 2-1. 기본 barplot 그리기 12345678910111213141516x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]# figure sizeplt.figure(figsize = (7,4))# 수직 barplotplt.bar(x, y, alpha = 0.7, color = 'red')# titleplt.title('Subjects')# y labelplt.ylabel('Grades')plt.show() 문자열이 겹히는 현상 발생했다. 이를 해결하는 방법은 2가지다: 문자열 화전: plt.xtick(rotation = …) barh(수평바 그래프) 사용 12345678910111213141516171819x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]# figure sizeplt.figure(figsize = (7,4))# 수직 barplotplt.bar(x, y, alpha = 0.7, color = 'red')# titleplt.title('Subjects')# x ticksplt.xticks(rotation = 20)# y labelplt.ylabel('Grades')plt.show() 2-2. 기본 Barhplot 그리기 barh 함수에서는 xticks / ylabel 로 설정했던 부분을 yticks / xlabel 로 변경함 12345678910111213141516171819x = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']y = [90, 60, 80, 50, 70, 40]# figure sizeplt.figure(figsize = (7,4))# 수직 barplotplt.barh(x, y, alpha = 0.7, color = 'green')# titleplt.title('Subjects')# y ticks# plt.yticks(x)# x labelplt.xlabel('Grades')plt.show() 2-3. Barplot에서 비교 그래프 그리기 reference: Grouped bar chart with labels (1) barplot 12345678910111213141516171819202122232425262728x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.bar(x - width/2, y_1, width, alpha = 0.5)axes.bar(x + width/2, y_2, width, alpha = 0.8)# ticks &amp; label 설정plt.xticks(x)axes.set_xticklabels(x_label)plt.ylabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() (2) barhplot 123456789101112131415161718192021222324252627x_label = ['Math', 'Programming', 'Data Science', 'Art', 'English', 'Physics']x = np.arange(len(x_label)) # x = [0, 1, 2, 3, 4, 5]y_1 = [90, 60, 80, 50, 70, 40]y_2 = [80, 40, 90, 60, 50, 70]# 넓이 지정width = 0.35# subplots 생성fig, axes = plt.subplots()# 넓이 설정axes.barh(x - width/2, y_1, width, alpha = 0.5, color = \"green\")axes.barh(x + width/2, y_2, width, alpha = 0.5, color = \"blue\")# ticks &amp; label 설정plt.yticks(x)axes.set_yticklabels(x_label)plt.xlabel('Grades')# titleplt.title('Subjects')# legendplt.legend(['John', 'Peter'])plt.show() 3. Line Plot plt.plot ( x, y, label=…, color=…, alpha=…, marker=…, linestyle=…) 3-1. 기본 lineplot 그리기 123456789101112x = np.arange(0, 10, 0.1)y = 1 + np.sin(x)plt.plot(x, y)plt.xlabel('x value')plt.ylabel('y value')plt.title('sin graph', fontsize = 16)plt.grid()plt.show() 3-2. 2개 이상의 그래프 그리기 label: line 이름 (legend에 나타남) color: 컬러 옵션 alpha: 투명도 옵션 123456789101112131415x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1 + np.cos(x)plt.plot(x, y_1,label='1+sin', color='blue', alpha = 0.3) # label 설정값을 legend에 나타날 수 있음plt.plot(x, y_2, label='1+cos', color='red', alpha = 0.7)plt.xlabel(\"x value\")plt.ylabel(\"y value\")plt.title(\"sin and cos graph\", fontsize = 18)plt.grid()plt.legend()plt.show() 3-3. 마커 스타일링 marker: 마커 옵션 123456789101112131415x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)plt.plot(x, y_1, label='1+sin', color='blue', alpha=0.3, marker='o')plt.plot(x, y_2, label='1+cos', color='red', alpha=0.7, marker='+')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.grid()plt.legend()plt.show() 3-4. 라인 스타일링 linestyle: 라인 스타일 변경 옵션 123456789101112131415x = np.arange(0, 10, 0.1)y_1 = 1 + np.sin(x)y_2 = 1+ np.cos(x)plt.plot(x, y_1, label='1+sin', color='blue', linestyle=':')plt.plot(x, y_2, label='1+cos', color='red', linestyle='-.')plt.xlabel('x value')plt.ylabel('y value')plt.title('sin and cos graph', fontsize = 18)plt.grid()plt.legend()plt.show() 4. Areaplot (Filled Area) reference: &lt;plt.fill_between&gt; Document plt.fill_between (x, y, color=…, alpha=…) 4-1. 기본 areaplot 그리기 12y = np.random.randint(low=5, high=10, size=20)y array([8, 8, 7, 6, 5, 8, 6, 9, 8, 8, 5, 5, 6, 6, 5, 5, 6, 8, 9, 5]) 1234567x = np.arange(1,21)y = np.random.randint(low=5, high=10, size=20)# fill_between으로 색칠하기plt.fill_between(x, y, color = \"green\", alpha = 0.6)plt.show() 4-2. 경계선을 굵게 그리고 area는 옅게 그리는 효과 적용 1234plt.fill_between(x, y, color='green', alpha=0.3)plt.plot(x, y, color='green', alpha=0.7)plt.show() 4-3. 여러 그래프를 겹쳐서 표현 123456789101112x = np.arange(0, 10, 0.05)y_1 = np.cos(x) + 1y_2 = np.sin(x) + 1y_3 = y_1 * y_2 / np.piplt.fill_between(x, y_1, label='1+cos', color='green', alpha=0.1)plt.fill_between(x, y_2, label='1+sin', color='blue', alpha=0.2)plt.fill_between(x, y_3, label='sin*cos/pi', color='red', alpha=0.3)plt.legend()plt.show() 많이 겹치는 부분이 어디인지 확인하고 싶을 때 많이 활용됨 5. Histogram reference: &lt;plt.hist&gt; Document plt.hist (x, bins = …) 5-1. 기본 Histogram 그리기 12345678N = 100000bins = 30x = np.random.randn(N)plt.hist(x, bins = bins)plt.show() 5-2. 다중 Histogram 그리기 fig, axs = plt.subplots (row, column, sharey = True, tight_layout = True) axes[i].hist ( x, bins = …) sharey: 다중 그래프가 같은 y축을 share tight_layout: graph의 패딩을 자동으로 조절해주어 fit한 graph를 생성 12345678910111213141516N = 100000bins = 30x = np.random.randn(N)fig, axes = plt.subplots(1, 3, sharey = True, tight_layout = True)fig.set_size_inches(12, 5)axes[0].hist(x, bins = bins)axes[1].hist(x, bins = bins*2)axes[2].hist(x, bins = bins*4)plt.show() 5-3. Y축에 Density 표기 pdf(확률 밀도 함수): density = True cdf(누적 확률 함수): density = True, cumulatice = True 1234567891011121314N = 100000bins = 30x = np.random.randn(N)fig, axes = plt.subplots(1, 2, tight_layout = True)fig.set_size_inches(12, 4)# density=True 값을 통하여 Y축에 density를 표기할 수 있다axes[0].hist(x, bins = bins, density = True, cumulative = True) #cdf: 누적확률함수axes[1].hist(x, bins = bins, density = True) # pdf: 확률밀도함수plt.show() 6. Pie Chart reference: &lt;plt.pie&gt; Document plt.pie( x, explode=None, labels=None, colors=None, autopct=None, shadow=False, startangle=None,…) pie chart 옵션 explode: 파이에서 툭 튀어져 나온 비율 autopct: 퍼센트 자동으로 표기 shadow: 그림자 표시 startangle: 파이를 그리기 시작할 각도 리턴을 받는 인자 texts: label에 대한 텍스트 효과 autotexts: 파이 위에 그려지는 텍스트 효과 12345678910111213141516171819202122232425labels = ['Samsung', 'Huawei', 'Apple', 'Xiaomi', 'Oppo', 'Etc']sizes = [20.4, 15.8, 10.5, 9, 7.6, 36.7]explode = (0.3, 0, 0, 0, 0, 0)# text, autotext 인자를 활용하여 텍스트 스타일링을 적용한다patches, texts, autotexts = plt.pie(sizes, explode = explode, labels = labels, autopct = \"%1.1f%%\", shadow = True, startangle=90)plt.title('Smartphone Pie', fontsize=15)# label 텍스트에 대한 스타일 적용for t in texts: t.set_fontsize(12) t.set_color('gray') # pie 위의 텍스트에 대한 스타일 적용for t in autotexts: t.set_fontsize(18) t.set_color('white') plt.show() 7. Box Plot reference: &lt;plt.boxplot&gt; Document plt.boxplot (data, vert=True, flierprops = …) vert: boxplot 축 바꾸기 (If True: 수직 boxplot; If not: 수평 boxplot) flierprops: oulier marker 설정 (Symbol &amp; Color) 샘플 데이터 생성 123456# Data Generation Process (DGP)spread = np.random.rand(50) * 100center = np.ones(25) * 50flier_high = np.random.rand(10) * 100 + 100flier_low = np.random.rand(10) * -100data = np.concatenate((spread, center, flier_high, flier_low)) 7-1. 기본 박스플롯 생성 123plt.boxplot(data)plt.tight_layoutplt.show() 7-2. 다중 박스플롯 생성 다중 그래프 생성을 위해서는 data 자체가 2차원으로 구성되어 있어야 한다 row와 column으로 구성된 DataFrame에서 Column은 x축에 Row는 Y축에 구성되어 있음 1234567891011121314151617# DGPspread1 = np.random.rand(50) * 100center1 = np.ones(25) * 50flier_high1 = np.random.rand(10) * 100 + 100flier_low1 = np.random.rand(10) * -100data1 = np.concatenate((spread1, center1, flier_high1, flier_low1))spread2 = np.random.rand(50) * 100center2 = np.ones(25) * 40flier_high2 = np.random.rand(10) * 100 + 100flier_low2 = np.random.rand(10) * -100data2 = np.concatenate((spread2, center2, flier_high2, flier_low2))data1.shape = (-1, 1)data2.shape = (-1, 1)data = [data1, data2, data2[::2, 0]] 12plt.boxplot(data)plt.show() 7-3. Box Plot 축 바꾸기 vert = False 옵션을 사용 1234plt.boxplot(data, vert = False)plt.title('Horizontal Box Plot', fontsize = 16)plt.show() 7-4. Outlier 마커 심볼과 컬러 변경 flierprops = … 옵션 사용 123456outlier_marker = dict(markerfacecolor = 'r', marker = 'D') # red diamondplt.boxplot(data, flierprops = outlier_marker)plt.title('Change Outlier Symbols', fontsize = 16)plt.show() 8. 3D 그래프 그리기 reference: mplot3d tutorial 3D 로 그래프를 그리기 위해서는 mplot3d를 추가로 import 해야 함 1from mpl_toolkits import mplot3d 8-1. 밑그림 그리기 (canvas) 12fig = plt.figure()ax = plt.axes(projection = '3d') 8-2. 3D plot 그리기 Axes = plt.axes(projection = ‘3d’) Axes .plot (x, y, z, color=…, alpha=…, marker=…) Axes .plot3D (x, y, z, color=…, alpha=…, marker=…) 12345678910# projection = 3d로 설정ax = plt.axes(projection = '3d')# x, y, z 데이터 생성z = np.linspace(0, 15, 1000)x = np.sin(z)y = np.cos(z)ax.plot(x, y, z, 'gray')plt.show() 12345678910111213# projection = 3d로 설정ax = plt.axes(projection = '3d')# x, y, z 데이터 생성sample_size = 100x = np.cumsum(np.random.normal(0, 1, sample_size)) # cumsum: 누적 합y = np.cumsum(np.random.normal(0, 1, sample_size))z = np.cumsum(np.random.normal(0, 1, sample_size))ax.plot3D(x, y, z, alpha=0.6, marker='o')plt.title('ax.plot')plt.show() 8-3. 3d-scatter 그리기 reference: &lt;Axes.scatter&gt; Document Axes = fig.add_subplot(111, projection=‘3d’) # Axe3D object Axes .scatter( x, y, z, s=None, c=None, marker=None, cmap=None, alpha=None, …) s: marker size c: marker color 12345678910111213fig = plt.figure(figsize=(10, 5))ax = fig.add_subplot(111, projection='3d') # Axe3D objectsample_size = 500x = np.cumsum(np.random.normal(0, 5, sample_size))y = np.cumsum(np.random.normal(0, 5, sample_size))z = np.cumsum(np.random.normal(0, 5, sample_size))ax.scatter(x, y, z, c=z, s=20, alpha=0.5, cmap='Greens')plt.title('ax.scatter')plt.show() 컬러가 찐한 부분에 데이터가 더 많이 몰려있음 8-4. contour3D 그리기 (등고선) Axes = plt.axes(projection=‘3d’) Axes .contour3D (x, y, z ) 12345678910111213x = np.linspace(-6, 6, 30)y = np.linspace(-6, 6, 30)x, y = np.meshgrid(x, y)z = np.sin(np.sqrt(x**2 + y**2))fig = plt.figure(figsize=(12, 6))ax = plt.axes(projection='3d')ax.contour3D(x, y, z, 20, cmap='Reds')plt.title(\"ax.contour3D\")plt.show() 9. imshow 이미지 데이터가 numpy array에서는 숫자형식으로 표현됨 명령어imshow는 이 컬러숫자들을 이미지로 변환하여 보여줌 예제: sklearn.datasets안의 load_digits데이터 load_digits 는 0~16 값을 가지는 array로 이루어져 있다 1개의 array는 8 X 8 배열 안에 표현되어 있다 숫자는 0~9까지 이루어져있다 12345from sklearn.datasets import load_digitsdigits = load_digits()X = digits.images[:10] # 앞에 10개 image를 뽑아서 저장함X[0] # 첫번째 image의 컬러숫자를 살펴보자 array([[ 0., 0., 5., 13., 9., 1., 0., 0.], [ 0., 0., 13., 15., 10., 15., 5., 0.], [ 0., 3., 15., 2., 0., 11., 8., 0.], [ 0., 4., 12., 0., 0., 8., 8., 0.], [ 0., 5., 8., 0., 0., 9., 8., 0.], [ 0., 4., 11., 0., 1., 12., 7., 0.], [ 0., 2., 14., 5., 10., 12., 0., 0.], [ 0., 0., 6., 13., 10., 0., 0., 0.]]) 지금 한 위치에 숫자 하나밖에 없어서 컬러는 흑백으로 나옴. 숫자가 클수록 black에 가깝고, 작을수록 white에 가까움 12345678fig, axes = plt.subplots(nrows=2, ncols=5, sharex=True, figsize=(12, 6), sharey=True)for i in range(10): axes[i//5][i%5].imshow(X[i], cmap='Blues') axes[i//5][i%5].set_title(str(i), fontsize=20) plt.tight_layout()plt.show() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"}]},{"title":"Python >> Matplotlib - (1) 기본 canvas 그리기 및 스타일링","slug":"S-Python-Matplotlib1","date":"2020-06-28T05:12:24.000Z","updated":"2020-07-03T12:27:12.453Z","comments":true,"path":"2020/06/28/S-Python-Matplotlib1/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/28/S-Python-Matplotlib1/","excerpt":"","text":"기본적인 canvas 그리기 및 스타일링 1. 밑 그림 그리기 1-1. 단일 그래프 (single graph) 1-2. 다중 그래프 (multiple graphs) 1-3. 그래프 배열 (subplot / subplots) 2. 주요 스타일 옵션 2-1. 타이틀 2-2. X, Y축 Label 설정 2-3. X, Y축 Tick 조정 (rotation) 2-4. 범례 (Legend) 설정 2-5. X와 Y의 한계점(Limit) 설정 2-6. 스타일 세부 설정 - 마커, 라인, 컬러 2-7. 그리드 (grid) 설정 reference: pyplot 공식 Document 살펴보기 123import matplotlib.pyplot as pltimport pandas as pdimport numpy as np 1# plt.rcParams[\"figure.figsize\"] = (12, 9) # figure size 설정 1. 밑 그림 그리기 1-1. 단일 그래프 (single graph) plt.plot(df_name) plt.show() 12345678## data 생성data = np.arange(1, 100)## plotplt.plot(data)## 그래프만 보여주는 코드 (타 실행 결과 생략하고 그래프만 보여줌)plt.show() 1-2. 다중 그래프 (multiple graphs) 여러 그래프를 같은 canvas 안에 그리기: 명령어 plt.plot(df_name) 를 연속 사용 새 그래프를 새로운 canvas 안에 그리기: 세 그래프를 그리기 전에 plt.figure()명령어를 추가 (1) 1개의 canvas 안에 다중 그래프 그리기 123456789data1 = np.arange(1, 51)data2 = np.arange(51, 101)plt.plot(data1)plt.plot(data2)plt.plot(data2 + 50)plt.show() (2) 새로운 canvas에서 새 그래프를 그리기 figure()는 새로운 그래프 canvas를 생성한다 12345678910data1 = np.arange(100, 201)data2 = np.arange(200, 301)plt.plot(data)plt.figure() # figure() 명령어를 추가plt.plot(data2)plt.plot(data2 + 50)plt.show() 1-3. 그래프 배열 (subplot / subplots) 여러 개 plot을 지정된 행,열수에 따라 배열해주기: plt.subplot(row, column, index) # 각 plot의 좌표 설정 plt.subplots(행의 갯수, 열의 갯수) # 행,열수 설정 (1) subplot (plot의 좌표를 설정하기) 이 방법은 그래프마다 설정해줘야 함 plt.subplot(row, column, index) # 콤마를 제거해도 됨 123456789data1 = np.arange(100, 201)plt.subplot(2, 1, 1)plt.plot(data1)data2 = np.arange(200, 301)plt.subplot(2, 1, 2)plt.plot(data2)plt.show() 위의 코드와 동일하나, \"콤마\"를 제거한 상태 123456789data1 = np.arange(100, 201)plt.subplot(211) # 콤마를 생략함: 211 -&gt; row : 2, col: 1, index : 1plt.plot(data1)data2 = np.arange(200, 301)plt.subplot(212) # 콤마를 생략함plt.plot(data2)plt.show() 12345678910111213data1 = np.arange(100, 201)plt.subplot(1, 3, 1)plt.plot(data1)data2 = np.arange(200, 301)plt.subplot(1, 3, 2)plt.plot(data2)data3 = np.arange(300, 401)plt.subplot(1, 3, 3)plt.plot(data3)plt.show() (2) subplots (배열 기준인 행,열수를 지정하기) subplot와 다르게 subplots()명령어는 한번만 설정해주면 됨 plt.subplots(행의 갯수, 열의 갯수) 123456789101112131415data = np.arange(1, 51)# 밑 그림fig, axes = plt.subplots(2, 3)# plotaxes[0, 0].plot(data)axes[0, 1].plot(data * data)axes[0, 2].plot(data ** 3) # data^3axes[1, 0].plot(data % 10)axes[1, 1].plot(-data)axes[1, 2].plot(data // 20)plt.tight_layout()plt.show() 2. 주요 스타일 옵션 1234from IPython.display import Image# 출처: matplotlib.orgImage('https://matplotlib.org/_images/anatomy.png') 2-1. 타이틀 타이틀 추가: plt.title(\"…\") 타이틀 fontsize 설정: plt.title(\"…\", fontsize = … ) 1234plt.plot([1,2,3], [3,6,9])plt.plot([1,2,3], [2,4,9])plt.title(\"이것은 타이틀 입니다\") Text(0.5, 1.0, '이것은 타이틀 입니다') 1234plt.plot([1,2,3], [3,6,9])plt.plot([1,2,3], [2,4,9])plt.title(\"타이틀 fontsize를 키웁니다\", fontsize = 20) Text(0.5, 1.0, '타이틀 fontsize를 키웁니다') 2-2. X, Y축 Label 설정 plt.xlabel ( “x_name”, fontsize = …) plt.ylabel ( “y_name”, fontsize = …) 123456789plt.plot([1,2,3], [3,6,9])plt.plot([1,2,3], [2,4,9])# 타이틀 설정plt.title(\"Label 설정 예제\", fontsize = 16)# X축 &amp; Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16) Text(0, 0.5, 'Y축') 2-3. X, Y축 Tick 조정 (rotation) Tick은 X, Y축에 위치한 눈금을 말한다 rotation 명령어를 통해 Tick의 각도를 조절할 수 있다 plt.xticks ( rotation = … ) plt.yticks ( rotation = … ) Rotation 각도는 역시개방향 회전각도를 말한다 1234567891011121314plt.plot(np.arange(10), np.arange(10)*2)plt.plot(np.arange(10), np.arange(10)**2)plt.plot(np.arange(10), np.log(np.arange(10)))# titleplt.title(\"X, Y축 Tick 조정\", fontsize = 16)# X축, Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16)# X tick, Y tick rotation 조정plt.xticks(rotation = 90)plt.yticks(rotation = 30) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log This is separate from the ipykernel package so we can avoid doing imports until (array([-10., 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.]), &lt;a list of 11 Text yticklabel objects&gt;) 2-4. 범례 (Legend) 설정 plt.legend ( [ “name1” , “name2” , … ], fontsize = …) 1234567891011121314151617plt.plot(np.arange(10), np.arange(10)*2)plt.plot(np.arange(10), np.arange(10)**2)plt.plot(np.arange(10), np.log(np.arange(10)))# titleplt.title(\"범례(Legend) 설정\", fontsize = 16)# X축, Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16)# X tick, Y tick rotation 조정plt.xticks(rotation = 90)plt.yticks(rotation = 30)# legend 설정plt.legend([\"2x\", \"x^2\", \"logx\"], fontsize = 14) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log This is separate from the ipykernel package so we can avoid doing imports until &lt;matplotlib.legend.Legend at 0x173a5712888&gt; 2-5. X와 Y의 한계점(Limit) 설정 plt.xlim ( a, b ) plt.ylim ( c, d ) 123456789101112131415161718192021plt.plot(np.arange(10), np.arange(10)*2)plt.plot(np.arange(10), np.arange(10)**2)plt.plot(np.arange(10), np.log(np.arange(10)))# titleplt.title(\"X축, Y축 Limit 설정\", fontsize = 16)# X축, Y축 Label 설정plt.xlabel(\"X축\", fontsize = 16)plt.ylabel(\"Y축\", fontsize = 16)# X tick, Y tick rotation 조정plt.xticks(rotation = 90)plt.yticks(rotation = 30)# legend 설정plt.legend([\"2x\", \"x^2\", \"logx\"], fontsize = 14)# x, y limit 설정plt.xlim(0, 5)plt.ylim(0, 20) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log This is separate from the ipykernel package so we can avoid doing imports until (0, 20) 2-6. 스타일 세부 설정 - 마커, 라인, 컬러 reference: 세부 Document 확인하기 스타일 세부 설정은 마커, 선의 동류 설정, 드리고 컬러가 있으며, 문다열로 세부설정을 하게 된다 (1) marker의 종류 ‘.’ point marker ‘,’ pixel marker ‘o’ circle marker ‘v’ triangle_down marker ‘^’ triangle_up marker ‘&lt;’ triangle_left marker ‘&gt;’ triangle_right marker ‘1’ tri_down marker ‘2’ tri_up marker ‘3’ tri_left marker ‘4’ tri_right marker 's ’ square marker ‘p’ pentagon marker ‘*’ star marker ‘h’ hexagon1 marker ‘H’ hexagon2 marker ‘+’ plus marker ‘x’ x marker ‘D’ diamond marker ‘d’ thin_diamond marker ‘|’ vline marker ‘_’ hline marker 123456789101112# marker 스타일 설정plt.plot(np.arange(10), np.arange(10)*2, marker='o', markersize=5)plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='v', markersize=10)plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='+', markersize=15)plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='*', markersize=20)# 타이틀 &amp; font 설정plt.title('마커 스타일 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (2) line의 종류 ‘-’ solid line style ‘–’ dashed line style ‘-.’ dash-dot line style ‘:’ dotted line style 12345678910111213# line 스타일 설정plt.plot(np.arange(10), np.arange(10)*2, marker='o', linestyle='')plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='o', linestyle='-')plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='v', linestyle='--')plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='+', linestyle='-.')plt.plot(np.arange(10), np.arange(10)*2 - 40, marker='*', linestyle=':')# 타이틀 &amp; font 설정plt.title('다양한 선의 종류 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (3) color의 종류 ‘b’ blue ‘g’ green ‘r’ red ‘c’ cyan ‘m’ magenta ‘y’ yellow ‘k’ black ‘w’ white more choices: matplotlib.colors (e.g. “purple”, “#008000”) 123456789101112# color 설정plt.plot(np.arange(10), np.arange(10)*2, marker='o', linestyle='-', color='b')plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='v', linestyle='--', color='c')plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='+', linestyle='-.', color='y')plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='*', linestyle=':', color='r')# 타이틀 &amp; font 설정plt.title('색상 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (4) Format: '[marker][line][color]' example: ‘b’ # blue markers with default shape ‘or’ # red circles ‘-g’ # green solid line ‘–’ # dashed line with default color ‘^k:’ # black triangle_up markers connected by a dotted line Each of them is optional. If not provided, the value from the style cycle is used. Exception: If line is given, but no marker, the data will be a line without markers. 123456789101112# \"marker + line + color\" format 설정plt.plot(np.arange(10), np.arange(10)*2, \"o-r\")plt.plot(np.arange(10), np.arange(10)*2 - 10, 'v--b')plt.plot(np.arange(10), np.arange(10)*2 - 20, '+y')plt.plot(np.arange(10), np.arange(10)*2 - 30, ':k')# 타이틀 &amp; font 설정plt.title('marker/line + color 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') (5) 색상 투명도 설정 alpha = … (0.0 ~ 1.0) 123456789101112# color 투명도 설정plt.plot(np.arange(10), np.arange(10)*2, color='b', alpha=0.1)plt.plot(np.arange(10), np.arange(10)*2 - 10, color='b', alpha=0.3)plt.plot(np.arange(10), np.arange(10)*2 - 20, color='b', alpha=0.6)plt.plot(np.arange(10), np.arange(10)*2 - 30, color='b', alpha=1.0)# 타이틀 &amp; font 설정plt.title('투명도 (alpha) 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20) Text(0, 0.5, 'Y축') 2-7. 그리드 (grid) 설정 그리드 (grid) 추가: plt.grid() 1234567891011121314plt.plot(np.arange(10), np.arange(10)*2, marker='o', linestyle='-', color='b')plt.plot(np.arange(10), np.arange(10)*2 - 10, marker='v', linestyle='--', color='c')plt.plot(np.arange(10), np.arange(10)*2 - 20, marker='+', linestyle='-.', color='y')plt.plot(np.arange(10), np.arange(10)*2 - 30, marker='*', linestyle=':', color='r')# 타이틀 &amp; font 설정plt.title('그리드 설정 예제', fontsize=20)# X축 &amp; Y축 Label 설정plt.xlabel('X축', fontsize=20)plt.ylabel('Y축', fontsize=20)# grid 옵션 추가plt.grid() document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"}]},{"title":"Python >> Matplotlib 개요","slug":"S-Python-Matplotlib0","date":"2020-06-28T05:11:58.000Z","updated":"2020-06-28T05:42:20.736Z","comments":true,"path":"2020/06/28/S-Python-Matplotlib0/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/28/S-Python-Matplotlib0/","excerpt":"","text":"시각화 library – [matplotlib] 개요 matplotlib: 파이썬 기반 시각화 라이브러리 1. 불러오기 2. matplotlib 주요 장점 3. matplotlib 주요 단점 4. matplotlib 웹사이트 matplotlib: 파이썬 기반 시각화 라이브러리 1. 불러오기 1import matplotlib.pyplot 1import matplotlib.pyplot as plt # alias 설정 pandas도 matplotlib을 내장 2. matplotlib 주요 장점 파이썬 표준 시각화 도구라고 불릴 만큼 다양한 기능 지원 세부 옵션을 통하여 아름다운 스타일링 가능 보다 다양한 그래프를 그릴 수 있음 pandas와 연동이 용이함 3. matplotlib 주요 단점 한글에 대한 완벽한 지원 X 한글 사용시 추가설정 필요 (설정방법은 [Python &gt;&gt; Pandas 시각화] 안의 [0.준비 - 한글폰트 깨짐현상 해결]을 참조) 세부 기능이 많으나, 사용성이 복잡하다고 느낄 수 있음 4. matplotlib 웹사이트 http://matplotlib.org/ 여거시 matplotlib의 Documents, Samples 들을 볼 수 있음 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"사각화","slug":"사각화","permalink":"https://hyemin-kim.github.io/tags/%EC%82%AC%EA%B0%81%ED%99%94/"}]},{"title":"Python >> Pandas 시각화","slug":"S-Python-Pandas-visual","date":"2020-06-25T05:09:37.000Z","updated":"2020-06-25T05:28:17.721Z","comments":true,"path":"2020/06/25/S-Python-Pandas-visual/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/25/S-Python-Pandas-visual/","excerpt":"","text":"Pandas - 데이터 시각화 0. 준비 – 한글폰트 깨짐현상 해결 1. Plot 그래프 line 그래프 bar 그래프 히스토그램 (hist) 커널 밀도 그래프 (kde) 고밀도 산점도 그래프 (hexbin) 박스 플롯 (box) area plot 파이 그래프 (pie plot) 산점도 그래프 (scatter plot) 1import pandas as pd 1df = pd.read_csv(\"house_price_clean.csv\") 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 4 인천 60㎡이하 2015 10 3488 ... ... ... ... ... ... 3288 경남 60㎡초과 85㎡이하 2020 2 3065 3289 경남 85㎡초과 102㎡이하 2020 2 3247 3290 제주 60㎡이하 2020 2 4039 3291 제주 60㎡초과 85㎡이하 2020 2 3962 3292 제주 102㎡초과 2020 2 3601 3293 rows × 5 columns 0. 준비 – 한글폰트 깨짐현상 해결 reference: 주피터 노트북(Jupyter notebook) - Matplotlib 한글 깨짐 현상 해결 matplotlib/seaborn으로 시각화할 때 한글 폰트 깨짐현상 해결방법 Jupyter Notebook에서 그래프를 그릴 때 한글 깨짐 현상이 발생한다 1df.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x179eb070ac8&gt; 우리는 설정 파일을 수정하여 한글 폰트를 영구 등록함으로써 이 문제를 해결할 수 있다 (1) 설정 파일 위치 찾기 1234import matplotlib as mpl#font 설정 파일 위치 출력mpl.matplotlib_fname() 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data\\\\matplotlibrc' (2) 설정 파일 수정하기 맨 마지막 matplotlibrc 는 우리가 수정해야할 파일의 이름이다 step 1. 한글 폰트 적용 수정전: # font.family : sans-serif 수정후: font.family : Malgun Gothic step 2. minus 깨짐 방지 수정전: # axes.unicode_minus : True ## use unicode for the minus symbol 수정후: axes.unicode_minus : False ## use unicode for the minus symbol (3) Tip: 전역으로 시각화 figsize 조절 12import matplotlib.pyplot as pltplt.rcParams['figure.figsize'] = (8, 5) 설정을 완료한 후 jupyter notebook의 kernel을 리셋하고 다시 그래프를 그리면, 한글폰트가 깨지지 않고 잘 출력되는 것을 확인하실 수 있다. 1df.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f01b0c48&gt; 1. Plot 그래프 df_name [ col_name ] .plot ( kind = ‘…’ ) plot은 일반 선그래프를 나타난다 kind 옵션을 통해 원하는 그패프를 그릴 수 있다 kind 옵션: line: 선 그래프 bar: 바 그래프 barh: 수평 바 프래프 hist: 히스토르램 kde: 커널 밀도 그래프 hexbin: 고밀도 산점도 그래프 box: 박스 플롯 area: 면적 그래프 pie: 파이 그래프 scatter: 산점도 그래프 line 그래프 line 그래프는 데이터가 연속적인 경우 사용하기 적절하다. (예를 들면, 주가 데이터) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 4 인천 60㎡이하 2015 10 3488 ... ... ... ... ... ... 3288 경남 60㎡초과 85㎡이하 2020 2 3065 3289 경남 85㎡초과 102㎡이하 2020 2 3247 3290 제주 60㎡이하 2020 2 4039 3291 제주 60㎡초과 85㎡이하 2020 2 3962 3292 제주 102㎡초과 2020 2 3601 3293 rows × 5 columns (1) 모든 observation의 분양가 살펴보기 12# index - 분양가df[\"분양가\"].plot(kind = 'line') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f01a0bc8&gt; (2) 연도에 따른 서울 분양가 변화 추세 123# select \"서울\" datadf_seoul = df.loc[df[\"지역\"] == \"서울\"]df_seoul .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 64 서울 60㎡이하 2015 11 6320 ... ... ... ... ... ... 3178 서울 102㎡초과 2020 1 8779 3234 서울 60㎡이하 2020 2 8193 3235 서울 60㎡초과 85㎡이하 2020 2 8140 3236 서울 85㎡초과 102㎡이하 2020 2 13835 3237 서울 102㎡초과 2020 2 9039 212 rows × 5 columns 123# group by \"year\" df_seoul_year = df_seoul.groupby('연도').mean()df_seoul_year .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 월 분양가 연도 2015 11.0 6201.000000 2016 6.5 6674.520833 2017 6.5 6658.729167 2018 6.5 7054.687500 2019 6.5 8735.083333 2020 1.5 9647.375000 12# line plotdf_seoul_year[\"분양가\"].plot(kind = 'line') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f028b5c8&gt; bar 그래프 bar 그패프는 그룹별로 비교할 때 유용하다 지역별 평균 분양가 살펴보기 1df.groupby(\"지역\")[\"분양가\"].mean() 지역 강원 2448.156863 경기 4133.952830 경남 2858.932367 경북 2570.465000 광주 3055.043750 대구 3679.620690 대전 3176.127389 부산 3691.981132 서울 7308.943396 세종 2983.543147 울산 2990.373913 인천 3684.302885 전남 2326.250000 전북 2381.416268 제주 3472.677966 충남 2534.950000 충북 2348.183962 Name: 분양가, dtype: float64 12# 수직 바 그래프df.groupby(\"지역\")[\"분양가\"].mean().plot(kind = 'bar') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f028b548&gt; 12# 수평 바 그래프df.groupby(\"지역\")[\"분양가\"].mean().plot(kind = 'barh') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179edd9d4c8&gt; 히스토그램 (hist) 히스토그램은 분포-빈도 를 시각화하여 보여준다. 가로축에는 분포를, 세로축에는 빈도가 시각화되어 보여짐. 1df[\"분양가\"].plot(kind = \"hist\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f021cc88&gt; 커널 밀도 그래프 (kde) 히스토그램과 유사하게 밀도를 보여주는 그래프다 히스토그램과 유사한 모양새를 각추고 있다 하지만 히스토그램과 다르게 부드러운 라인을 가지고 있다 1df[\"분양가\"].plot(kind = \"kde\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f043d608&gt; 고밀도 산점도 그래프 (hexbin) hexbin은 고밀고 산점도 그래프다 x와 y 키 값을 넣어 주어야 한다 x, y 값 모두 numeric value 이어야한다 데이터의 밀도를 추정한다 1df.plot(kind = \"hexbin\", x = \"분양가\", y = \"연도\", gridsize = 20) &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f028a9c8&gt; 박스 플롯 (box) 1df_seoul = df.loc[df[\"지역\"] == \"서울\"] 1df_seoul[\"분양가\"].plot(kind = \"box\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f226d748&gt; box plot 해석 IQR (Inter Quantile Range) = 3Q - 1Q Upper fence = 75th Percentile + 1.5*IQR Lower fence = 25th Percentile - 1.5*IQR box plot은 데이터 outlier 감지할 때 가장 많이 활용되며, 25%, median, 75% 분위값을 활용하는 용도로도 많이 활용된다 area plot area plot은 line 그래프에서 아래 area를 모두 색칠해 주는 것이 특징이다. 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역 규모 연도 월 분양가 0 서울 60㎡이하 2015 10 5652 1 서울 60㎡초과 85㎡이하 2015 10 5882 2 서울 85㎡초과 102㎡이하 2015 10 5721 3 서울 102㎡초과 2015 10 5879 4 인천 60㎡이하 2015 10 3488 ... ... ... ... ... ... 3288 경남 60㎡초과 85㎡이하 2020 2 3065 3289 경남 85㎡초과 102㎡이하 2020 2 3247 3290 제주 60㎡이하 2020 2 4039 3291 제주 60㎡초과 85㎡이하 2020 2 3962 3292 제주 102㎡초과 2020 2 3601 3293 rows × 5 columns 1df.groupby(\"월\")[\"분양가\"].count().plot(kind = \"line\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f22a6688&gt; 1df.groupby(\"월\")[\"분양가\"].count().plot(kind = \"area\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f2267588&gt; 파이 그래프 (pie plot) pie는 대표적으로 데이터의 점유율을 보유줄 때 유용하다 연도별 분양가 데이터 점유율 1df.groupby(\"연도\")[\"분양가\"].count().plot(kind = 'pie') &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f224fec8&gt; 산점도 그래프 (scatter plot) 점으로 데이터를 표기해준다 x, y값을 넣어주어야한다 (hexbin과 유사) x축과 y축을 지정해주면 그에 맞는 데이터 분포를 볼 수 있다 역시 numeric column 만 지정할 수 있다 1df.plot(x = \"월\", y = \"분양가\", kind = \"scatter\") &lt;matplotlib.axes._subplots.AxesSubplot at 0x179f23372c8&gt; document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"}]},{"title":"【실습】 Python >> Pandas 전처리 -- 부동산 데이터","slug":"E-Python-Pandas-Pre-1","date":"2020-06-22T10:14:57.000Z","updated":"2020-06-23T16:35:19.434Z","comments":true,"path":"2020/06/22/E-Python-Pandas-Pre-1/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/22/E-Python-Pandas-Pre-1/","excerpt":"","text":"&lt;Pandas 전처리&gt; 실습 – 부동산 데이터 0. 샘플데이터 1. column 이름 제정의 (rename) 2. Data Overview 2-1. Data Shape 확인하기 2-2. 걸측값과 Data Type 확인하기 2-3. 통계값 확인하기 3. 데이터 타입 변환 3-1. str.strip()을 활용하여 공백이 있는 데이터의 공백 없애기 3-2. 빈 공백에 0을 넣어주기 3-3. NaN 값은 fillna로 채워주기 3-4. str.replace() 를 활용하여 콤마를 제거하기 3-5. str.replace()를 활용하여 “-” 제거하기 3-6. 규모구분 column에 불필요한 “전용면적” 제거하기 4. 전처리 내용 복습하기 5. 지역별 분양가격을 확인해보기 5-1. 지역별 평균 분양가격 확인해보기 5-2. 분양가격이 100보다 작은 행을 제거해보기 5-3. 지역별 “분양가격” 데이터의 갯수를 확인해보기 5-4. 지역별 제일 비싼 분양가를 확인해보기 6. 연도별 평균 분양가격을 확인해보기 7. 피벗테이블 활용하기 8. 연도별, 규모별 가격을 알아보기 1import pandas as pd 0. 샘플데이터 공공데이터포털 에서 제공하는 공공데이터 “민간 아파트 가격동향” 를 활용한다. 1df = pd.read_csv(\"seoul_house_price.csv\") 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격(㎡) 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 전용면적 60㎡이하 2020 2 4039 4502 제주 전용면적 60㎡초과 85㎡이하 2020 2 3962 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4504 제주 전용면적 102㎡초과 2020 2 3601 4505 rows × 5 columns 1. column 이름 제정의 (rename) [목표] 분양가격 column의 이름을 재정의: “분양가격(m2)​” --&gt; “분양가격” 1df = df.rename(columns = {\"분양가격(㎡)\" : \"분양가격\"}) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 전용면적 60㎡이하 2020 2 4039 4502 제주 전용면적 60㎡초과 85㎡이하 2020 2 3962 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4504 제주 전용면적 102㎡초과 2020 2 3601 4505 rows × 5 columns 2. Data Overview 2-1. Data Shape 확인하기 1df.shape (4505, 5) 2-2. 걸측값과 Data Type 확인하기 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 4505 entries, 0 to 4504 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 지역명 4505 non-null object 1 규모구분 4505 non-null object 2 연도 4505 non-null int64 3 월 4505 non-null int64 4 분양가격 4210 non-null object dtypes: int64(2), object(3) memory usage: 176.1+ KB 2-3. 통계값 확인하기 1df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 연도 월 count 4505.000000 4505.000000 mean 2017.452830 6.566038 std 1.311432 3.595519 min 2015.000000 1.000000 25% 2016.000000 3.000000 50% 2017.000000 7.000000 75% 2019.000000 10.000000 max 2020.000000 12.000000 3. 데이터 타입 변환 [목표] &lt;object 타입&gt;으로 되어있는 \"분양가격\"을 &lt;int 타입&gt;으로 변환하기 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-193-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: invalid literal for int() with base 10: ' ' !! “분양가격” column에 “2칸 공백” 값이 있어서 Error가 납니다 3-1. str.strip()을 활용하여 공백이 있는 데이터의 공백 없애기 df_name [ “col_name” ] .str.strip() 1df.loc[df[\"분양가격\"] == ' '] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 28 광주 전용면적 85㎡초과 102㎡이하 2015 10 29 광주 전용면적 102㎡초과 2015 10 34 대전 전용면적 102㎡초과 2015 10 81 제주 전용면적 60㎡이하 2015 10 113 광주 전용면적 85㎡초과 102㎡이하 2015 11 114 광주 전용면적 102㎡초과 2015 11 119 대전 전용면적 102㎡초과 2015 11 166 제주 전용면적 60㎡이하 2015 11 198 광주 전용면적 85㎡초과 102㎡이하 2015 12 199 광주 전용면적 102㎡초과 2015 12 204 대전 전용면적 102㎡초과 2015 12 251 제주 전용면적 60㎡이하 2015 12 283 광주 전용면적 85㎡초과 102㎡이하 2016 1 284 광주 전용면적 102㎡초과 2016 1 289 대전 전용면적 102㎡초과 2016 1 336 제주 전용면적 60㎡이하 2016 1 1df[\"분양가격\"] = df[\"분양가격\"].str.strip(' ') 1df.loc[df[\"분양가격\"] == \" \"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 3-2. 빈 공백에 0을 넣어주기 1df.loc[df[\"분양가격\"] == '', \"분양가격\"] = 0 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-198-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: cannot convert float NaN to integer !! “분양가격” column에 “NaN” 값이 있어서 Error가 또 납니다 ㅠㅠ 3-3. NaN 값은 fillna로 채워주기 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 전용면적 60㎡이하 2020 2 4039 4502 제주 전용면적 60㎡초과 85㎡이하 2020 2 3962 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4504 제주 전용면적 102㎡초과 2020 2 3601 4505 rows × 5 columns 1df.loc[df[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 368 광주 전용면적 85㎡초과 102㎡이하 2016 2 NaN 369 광주 전용면적 102㎡초과 2016 2 NaN 374 대전 전용면적 102㎡초과 2016 2 NaN 388 강원 전용면적 85㎡초과 102㎡이하 2016 2 NaN 421 제주 전용면적 60㎡이하 2016 2 NaN ... ... ... ... ... ... 4461 세종 전용면적 60㎡이하 2020 2 NaN 4488 전남 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4493 경북 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4499 경남 전용면적 102㎡초과 2020 2 NaN 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 295 rows × 5 columns 1df[\"분양가격\"] = df[\"분양가격\"].fillna(0) 1df.loc[df[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-203-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: invalid literal for int() with base 10: '6,657' !! 이번에는 \",\"가 들어간 데이터가 문제네요… 3-4. str.replace() 를 활용하여 콤마를 제거하기 1df.loc[df[\"분양가격\"] == \"6,657\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 2125 서울 전체 2017 11 6,657 1df[\"분양가격\"] = df[\"분양가격\"].str.replace(',', '') 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-206-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: cannot convert float NaN to integer !! 다시 NaN값이 생겨서 fillna로 채워줍니다. 1df[\"분양가격\"] = df[\"분양가격\"].fillna(0) 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-208-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: invalid literal for int() with base 10: '-' !! 이번에는 \"-\"가 멀썽이네요… 3-5. str.replace()를 활용하여 “-” 제거하기 1df[\"분양가격\"] = df[\"분양가격\"].str.replace(\"-\", \"\") 1df.loc[df[\"분양가격\"] == \"\", \"분양가격\"] = 0 1df[\"분양가격\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-211-5870dcdf031c&gt; in &lt;module&gt; ----&gt; 1 df[\"분양가격\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 872 # work around NumPy brokenness, #1987 873 if np.issubdtype(dtype.type, np.integer): --&gt; 874 return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape) 875 876 # if we have a datetime/timedelta array of objects pandas\\_libs\\lib.pyx in pandas._libs.lib.astype_intsafe() ValueError: cannot convert float NaN to integer 1df[\"분양가격\"] = df[\"분양가격\"].fillna(0) 1df[\"분양가격\"] = df[\"분양가격\"].astype(int) 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 4505 entries, 0 to 4504 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 지역명 4505 non-null object 1 규모구분 4505 non-null object 2 연도 4505 non-null int64 3 월 4505 non-null int64 4 분양가격 4505 non-null int32 dtypes: int32(1), int64(2), object(2) memory usage: 158.5+ KB 이제 드디어 “분양가격” column의 Type을 int로 성공적으로 바꿨습니다!!! 3-6. 규모구분 column에 불필요한 “전용면적” 제거하기 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 전용면적 60㎡이하 2015 10 5652 2 서울 전용면적 60㎡초과 85㎡이하 2015 10 5882 3 서울 전용면적 85㎡초과 102㎡이하 2015 10 5721 4 서울 전용면적 102㎡초과 2015 10 5879 1df[\"규모구분\"] = df[\"규모구분\"].str.replace(\"전용면적\", \"\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 4. 전처리 내용 복습하기 방급 진행 했던 전처리 과정을 복습해봅시다! 1df2 = pd.read_csv(\"seoul_house_price.csv\") (1) 콤마가 있는 경우 df_name [ “col_name” ] .str.replace (’,’, ‘’) 1df2.iloc[2125] 지역명 서울 규모구분 전체 연도 2017 월 11 분양가격(㎡) 6,657 Name: 2125, dtype: object 1df2 = df2.rename(columns = {\"분양가격(㎡)\" : \"분양가격\"}) 1df2[\"분양가격\"] = df2[\"분양가격\"].str.replace(\",\", \"\") 1df2.iloc[2125] 지역명 서울 규모구분 전체 연도 2017 월 11 분양가격 6657 Name: 2125, dtype: object (2) - 가 있는 경우 df_name [ “col_name” ] **.str.replace(’-’, ‘’) 1df2.loc[df2[\"분양가격\"] == \"-\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 3683 광주 전용면적 85㎡초과 102㎡이하 2019 5 - 3686 대전 전용면적 60㎡이하 2019 5 - 3688 대전 전용면적 85㎡초과 102㎡이하 2019 5 - 3690 울산 전체 2019 5 - 3691 울산 전용면적 60㎡이하 2019 5 - 3692 울산 전용면적 60㎡초과 85㎡이하 2019 5 - 3693 울산 전용면적 85㎡초과 102㎡이하 2019 5 - 3694 울산 전용면적 102㎡초과 2019 5 - 3696 세종 전용면적 60㎡이하 2019 5 - 1df2[\"분양가격\"] = df2[\"분양가격\"].str.replace(\"-\", \"\") 1df2.loc[df2[\"분양가격\"] == \"-\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (3) 공백이 2개 들어간 경우 df_name [ “col_name” ] **.str.strip(\" \") 1df2.loc[df2[\"분양가격\"] == \" \"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 28 광주 전용면적 85㎡초과 102㎡이하 2015 10 29 광주 전용면적 102㎡초과 2015 10 34 대전 전용면적 102㎡초과 2015 10 81 제주 전용면적 60㎡이하 2015 10 113 광주 전용면적 85㎡초과 102㎡이하 2015 11 114 광주 전용면적 102㎡초과 2015 11 119 대전 전용면적 102㎡초과 2015 11 166 제주 전용면적 60㎡이하 2015 11 198 광주 전용면적 85㎡초과 102㎡이하 2015 12 199 광주 전용면적 102㎡초과 2015 12 204 대전 전용면적 102㎡초과 2015 12 251 제주 전용면적 60㎡이하 2015 12 283 광주 전용면적 85㎡초과 102㎡이하 2016 1 284 광주 전용면적 102㎡초과 2016 1 289 대전 전용면적 102㎡초과 2016 1 336 제주 전용면적 60㎡이하 2016 1 1df2[\"분양가격\"] = df2[\"분양가격\"].str.strip(\" \") 1df2.loc[df2[\"분양가격\"] == \" \"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (4) 빈 칸을 0으로 채우기 df_name.loc [ df_name [ “col_name” ] == “” , “col_name”] = 0 1df2.loc[df2[\"분양가격\"] == \"\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 28 광주 전용면적 85㎡초과 102㎡이하 2015 10 29 광주 전용면적 102㎡초과 2015 10 34 대전 전용면적 102㎡초과 2015 10 81 제주 전용면적 60㎡이하 2015 10 113 광주 전용면적 85㎡초과 102㎡이하 2015 11 114 광주 전용면적 102㎡초과 2015 11 119 대전 전용면적 102㎡초과 2015 11 166 제주 전용면적 60㎡이하 2015 11 198 광주 전용면적 85㎡초과 102㎡이하 2015 12 199 광주 전용면적 102㎡초과 2015 12 204 대전 전용면적 102㎡초과 2015 12 251 제주 전용면적 60㎡이하 2015 12 283 광주 전용면적 85㎡초과 102㎡이하 2016 1 284 광주 전용면적 102㎡초과 2016 1 289 대전 전용면적 102㎡초과 2016 1 336 제주 전용면적 60㎡이하 2016 1 3683 광주 전용면적 85㎡초과 102㎡이하 2019 5 3686 대전 전용면적 60㎡이하 2019 5 3688 대전 전용면적 85㎡초과 102㎡이하 2019 5 3690 울산 전체 2019 5 3691 울산 전용면적 60㎡이하 2019 5 3692 울산 전용면적 60㎡초과 85㎡이하 2019 5 3693 울산 전용면적 85㎡초과 102㎡이하 2019 5 3694 울산 전용면적 102㎡초과 2019 5 3696 세종 전용면적 60㎡이하 2019 5 1df2.loc[df2[\"분양가격\"] == \"\", \"분양가격\"] = 0 1df2.loc[df2[\"분양가격\"] == \"\"] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (5) NaN 값을 0으로 바꾸기 df_name.loc [ df_name [ “col_name” ] .isna() ] df_name [ “col_name” ].fillna(0) 1df2.loc[df2[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 368 광주 전용면적 85㎡초과 102㎡이하 2016 2 NaN 369 광주 전용면적 102㎡초과 2016 2 NaN 374 대전 전용면적 102㎡초과 2016 2 NaN 388 강원 전용면적 85㎡초과 102㎡이하 2016 2 NaN 421 제주 전용면적 60㎡이하 2016 2 NaN ... ... ... ... ... ... 4461 세종 전용면적 60㎡이하 2020 2 NaN 4488 전남 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4493 경북 전용면적 85㎡초과 102㎡이하 2020 2 NaN 4499 경남 전용면적 102㎡초과 2020 2 NaN 4503 제주 전용면적 85㎡초과 102㎡이하 2020 2 NaN 295 rows × 5 columns 1df2[\"분양가격\"] = df2[\"분양가격\"].fillna(0) 1df2.loc[df2[\"분양가격\"].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 (6) column type 바꾸기 df_name [ “col_name” ] .astype(…) 1df2[\"분양가격\"].astype(int) 0 5841 1 5652 2 5882 3 5721 4 5879 ... 4500 3955 4501 4039 4502 3962 4503 0 4504 3601 Name: 분양가격, Length: 4505, dtype: int32 5. 지역별 분양가격을 확인해보기 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 60㎡이하 2020 2 4039 4502 제주 60㎡초과 85㎡이하 2020 2 3962 4503 제주 85㎡초과 102㎡이하 2020 2 0 4504 제주 102㎡초과 2020 2 3601 4505 rows × 5 columns 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 4505 entries, 0 to 4504 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 지역명 4505 non-null object 1 규모구분 4505 non-null object 2 연도 4505 non-null int64 3 월 4505 non-null int64 4 분양가격 4505 non-null int32 dtypes: int32(1), int64(2), object(2) memory usage: 158.5+ KB 5-1. 지역별 평균 분양가격 확인해보기 1df.groupby(\"지역명\")[\"분양가격\"].mean() 지역명 강원 2339.807547 경기 4072.667925 경남 2761.275472 경북 2432.128302 광주 2450.728302 대구 3538.920755 대전 2479.135849 부산 3679.920755 서울 7225.762264 세종 2815.098113 울산 1826.101887 인천 3578.433962 전남 2270.177358 전북 2322.060377 제주 2979.407547 충남 2388.324528 충북 2316.871698 Name: 분양가격, dtype: float64 5-2. 분양가격이 100보다 작은 행을 제거해보기 특정 조건에 만족하는 행을 제거하고자 할 때는 index를 list로 가져온다 idx = df.loc [ 조건식 ] .index drop을 활용하여 행을 제거한다 df_name = df_name .drop (idx, axis = 0) 1idx = df.loc[df[\"분양가격\"] &lt; 100].index 1idx Int64Index([ 28, 29, 34, 81, 113, 114, 119, 166, 198, 199, ... 4418, 4448, 4453, 4458, 4459, 4461, 4488, 4493, 4499, 4503], dtype='int64', length=320) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4500 제주 전체 2020 2 3955 4501 제주 60㎡이하 2020 2 4039 4502 제주 60㎡초과 85㎡이하 2020 2 3962 4503 제주 85㎡초과 102㎡이하 2020 2 0 4504 제주 102㎡초과 2020 2 3601 4505 rows × 5 columns 1df = df.drop(idx, axis = 0) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 ... ... ... ... ... ... 4498 경남 85㎡초과 102㎡이하 2020 2 3247 4500 제주 전체 2020 2 3955 4501 제주 60㎡이하 2020 2 4039 4502 제주 60㎡초과 85㎡이하 2020 2 3962 4504 제주 102㎡초과 2020 2 3601 4185 rows × 5 columns 다시 한 번 지역명으로 group을 묶어 분양가격을 확인해보자! 1df.groupby(\"지역명\")[\"분양가격\"].mean() 지역명 강원 2412.642023 경기 4072.667925 경남 2814.376923 경북 2547.486166 광주 3049.028169 대구 3663.335938 대전 3128.433333 부산 3679.920755 서울 7225.762264 세종 2984.004000 울산 3043.503145 인천 3633.275862 전남 2304.969349 전북 2348.648855 제주 3432.795652 충남 2501.604743 충북 2316.871698 Name: 분양가격, dtype: float64 5-3. 지역별 “분양가격” 데이터의 갯수를 확인해보기 1df.groupby(\"지역명\")[\"분양가격\"].count() 지역명 강원 257 경기 265 경남 260 경북 253 광주 213 대구 256 대전 210 부산 265 서울 265 세종 250 울산 159 인천 261 전남 261 전북 262 제주 230 충남 253 충북 265 Name: 분양가격, dtype: int64 5-4. 지역별 제일 비싼 분양가를 확인해보기 1df.groupby(\"지역명\")[\"분양가격\"].max() 지역명 강원 3906 경기 5670 경남 4303 경북 3457 광주 4881 대구 5158 대전 4877 부산 4623 서울 13835 세종 3931 울산 3594 인천 5188 전남 3053 전북 3052 제주 5462 충남 3201 충북 2855 Name: 분양가격, dtype: int32 6. 연도별 평균 분양가격을 확인해보기 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 1df.groupby(\"연도\")[\"분양가격\"].mean() 연도 2015 2788.707819 2016 2934.250000 2017 3143.311795 2018 3326.951034 2019 3693.422149 2020 3853.960526 Name: 분양가격, dtype: float64 7. 피벗테이블 활용하기 행 인덱스: 연도 열 인덱스: 규모구분 값: 분양가 (평균) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 지역명 규모구분 연도 월 분양가격 0 서울 전체 2015 10 5841 1 서울 60㎡이하 2015 10 5652 2 서울 60㎡초과 85㎡이하 2015 10 5882 3 서울 85㎡초과 102㎡이하 2015 10 5721 4 서울 102㎡초과 2015 10 5879 1pd.pivot_table(df, index = \"연도\", columns = \"규모구분\", values = \"분양가격\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 규모구분 102㎡초과 60㎡이하 60㎡초과 85㎡이하 85㎡초과 102㎡이하 전체 연도 2015 2980.977778 2712.583333 2694.490196 2884.395833 2694.862745 2016 3148.099476 2848.144279 2816.965686 3067.380435 2816.073529 2017 3427.649746 3112.538071 2981.950980 3204.075145 3008.279412 2018 3468.355932 3286.184783 3227.458128 3467.184211 3235.098522 2019 4039.854839 3486.910112 3538.545918 3933.538462 3515.974490 2020 4187.566667 3615.968750 3594.852941 4532.090909 3603.911765 8. 연도별, 규모별 가격을 알아보기 1df.groupby([\"연도\", \"규모구분\"])[\"분양가격\"].mean() 연도 규모구분 2015 102㎡초과 2980.977778 60㎡이하 2712.583333 60㎡초과 85㎡이하 2694.490196 85㎡초과 102㎡이하 2884.395833 전체 2694.862745 2016 102㎡초과 3148.099476 60㎡이하 2848.144279 60㎡초과 85㎡이하 2816.965686 85㎡초과 102㎡이하 3067.380435 전체 2816.073529 2017 102㎡초과 3427.649746 60㎡이하 3112.538071 60㎡초과 85㎡이하 2981.950980 85㎡초과 102㎡이하 3204.075145 전체 3008.279412 2018 102㎡초과 3468.355932 60㎡이하 3286.184783 60㎡초과 85㎡이하 3227.458128 85㎡초과 102㎡이하 3467.184211 전체 3235.098522 2019 102㎡초과 4039.854839 60㎡이하 3486.910112 60㎡초과 85㎡이하 3538.545918 85㎡초과 102㎡이하 3933.538462 전체 3515.974490 2020 102㎡초과 4187.566667 60㎡이하 3615.968750 60㎡초과 85㎡이하 3594.852941 85㎡초과 102㎡이하 4532.090909 전체 3603.911765 Name: 분양가격, dtype: float64 예쁘게 출력이 안되어서 보기가 힘들때는 pd.DataFrame()으로 한 번 더 감싸주면 됩니다. 1pd.DataFrame(df.groupby([\"연도\", \"규모구분\"])[\"분양가격\"].mean()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 분양가격 연도 규모구분 2015 102㎡초과 2980.977778 60㎡이하 2712.583333 60㎡초과 85㎡이하 2694.490196 85㎡초과 102㎡이하 2884.395833 전체 2694.862745 2016 102㎡초과 3148.099476 60㎡이하 2848.144279 60㎡초과 85㎡이하 2816.965686 85㎡초과 102㎡이하 3067.380435 전체 2816.073529 2017 102㎡초과 3427.649746 60㎡이하 3112.538071 60㎡초과 85㎡이하 2981.950980 85㎡초과 102㎡이하 3204.075145 전체 3008.279412 2018 102㎡초과 3468.355932 60㎡이하 3286.184783 60㎡초과 85㎡이하 3227.458128 85㎡초과 102㎡이하 3467.184211 전체 3235.098522 2019 102㎡초과 4039.854839 60㎡이하 3486.910112 60㎡초과 85㎡이하 3538.545918 85㎡초과 102㎡이하 3933.538462 전체 3515.974490 2020 102㎡초과 4187.566667 60㎡이하 3615.968750 60㎡초과 85㎡이하 3594.852941 85㎡초과 102㎡이하 4532.090909 전체 3603.911765 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (7) 기타","slug":"S-Python-Pandas-Pre7","date":"2020-06-20T13:28:42.000Z","updated":"2020-06-23T16:53:03.553Z","comments":true,"path":"2020/06/20/S-Python-Pandas-Pre7/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/20/S-Python-Pandas-Pre7/","excerpt":"","text":"기타 1. 데이터 타입별 column 선택 (select_dtypes) 문자열이 있는 column만 선택 / 배제 2. One-hot-encoding (원핫인코딩) 1import pandas as pd 1df = pd.read_csv(\"korean-idol.csv\") 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1. 데이터 타입별 column 선택 (select_dtypes) 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 문자열이 있는 column만 선택 / 배제 df_name .select_dtypes (include = ‘object’) df_name .select_dtypes (exclude = ‘object’) (1) 문자열 column만 선택 1df.select_dtypes(include = 'object') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 혈액형 0 지민 방탄소년단 빅히트 남자 1995-10-13 A 1 지드래곤 빅뱅 YG 남자 1988-08-18 A 2 강다니엘 NaN 커넥트 남자 1996-12-10 A 3 뷔 방탄소년단 빅히트 남자 1995-12-30 AB 4 화사 마마무 RBW 여자 1995-07-23 A 5 정국 방탄소년단 빅히트 남자 1997-09-01 A 6 민현 뉴이스트 플레디스 남자 1995-08-09 O 7 소연 아이들 큐브 여자 1998-08-26 B 8 진 방탄소년단 빅히트 남자 1992-12-04 O 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 A 10 태연 소녀시대 SM 여자 1989-03-09 A 11 차은우 아스트로 판타지오 남자 1997-03-30 B 12 백호 뉴이스트 플레디스 남자 1995-07-21 AB 13 JR 뉴이스트 플레디스 남자 1995-06-08 O 14 슈가 방탄소년단 빅히트 남자 1993-03-09 O (2) 문자열 column 배제 (문자열이 아닌 column만 선택) 1df.select_dtypes(exclude = 'object') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 0 173.6 10523260 1 177.0 9916947 2 180.0 8273745 3 178.0 8073501 4 162.1 7650928 5 178.0 5208335 6 182.3 4989792 7 NaN 4668615 8 179.2 4570308 9 167.1 4036489 10 NaN 3918661 11 183.0 3506027 12 175.0 3301654 13 176.0 3274137 14 174.0 2925442 문자열이 포함된 DataFrame의 연산으로 발생되는 Error문제는 이 방법을 이용하여 해결할 수 있다 1df + 10 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py in na_arithmetic_op(left, right, op, str_rep) 148 try: --&gt; 149 result = expressions.evaluate(op, str_rep, left, right) 150 except TypeError: D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in evaluate(op, op_str, a, b, use_numexpr) 207 if use_numexpr: --&gt; 208 return _evaluate(op, op_str, a, b) 209 return _evaluate_standard(op, op_str, a, b) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_numexpr(op, op_str, a, b) 120 if result is None: --&gt; 121 result = _evaluate_standard(op, op_str, a, b) 122 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_standard(op, op_str, a, b) 69 with np.errstate(all=\"ignore\"): ---&gt; 70 return op(a, b) 71 TypeError: can only concatenate str (not \"int\") to str ​ 1df.select_dtypes(exclude = 'object') + 10 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 0 183.6 10523270 1 187.0 9916957 2 190.0 8273755 3 188.0 8073511 4 172.1 7650938 5 188.0 5208345 6 192.3 4989802 7 NaN 4668625 8 189.2 4570318 9 177.1 4036499 10 NaN 3918671 11 193.0 3506037 12 185.0 3301664 13 186.0 3274147 14 184.0 2925452 (3) “문자열 column” / “비문자열 column” 의 column명을 추출 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 12obj_cols = df.select_dtypes(include = 'object').columnsobj_cols Index(['이름', '그룹', '소속사', '성별', '생년월일', '혈액형'], dtype='object') 12num_cols = df.select_dtypes(exclude = 'object').columnsnum_cols Index(['키', '브랜드평판지수'], dtype='object') 1df[num_cols] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 0 173.6 10523260 1 177.0 9916947 2 180.0 8273745 3 178.0 8073501 4 162.1 7650928 5 178.0 5208335 6 182.3 4989792 7 NaN 4668615 8 179.2 4570308 9 167.1 4036489 10 NaN 3918661 11 183.0 3506027 12 175.0 3301654 13 176.0 3274137 14 174.0 2925442 2. One-hot-encoding (원핫인코딩) One-hot-encoding: Categorical data를 dummy data로 변환시키는 방법 Dummy data로 변환 시 한개의 요소는 True (1) 로, 나머지 요소는 Flase (0) 로 변환시킨다 pd.get_dummies (df_name [ ‘col_name’ ], prefix = “…”) prefix: dummy data 로 분리된 새 column들의 column name에 접두사 붙이기 1df['혈액형'] 0 A 1 A 2 A 3 AB 4 A 5 A 6 O 7 B 8 O 9 A 10 A 11 B 12 AB 13 O 14 O Name: 혈액형, dtype: object 1pd.get_dummies(df['혈액형']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } A AB B O 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 1 0 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 0 1 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 0 1 0 12 0 1 0 0 13 0 0 0 1 14 0 0 0 1 1pd.get_dummies(df['혈액형'], prefix = '혈액형') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형_A 혈액형_AB 혈액형_B 혈액형_O 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 1 0 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 0 1 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 0 1 0 12 0 1 0 0 13 0 0 0 1 14 0 0 0 1 categorical data의 각 카테고리가 숫자형식으로 표현됐을 때 one-hot-encoding이 더 중요해지는 이유: categorical data의 각 카테고리를 상징하는 숫자들은 그저 분류의 의미를 가질 뿐, 숫자의 크기 자체는 아무 의미도 없고, 숫자들의 연산도 역시 무의미하다. 하지만 이를 one-hot-encoding 작업 없이 머신러닝 알고리즘에 바로 넣으면 컴퓨터가 이 숫자들을 대소비교가 가능하고 연산이 가능하는 \"숫자\"로 인식하게 되므로 카테고리 간에 잘못된 관계를 맺을 수 있음. 따라서 이런 경우에는 one-hot-encoding 작업이 꼭 필요하다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 123456blood_map = { 'A': 0, 'B': 1, 'AB': 2, 'O': 3,} 1df[\"혈액형_code\"] = df[\"혈액형\"].map(blood_map) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 혈액형_code 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 2 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 0 1df[\"혈액형_code\"].value_counts() 0 7 3 4 2 2 1 2 Name: 혈액형_code, dtype: int64 1df[\"혈액형_code\"] 0 0 1 0 2 0 3 2 4 0 5 0 6 3 7 1 8 3 9 0 10 0 11 1 12 2 13 3 14 3 Name: 혈액형_code, dtype: int64 1pd.get_dummies(df[ \"혈액형_code\" ]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 0 1 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 1 0 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 1 0 0 12 0 0 1 0 13 0 0 0 1 14 0 0 0 1 1pd.get_dummies(df[\"혈액형_code\"], prefix = \"혈액형\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형_0 혈액형_1 혈액형_2 혈액형_3 0 1 0 0 0 1 1 0 0 0 2 1 0 0 0 3 0 0 1 0 4 1 0 0 0 5 1 0 0 0 6 0 0 0 1 7 0 1 0 0 8 0 0 0 1 9 1 0 0 0 10 1 0 0 0 11 0 1 0 0 12 0 0 1 0 13 0 0 0 1 14 0 0 0 1 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (6) 데이터프레임의 산술연산","slug":"S-Python-Pandas-Pre6","date":"2020-06-20T13:28:21.000Z","updated":"2020-06-23T16:52:30.215Z","comments":true,"path":"2020/06/20/S-Python-Pandas-Pre6/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/20/S-Python-Pandas-Pre6/","excerpt":"","text":"데이터프레임의 산술연산 1. Column 과 Column 간 연산 (+, -, *, /, %) 2. Column 과 숫자 간 연산 (+, -, *, /, %) 3. 복합 연산 4. mean(), sum() 을 axis 기준으로 연산 5. NaN 값이 존재할 경우 연산 6. DataFrame 과 DataFrame 간 연산 6-1. 문자열이 포함된 Series / DataFrame의 연산은 불가하다 6-2. 두 DataFrame의 column 이름은 같으나 column 순서만 바뀌어 있는 경우 6-3. 행의 갯수가 다른 경우 1import pandas as pd 1import numpy as np 예제 DataFrame 생성 1df = pd.DataFrame({\"통계\": [60, 70, 80, 85, 75], \"미술\": [50, 55, 80, 100, 95], \"체육\": [70, 65, 50, 95, 100] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 1. Column 과 Column 간 연산 (+, -, *, /, %) 1type(df[\"통계\"]) pandas.core.series.Series 즉 Series 과 Series 간의 연산 1df[\"통계\"] + df[\"미술\"] + df[\"체육\"] 0 180 1 190 2 210 3 280 4 270 dtype: int64 1df[\"통계\"] - df[\"미술\"] 0 10 1 15 2 0 3 -15 4 -20 dtype: int64 1df[\"통계\"] * df[\"미술\"] 0 3000 1 3850 2 6400 3 8500 4 7125 dtype: int64 1df[\"통계\"] / df[\"미술\"] 0 1.200000 1 1.272727 2 1.000000 3 0.850000 4 0.789474 dtype: float64 1df[\"통계\"] % df[\"미술\"] 0 10 1 15 2 0 3 85 4 75 dtype: int64 2. Column 과 숫자 간 연산 (+, -, *, /, %) 1df[\"통계\"] 0 60 1 70 2 80 3 85 4 75 Name: 통계, dtype: int64 1df[\"통계\"] + 10 0 70 1 80 2 90 3 95 4 85 Name: 통계, dtype: int64 1df[\"통계\"] - 10 0 50 1 60 2 70 3 75 4 65 Name: 통계, dtype: int64 1df[\"통계\"] * 10 0 600 1 700 2 800 3 850 4 750 Name: 통계, dtype: int64 1df[\"통계\"] / 10 0 6.0 1 7.0 2 8.0 3 8.5 4 7.5 Name: 통계, dtype: float64 1df[\"통계\"] % 10 0 0 1 0 2 0 3 5 4 5 Name: 통계, dtype: int64 3. 복합 연산 1df = pd.DataFrame({\"통계\": [60, 70, 80, 85, 75], \"미술\": [50, 55, 80, 100, 95], \"체육\": [70, 65, 50, 95, 100] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 1df[\"통계미술+10\"] = df[\"통계\"] + df[\"미술\"] + 10 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 통계미술+10 0 60 50 70 120 1 70 55 65 135 2 80 80 50 170 3 85 100 95 195 4 75 95 100 180 1df[\"통계\"] + df[\"미술\"] - df[\"체육\"] 0 40 1 60 2 110 3 90 4 70 dtype: int64 4. mean(), sum() 을 axis 기준으로 연산 1df = pd.DataFrame({\"통계\": [60, 70, 80, 85, 75], \"미술\": [50, 55, 80, 100, 95], \"체육\": [70, 65, 50, 95, 100] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 (1) 각 column의 모든 row 값의 합 구하기 1df.sum(axis = 0) 통계 370 미술 380 체육 380 dtype: int64 (2) 각 column의 모든 row 값의 평균 구하기 1df.mean(axis = 0) 통계 74.0 미술 76.0 체육 76.0 dtype: float64 (3) 각 row의 모든 column 값의 합 구하기 1df.sum(axis = 1) 0 180 1 190 2 210 3 280 4 270 dtype: int64 (4) 각 row의 모든 column 값의 평균 구하기 1df.mean(axis = 1) 0 60.000000 1 63.333333 2 70.000000 3 93.333333 4 90.000000 dtype: float64 5. NaN 값이 존재할 경우 연산 NaN 값이 포함된 모든 연산의 결과가 다 NaN 값이다 1df = pd.DataFrame({\"통계\": [60, np.nan, 80, 85, 75], \"미술\": [50, 55, np.nan, 100, 95], \"체육\": [70, 65, 50, 95, np.nan] }) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60.0 50.0 70.0 1 NaN 55.0 65.0 2 80.0 NaN 50.0 3 85.0 100.0 95.0 4 75.0 95.0 NaN 1df[\"통계\"] / 2 0 30.0 1 NaN 2 40.0 3 42.5 4 37.5 Name: 통계, dtype: float64 11000 / df[\"통계\"] 0 16.666667 1 NaN 2 12.500000 3 11.764706 4 13.333333 Name: 통계, dtype: float64 1df[\"통계\"] / np.nan 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN Name: 통계, dtype: float64 1np.nan / df[\"통계\"] 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN Name: 통계, dtype: float64 6. DataFrame 과 DataFrame 간 연산 6-1. 문자열이 포함된 Series / DataFrame의 연산은 불가하다 1df1 = pd.DataFrame({'통계': [60, 70, 80, 85, 75], '미술': [50, 55, 80, 100, 95], '체육': [70, 65, 50, 95, 100] }) 1df2 = pd.DataFrame({'통계': ['good', 'bad', 'ok' , 'good', 'ok'], '미술': [50, 60 , 80, 100, 95], '체육': [70, 65, 50, 70 , 100] }) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 60 50 70 1 70 55 65 2 80 80 50 3 85 100 95 4 75 95 100 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 체육 0 good 50 70 1 bad 60 65 2 ok 80 50 3 good 100 70 4 ok 95 100 1df1 + df2 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py in na_arithmetic_op(left, right, op, str_rep) 148 try: --&gt; 149 result = expressions.evaluate(op, str_rep, left, right) 150 except TypeError: D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in evaluate(op, op_str, a, b, use_numexpr) 207 if use_numexpr: --&gt; 208 return _evaluate(op, op_str, a, b) 209 return _evaluate_standard(op, op_str, a, b) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_numexpr(op, op_str, a, b) 120 if result is None: --&gt; 121 result = _evaluate_standard(op, op_str, a, b) 122 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_standard(op, op_str, a, b) 69 with np.errstate(all=\"ignore\"): ---&gt; 70 return op(a, b) 71 TypeError: unsupported operand type(s) for +: 'int' and 'str' 1df2 + 10 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py in na_arithmetic_op(left, right, op, str_rep) 148 try: --&gt; 149 result = expressions.evaluate(op, str_rep, left, right) 150 except TypeError: D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in evaluate(op, op_str, a, b, use_numexpr) 207 if use_numexpr: --&gt; 208 return _evaluate(op, op_str, a, b) 209 return _evaluate_standard(op, op_str, a, b) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_numexpr(op, op_str, a, b) 120 if result is None: --&gt; 121 result = _evaluate_standard(op, op_str, a, b) 122 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py in _evaluate_standard(op, op_str, a, b) 69 with np.errstate(all=\"ignore\"): ---&gt; 70 return op(a, b) 71 TypeError: can only concatenate str (not \"int\") to str 6-2. 두 DataFrame의 column 이름은 같으나 column 순서만 바뀌어 있는 경우 연산시 자동으로 column 이름 기준으로 연산 된다 12df1 = pd.DataFrame({'미술': [10, 20, 30, 40, 50], '통계':[60, 70, 80, 90, 100] })df2 = pd.DataFrame({'통계': [10, 20, 30, 40, 50], '미술': [60, 70, 80, 90, 100] }) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 1df1 + df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 70 70 1 90 90 2 110 110 3 130 130 4 150 150 6-3. 행의 갯수가 다른 경우 행 index 기준으로 연산하되, 하나의 DataFrame에만 존재하는 행은 연산결과가 NaN으로 나옴 12df1 = pd.DataFrame({'미술': [10, 20, 30, 40, 50, 60], '통계':[60, 70, 80, 90, 100, 110] })df2 = pd.DataFrame({'통계': [10, 20, 30, 40, 50], '미술': [60, 70, 80, 90, 100] }) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 5 60 110 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통계 미술 0 10 60 1 20 70 2 30 80 3 40 90 4 50 100 1df1 * df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 미술 통계 0 600.0 600.0 1 1400.0 1400.0 2 2400.0 2400.0 3 3600.0 3600.0 4 5000.0 5000.0 5 NaN NaN document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (5) column 값을 변환시키는 방법","slug":"S-Python-Pandas-Pre5","date":"2020-06-19T12:11:52.000Z","updated":"2020-06-23T16:51:01.668Z","comments":true,"path":"2020/06/19/S-Python-Pandas-Pre5/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/19/S-Python-Pandas-Pre5/","excerpt":"","text":"DataFrame의 column 값을 변환시키는 방법 1. apply + 일반 함수 1-1. (목표) ‘성별’ column의 “남자” / \"여자\"를 1 / 2로 바꾼다 1-2. (목표) cm당 브랜드 평판지수를 구한다 (브랜드평판지수 / 키) 2. apply + lamda 함수 3. map + map 함수 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. apply + 일반 함수 apply는 Series나 DataFrame에 좀 더 구체적인 로직을 적용하고 싶은 경우 활용한다 apply를 적용하기 위해서는 함수가 먼저 정의되어야한다 apply는 정의한 로직 함수를 인자로 넘겨준다 Series에 적용할 경우: df_name [ “col_name” ] .apply( func ) DataFrame에 적용할 경우: df_name .apply( func, axis = 1) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1-1. (목표) ‘성별’ column의 “남자” / \"여자\"를 1 / 2로 바꾼다 변환 규칙: 남자: 1 여자: 2 기타: -1 (1) 로직 함수 정의 [주의] 반드시 return 값이 존재하여야한다 12345def male_or_female(x): if x == \"남자\": return 1 elif x == \"여자\": return 2 (2) apply로 DataFrame에 적용 1df[\"성별_NEW\"] = df[\"성별\"].apply(male_or_female) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 1 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 1 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 2 1-2. (목표) cm당 브랜드 평판지수를 구한다 (브랜드평판지수 / 키) 변환 규칙: 키: 178 브랜드평판지수: 99000 값: 99000 / 178 (1) 로직 함수 정의 123def cm_to_brand(df): value = df[\"브랜드평판지수\"] / df[\"키\"] return value (2) apply로 DataFrame에 적용 1df.apply(cm_to_brand, axis = 1) 0 60617.857143 1 56027.949153 2 45965.250000 3 45356.747191 4 47198.815546 5 29260.308989 6 27371.321997 7 NaN 8 25503.950893 9 24156.128067 10 NaN 11 19158.617486 12 18866.594286 13 18603.051136 14 16812.885057 dtype: float64 2. apply + lamda 함수 df_name [ “col_name” ] .apply (lambda_func) lambda는 1줄로 작성하는 간단 함수식이다 return을 별도로 멱기하지 않는다 (1) male_or_female 함수 1male_or_female = lambda x: 1 if x == \"남자\" else 0 1df[\"성별\"].apply(male_or_female) 0 1 1 1 2 1 3 1 4 0 5 1 6 1 7 0 8 1 9 1 10 0 11 1 12 1 13 1 14 1 Name: 성별, dtype: int64 (2) 실제로는 간단한 계산식을 적용하려는 경우에 많이 사용한다 1df[\"키/2\"] = df[\"키\"].apply(lambda x: x / 2) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW 키/2 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 86.80 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 1 88.50 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 90.00 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 1 89.00 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 2 81.05 apply에 함수식을 만들어서 적용해주는 것과 동일하기 때문에, 복잠한 조건식은 &lt;함수&gt;로, 간단한 계산식은 &lt; lambda &gt; 로 적용하면 된다 3. map + map 함수 df_name [ “col_name” ] .map ( map_func ) Step 1: dictionary 형식으로 map 함수를 정의하기 Step 2: DataFrame / Series에 map 함수를 적용 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성별_NEW 키/2 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 86.80 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 1 88.50 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 90.00 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 1 89.00 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 2 81.05 1234my_map = { \"남자\": \"male\", \"여자\": \"female\"} 1df[\"성별\"].map(my_map) 0 male 1 male 2 male 3 male 4 female 5 male 6 male 7 female 8 male 9 male 10 female 11 male 12 male 13 male 14 male Name: 성별, dtype: object document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (4) Series의 Type 변환하기","slug":"S-Python-Pandas-Pre4","date":"2020-06-19T06:53:13.000Z","updated":"2020-06-23T16:49:03.475Z","comments":true,"path":"2020/06/19/S-Python-Pandas-Pre4/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/19/S-Python-Pandas-Pre4/","excerpt":"","text":"Series의 Type 변환하기 1. Series의 Type 1-1. Type 확인하기 1-2. Type 변환하기 1-3. 날짜 (datatime) 타입 변환하기 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. Series의 Type 1-1. Type 확인하기 df_name.info() 명령어를 사용하여 Dataframe의 Series Type을 확인할 수 있다 df_name [ “col_name” ] .dtypes 명령어를 사용하여 특정 Series의 Type을 확인할 수 있다 Series Type object: 일반 문자영 타입 float: 실수 int: 정수 category: 카테고리 datatime: 시간 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 1df[\"이름\"].dtypes dtype('O') 1-2. Type 변환하기 df_name [ “col_name” ] .astype(…) e.g. “키” column을 float에서 int로 변환해보기 1df[\"키\"].astype(int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-12-c145a39acdb2&gt; in &lt;module&gt; ----&gt; 1 df[\"키\"].astype(int) D:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py in astype(self, dtype, copy, errors) 5696 else: 5697 # else, only a single dtype is given -&gt; 5698 new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors) 5699 return self._constructor(new_data).__finalize__(self) 5700 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in astype(self, dtype, copy, errors) 580 581 def astype(self, dtype, copy: bool = False, errors: str = \"raise\"): --&gt; 582 return self.apply(\"astype\", dtype=dtype, copy=copy, errors=errors) 583 584 def convert(self, **kwargs): D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py in apply(self, f, filter, **kwargs) 440 applied = b.apply(f, **kwargs) 441 else: --&gt; 442 applied = getattr(b, f)(**kwargs) 443 result_blocks = _extend_blocks(applied, result_blocks) 444 D:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py in astype(self, dtype, copy, errors) 623 vals1d = values.ravel() 624 try: --&gt; 625 values = astype_nansafe(vals1d, dtype, copy=True) 626 except (ValueError, TypeError): 627 # e.g. astype_nansafe can fail on object-dtype of strings D:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py in astype_nansafe(arr, dtype, copy, skipna) 866 867 if not np.isfinite(arr).all(): --&gt; 868 raise ValueError(\"Cannot convert non-finite values (NA or inf) to integer\") 869 870 elif is_object_dtype(arr): ValueError: Cannot convert non-finite values (NA or inf) to integer “키” column에 NaN값이 존재하기 때문에 Error 발생! column에 NaN 값이 있는 경우: 면저 NaN 값을 다른 값으로 대체한 후 Type을 변환할 수 있다 1df[\"키\"] = df[\"키\"].fillna(-1) 1df[\"키\"] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df[\"키\"].astype(int) 0 173 1 177 2 180 3 178 4 162 5 178 6 182 7 -1 8 179 9 167 10 -1 11 183 12 175 13 176 14 174 Name: 키, dtype: int32 1-3. 날짜 (datatime) 타입 변환하기 (1) datetime 타입으로 변환하기 pd.to_datetime ( df_name [ “col_nema”] ) 1df[\"생년월일\"] 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: object 1pd.to_datetime(df[\"생년월일\"]) 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: datetime64[ns] 변환된 것을 원래 column에 다시 대입을 해줘야 정상적으로 변환된 값이 들어간다 12df[\"생년월일\"] = pd.to_datetime(df[\"생년월일\"])df[\"생년월일\"] 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: datetime64[ns] (2) datatime 타입을 활용하기 df_name [ “datetime_col” ] .dt 을 활용하여 매우 손쉽게 년, 월, 일, 요일 등등 날짜 정보를 세부적으로 추출해낼 수 있다 년: df_name [ “datetime_col” ] .dt.year 월: df_name [ “datetime_col” ] .dt.month 일: df_name [ “datetime_col” ] .dt.day 요일: df_name [ “datetime_col” ] .dt.dayofweek 주: df_name [ “datetime_col” ] .dt.weekofyear 1df[\"생년월일\"] 0 1995-10-13 1 1988-08-18 2 1996-12-10 3 1995-12-30 4 1995-07-23 5 1997-09-01 6 1995-08-09 7 1998-08-26 8 1992-12-04 9 1994-03-22 10 1989-03-09 11 1997-03-30 12 1995-07-21 13 1995-06-08 14 1993-03-09 Name: 생년월일, dtype: datetime64[ns] 년 추출: 1df[\"생년월일\"].dt.year 0 1995 1 1988 2 1996 3 1995 4 1995 5 1997 6 1995 7 1998 8 1992 9 1994 10 1989 11 1997 12 1995 13 1995 14 1993 Name: 생년월일, dtype: int64 월 추출: 1df[\"생년월일\"].dt.month 0 10 1 8 2 12 3 12 4 7 5 9 6 8 7 8 8 12 9 3 10 3 11 3 12 7 13 6 14 3 Name: 생년월일, dtype: int64 일 추출: 1df[\"생년월일\"].dt.day 0 13 1 18 2 10 3 30 4 23 5 1 6 9 7 26 8 4 9 22 10 9 11 30 12 21 13 8 14 9 Name: 생년월일, dtype: int64 요일 추출: 월 [0], 화 [1], 수 [2], 목 [3], 금 [4], 토 [5], 일 [6] 1df[\"생년월일\"].dt.dayofweek 0 4 1 3 2 1 3 5 4 6 5 0 6 2 7 2 8 4 9 1 10 3 11 6 12 4 13 3 14 1 Name: 생년월일, dtype: int64 주 추출: 1df[\"생년월일\"].dt.weekofyear 0 41 1 33 2 50 3 52 4 29 5 36 6 32 7 35 8 49 9 12 10 10 11 13 12 29 13 23 14 10 Name: 생년월일, dtype: int64 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (3) DataFrame의 합침 및 병합","slug":"S-Python-Pandas-Pre3","date":"2020-06-19T06:52:54.000Z","updated":"2020-06-23T16:46:15.090Z","comments":true,"path":"2020/06/19/S-Python-Pandas-Pre3/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/19/S-Python-Pandas-Pre3/","excerpt":"","text":"DataFrame의 합침 및 병합 1. DataFrame 합치기 (concat) 1-1. Row 기준 합치기 (밑으로 합침) 1-2. column 기준으로 합치기 (옆으로 합침) 2. DataFrame 병합하기 (merge) 2-0. 예제 데이터 만들기 2-1. left, right 방식 2-2. inner, outer 방식 2-3. column명은 다르지만, 동일한 성질의 데이터 인 경우? 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1df2 = pd.read_csv('korean-idol-2.csv') 1. DataFrame 합치기 (concat) 1-1. Row 기준 합치기 (밑으로 합침) df_concat = pd.concat ( [ df_name1 , df_name2 ], sort = False) df_concat .reset_index (drop = True) 합칠 데이터프리임을 list로 묶어준다. sort=False 옵션을 주어 column의 순서가 유지되도록 한다 합친 dataframe을 새 변수에 대입한 뒤 reset_index 옵션으로 index를 초기화한다 (아님 각각 원래의 index을 가지고 있음) reseet_index에서 drop=True 옵션을 사용해 원래의 행 index가 새로 index column으로 생성되지 않도록 한다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_copy = df.copy() (1) sort 옵션 sort = False: column 순서 유지; sort = True: column을 이름순으로 재정열 1pd.concat([df, df_copy], sort = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1pd.concat([df, df_copy], sort = True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 그룹 브랜드평판지수 생년월일 성별 소속사 이름 키 혈액형 0 방탄소년단 10523260 1995-10-13 남자 빅히트 지민 173.6 A 1 빅뱅 9916947 1988-08-18 남자 YG 지드래곤 177.0 A 2 NaN 8273745 1996-12-10 남자 커넥트 강다니엘 180.0 A 3 방탄소년단 8073501 1995-12-30 남자 빅히트 뷔 178.0 AB 4 마마무 7650928 1995-07-23 여자 RBW 화사 162.1 A 5 방탄소년단 5208335 1997-09-01 남자 빅히트 정국 178.0 A 6 뉴이스트 4989792 1995-08-09 남자 플레디스 민현 182.3 O 7 아이들 4668615 1998-08-26 여자 큐브 소연 NaN B 8 방탄소년단 4570308 1992-12-04 남자 빅히트 진 179.2 O 9 핫샷 4036489 1994-03-22 남자 스타크루이엔티 하성운 167.1 A 10 소녀시대 3918661 1989-03-09 여자 SM 태연 NaN A 11 아스트로 3506027 1997-03-30 남자 판타지오 차은우 183.0 B 12 뉴이스트 3301654 1995-07-21 남자 플레디스 백호 175.0 AB 13 뉴이스트 3274137 1995-06-08 남자 플레디스 JR 176.0 O 14 방탄소년단 2925442 1993-03-09 남자 빅히트 슈가 174.0 O 0 방탄소년단 10523260 1995-10-13 남자 빅히트 지민 173.6 A 1 빅뱅 9916947 1988-08-18 남자 YG 지드래곤 177.0 A 2 NaN 8273745 1996-12-10 남자 커넥트 강다니엘 180.0 A 3 방탄소년단 8073501 1995-12-30 남자 빅히트 뷔 178.0 AB 4 마마무 7650928 1995-07-23 여자 RBW 화사 162.1 A 5 방탄소년단 5208335 1997-09-01 남자 빅히트 정국 178.0 A 6 뉴이스트 4989792 1995-08-09 남자 플레디스 민현 182.3 O 7 아이들 4668615 1998-08-26 여자 큐브 소연 NaN B 8 방탄소년단 4570308 1992-12-04 남자 빅히트 진 179.2 O 9 핫샷 4036489 1994-03-22 남자 스타크루이엔티 하성운 167.1 A 10 소녀시대 3918661 1989-03-09 여자 SM 태연 NaN A 11 아스트로 3506027 1997-03-30 남자 판타지오 차은우 183.0 B 12 뉴이스트 3301654 1995-07-21 남자 플레디스 백호 175.0 AB 13 뉴이스트 3274137 1995-06-08 남자 플레디스 JR 176.0 O 14 방탄소년단 2925442 1993-03-09 남자 빅히트 슈가 174.0 O (2) reset_index 옵션 reset_index(): index가 초기화됨, 원래의 index가 새로 index column으로 저장됨 reset_index(drop = True): index가 초기화됨, 원래의 index가 새로 index column으로 생성되지 않음 1df_concat = pd.concat([df, df_copy], sort = False) 1df_concat.reset_index() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } index 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 15 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 16 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 17 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 18 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 19 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 20 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 21 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 22 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 23 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 24 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 25 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 26 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 27 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 28 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 29 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df_concat.reset_index(drop = True) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 15 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 16 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 17 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 18 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 19 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 20 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 21 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 22 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 23 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 24 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 25 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 26 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 27 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 28 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 29 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1-2. column 기준으로 합치기 (옆으로 합침) column 기준으로 합치고자 할 때는 axis = 1 옵션을 준다: pd.concat ( [df_name1, df_name2], axis = 1) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df2 = pd.read_csv('korean-idol-2.csv') 1df2.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 지드래곤 3500 3 2 강다니엘 3200 4 3 뷔 3050 4 4 화사 4300 3 1pd.concat([df, df2], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000 3 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 지드래곤 3500 3 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200 4 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 뷔 3050 4 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300 3 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 정국 2900 5 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400 6 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 소연 4500 5 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200 4 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300 4 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700 3 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850 5 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900 4 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 JR 4100 3 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 슈가 4150 3 행의 갯수가 맞지 않을 시 두 DataFrame이 행 index기준으로 합치게 됨 행 갯수가 적은 DataFrame의 빈칸에는 NaN로 채워지게 됨 12df3 = df2.drop([3,5])df3 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 지드래곤 3500 3 2 강다니엘 3200 4 4 화사 4300 3 6 민현 3400 6 7 소연 4500 5 8 진 4200 4 9 하성운 4300 4 10 태연 3700 3 11 차은우 3850 5 12 백호 3900 4 13 JR 4100 3 14 슈가 4150 3 1pd.concat([df, df3], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 지드래곤 3500.0 3.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 소연 4500.0 5.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 JR 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 슈가 4150.0 3.0 12df4 = df2.drop([13, 14])pd.concat([df,df4], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 지드래곤 3500.0 3.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 뷔 3050.0 4.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 정국 2900.0 5.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 소연 4500.0 5.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 NaN NaN NaN 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 NaN NaN NaN 2. DataFrame 병합하기 (merge) concat과 merge의 차이: concat: row 나 column 기준으로 단순하게 이어 붙히기 merge: 특정 고유한 키(unique id) 값을 기준으로 병합하기 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df2.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 지드래곤 3500 3 2 강다니엘 3200 4 3 뷔 3050 4 4 화사 4300 3 df와 df2는 \"이름\"이라는 column이 겹친다 따라서, 우리는 \"이름\"을 기준으로 두 DataFrame을 병합할 수 있다 pd.merge (left_df, right_df, on = “기준 column”, how = “…” ) left_df와 right_df 에는 병합할 두 DataFrame을 대입한다 on 에는 병합의 기준이 되는 column을 넣어 준다 how 에는 ‘left’, ‘right’, ‘inner’, 'outer’라는 4가지의 병합 방식중 한가지를 택한다 2-0. 예제 데이터 만들기 1df_right = df2.drop([1,3,5,7]) 1df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 2 강다니엘 3200 4 4 화사 4300 3 6 민현 3400 6 8 진 4200 4 9 하성운 4300 4 10 태연 3700 3 11 차은우 3850 5 12 백호 3900 4 13 JR 4100 3 14 슈가 4150 3 12df_right = df_right.reset_index(drop = True)df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 5 하성운 4300 4 6 태연 3700 3 7 차은우 3850 5 8 백호 3900 4 9 JR 4100 3 10 슈가 4150 3 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 concat로 합치는 경우: 데이터가 행 index기준으로 합치게 되기 때문에 이름이 다른 시람의 데이터가 합치게 된다 1pd.concat([df, df_right], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 이름 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 강다니엘 3200.0 4.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 화사 4300.0 3.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 민현 3400.0 6.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 진 4200.0 4.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 하성운 4300.0 4.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 태연 3700.0 3.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 차은우 3850.0 5.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 백호 3900.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 JR 4100.0 3.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 슈가 4150.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 NaN NaN NaN 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 NaN NaN NaN 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 NaN NaN NaN 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 NaN NaN NaN 따리서, 우리는 merge를 사용하여 두 DataFrame를 “이름” 기준으로 병합한다 2-1. left, right 방식 \"left\"옵션을 부여할 때: left DataFrame에 키 값이 존재하면 해당 데이터를 유지하고, 병합한 right DataFrame의 값은 NaN이 대입 됨 반대로, \"right\"옵션을 부여할 때 right DataFrame을 기준으로 병합하게 됨 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 5 하성운 4300 4 6 태연 3700 3 7 차은우 3850 5 8 백호 3900 4 9 JR 4100 3 10 슈가 4150 3 1pd.merge(df, df_right, on = \"이름\", how = \"left\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 NaN NaN 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 NaN NaN 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150.0 3.0 1pd.merge(df, df_right, on = \"이름\", how = \"right\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000 3 1 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200 4 2 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300 3 3 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400 6 4 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200 4 5 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300 4 6 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700 3 7 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850 5 8 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900 4 9 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100 3 10 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150 3 현재, left DataFrame이 더 많은 데이터를 보유하고 있으니, right를 기준으로 병합하면 DataFrame 사이즈가 줄어드게 된다 2-2. inner, outer 방식 inner 방식은 두 DataFrame에 모두 키 값이 존재하는 경우만 병합한다 (교집합과 비슷) outer 방식은 하나의 DataFrame에만 키 값이 존재하더라도 모두 병합한다 (합집합과 비슷) outer 방식에서는 없는 값은 NaN으로 대입된다 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df_right .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 5 하성운 4300 4 6 태연 3700 3 7 차은우 3850 5 8 백호 3900 4 9 JR 4100 3 10 슈가 4150 3 1pd.merge(df, df_right, on = \"이름\", how = 'inner') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000 3 1 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200 4 2 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300 3 3 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400 6 4 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200 4 5 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300 4 6 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700 3 7 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850 5 8 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900 4 9 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100 3 10 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150 3 1pd.merge(df, df_right, on = \"이름\", how = 'outer') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 연봉 가족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 NaN NaN 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 NaN NaN 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4150.0 3.0 2-3. column명은 다르지만, 동일한 성질의 데이터 인 경우? pd.merge ( left_df, right_df, left_on = “left_col”, right_on = “right_col”, how = “…” ) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_right.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 연봉 가족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 1df_right.columns = [\"성함\", \"연봉\", \"기족수\"] 1df_right.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 성함 연봉 기족수 0 지민 3000 3 1 강다니엘 3200 4 2 화사 4300 3 3 민현 3400 6 4 진 4200 4 df의 \"이름\"과 df_right의 \"성함\"은 column name이 다르지만, 동일한 성질의 데이터다. 이럴 때는 left_on, right_on 옵션을 사용해 기준 column을 지정한다 1pd.merge(df, df_right, left_on = \"이름\", right_on = \"성함\", how = \"outer\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 성함 연봉 기족수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 지민 3000.0 3.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 NaN NaN NaN 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 강다니엘 3200.0 4.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 NaN NaN NaN 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 화사 4300.0 3.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 NaN NaN NaN 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 민현 3400.0 6.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 NaN NaN NaN 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 진 4200.0 4.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 하성운 4300.0 4.0 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 태연 3700.0 3.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 차은우 3850.0 5.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 백호 3900.0 4.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 JR 4100.0 3.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 슈가 4150.0 3.0 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (2) 결측값 및 중복값 처리","slug":"S-Python-Pandas-Pre2","date":"2020-06-17T15:07:04.000Z","updated":"2020-06-23T16:45:00.840Z","comments":true,"path":"2020/06/18/S-Python-Pandas-Pre2/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/18/S-Python-Pandas-Pre2/","excerpt":"","text":"결측값 및 중복값 처리 1. 결측값을 제거하기 – dropna() 2. 결측값을 채워주기 – fillna 2-1. NA값을 특정 숫자로 채우기 2-2. NA값을 통계값으로 채우기 3. 중복된 값을 제거하기 – drop_duplicates 3-1. column의 중복값 제거 3-2. 행 전체 제거 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 결측값을 제거하기 – dropna() 결측값이 있는 행을 제거: (1) df_name .dropna() (2) df_name .dropna(axis=0) 결측값이 있는 열을 제거: df_name .dropna(axis=1) NA가 하나라도 있는 경우 제거: df_name .dropna(axis=0, how = ‘any’) 모두가 NA인 경우 제거: df_name .dropna(axis=0, how = ‘all’) 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 (1) 결측값이 있는 행 제거 1df.dropna() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.dropna(axis = 0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 (2) 결측 값이 있는 열 제거 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 1df.dropna(axis=1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 성별 생년월일 혈액형 브랜드평판지수 0 지민 빅히트 남자 1995-10-13 A 10523260 1 지드래곤 YG 남자 1988-08-18 A 9916947 2 강다니엘 커넥트 남자 1996-12-10 A 8273745 3 뷔 빅히트 남자 1995-12-30 AB 8073501 4 화사 RBW 여자 1995-07-23 A 7650928 5 정국 빅히트 남자 1997-09-01 A 5208335 6 민현 플레디스 남자 1995-08-09 O 4989792 7 소연 큐브 여자 1998-08-26 B 4668615 8 진 빅히트 남자 1992-12-04 O 4570308 9 하성운 스타크루이엔티 남자 1994-03-22 A 4036489 10 태연 SM 여자 1989-03-09 A 3918661 11 차은우 판타지오 남자 1997-03-30 B 3506027 12 백호 플레디스 남자 1995-07-21 AB 3301654 13 JR 플레디스 남자 1995-06-08 O 3274137 14 슈가 빅히트 남자 1993-03-09 O 2925442 (3) NA가 하나라도 있는 경우 행 제거 1df.dropna(axis=0, how = 'any') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 (4) 모두가 NA인 경우 행 제거 1import numpy as np 1df.iloc[10] = np.nan 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489.0 10 NaN NaN NaN NaN NaN NaN NaN NaN 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442.0 1df.dropna(axis=0, how = 'all') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260.0 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947.0 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745.0 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501.0 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928.0 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335.0 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792.0 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615.0 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308.0 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489.0 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027.0 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654.0 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137.0 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442.0 2. 결측값을 채워주기 – fillna df_name [ 'na_col_name ’ ] .fillna(fill_value) 결측값을 채운 데이터프레임을 유지시키려면: (1) inplace = True 옵션을 추가함 (2) 원 dataframe에 다시 대입함 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB \"키\"에 2개의 데이터가 누락, \"그룹\"에 1개의 데이터가 누락된 것을 확인할 수 있다 2-1. NA값을 특정 숫자로 채우기 df_name[ 'na_col_name ’ ] .fillna (new_value, inplace = True) df_name[ 'na_col_name ’ ] = df_name[ 'na_col_name ’ ] .fillna (new_value) e.g. 누락된 ‘키’ 값을 '-1’로 채워줌 1df['키'].fillna(-1) 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 이때는 원 데이터가 변화되지 않음. 1df['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 수정된 데이터를 유지시키려면: &lt;방법1&gt; 1df2 = df.copy() 1df2['키'].fillna(-1, inplace = True) 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 &lt;방법2&gt; 1df2 = df.copy() 1df2['키'] = df2['키'].fillna(-1) 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 -1.0 8 179.2 9 167.1 10 -1.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 2-2. NA값을 통계값으로 채우기 df_name[ 'na_col_name ’ ] .fillna (df_name[ 'na_col_name ’ ] .mean(), inplace = True) df_name[ 'na_col_name ’ ] = df_name[ 'na_col_name ’ ] .fillna (df_name[ 'na_col_name ’ ] .mean()) 1df2 = df.copy() 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 (1) 평균으로 대체 1df2['키'].mean() 175.79230769230767 1df2['키'].fillna(df2['키'].mean(), inplace = True) 1df2['키'] = df2['키'].fillna(df2['키'].mean()) 1df2['키'] 0 173.600000 1 177.000000 2 180.000000 3 178.000000 4 162.100000 5 178.000000 6 182.300000 7 175.792308 8 179.200000 9 167.100000 10 175.792308 11 183.000000 12 175.000000 13 176.000000 14 174.000000 Name: 키, dtype: float64 (2) 중위값으로 대체 1df2 = df.copy() 1df2['키'].median() 177.0 1df2['키'].fillna(df2['키'].median(), inplace = True) 1df2['키'] = df2['키'].fillna(df2['키'].median()) 1df2['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 177.0 8 179.2 9 167.1 10 177.0 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 3. 중복된 값을 제거하기 – drop_duplicates 1df = pd.read_csv('korean-idol.csv') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 3-1. column의 중복값 제거 df_name [“col_name”] .drop_duplicates( keep = … ) 여러 개 중복값 (NaN 포함) 중에서 기본적으로 첫번째 것만 유지시키고 나머지는 다 제거한다 하지만 keep 옵션으로 유지하고 싶은 데이터를 선택할 수 있다. [keep: ‘first’ / ‘last’] 이때는 해당 위치의 값만 삭제되고 행 자체는 유지된다 (1) 중복값 중의 첫번째를 유지시킴 (default) 1df['키'] 0 173.6 1 177.0 2 180.0 3 NaN 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df['키'].drop_duplicates() # remove 2nd \"178.0\" &amp; 2nd \"NaN\" 0 173.6 1 177.0 2 180.0 3 NaN 4 162.1 5 178.0 6 182.3 8 179.2 9 167.1 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df['키'].drop_duplicates(keep='first') 0 173.6 1 177.0 2 180.0 3 NaN 4 162.1 5 178.0 6 182.3 8 179.2 9 167.1 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 (2) 중복값 중의 마지막을 유지시킴 1df['키'] 0 173.6 1 177.0 2 180.0 3 178.0 4 162.1 5 178.0 6 182.3 7 NaN 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 1df['키'].drop_duplicates(keep='last') 0 173.6 1 177.0 2 180.0 4 162.1 5 178.0 6 182.3 8 179.2 9 167.1 10 NaN 11 183.0 12 175.0 13 176.0 14 174.0 Name: 키, dtype: float64 이때는 해당위치의 값만 제거되고 행 자체는 유지됨 1df['키'] = df['키'].drop_duplicates(keep='last') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 NaN AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 3-2. 행 전체 제거 df_name .drop_duplicates(“col_name”, keep = …) 지정한 column에서 중복값이 포함되어 있으면 중복값을 포함한 행을 전체 제거 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 NaN AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df['그룹'] 0 방탄소년단 1 빅뱅 2 NaN 3 방탄소년단 4 마마무 5 방탄소년단 6 뉴이스트 7 아이들 8 방탄소년단 9 핫샷 10 소녀시대 11 아스트로 12 뉴이스트 13 뉴이스트 14 방탄소년단 Name: 그룹, dtype: object 1df.drop_duplicates('그룹') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 1df.drop_duplicates('그룹', keep = 'last') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 전처리 - (1) row & column 의 추가 및 제거","slug":"S-Python-Pandas-Pre1","date":"2020-06-17T15:02:25.000Z","updated":"2020-06-23T16:39:44.452Z","comments":true,"path":"2020/06/18/S-Python-Pandas-Pre1/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/18/S-Python-Pandas-Pre1/","excerpt":"","text":"row &amp; column 의 추가 및 제거 1. row의 추가 2. column의 추가 3. row의 제거 4. column의 제거 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1. row의 추가 df_name .append ( {…} , ignore_index = True ) dictionary 형태의 데이터를 만들어 준다음 append() 함수를 사용하여 데이터를 추가할 수 있다. ignore_index=True옵션을 반드시 같이 추가해야한다 1df = df.append({'이름': '홍길동', '그룹': 'a그룹', '소속사':'A사', '성별': '남자', '생년월일': '1990-01-01', '키': 185.0, '혈액형': 'B', '브랜드평판지수': 12345678}, ignore_index=True) 1df.tail() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 15 홍길동 a그룹 A사 남자 1990-01-01 185.0 B 12345678 2. column의 추가 새로운 column을 만들고 값을 대입해주면, column이 쉽게 추가될 수 있다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df['국적'] = '대한민국' 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 국적 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 대한민국 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 대한민국 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 대한민국 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 대한민국 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 대한민국 새로운 column의 값을 다르게 부여하고 싶다면 loc 함수를 활용하면 된다 1df.loc[ df['이름'] == '지드래곤', '국적'] = 'korea' 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 국적 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 대한민국 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 korea 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 대한민국 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 대한민국 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 대한민국 3. row의 제거 하나의 행: df_name .drop (index_num, axis = 0) 복수의 행: df_name .drop ( [ index_num1, index_num2 ], axis = 0) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop(3, axis = 0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop([3, 5], axis = 0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4. column의 제거 하나의 열: df_name .drop ( ‘col_name’, axis = 1) 복수의 열: df_name .drop ( [ ‘col_name1’, ‘col_name2’ ], axis = 1) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop(\"그룹\", axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 큐브 여자 1998-08-26 NaN B 4668615 8 진 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 SM 여자 1989-03-09 NaN A 3918661 11 차은우 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 빅히트 남자 1993-03-09 174.0 O 2925442 1df.drop([\"그룹\", \"소속사\"], axis = 1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 남자 1995-10-13 173.6 A 10523260 1 지드래곤 남자 1988-08-18 177.0 A 9916947 2 강다니엘 남자 1996-12-10 180.0 A 8273745 3 뷔 남자 1995-12-30 178.0 AB 8073501 4 화사 여자 1995-07-23 162.1 A 7650928 5 정국 남자 1997-09-01 178.0 A 5208335 6 민현 남자 1995-08-09 182.3 O 4989792 7 소연 여자 1998-08-26 NaN B 4668615 8 진 남자 1992-12-04 179.2 O 4570308 9 하성운 남자 1994-03-22 167.1 A 4036489 10 태연 여자 1989-03-09 NaN A 3918661 11 차은우 남자 1997-03-30 183.0 B 3506027 12 백호 남자 1995-07-21 175.0 AB 3301654 13 JR 남자 1995-06-08 176.0 O 3274137 14 슈가 남자 1993-03-09 174.0 O 2925442 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"}]},{"title":"Python >> Pandas 데이터 파악 - (7) 기타","slug":"S-Python-Pandas7","date":"2020-06-17T06:12:40.000Z","updated":"2020-06-23T16:56:11.819Z","comments":true,"path":"2020/06/17/S-Python-Pandas7/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/17/S-Python-Pandas7/","excerpt":"","text":"기타 1. 피벗테이블 2. GroupBy (그룹으로 묶어 보기) 3. Multi-Index (복합 인덱스) 3-1. Multi-Index 적용 3-2. Multi-Index 데이터 프레임을 피벗테이블로 변환 3-3. 인덱스 초기화 (reset_index) 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 피벗테이블 데이터 열 중에서 두 개의 열을 각각 행 인덱스, 열 인덱스로 사용하여 데이터를 조회하여 펼쳐놓은 건을 의미함 왼쪽에 나타나는 인덱스를 행 인덱스, 상단에 나타나는 인덱스를 열 인덱스라고 부른다 pd.pivot_table(df_name, index = “col_name_분류기준1”, columns = “col_name_분류기준2”, values = “col_name_조회대상”, aggfunc = …) index는 행 인덱스 columns는 열 인덱스 values는 조회하고 싶은 값 aggfunc는 value를 산출하는 연산법 (1) e.g.: aggfunc = np.sum / np.mean (2) 설정하지 않은 경우 기본적으로 평균값을 구한다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1pd.pivot_table(df, index = \"소속사\", columns = \"혈액형\", values = \"키\") .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형 A AB B O 소속사 RBW 162.1 NaN NaN NaN YG 177.0 NaN NaN NaN 빅히트 175.8 178.0 NaN 176.60 스타크루이엔티 167.1 NaN NaN NaN 커넥트 180.0 NaN NaN NaN 판타지오 NaN NaN 183.0 NaN 플레디스 NaN 175.0 NaN 179.15 1import numpy as np 1pd.pivot_table(df, index = \"그룹\", columns = \"혈액형\", values = \"브랜드평판지수\", aggfunc = np.sum) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형 A AB B O 그룹 뉴이스트 NaN 3301654.0 NaN 8263929.0 마마무 7650928.0 NaN NaN NaN 방탄소년단 15731595.0 8073501.0 NaN 7495750.0 빅뱅 9916947.0 NaN NaN NaN 소녀시대 3918661.0 NaN NaN NaN 아스트로 NaN NaN 3506027.0 NaN 아이들 NaN NaN 4668615.0 NaN 핫샷 4036489.0 NaN NaN NaN 2. GroupBy (그룹으로 묶어 보기) groupby는 데이터를 그룹으로 묶어 분석할 때 활용한다 소속사별 키의 평균, 성별 키의 평균 등 특정, 그룹별 통계 및 데이터의 성질을 확인하고자 할 때 활용한다 groupby와 함께 count() - 갯수 sum() - 합계 mean() - 평균 var() - 분산 std() -표준편차 min() / max() - 최소값, 최대값 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.groupby(\"소속사\") &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000024E760EC288&gt; 1df.groupby('소속사').count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 성별 생년월일 키 혈액형 브랜드평판지수 소속사 RBW 1 1 1 1 1 1 1 SM 1 1 1 1 0 1 1 YG 1 1 1 1 1 1 1 빅히트 5 5 5 5 5 5 5 스타크루이엔티 1 1 1 1 1 1 1 커넥트 1 0 1 1 1 1 1 큐브 1 1 1 1 0 1 1 판타지오 1 1 1 1 1 1 1 플레디스 3 3 3 3 3 3 3 산술 통계는 자동으로 산술통계가 가능한 열만 출력됨. 1df.groupby('그룹').mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 그룹 뉴이스트 177.766667 3.855194e+06 마마무 162.100000 7.650928e+06 방탄소년단 176.560000 6.260169e+06 빅뱅 177.000000 9.916947e+06 소녀시대 NaN 3.918661e+06 아스트로 183.000000 3.506027e+06 아이들 NaN 4.668615e+06 핫샷 167.100000 4.036489e+06 1df.groupby('성별').sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 성별 남자 2123.2 68599637 여자 162.1 16238204 특정 열만 출력하고 싶다면? 1df.groupby('혈액형')['키'].mean() 혈액형 A 172.966667 AB 176.500000 B 183.000000 O 177.875000 Name: 키, dtype: float64 3. Multi-Index (복합 인덱스) 3-1. Multi-Index 적용 행 인덱스를 복합적으로 구성하고 싶은 경우는 인덱스를 리스트로 만들어 준다 df_name .groupby([‘col_name_1’,‘col_name_2’]) .mean() 데이터를 먼저 col_1기준으로 분류한 다음, col_2기준으로 한번 더 분류한다. 2번 분류 후의 데이터에 대해 산술통계값을 구한다 1df.groupby(['혈액형', '성별']).mean() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 혈액형 성별 A 남자 175.140 7591755.20 여자 162.100 5784794.50 AB 남자 176.500 5687577.50 B 남자 183.000 3506027.00 여자 NaN 4668615.00 O 남자 177.875 3939919.75 3-2. Multi-Index 데이터 프레임을 피벗테이블로 변환 Multi-Index로 된 데이터프레임을 피벗테이블 형태로 다시 변환해줄 수 있다 df_name .unstack( ‘col_열’ ) col_열: groupby에서 선택한 두 column중 pivot table의 열인덱스로 지정해주고 싶은 column명을 입력 1df2 = df.groupby(['혈액형', '성별']).mean() 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 혈액형 성별 A 남자 175.140 7591755.20 여자 162.100 5784794.50 AB 남자 176.500 5687577.50 B 남자 183.000 3506027.00 여자 NaN 4668615.00 O 남자 177.875 3939919.75 1df2.unstack('혈액형') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } 키 브랜드평판지수 혈액형 A AB B O A AB B O 성별 남자 175.14 176.5 183.0 177.875 7591755.2 5687577.5 3506027.0 3939919.75 여자 162.10 NaN NaN NaN 5784794.5 NaN 4668615.0 NaN 1df2.unstack('성별') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; } .dataframe thead tr:last-of-type th { text-align: right; } 키 브랜드평판지수 성별 남자 여자 남자 여자 혈액형 A 175.140 162.1 7591755.20 5784794.5 AB 176.500 NaN 5687577.50 NaN B 183.000 NaN 3506027.00 4668615.0 O 177.875 NaN 3939919.75 NaN 3-3. 인덱스 초기화 (reset_index) reset_index() 는 Multi-Index로 구성된 데이터 프레임의 인덱스를 초기화해 준다 그 의미는 Multi-Index로 구성된 데이터 프레임 중의 index들을 dataframe의 column으로 변환시키는 것 df_name = df_name .reset_index() 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 혈액형 성별 A 남자 175.140 7591755.20 여자 162.100 5784794.50 AB 남자 176.500 5687577.50 B 남자 183.000 3506027.00 여자 NaN 4668615.00 O 남자 177.875 3939919.75 1df2 = df2.reset_index() 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 혈액형 성별 키 브랜드평판지수 0 A 남자 175.140 7591755.20 1 A 여자 162.100 5784794.50 2 AB 남자 176.500 5687577.50 3 B 남자 183.000 3506027.00 4 B 여자 NaN 4668615.00 5 O 남자 177.875 3939919.75 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (6) 결측값 확인 및 추출","slug":"S-Python-Pandas6","date":"2020-06-11T16:21:05.000Z","updated":"2020-06-23T16:55:47.756Z","comments":true,"path":"2020/06/12/S-Python-Pandas6/","link":"","permalink":"https://hyemin-kim.github.io/2020/06/12/S-Python-Pandas6/","excerpt":"","text":"결측값 확인 및 추출 1. 결측값에 대하여 2. column별 (비)결측값 개수 확인 – info() 3. (비)결측값 위치 확인 3-1. 전체 Data 3-2. 특정 column 4. (비)결측값 추출 4-1. 해당 column만 추출 4-2. 전체 column 추출 4-3. 지정한 column 추출 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 결측값에 대하여 Null 값은 비어있는 값, 고급 언어로 결측값이다 pandas 에서는 NaN =&gt; Not a Number 로 표기 된다 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2. column별 (비)결측값 개수 확인 – info() info() 로 각 column별의 결측값(NaN) 개수를 쉽게 확인할 수 있다. 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 이름 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB 3. (비)결측값 위치 확인 .isna() .isnull() .notna() .notnull() 3-1. 전체 Data df_name .명령어 (1) 결측값 = True 1df.isna() 1df.isnull() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 False False False False False False False False 1 False False False False False False False False 2 False True False False False False False False 3 False False False False False False False False 4 False False False False False False False False 5 False False False False False False False False 6 False False False False False False False False 7 False False False False False True False False 8 False False False False False False False False 9 False False False False False False False False 10 False False False False False True False False 11 False False False False False False False False 12 False False False False False False False False 13 False False False False False False False False 14 False False False False False False False False (2) 비결측값 = True 1df.notna() 1df.notnull() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 True True True True True True True True 1 True True True True True True True True 2 True False True True True True True True 3 True True True True True True True True 4 True True True True True True True True 5 True True True True True True True True 6 True True True True True True True True 7 True True True True True False True True 8 True True True True True True True True 9 True True True True True True True True 10 True True True True True False True True 11 True True True True True True True True 12 True True True True True True True True 13 True True True True True True True True 14 True True True True True True True True 3-2. 특정 column df_name [ ‘col_name’ ] .명령어 (1) 결측값 = True 1df['그룹'].isna() 1df['그룹'].isnull() 0 False 1 False 2 True 3 False 4 False 5 False 6 False 7 False 8 False 9 False 10 False 11 False 12 False 13 False 14 False Name: 그룹, dtype: bool (2) 비결측값 = True 1df['그룹'].notna() 1df['그룹'].notnull() 0 True 1 True 2 False 3 True 4 True 5 True 6 True 7 True 8 True 9 True 10 True 11 True 12 True 13 True 14 True Name: 그룹, dtype: bool 4. (비)결측값 추출 4-1. 해당 column만 추출 결측값: df_name [ ‘col_name’] [ df_name [ ‘col_name’ ] .isna() / isnull() ] 비결측값: df_name [ ‘col_name’ ] [df_name [ ‘col_name’ ] .notna() / notnull()] 1df['그룹'][df['그룹'].isna()] 2 NaN Name: 그룹, dtype: object 1df['그룹'][df['그룹'].notnull()] 0 방탄소년단 1 빅뱅 3 방탄소년단 4 마마무 5 방탄소년단 6 뉴이스트 7 아이들 8 방탄소년단 9 핫샷 10 소녀시대 11 아스트로 12 뉴이스트 13 뉴이스트 14 방탄소년단 Name: 그룹, dtype: object 4-2. 전체 column 추출 결측값: df_name .loc [df_name [ ‘col_name’ ] .isna() / isnull() ] 비결측값: df_name .loc [df_name ['col_name] .notna() / notnull() ] 1df.loc[df['그룹'].isna()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1df.loc[df['그룹'].notnull()] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 4-3. 지정한 column 추출 결측값: df_name .loc [df_name [ ‘na_col_name’ ] .isna() / isnull() , [‘col_name1’, ‘col_name2’, …]] 비결측값: df_name .loc [df_name ['na_col_name] .notna() / notnull() , [‘col_name1’, ‘col_name2’, …]] 1df.loc[df['그룹'].isna(), ['이름', '소속사']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 2 강다니엘 커넥트 1df.loc[df['그룹'].notnull(), ['이름', '소속사']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 0 지민 빅히트 1 지드래곤 YG 3 뷔 빅히트 4 화사 RBW 5 정국 빅히트 6 민현 플레디스 7 소연 큐브 8 진 빅히트 9 하성운 스타크루이엔티 10 태연 SM 11 차은우 판타지오 12 백호 플레디스 13 JR 플레디스 14 슈가 빅히트 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (5) 범위선택","slug":"S-Python-Pandas5","date":"2020-05-24T12:58:03.000Z","updated":"2020-06-23T16:55:22.707Z","comments":true,"path":"2020/05/24/S-Python-Pandas5/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas5/","excerpt":"","text":"범위선택 1. 단일 column을 선택하는 방법 2. index &amp; column 범위 선택 (range selection) 2-1. 단순 index에 대한 범위 선택 2-2. index &amp; column 범위선택 – loc 2-3. index &amp; column 범위선택 – iloc (position으로 색인) 3. index &amp; column 조건범위선택 – Boolean Indexing 3-1. 조건에 만족한 row들의 모든 column을 추출 3-2. 조건에 만족한 row들의 특정 column들을 추출 4. index &amp; column 조건범위선택 – inis을 활용란 색인 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1. 단일 column을 선택하는 방법 df_name [ 'col_name ’ ] df_name [ \"col_name \" ] df_name .col_name 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df['이름'] 1df[\"이름\"] 1df.이름 0 지민 1 지드래곤 2 강다니엘 3 뷔 4 화사 5 정국 6 민현 7 소연 8 진 9 하성운 10 태연 11 차은우 12 백호 13 JR 14 슈가 Name: 이름, dtype: object 2. index &amp; column 범위 선택 (range selection) 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2-1. 단순 index에 대한 범위 선택 1df[:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1df.head(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 2-2. index &amp; column 범위선택 – loc df_name .loc [행(index) 범위, (열)column 범위] 행 범위는 “:” “:b” “a:b” 등 형식을 사용 열 범위는 'column name ’ ['column name1 ', 'column name2 '] 'column name1 ’ : 'column name2 ’ 등 형식을 사용 주의: pandas의 loc에서 범위 a : b는 index a &amp; index b 모두 포함 numpy에서는 index a 포함, index b 미포함 1df.loc[:, '이름'] 0 지민 1 지드래곤 2 강다니엘 3 뷔 4 화사 5 정국 6 민현 7 소연 8 진 9 하성운 10 태연 11 차은우 12 백호 13 JR 14 슈가 Name: 이름, dtype: object 1df.loc[:, ['이름', '생년월일']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 생년월일 0 지민 1995-10-13 1 지드래곤 1988-08-18 2 강다니엘 1996-12-10 3 뷔 1995-12-30 4 화사 1995-07-23 5 정국 1997-09-01 6 민현 1995-08-09 7 소연 1998-08-26 8 진 1992-12-04 9 하성운 1994-03-22 10 태연 1989-03-09 11 차은우 1997-03-30 12 백호 1995-07-21 13 JR 1995-06-08 14 슈가 1993-03-09 1df.loc[3:8, ['이름', '생년월일']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 생년월일 3 뷔 1995-12-30 4 화사 1995-07-23 5 정국 1997-09-01 6 민현 1995-08-09 7 소연 1998-08-26 8 진 1992-12-04 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.loc[2:5, '이름':'생년월일'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 2 강다니엘 NaN 커넥트 남자 1996-12-10 3 뷔 방탄소년단 빅히트 남자 1995-12-30 4 화사 마마무 RBW 여자 1995-07-23 5 정국 방탄소년단 빅히트 남자 1997-09-01 2-3. index &amp; column 범위선택 – iloc (position으로 색인) 행(index) 범위 선택은 loc와 동일 열(column) 범위는 'column 명’대신 column position을 사용 행 범위는 “:” “:b” “a:b” 등 형식을 사용 열 범위는 “c” “[c, d]” “c:d” 등 형식을 사용 주의: pandas의 iloc에서 범위 a : b는 index a 포함, index b 미포함 (numpy와 동일) pandas의 loc에서 범위 a : b는 index a &amp; index b 모두 포함 1df.iloc[:, [0, 2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 0 지민 빅히트 1 지드래곤 YG 2 강다니엘 커넥트 3 뷔 빅히트 4 화사 RBW 5 정국 빅히트 6 민현 플레디스 7 소연 큐브 8 진 빅히트 9 하성운 스타크루이엔티 10 태연 SM 11 차은우 판타지오 12 백호 플레디스 13 JR 플레디스 14 슈가 빅히트 1df.iloc[1:5, [0, 2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 1 지드래곤 YG 2 강다니엘 커넥트 3 뷔 빅히트 4 화사 RBW 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.iloc[1:5, 0:4] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 1 지드래곤 빅뱅 YG 남자 2 강다니엘 NaN 커넥트 남자 3 뷔 방탄소년단 빅히트 남자 4 화사 마마무 RBW 여자 3. index &amp; column 조건범위선택 – Boolean Indexing Boolean indexing은 Numpy에서의 Boolean indexing과 같은 원리다 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 3-1. 조건에 만족한 row들의 모든 column을 추출 df [조건 ] 1df['키'] &gt; 180 0 False 1 False 2 False 3 False 4 False 5 False 6 True 7 False 8 False 9 False 10 False 11 True 12 False 13 False 14 False Name: 키, dtype: bool 1df[df['키'] &gt; 180] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 3-2. 조건에 만족한 row들의 특정 column들을 추출 방법 1. df_name [조건 ] [column범위 ] 1df[ df['키'] &gt; 180 ] ['이름'] 6 민현 11 차은우 Name: 이름, dtype: object 1df [ df['키'] &gt; 180 ] [['이름', '키']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 키 6 민현 182.3 11 차은우 183.0 방법 2. loc를 활용: df_name.loc[ 조건 , column범위 ] 【추천】 1df.loc[ df['키'] &gt; 180, '이름' ] 6 민현 11 차은우 Name: 이름, dtype: object 1df.loc[ df['키'] &gt; 180, ['이름', '그룹'] ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 6 민현 뉴이스트 11 차은우 아스트로 1df.loc[ df['키'] &gt; 180, '이름' : '성별'] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 6 민현 뉴이스트 플레디스 남자 11 차은우 아스트로 판타지오 남자 4. index &amp; column 조건범위선택 – inis을 활용란 색인 column값이 미리 정의한 list에 속한다는 조건을 걸고자 할 때 사용한다 1my_condition = ['플레디스', 'SM'] 1df['소속사'].isin(my_condition) 0 False 1 False 2 False 3 False 4 False 5 False 6 True 7 False 8 False 9 False 10 True 11 False 12 True 13 True 14 False Name: 소속사, dtype: bool 1df.loc[ df['소속사'].isin(my_condition) ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 1df.loc[ df['소속사'].isin(my_condition) , ['이름', '소속사'] ] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 소속사 6 민현 플레디스 10 태연 SM 12 백호 플레디스 13 JR 플레디스 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (4) 정렬","slug":"S-Python-Pandas4","date":"2020-05-24T08:07:08.000Z","updated":"2020-06-23T16:54:53.058Z","comments":true,"path":"2020/05/24/S-Python-Pandas4/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas4/","excerpt":"","text":"정렬 (sort) 1. index 순으로 정렬 2. column의 value순으로 정렬 2-1. 단일 column 기준 2-2. 복수 column 기준 1import pandas as pd 1df = pd.read_csv('korean-idol.csv') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1. index 순으로 정렬 오름차순 정렬: df_name.sort_index() (default) 내림차순 정렬: df_name.sort_index(ascending = False) 1df.sort_index() # 오름차순 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.sort_index(ascending = False) # 내림차순 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 2. column의 value순으로 정렬 오름차순 정렬: df_name.sort_values(by = ‘col_name’) 내림차순 정렬: df_name.sort_values(by = ‘col_name’, ascending = False) 2-1. 단일 column 기준 1df.sort_values(by='키') # 오름차순 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 1df.sort_values(by = '키', ascending = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 2-2. 복수 column 기준 먼저 column1 기준으로 정렬하고, column1 값이 동일한 row들은 column2기준으로 정렬: df_name .sort_value ( by = [ ‘col_name 1’ , ‘col_name 2’ ] ) 1df.sort_values(by = ['키', '브랜드평판지수']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 1df.sort_values(by = ['키', '브랜드평판지수'], ascending = False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (3) 기본정보 & 통계정보 파악","slug":"S-Python-Pandas3","date":"2020-05-24T08:06:08.000Z","updated":"2020-06-23T16:54:35.835Z","comments":true,"path":"2020/05/24/S-Python-Pandas3/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas3/","excerpt":"","text":"기본정보 &amp; 통계정보 파악 1. 파일 읽어오기 (csv) 2. 기본 행&amp;열 정보 알아보기 (column, index, info) 2-1. column (열) 이름 출력하기 2-2. column (열) 이름 재정의하기 2-3. index (행) 정보 출력하기 2-4. info (기본적인 column 정보와 데이터 타입) 3. 형태 (shape) 알아보기 4. 상위 5개, 하위 5개의 정보만 보기 5. 통계 정보 알아보기 5-1. 전체 통계 정보 5-2. 최소값(min), 최대값(max), 중앙값(median), 최빈값(mode) 5-3. 합계(sum), 평균(mean), 분산(var), 표준편차(std) 5-4. 갯수를 세는 count 1import pandas as pd 1. 파일 읽어오기 (csv) 1df = pd.read_csv('korean-idol.csv') 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2. 기본 행&amp;열 정보 알아보기 (column, index, info) 2-1. column (열) 이름 출력하기 df_name .columns 1df.columns Index(['이름', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ 2-2. column (열) 이름 재정의하기 (1) 전체 column 이름 df_name .columns = […] 예: “이름” --&gt; “name”: 1new_col = ['name', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'] 1df.columns = new_col 1df.columns Index(['name', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ (2) 개별 column 이름 df_name .rename ( columns = { “old_name” : “new_name” } ) ​ 1df = pd.read_csv('korean-idol.csv') 1df.columns Index(['이름', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ 1df = df.rename(columns = {\"이름\" : \"name\"}) 1df.columns Index(['name', '그룹', '소속사', '성별', '생년월일', '키', '혈액형', '브랜드평판지수'], dtype='object') ​ 2-3. index (행) 정보 출력하기 df_name .index 1df.index RangeIndex(start=0, stop=15, step=1) 2-4. info (기본적인 column 정보와 데이터 타입) df_name .info() Tip: info메소드는 주로 빠진 값 (null 값)과 데이터 타입을 볼 때 활용함 1df.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 15 entries, 0 to 14 Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 name 15 non-null object 1 그룹 14 non-null object 2 소속사 15 non-null object 3 성별 15 non-null object 4 생년월일 15 non-null object 5 키 13 non-null float64 6 혈액형 15 non-null object 7 브랜드평판지수 15 non-null int64 dtypes: float64(1), int64(1), object(6) memory usage: 1.1+ KB “object” type은 주로 문자형 데이터를 가리킴. 3. 형태 (shape) 알아보기 shape는 tuple형태로 반환되며, 첫번째는 row, 두번째는 column의 숫자를 의미함. 1df.shape (15, 8) 4. 상위 5개, 하위 5개의 정보만 보기 상위 5개 row: df_name .head() 하위 5개 row: df_name .tail() 상위 n개 row: df_name .head(n) 하위 n개 row: df_name .tail(n) 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.tail() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1df.head(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 1df.tail(2) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 5. 통계 정보 알아보기 통계값은 산술 연산이 가능한 숫자형 (float / int) 인 column을 다룬다 5-1. 전체 통계 정보 df_name .describe() 산술 연산이 가능한 column만 출력됨 1df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 키 브랜드평판지수 count 13.000000 1.500000e+01 mean 175.792308 5.655856e+06 std 5.820576 2.539068e+06 min 162.100000 2.925442e+06 25% 174.000000 3.712344e+06 50% 177.000000 4.668615e+06 75% 179.200000 7.862214e+06 max 183.000000 1.052326e+07 5-2. 최소값(min), 최대값(max), 중앙값(median), 최빈값(mode) 최소값: df_name [ ‘col_name’ ] .min() 최대값: df_name [ ‘col_name’ ] .max() 중앙값: df_name [ ‘col_name’ ] .median() 최빈값: df_name [ ‘col_name’ ] .mode() 1df['키'].min() 162.1 1df['키'].max() 183.0 1df['키'].median() 177.0 1df['키'].mode() 0 178.0 dtype: float64 5-3. 합계(sum), 평균(mean), 분산(var), 표준편차(std) 합계(sum): df_name [ ‘col_name’ ] .sum() 평균(mean): df_name [ ‘col_name’ ] .mean() 분산(variance): df_name [ ‘col_name’ ] .var() 표준편차(standard deviation): df_name [ ‘col_name’ ] .std() 1df['키'].sum() 2285.3 1df['키'].mean() 175.7923076923077 1df['키'].var() 33.879102564102595 1df['키'].std() 5.820575793175672 5-4. 갯수를 세는 count df_name [ ‘col_name’ ] .count 1df['키'].count() 13 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (2) 파일 불러오기 및 복사","slug":"S-Python-Pandas2","date":"2020-05-24T06:04:59.000Z","updated":"2020-06-23T16:54:11.248Z","comments":true,"path":"2020/05/24/S-Python-Pandas2/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/24/S-Python-Pandas2/","excerpt":"","text":"파일 불러오기 및 복사 1. csv파일 읽어오기 – \"pd.read_csv\" 1-1. Jupyter Notebook 기반 1-2. Colab 기반 2. Excle파일 읽어오기 – \"pd.read_excel\" 2-1. Jupyter Notebook 기반 2-2. Colab 기반 3. 복사 (copy) 1. csv파일 읽어오기 – \"pd.read_csv\" 1-1. Jupyter Notebook 기반 1import pandas as pd 1pd.read_csv('korean-idol.csv') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 1-2. Colab 기반 방법 1. 로컬에서 파일 읽어오기 123456from google.colab import filesmyfile = files.upload()import iopd.read_csv(io.BytesIO(myfile['korean-idol.csv'])) 방법 2: 구글 드라이브에 있는 샘플 파일 읽어오기 123456789from google.colab import drivedrive.mount('/content/drive')# 나타나는 link에 따라 google drive 로그인하여 link복사, # 'Enter your authorization code:'에서 복사된 link를 입력filename = 'colab 왼쪽 목록에서 파일 경로를 복사하여 붙혀놓기'pd.read_csv(filename) 2. Excle파일 읽어오기 – \"pd.read_excel\" 2-1. Jupyter Notebook 기반 1pd.read_excel('korean-idol.xlsx') .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 5 정국 방탄소년단 빅히트 남자 1997-09-01 178.0 A 5208335 6 민현 뉴이스트 플레디스 남자 1995-08-09 182.3 O 4989792 7 소연 아이들 큐브 여자 1998-08-26 NaN B 4668615 8 진 방탄소년단 빅히트 남자 1992-12-04 179.2 O 4570308 9 하성운 핫샷 스타크루이엔티 남자 1994-03-22 167.1 A 4036489 10 태연 소녀시대 SM 여자 1989-03-09 NaN A 3918661 11 차은우 아스트로 판타지오 남자 1997-03-30 183.0 B 3506027 12 백호 뉴이스트 플레디스 남자 1995-07-21 175.0 AB 3301654 13 JR 뉴이스트 플레디스 남자 1995-06-08 176.0 O 3274137 14 슈가 방탄소년단 빅히트 남자 1993-03-09 174.0 O 2925442 2-2. Colab 기반 구글 드라이브에 있는 샘플 파일 읽어오기 123456from google.colab import drivedrive.mount('/content/drive')filename = '파일 경로 붙혀놓기'pd.read_excel(filename) 3. 복사 (copy) dataframe을 복사할 때 \"df_name.copy()\"를 사용한다 \"=\"를 사용하여 원본데이터를 \"복사\"하면 복사된 데이터를 수정할 때 원본 데이터도 같이 변화한다 1df = pd.read_csv('korean-idol.csv') 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_new = df 1df_new.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_new['이름'] = 0 1df_new.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 0 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 0 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 0 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 0 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 0 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 0 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 0 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 0 마마무 RBW 여자 1995-07-23 162.1 A 7650928 이렇게 되는 이유는 두 dataframe이 같은 메모리 주소를 참조하기 때문이다. 1hex(id(df_new)) '0x25109f6e6c8' 1hex(id(df)) '0x25109f6e6c8' 원본 데이터를 유지 시키고, 새로운 변수에 복사할 때 copy() 를 사용한다 1df = pd.read_csv('korean-idol.csv') 1df_copy = df.copy() 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df_copy.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 복사된 dataframe이 원본 데이터와 같은 메모리 주소를 참조한다. 1hex(id(df)) '0x25109fefa48' 1hex(id(df_copy)) '0x25109ff4408' copy본을 수정할 때 원본 데이터가 유지된다 1df_copy['이름'] = 0 1df_copy.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 0 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 0 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 0 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 0 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 0 마마무 RBW 여자 1995-07-23 162.1 A 7650928 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 이름 그룹 소속사 성별 생년월일 키 혈액형 브랜드평판지수 0 지민 방탄소년단 빅히트 남자 1995-10-13 173.6 A 10523260 1 지드래곤 빅뱅 YG 남자 1988-08-18 177.0 A 9916947 2 강다니엘 NaN 커넥트 남자 1996-12-10 180.0 A 8273745 3 뷔 방탄소년단 빅히트 남자 1995-12-30 178.0 AB 8073501 4 화사 마마무 RBW 여자 1995-07-23 162.1 A 7650928 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Pandas 데이터 파악 - (1) Series와 DataFrame","slug":"S-Python-Pandas1","date":"2020-05-22T11:37:46.000Z","updated":"2020-06-23T16:53:52.755Z","comments":true,"path":"2020/05/22/S-Python-Pandas1/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/22/S-Python-Pandas1/","excerpt":"","text":"Series &amp; DataFrame 1. pandas 패키지 로드 2. pandas의 Series 와 DataFrame 2-1. Series 2-2. DataFrame 방법 1. list로 만들기 방법 2. dict로 만들기 2-3. index를 특정column으로 지정하기 2-4. column = Series 1. pandas 패키지 로드 1import pandas 별칭은 주로 pd로 사용한다 1import pandas as pd 1pd &lt;module 'pandas' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'&gt; 2. pandas의 Series 와 DataFrame 1차원, 1개의 column은 Series라고 한다 2-1. Series Series 생성: pd.Series(“list”) pd.Series(“list_name”) (1) pd.Series(“list”) 1pd.Series([1, 2, 3, 4]) 0 1 1 2 2 3 3 4 dtype: int64 (2) pd.Series(“list_name”) 1a = [1, 2, 3, 4] 1pd.Series(a) 0 1 1 2 2 3 3 4 dtype: int64 1mylist = [1, 2, 3, 4] 1pd.Series(mylist) 0 1 1 2 2 3 3 4 dtype: int64 2-2. DataFrame 방법 1. list로 만들기 123company1 = [['삼성', 2000, '스마트폰'], ['현대', 1000, '자동차'], ['네이버', 500, '포털']] 1pd.DataFrame(company1) .dataframe tbody tr th:only-of-type { vertical-align: middle } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 &lt;활용을 하기 위해 DataFrame을 변수에 지정하기&gt; 1df1 = pd.DataFrame(company1) 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 &lt;제목컬럼 만들기&gt; – “dfname.column = [ ]” 1df1.columns = ['기업명', '매출액', '업종'] 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 주의: column명의 개수는 반드시 DataFrame의 column수와 동일해야 함 방법 2. dict로 만들기 1234company2 = {'기업명': ['삼성', '현대', '네이버'], '매출액': [2000, 1000, 500], '업종': ['스므트폰', '자동차', '포털'] } 1df2 = pd.DataFrame(company2) 1df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 0 삼성 2000 스므트폰 1 현대 1000 자동차 2 네이버 500 포털 2-3. index를 특정column으로 지정하기 “dfname.index = [ ]” 명령을 사용한다 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 0 삼성 2000 스마트폰 1 현대 1000 자동차 2 네이버 500 포털 1df1.index = df1['기업명'] 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 기업명 매출액 업종 기업명 삼성 삼성 2000 스마트폰 현대 현대 1000 자동차 네이버 네이버 500 포털 2-4. column = Series 1df1['매출액'] 기업명 삼성 2000 현대 1000 네이버 500 Name: 매출액, dtype: int64 1type(df1['매출액']) pandas.core.series.Series document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"}]},{"title":"Python >> Numpy - (4) 행렬. Broadcasting","slug":"S-Python-Numpy4","date":"2020-05-20T07:55:34.000Z","updated":"2020-06-11T17:09:58.983Z","comments":true,"path":"2020/05/20/S-Python-Numpy4/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/20/S-Python-Numpy4/","excerpt":"행렬 (덧셈, 뺄셈, 곱셈). Broadcasting.","text":"행렬 (덧셈, 뺄셈, 곱셈). Broadcasting. 목록 1. 행렬 - 덧셈 1-1. 덧셈 1-2. Sum – Matrix안의 계산 2. 행렬 - 뺄셈 3. 행렬 - 곱셈 3-1. 일반 곱셈 3-2. dot product / 내적곱 4. Broadcasting 4-1. 숫자의 연산 4-2. array (배열)의 broadcasting 1import numpy as np 1. 행렬 - 덧셈 행렬의 shape이 같아야 덧셈 가능 1-1. 덧셈 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 4, 5], [1, 2, 3]]) 1a + b array([[4, 6, 8], [3, 5, 7]]) 12a = np.array([[1, 2, 3], [2, 3, 4]]) 123b = np.array([[1, 2], [3, 4], [5, 6]]) 1a + b # shape이 다르면 error발생 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-7-37f7d36ad418&gt; in &lt;module&gt; ----&gt; 1 a + b # shape이 다르면 error발생 ValueError: operands could not be broadcast together with shapes (2,3) (3,2) 1-2. Sum – Matrix안의 계산 명령어: np.sum(‘array_name’, axis = ‘0/1/…’) 주의: 계산할 때 axis의 방향대로 Sum을 구한다. 예를 들면, 2darray에서, axis = 0 이면: 수직방향으로 Sum을 구한다 axis = 1 이면: 수평방향으로 Sum을 구한다 12a = np.array([[1, 2, 3], [2, 3, 4]]) 1np.sum(a, axis = 0) array([3, 5, 7]) 1np.sum(a, axis = 1) array([6, 9]) 2. 행렬 - 뺄셈 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 4, 5], [1, 2, 3]]) 1a - b array([[-2, -2, -2], [ 1, 1, 1]]) 12a = np.array([[1, 2, 3], [2, 3, 4]]) 123b = np.array([[1, 2], [3, 4], [5, 6]]) 1a - b # shape이 다르면 error발생 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-18-e62ba154daaa&gt; in &lt;module&gt; ----&gt; 1 a - b # shape이 다르면 error발생 ValueError: operands could not be broadcast together with shapes (2,3) (3,2) 3. 행렬 - 곱셈 3-1. 일반 곱셈 일반곱셈은 덧셈과 뺏셈이랑 동일하게 같은 위치에 있는 애들끼리 곱한다. [shape이 완전 같아야 함] 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 4, 5], [1, 2, 3]]) 1a * b array([[ 3, 8, 15], [ 2, 6, 12]]) 3-2. dot product / 내적곱 [맞닿는 shape이 같아야 함] 12a = np.array([[1, 2, 3], [2, 3, 4]]) 123b = np.array([[1, 2], [3, 4], [5, 6]]) 1a.shape, b.shape ((2, 3), (3, 2)) 방법 1: np.dot(a, b) 1np.dot(a, b) array([[22, 28], [31, 40]]) 방법2: a.dot(b) 1a.dot(b) array([[22, 28], [31, 40]]) 4. Broadcasting 4-1. 숫자의 연산 array a 의 모든 원소에 3을 더하고 싶다면: 단순히 행렬 덧셈을 사용할 때: 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[3, 3, 3], [3, 3, 3]]) 1a + b array([[4, 5, 6], [5, 6, 7]]) Broadcasting 사용할 때: 12a = np.array([[1, 2, 3], [2, 3, 4]]) 1a + 3 array([[4, 5, 6], [5, 6, 7]]) 1a - 3 array([[-2, -1, 0], [-1, 0, 1]]) 1a * 3 array([[ 3, 6, 9], [ 6, 9, 12]]) 1a / 3 array([[0.33333333, 0.66666667, 1. ], [0.66666667, 1. , 1.33333333]]) 4-2. array (배열)의 broadcasting original array의 shape이 유지됨. 12a = np.array([[1, 2, 3], [2, 3, 4]]) 12b = np.array([[1], [2]]) 1a.shape, b.shape ((2, 3), (2, 1)) 1a * b array([[1, 2, 3], [4, 6, 8]]) 12a = np.array([[1, 2, 3], [2, 3, 4]]) 1b = np.array([1, 2, 3]) 1a * b array([[ 1, 4, 9], [ 2, 6, 12]]) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python >> Numpy - (3) 수열. 정렬","slug":"S-Python-Numpy3","date":"2020-05-19T17:10:54.000Z","updated":"2020-06-11T17:09:51.726Z","comments":true,"path":"2020/05/20/S-Python-Numpy3/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/20/S-Python-Numpy3/","excerpt":"arange. range. 정렬(sort &amp; argsort)","text":"arange. range. 정렬(sort &amp; argsort) 목록 1. arange란? 1-1. 순서대로 리스트에 값을 생성하려면? 1-2. arange를 사용해서 쉽게 생성하기 1-3. keyword인자를 사용해보기 1-4. 홀수의 값만 생성 2. range (Numpy와는 상관없는 Python문법) 3. 정렬 3-1. 1차원 정렬 3-2. N차원 정렬 3-3. index를 반환하는 argsort 1import numpy as np 1. arange란? arange와 range를 같이 보고 이해하면 됨 [실제 상황 예시] 우리는 순차적인 값을 생성할 때가 많다. 예를 들면: 회원에 대한 가입번호 부여 100개 한정 판매 상품에 대한 고유 번호 부여 이 밖에도 데이터 관리를 위한 인덱스를 차례대로 부여하는 것은 매우 흔한 일이다. 1-1. 순서대로 리스트에 값을 생성하려면? 1~10까지 값을 생성하려면? 1arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1arr [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1-2. arange를 사용해서 쉽게 생성하기 np.arange(a, b): a 부터 b-1 까지 생성한다 (a포함, b미포함) 1arr = np.arange(1, 11) 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 1-3. keyword인자를 사용해보기 np.arange(start = a, stop = b) 1arr = np.arange(start=1, stop=11) 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 1arr = np.arange(stop=11, start=1) # start &amp; stop 지정했기 때문에 순서 바꿔도 됨 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 1arr = np.arange(11,1) # start &amp; stop 지정 안하면 순서 바꿨을 때 오류 남 1arr array([], dtype=int32) 1-4. 홀수의 값만 생성 1~10 사이의 값중 홀수만 생성 step 키워드 활용 np.arange(start, stop, step) 1arr = np.arange(1, 11, 2) 1arr array([1, 3, 5, 7, 9]) 1arr = np.arange(start=1, stop=11, step=2) 1arr array([1, 3, 5, 7, 9]) 2. range (Numpy와는 상관없는 Python문법) range는 말 그대로 범위를 지정해 주는 것이다 보통 for-in 의 반복문에서 많이 사용된다 arange와는 다르게 array형태로 저장되어있지 않고 그냥 가볍게 바로바로 쓴다 arange 구문 활용시 1arr = np.arange(1, 11) 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 12for i in arr: print(i) 1 2 3 4 5 6 7 8 9 10 range 구문 활용시 12for i in range(1, 11): print(i) 1 2 3 4 5 6 7 8 9 10 12for i in range(1, 11, 2): print(i) 1 3 5 7 9 3. 정렬 3-1. 1차원 정렬 1차원 정렬은 매우 간단함 오름차순으로 정렬: np.sort(arr) 내림차순으로 정렬: np.sort(arr)[::-1] 1arr = np.array([1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1arr array([ 1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1np.sort(arr) array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 1np.sort(arr)[::-1] array([10, 9, 8, 8, 7, 6, 5, 4, 3, 2, 1]) 하지만, 그냥 이상태에서는 정렬된 이 값들이 유지가 안됨 값을 sort 된 상태로 유지시키려면: 변수로 다시 지정해주기 np.sort(arr) 대신 arr.sort() 쓴다 [arr자체에 sort명령을 씌워줌] 1arr array([ 1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1np.sort(arr) array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 1arr # np.sort 만 실행했을 때 유지가 안됨 array([ 1, 10, 5, 8, 2, 4, 3, 6, 8, 7, 9]) 1arr2 = np.sort(arr) # 방법1: arr2로 지정하기 1arr2 array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 1arr.sort() # 방법2: arr.sort 사용하기 1arr array([ 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10]) 3-2. N차원 정렬 N차원 정렬에서는 axis 중요함. (즉, 정렬 기준이 되는 축) 123arr2d = np.array([[5, 6, 7, 8], [4, 3, 2, 1], [10, 9, 12, 11]]) 1arr2d.shape (3, 4) 열 정렬 (왼쪽에서 오른쪽으로 정렬) – axis 1을 기준으로 삼 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 1) # 정렬 후 array([[ 5, 6, 7, 8], [ 1, 2, 3, 4], [ 9, 10, 11, 12]]) 행 정렬 (위에서 아래로 정렬) – axis 0을 기준으로 삼 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 0) # 정렬 후 array([[ 4, 3, 2, 1], [ 5, 6, 7, 8], [10, 9, 12, 11]]) 3-3. index를 반환하는 argsort 정렬한 결과에는 값을 반환하는 것이 아닌 index를 반환한다 열 정렬 (왼쪽에서 오른쪽으로 정렬) 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 1) # sort 정렬 후 array([[ 5, 6, 7, 8], [ 1, 2, 3, 4], [ 9, 10, 11, 12]]) 1np.argsort(arr2d, axis = 1) # argsort 정렬 후 array([[0, 1, 2, 3], [3, 2, 1, 0], [1, 0, 3, 2]], dtype=int64) 행 정렬 (위에서 아래로 정렬) 1arr2d # 정렬 전 array([[ 5, 6, 7, 8], [ 4, 3, 2, 1], [10, 9, 12, 11]]) 1np.sort(arr2d, axis = 0) # sort 정렬 후 array([[ 4, 3, 2, 1], [ 5, 6, 7, 8], [10, 9, 12, 11]]) 1np.argsort(arr2d, axis = 0) # argsort 정렬 후 array([[1, 1, 1, 1], [0, 0, 0, 0], [2, 2, 2, 2]], dtype=int64) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python >> Numpy - (2) Slicing. 인덱싱","slug":"S-Python-Numpy2","date":"2020-05-19T12:55:06.000Z","updated":"2020-06-11T17:09:45.587Z","comments":true,"path":"2020/05/19/S-Python-Numpy2/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/19/S-Python-Numpy2/","excerpt":"슬라이싱 (Slicing). Fancy 인덱싱. Boolean 인덱싱.","text":"슬라이싱 (Slicing). Fancy 인덱싱. Boolean 인덱싱. 목록 1. 슬라이싱 (Slicing) 1-1. index 지정하여 색인 1차원 array 2차원 array 1-2. 범위 색인 1차원 array 2차원 array 2. Fancy 인덱싱 2-1. 1차원 array 2-2. 2차원 array 3. Boolean 인덱싱 3-1. True와 False값으로 색인하기 3-2. 조건필터 1. 슬라이싱 (Slicing) 1import numpy as np 베열의 부분 선택 (과일을 슬라이스해서 부분만 먹듯…) 1arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1arr.shape (10,) 1-1. index 지정하여 색인 1차원 array 1arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1arr[0] # index: 앞에서 부터 0, 1, 2, ... 0 1arr[5] 5 1arr[10] # index가 넘으면 error남 --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-7-ff656e92d79c&gt; in &lt;module&gt; ----&gt; 1 arr[10] IndexError: index 10 is out of bounds for axis 0 with size 10 1arr[-1] # 뒤에서 부터 1번째. index: 뒤에서 부터 -1, -2, -3,... 9 1arr[-10] 0 1arr[-11] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-10-91f133f07612&gt; in &lt;module&gt; ----&gt; 1 arr[-11] IndexError: index -11 is out of bounds for axis 0 with size 10 2차원 array 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 1arr2d.shape (3, 4) arr2d[행, 열] 1arr2d[0, 2] 3 1arr2d[2, 1] 10 1-2. 범위 색인 1차원 array arr[a, b] – arr의 “index a” 부터 \"index b-1\"까지 (a 포함, b 미포함) index: 1 이상 1arr array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1arr[1:] # index 1 포함 array([1, 2, 3, 4, 5, 6, 7, 8, 9]) index: 5 미만 1arr[:5] # index 5 미포함 array([0, 1, 2, 3, 4]) index: 1이상 5미만 1arr[1:5] # index 1 포함 &amp; index 5 미포함 array([1, 2, 3, 4]) index: -1까지 1arr[:-1] # index -1 (index 9) 미포함 array([0, 1, 2, 3, 4, 5, 6, 7, 8]) 2차원 array 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) row(행)을 모두 가져오려는 경우 1arr2d[0,:] # 0번 행의 모든 열 가져오기 array([1, 2, 3, 4]) colomn(열)을 모두 가져오려는 경우 1arr2d[:,2] array([ 3, 7, 11]) 부분적으로 가져오려는 경우 1arr2d[:2, :] # 0,1번 행의 모든 열 가져오기 array([[1, 2, 3, 4], [5, 6, 7, 8]]) 1arr2d[:2, 2:] # 0,1번 행의 2,3번 열 가져오기 array([[3, 4], [7, 8]]) 2. Fancy 인덱싱 fancy인덱싱은 범위가 아닌 특정 index의 집합의 값을 선택하여 추출하고 싶을 때 활용한다 1arr = np.array([10, 23, 2, 7, 90, 65, 32, 66, 70]) 2-1. 1차원 array 방법 1: 추출하고 싶은 index의 집합을 **[꺾쇠 괄호로]**묶어서 추출 1arr[[1, 3, 5]] array([23, 7, 65]) 방법 2: 추출하고 싶은 index의 집합을 변수에 지정한 후 추출 1idx = [1, 3, 5] 1arr[index] array([23, 7, 65]) 2-2. 2차원 array 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 1arr2d[[0,1], :] array([[1, 2, 3, 4], [5, 6, 7, 8]]) 1arr2d[:, [1,3]] array([[ 2, 4], [ 6, 8], [10, 12]]) 3. Boolean 인덱싱 조건 필터링을 통하여 Boolean값을 이용한 색인 1arr = np.array([1, 2, 3, 4, 5, 6, 7]) 123arr2d = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 3-1. True와 False값으로 색인하기 boolean index의 수가 꼭 array의 index와 같아야 됨! 1myTrueFalse = [True, False, True] 1arr[myTrueFalse] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-43-9c52b39d81ae&gt; in &lt;module&gt; ----&gt; 1 arr[myTrueFalse] IndexError: boolean index did not match indexed array along dimension 0; dimension is 7 but corresponding boolean dimension is 3 1myTrueFalse = [True, False, True, False, True, False, True] 1arr[myTrueFalse] array([1, 3, 5, 7]) 3-2. 조건필터 조건 연산자를 활용하여 필터를 생성할 수 있다 1arr2d array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) 1arr2d &gt; 2 # \"2보다 크다\"라는 조건의 만족여부에 따라 Boolean index 생성 array([[False, False, True, True], [ True, True, True, True], [ True, True, True, True]]) 위 Boolean index를 다시 array에 적용하여 해당 부분을 추출: arr2d[조건필터] 1arr2d[arr2d &gt; 2] # 1차원 array로 반환 array([ 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]) 1arr2d[arr2d &lt; 5] array([1, 2, 3, 4]) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python >> Numpy - (1) Numpy. array","slug":"S-Python-Numpy1","date":"2020-05-18T15:07:32.000Z","updated":"2020-06-25T09:04:02.406Z","comments":true,"path":"2020/05/19/S-Python-Numpy1/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/19/S-Python-Numpy1/","excerpt":"Numpy개요. Numpy import하기. nd array 생성. array에서의 데이터 타입","text":"Numpy개요. Numpy import하기. nd array 생성. array에서의 데이터 타입 목록 1. Numpy 개요 1-1. Numpy이란? 1-2. 별칭 - np 1-3. array (배열) 1-4. shape(차원) &amp; axis(축) 2. Numpy import하기 2-1. 별칭 (alias) 지정하기 (항상 해주세요!) 3. ndarray 생성하기 – \"np.array([…])\" 3-1. list로 부터 생성하기 – “np.array(list_name)” 3-2. shape확인하기 – “array_name .shape” 4. array에서의 data type 4-1. list에서의 data type 4-2. array에서의 data type case 1. int와 float타입이 혼재된 경우 case 2. int와 float 타입이 혼재되었으나, dtype을 지정한 경우 case 3. int / float 와 str 타입이 혼재된 경우 case 4. int와 str 타입이 혼재되어 있고 dtype이 int로 지정한 경우 1. Numpy 개요 1-1. Numpy이란? Numpy: 수학, 과학 계산용 패키지 ​ 1-2. 별칭 - np 1import numpy as np 1-3. array (배열) 배열: 여러 값들의 그룹 &lt; 1차원 배열 &gt; numpy.array([1, 2, 3, 4]) &lt; 2차원 배열 &gt; numpy.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]) &lt; n차원 배열 &gt; (nd array: n dimention array) 1-4. shape(차원) &amp; axis(축) shape은 차원의 수 를 확인 (3, ) =&gt; 3 X 1의 배열 (4,3) =&gt; 4 X 3의 배열 (2,5,3) =&gt; 2 X 5 X 3의 배열 axis는 기준이 되는 축 axis는 앞에서 부터 0, 1, 2… nd array의 축: axis 0, axis 1, axis 2, … axis n 2. Numpy import하기 1import numpy 1numpy &lt;module 'numpy' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'&gt; 2-1. 별칭 (alias) 지정하기 (항상 해주세요!) 1import numpy as np 1np &lt;module 'numpy' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'&gt; 3. ndarray 생성하기 – \"np.array([…])\" 1arr = np.array([1,2,3,4], dtype=int) 1arr # 주의: list와 다름 array([1, 2, 3, 4]) 1[1, 2, 3, 4] # list [1, 2, 3, 4] 1type(arr) numpy.ndarray 3-1. list로 부터 생성하기 – “np.array(list_name)” 1mylist1 = [1, 2, 3, 4] 12mylist2 = [[1, 2, 3, 4], [5, 6, 7, 8]] 1arr1 = np.array(mylist1) 1arr1 array([1, 2, 3, 4]) 1arr2 = np.array(mylist2) 1arr2 array([[1, 2, 3, 4], [5, 6, 7, 8]]) 3-2. shape확인하기 – “array_name .shape” 1arr1.shape (4,) 1arr2.shape (2, 4) 4. array에서의 data type array에서는 list와 다르게 1개의 단일 데이터 타입 만 허용 된다 4-1. list에서의 data type 1mylist = [1, 3.14, '사과', '1234'] 1mylist [1, 3.14, '사과', '1234'] 1mylist[0] 1 1mylist[2] '사과' 4-2. array에서의 data type case 1. int와 float타입이 혼재된 경우 int와 float타입이 혼재된 경우 int(정수)가 float(실수)로 바꿔진다 1arr = np.array([1, 2, 3, 3.14]) 1arr # 정수가 실수로 바꿔진다 array([1. , 2. , 3. , 3.14]) ​ case 2. int와 float 타입이 혼재되었으나, dtype을 지정한 경우 int와 float 타입이 혼재되었으나, dtype가 int로 지정된 경우, float의 앞에 정수 부분만 보류된다 1arr = np.array([1, 2, 3, 3.14], dtype = int) 1arr array([1, 2, 3, 3]) case 3. int / float 와 str 타입이 혼재된 경우 int / float 와 float타입이 혼재된 경우 int(정수)가 str(문자열)로 바꿔진다 1arr = np.array([1, 3.14, '사과', '1234']) 1arr array(['1', '3.14', '사과', '1234'], dtype='&lt;U32') 1arr[0] + arr[1] #str로 되어버려서 숫자의 사칙 연산이 안됨 '13.14' case 4. int와 str 타입이 혼재되어 있고 dtype이 int로 지정한 경우 (1) 문자내용인 str이 존재한 경우 error 발생 1arr = np.array([1, 3.14, '사과', '1234', '5.8'], dtype = int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-50-88e75a912236&gt; in &lt;module&gt; ----&gt; 1 arr = np.array([1, 3.14, '사과', '1234', '5.8'], dtype = int) ValueError: invalid literal for int() with base 10: '사과' (2) 실수(float)내용인 str이 존재한 경우도 error발생 1arr = np.array([1, 3.14, '1234', '5.8'], dtype = int) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-52-98017763e514&gt; in &lt;module&gt; ----&gt; 1 arr = np.array([1, 3.14, '1234', '5.8'], dtype = int) ValueError: invalid literal for int() with base 10: '5.8' (3) 정수(int)내용인 str만 존재한 경우 해당 str이 자동으로 int로 바꿔짐 1arr = np.array([1, 3.14, '1234'], dtype = int) 1arr array([ 1, 3, 1234]) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"}]},{"title":"Python 기초문법 - (6) Package","slug":"S-Python-base6","date":"2020-05-16T04:52:05.000Z","updated":"2020-06-11T17:10:50.910Z","comments":true,"path":"2020/05/16/S-Python-base6/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/16/S-Python-base6/","excerpt":"패키지(Package) 와 import","text":"패키지(Package) 와 import 목록 1. 패키지와 모듈 그리고 함수의 관계도 2. 모듈 import 하기 3. 패키지 에서 import하기 4. 별칭 (alias) 지어주기 5. 앞으로 자주 사용할 패키지, 모듈 미리보기 패키지(Package) 와 import 1. 패키지와 모듈 그리고 함수의 관계도 함수들이 뭉쳐진 하나의 .py파일 안에 이루어진 것을 모듈이라고 한다 여러 개의 모듈을 그룹화 하면 패키지가 된다 패키지는 종종 라이브러비라고도 불린다 123from IPython.display import Image# 출척: pythonstudy.xyzImage('http://pythonstudy.xyz/images/basics/python-package.png') 2. 모듈 import 하기 import 하는 방법 .py (파이썬 파일 확장자)로 된 파일을 우리는 모듈 이라고 한다, import 구문을 통해 해당 파일을 불러올 수 있다 1import pandas 위의 코드는 pandas라는 모듈을 우리가 불러오겠다라는 의미이다 3. 패키지 에서 import하기 패키지 안에서 하나의 모듈을 불러온다 1from pandas import DataFrame # pandas라는 패키지 안에서 DataFrame이라는 모듈을 불러온다 1DataFrame() # 모듈 DataFrame사용 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 통째로 패키지나 모듈을 불러온다 1import pandas 1pandas.DataFrame() # DataFrame이라는 모듈을 사용하기 위해서는 .을 찍고 이어서 쓰면 됨 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 4. 별칭 (alias) 지어주기 pandas라는 패키지 이름이 너무 길기 때문에 우리는 약어로 줄여쓸 수 있다. 보통 pd를 보편적으로 많이 사용한다. 줄여서 별명을 지어줄 때는 as를 붙혀준다 1import pandas as pd 1pd.DataFrame() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 5. 앞으로 자주 사용할 패키지, 모듈 미리보기 1234import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns numpy: 과학계산을 위한 패키지 pandas: 데이터 분석을 할 때 가장 많이 쓰이는 패키지 matplotlib: 시각확를 위한 패키지 seaborn: 시각화를 위한 패키지 (matplotlib을 더 쉽게 사용할 수 있도록 도와주는 패키지) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (5) List Comprehension. 문자열","slug":"S-Python-base5","date":"2020-05-13T16:37:58.000Z","updated":"2020-06-11T17:10:41.561Z","comments":true,"path":"2020/05/14/S-Python-base5/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/14/S-Python-base5/","excerpt":"List Comprehension (List에 조건필터를 적용). 문자열을 가지고 노는 방법.","text":"List Comprehension (List에 조건필터를 적용). 문자열을 가지고 노는 방법. 목록 1. List Comprehension (파이썬 고유의 아름다운 문법) 1-1. list comprehension 조건필터 1-2. [STEP 1] list를 만들어야 하니 일단 꺾쇠[ ]를 씌운다 1-3. [STEP 2] 조건 필터를 걸어 준다 1-4. [응용 STEP] 변수 값을 가공할 수도 있다 2. 문자열(string)을 가지고 놀기 2-1. 문자의 길이 2-2. 문장 쪼개기 – “.split” 2-3. 대문자 / 소문자로 만들기 – “.upper” / “.lower” 2.4. ~로 시작하는, ~로 끝나는 – “.startswith” , “.endswith” 2-5. 바꾸기 – “.replace(‘바꿀 대상, 바꿔야할 값’)” 2-6. 불필요한 공백 제거하기 – “.strip” 1. List Comprehension (파이썬 고유의 아름다운 문법) for ~ in 구조를 기본적으로 가지고 있다 List Comprehension 이니까 당연히 List를 사용한다 [실제 사례 연구] mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 이라는 list를 만들어 주고 우리는 이 중 짝수만 출력하고 싶으면 아래와 같이 쓸 수 있다: 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 123for i in mylist: if i % 2 == 0: print(i) 2 4 6 8 10 그럼 mylist에서 짝수만 뽑아서 list로 만들어 주고 싶다면: 12345678mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]even = []for i in mylist: if i % 2 == 0: even.append(i)print(even) [2, 4, 6, 8, 10] 이렇게 for in 문으로 해줄 수 있다. 하지만, 우리는 list comprehension을 통해 더욱 쉽게 해결 할 수 있다!! 1-1. list comprehension 조건필터 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 아래 문법이 바로 list comprehension 이다. 한 줄로 해결해 버리는 것이 매력임! 1even = [i for i in mylist if i % 2 == 0] 1even [2, 4, 6, 8, 10] 1-2. [STEP 1] list를 만들어야 하니 일단 꺾쇠[ ]를 씌운다 꺾쇠 안에 반복문이 들어간다 반복문을 돌면서 return 된 i값을 list에 넣는 원리이기 때문에 for구분 앞에 i를 써준다 1even = [i for i in mylist] 1even [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1-3. [STEP 2] 조건 필터를 걸어 준다 [i for i in mylist (이곳에 조건문)] 1[i for i in mylist if i % 2 == 0] [2, 4, 6, 8, 10] 이것을 변수에 다시 할당해주면 끝! 1even = [i for i in mylist if i % 2 == 0] 1even [2, 4, 6, 8, 10] 1-4. [응용 STEP] 변수 값을 가공할 수도 있다 예를 들어: mylist의 모든 값에 +2를 하고 다시 even이라는 list에 저장하고 싶다면 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1even = [i+2 for i in mylist] 1even [3, 4, 5, 6, 7, 8, 9, 10, 11, 12] 2. 문자열(string)을 가지고 놀기 2-1. 문자의 길이 1a = 'banana' 1len(a) 6 1a = 'banana pen' 1len(a) # 공백도 count된다 10 1b = '한글' 1len(b) 2 1b = '한글 바나나' 1len(b) 6 2-2. 문장 쪼개기 – “.split” split은 문장을 특정 규칙에 의해 쪼개 주는 기능을 한다 명령어: 변수명.split(‘쪼개는 기준’) 쪼개는 기준이 설정되어 있지 않으면 그냥 '빈칸’으로 인식된다 1a = 'This is a pen' 1a.split(' ') ['This', 'is', 'a', 'pen'] 1a.split() ['This', 'is', 'a', 'pen'] 1b = 'This-is-a-pen' 1b.split('-') ['This', 'is', 'a', 'pen'] return된 값을 list형식으로 저장한다 1aa = a.split(' ') 1aa ['This', 'is', 'a', 'pen'] 1aa[0] 'This' 1aa[2] 'a' 1aa[0] + aa[2] 'Thisa' 1c = '한글은 어떻게 될까요?' 1c.split() ['한글은', '어떻게', '될까요?'] 2-3. 대문자 / 소문자로 만들기 – “.upper” / “.lower” 1a = 'My name is hyemin' 1a.upper() 'MY NAME IS HYEMIN' 1a.lower() 'my name is hyemin' 1b = '한글엔 대소문자가 없어요ㅠ' 1b.upper() '한글엔 대소문자가 없어요ㅠ' 1b.lower() '한글엔 대소문자가 없어요ㅠ' 2.4. ~로 시작하는, ~로 끝나는 – “.startswith” , “.endswith” 123a = '01-sample.png'b = '02-sample.jpg'c = '03-sample.pdf' 1a.startswith('01') True 1a.endswith('.jpg') False 1b.endswith('.jpg') True 조건(혹은 형식)에 맞는 파일을 추출하고 싶을 때: 1mylist = [a, b] 123for file in mylist: if file.endswith('jpg'): print(file) 02-sample.jpg 2-5. 바꾸기 – “.replace(‘바꿀 대상, 바꿔야할 값’)” [예] file형식을 바꾸고 싶다면: 1a = '01-sample.png' 1a.replace('.png', '.jpg') '01-sample.jpg' 이 때 a의 값이 변하지 않아. 다시 할당 해야 함 1a '01-sample.png' 1a_new = a.replace('.png', '.jpg') # 새로 지정 1a_new '01-sample.jpg' 1a = a.replace('.png', '.jpg') # 덮어쒸우기 1a '01-sample.jpg' 2-6. 불필요한 공백 제거하기 – “.strip” [예] 12a = ' 01-sample.png'b = '01-sample.png' 1a == b False strip은 양 끝 불필요한 공백을 제거해 줌. 1a.strip() '01-sample.png' 1a.strip() == b True document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (4) 비교/논리 연산자. 조건문. 반복문","slug":"S-Python-base4","date":"2020-05-13T08:25:46.000Z","updated":"2020-06-11T17:10:35.405Z","comments":true,"path":"2020/05/13/S-Python-base4/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/13/S-Python-base4/","excerpt":"비교연산자. 조건문. 논리연산자. 반복문","text":"비교연산자. 조건문. 논리연산자. 반복문 목록 1. 비교연산자 1-1. 대소비교 &gt;, &gt;=, &lt;, &lt;= 1-2. 같다 == 1-3. 같지 않다 != 2. 조건문 2-1. 개념 2-2. if 2-3. else 2-4. elif 2-5. 1이나 0은 참이나 거짓을 표현하기도 한다 3. 논리 연산자 (and, or) 3-1. and 3-2. or 4. 반복문 4-1. 반복문이란? 4-2. for 와 in을 활용하자! 4-3. 반복문에서 짝수만 출력하려면? (continue구문) 4-4. 조건을 충족시 순환에서 빠져나와보자! (break구문) 1. 비교연산자 비교 연산자는 주로 대소비교를 할 때 사용한다. 1-1. 대소비교 &gt;, &gt;=, &lt;, &lt;= 11 &gt; 2 False 110 &gt;= 10 True 19 &lt; 10 True 18 &lt;= 7 False 1-2. 같다 == 주의: = 는 대입연산자. == 는 비교연산자 중의 “같다” 숫자형 &amp; 문자형 모두 비교 가능 12 = 2 File \"&lt;ipython-input-6-a8e553549e25&gt;\", line 1 2 = 2 ^ SyntaxError: can't assign to literal 12 == 2 True 12 == 3 False 1\"나\" == \"나\" True 1-3. 같지 않다 != 숫자형 &amp; 문자형 모두 비교 가능 12 != 2 False 12 != 3 True 1\"나\" != \"너\" True 2. 조건문 2-1. 개념 주어진 조건이 참인 경우 그 다음 내가 규칙(로직)을 실행하는 개념이다 2-2. if if는 어떤 조건이 성립한다면 ~이라는 의미 if구문 끝에는 반드시 콜론( : )이 있어야 함 12if 5 &gt; 3: print('참') 참 if구문 뒤에 indent가 있는 명령어는 if조건이 성립하면 실행 indent가 없으면 if의 성립여부와 무관하여 무조건 실행 12345if 5 &gt; 3: print('참') print('참') print('끝') 참 참 끝 12345if 5 &lt; 3: print('참') print('참') print('끝') # 앞에 indent가 없으면 if의 성립여부와 무관하여 실행 끝 2-3. else else는 if 조견 후에 따라오면, if가 아닌 경우에 실행 됨 1234if 5 &lt; 3: print(\"성립한다\")else: print(\"성립하지 않은다\") 성립하지 않은다 else는 꼭 if랑 같이 써야함. 단독으로 실행할 수 없음 12else: print(\"성립하지 않은다\") File \"&lt;ipython-input-22-6c0f4debaa4b&gt;\", line 1 else: ^ SyntaxError: invalid syntax 2-4. elif elif구문은 3가지 이상 문기(조건)의 동작을 수행할 때 사용 123456if 3 &gt; 5: print('if 구문')elif 3 &lt; 4: print('elif 구문')else: print('이것도 저것도 아니다') elif 구문 그럼, elif구문이 참인 여러 구문을 나열 했을 때는 어떻게 될까? 12345678910if 3 &gt; 5: print('if 구문')elif 3 &lt; 4: print('elif 1 구문')elif 3 &lt; 5: print('elif 2 구문')elif 3 &lt; 6: print('elif 3 구문')else: print('이것도 저것도 아니다') elif 1 구문 elif구문이 참인 여러 구문을 나열 했을 때는 첫번째 참인 elif구문만 실행됨 2-5. 1이나 0은 참이나 거짓을 표현하기도 한다 1234if 1: print('참')else: print('거짓') 참 1234if 0: print('참')else: print('거짓') 거짓 3. 논리 연산자 (and, or) and나 or조건은 두 가지 이상 조건을 다룰 때 활용한다 3-1. and and 조건은 모두 만족할 때 참으로 인식한다 1True and True and True True 1True and False and True False 1234if (0 &lt; 1) and (0 &lt; 2): print('모두 참')else: print('거짓') 모두 참 1234if (0 &lt; 1) and (0 &gt; 2): print('모두 참')else: print('거짓') 거짓 3-2. or or조건은 조건 중 하나라도 만족할 때 참으로 인식한다 1True or False or False True 1False or False or False False 1234if (0 &lt; 1) or (0 &gt; 2): print('하나라도 참')else: print('모두 거짓') 하나라도 참 1234if (0 &gt; 1) or (0 &gt; 2): print('하나라도 참')else: print('모두 거짓') 모두 거짓 4. 반복문 4-1. 반복문이란? 일을 반복 처리 해준다는 것 대상은 반드시 list, dict, set등 집합이어야 한다 [예] 반복문 쓰지 않을 때: 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] mylist에 들어 닜는 모든 값들을 출력하려고 한다면? 123456print(mylist[0])print(mylist[1])print(mylist[2])print('...')print(mylist[8])print(mylist[9]) 1 2 3 ... 9 10 반복문은 노가다를 획기적으로 줄여주는 방법이다! 4-2. for 와 in을 활용하자! [기본 문법] for 지정한 변수명 in [꺼내올 집합]: 명령어 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 12for i in mylist: print(i) 1 2 3 4 5 6 7 8 9 10 4-3. 반복문에서 짝수만 출력하려면? (continue구문) 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 방법1: 123for i in mylist: if i % 2 == 0: print(i) 2 4 6 8 10 방법2: continue구문을 사용하면 조건이 충족할 때 아래 명령어를 SKIP하고 다시 다음 순환으로 넘어간다 1234for i in mylist: if i % 2 == 1: continue print(i) 2 4 6 8 10 4-4. 조건을 충족시 순환에서 빠져나와보자! (break구문) 1mylist = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] i가 6 이상이면 STOP 1234for i in mylist: if i &gt;= 6: # i &gt; 6 이면 6까지 출력한다 break print(i) 1 2 3 4 5 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (3) 함수","slug":"S-Python-base3","date":"2020-05-13T07:16:31.000Z","updated":"2020-06-11T17:10:29.795Z","comments":true,"path":"2020/05/13/S-Python-base3/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/13/S-Python-base3/","excerpt":"함수의 기초","text":"함수의 기초 목록 1. 함수란 무엇일까? 2. 함수 정의: def (define) 3. 함수는 값을 return할 수 있고, 안해도 됨 4. parameter가 여러 개 있으면, 함수에 넘겨 줄 때 순서가 중요 함수 1. 함수란 무엇일까? 반복적으로 사용되는 부문을 묶어서, 재사용 가능하도록 만들어 주는 것 함수에는 **들어가는 놈 (input)**이 있고, **나오는 놈 (output 혹은 return)**이 있다. 전해진 로직(규칙)에 따라, input -&gt; output으로 효율적으로 바꿔주는 역할을 한다 [예시] 함수 없이 계산할 때 123a = 1b = 2c = 3 1(a + b) * c 9 123a = 2b = 2c = 3 1(a + b) * c 12 함수로 변경 후 12def func(a, b, c): return (a + b) * c 1func(1, 2, 3) 9 1func(2, 2, 3) 12 2. 함수 정의: def (define) 사용법: def 함수이름 (parameter1, parameter2, parameter3…): parameter는 함수로 부터 넘겨 받은 변수 또는 값이다 끝에 콜론 ( : ) 빼먹지 않음에 주의 해야함! 12def myfunc(var1): print(var1) # 실행 명령 1myfunc(\"안녕하세요\") 안녕하세요 3. 함수는 값을 return할 수 있고, 안해도 됨 리턴이 없는 경우 12def my_func(a, b): print(a, b) 1my_func(1,10) 1 10 리턴이 있는 경우 123def my_func(a, b): s = a + b return s 1my_func(2, 3) 5 리턴이 있는 경우는 변수에 값을 다시 할당 할 수 있음 1result = my_func(2,3) 1print(result) 5 1print(result + 10) 15 4. parameter가 여러 개 있으면, 함수에 넘겨 줄 때 순서가 중요 12def my_func(a, b, c): return (a + b) * c 123a = 10b = 20c = 3 1(a + b) * c 90 1my_func(a, b, c) 90 1my_func(c, b, a) # (c + b) * a = (3 + 20) * 10 230 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (2) 집합 형태의 데이터 타입","slug":"S-Python-base2","date":"2020-05-12T17:26:49.000Z","updated":"2020-06-11T17:10:22.797Z","comments":true,"path":"2020/05/13/S-Python-base2/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/13/S-Python-base2/","excerpt":"","text":"집합 형태의 데이터 타입 1. list (순서가 있는 집합) 1-1. [ ] 형테로 표현 1-2. 값 추가 – “.append( )” 1-3. 값 제거 – “.remove” / “.clear” 1-4. 인덱싱(Indexing) -&gt; 색인 1-5. 인덱스로 접근하여 값 바꾸기 1-6. 길이 파악하기 2. tuple (순서가 있는 집합, 읽기 전용) 2-1. ( ) 형태로 표현 2-2. 읽기 전용이라 “값 추가”, “값 제거”, “값 바꾸기” 모두 안됨 2-3. 길이 파악하기 3. set (순서 X, 중복 X) 3-1. set의 할당: set() 3-2. 값 추가 – \".add \" 3-3. 값 제거 – “.remove” / “.clear” 4. dict (사전형 집합, key와 value 쌍) 4-1. { } 형태로 표헌 4-2. 값 추가 (key와 value 모두 지정) 4-3. 값 바꾸기 4-4. 값 제거 – “.pop” / “.clear” 4-5. 길이 파악하기 짐합 형태의 데이터 타입 list (순서 O, 짐합) tuple (순서 X, 읽기 전용 집합) set (순서 X, 중복 X 집합) dict (key, value로 이루어진 사전형 집합) 1. list (순서가 있는 집합) 1-1. [ ] 형테로 표현 1mylist = [] 1mylist [] 1type(mylist) list 12mylist = [1,2,3,4,5]mylist [1, 2, 3, 4, 5] 12mylist2 = [5,4,3,2,1] # 순서가 있다mylist2 [5, 4, 3, 2, 1] 1-2. 값 추가 – “.append( )” 12mylist = []mylist [] 12mylist.append(1)mylist [1] 123mylist.append(2)mylist.append(3)mylist [1, 2, 3] .append 함수 안에 1 argument만 들어갈 수 있다 12mylist.append(4,5)mylist --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-22-6f00703728b8&gt; in &lt;module&gt; ----&gt; 1 mylist.append(4,5) 2 mylist TypeError: append() takes exactly one argument (2 given) 1-3. 값 제거 – “.remove” / “.clear” 부분 제거 – \".remove\" 1mylist [1, 2, 3] 12mylist.remove(1)mylist [2, 3] 전부 제거 – \".clear\" 1mylist.clear() 1mylist [] 같은 값이 여러 개 포함되어 있을 때의 제거 순서 앞에서 부터 순차적으로 제거 됨 12mylist = [1,2,3,1,2,3]mylist [1, 2, 3, 1, 2, 3] 12mylist.remove(1)mylist [2, 3, 1, 2, 3] 12mylist.remove(1)mylist [2, 3, 2, 3] 1-4. 인덱싱(Indexing) -&gt; 색인 인덱스는 0번 부터 시작한다 1mylist = [1,2,3,4] # 인덱스: 0번, 1번, 2번, 3번 1mylist[0] 1 1mylist[3] 4 1mylist[4] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-34-88b11041aa4f&gt; in &lt;module&gt; ----&gt; 1 mylist[4] IndexError: list index out of range 인덱스가 음수일 경우: 뒤에서 부터 n번째 1mylist[-1] 4 1-5. 인덱스로 접근하여 값 바꾸기 1mylist [1, 2, 3, 4] 1mylist[0] 1 1mylist[0] = 100 1mylist [100, 2, 3, 4] 1-6. 길이 파악하기 1mylist [100, 2, 3, 4] 1len(mylist) # length 4 2. tuple (순서가 있는 집합, 읽기 전용) 2-1. ( ) 형태로 표현 1mytuple = (1,2,3,4,5) 2-2. 읽기 전용이라 “값 추가”, “값 제거”, “값 바꾸기” 모두 안됨 1mytuple.append(1) # 읽기 전용이라 값을 추가할 수 없음 --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-45-d0f55ea1e3f6&gt; in &lt;module&gt; ----&gt; 1 mytuple.append(1) # 읽기 전용이라 값을 추가할 수 없음 AttributeError: 'tuple' object has no attribute 'append' 1mytuple.remove(1) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-46-05a40423345b&gt; in &lt;module&gt; ----&gt; 1 mytuple.remove(1) AttributeError: 'tuple' object has no attribute 'remove' 1mytuple[0] = 100 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-48-4e527888818c&gt; in &lt;module&gt; ----&gt; 1 mytuple[0] = 100 TypeError: 'tuple' object does not support item assignment 2-3. 길이 파악하기 1mytuple (1, 2, 3, 4, 5) 1len(mytuple) 5 3. set (순서 X, 중복 X) 3-1. set의 할당: set() 12myset = set()myset set() 1type(myset) set 3-2. 값 추가 – \".add \" 1234myset.add(1)myset.add(2)myset.add(3)myset {1, 2, 3} 1234567myset.add(1) myset.add(2)myset.add(3)myset.add(1) # 중복된 값을 한번만 기록myset.add(2)myset.add(3)myset {1, 2, 3} 12myset.add(4)myset {1, 2, 3, 4} 3-3. 값 제거 – “.remove” / “.clear” 부분 제거 – \".remove\" 1myset {1, 2, 3, 4} 1myset.remove(3) 1myset {1, 2, 4} 전부 제거 – \".clear\" 1mylist.clear() 1mylist [] 4. dict (사전형 집합, key와 value 쌍) 4-1. { } 형태로 표헌 1mydict = dict() 1mydict {} 1type(mydict) dict 4-2. 값 추가 (key와 value 모두 지정) mydict [ \" key \" ] = value key는 문자형 (str) / 숫자형 (int &amp; float) 모두 가능 1mydict[\"apple\"] = 123 1mydict {'apple': 123} 1mydict[\"apple\"] 123 1mydict[0] = 2 1mydict {'apple': 123, 0: 2} 1mydict[0] 2 1mydict[3.14] = 1 1mydict {'apple': 123, 0: 2, 3.14: 1} 1mydict[3.14] 1 4-3. 값 바꾸기 새 값을 해당 key에 할당하기 1mydict[\"apple\"] = \"hello\" 1mydict {'apple': 'hello', 0: 2, 3.14: 1} 4-4. 값 제거 – “.pop” / “.clear” 부분 제거 – \".pop\" 1mydict.pop('apple') 'hello' 1mydict {0: 2, 3.14: 1} 1mydict.pop(0) 2 1mydict {3.14: 1} 전부 제거 – \".clear\" 1mydict.clear() 1mydict {} 4-5. 길이 파악하기 123mydict[\"apple\"] = 123mydict[0] = 2mydict[3.14] = 1 1mydict {'apple': 'hello', 0: 2, 3.14: 1} 1len(mydict) 3 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"Python 기초문법 - (1) 출력. 데이터 타입. 데이터의 응용","slug":"S-Python-base1","date":"2020-05-11T17:18:11.000Z","updated":"2020-06-25T09:03:20.087Z","comments":true,"path":"2020/05/12/S-Python-base1/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/12/S-Python-base1/","excerpt":"출력. 변수. 데이터 타입. 데이터의 응용. 데이터 타입의 변환.","text":"출력. 변수. 데이터 타입. 데이터의 응용. 데이터 타입의 변환. 목록 1. 출력 (print) print( ) 함수 2. 변수와 대입 2-1. 변수의 이름 【가능한 경우】 【불가한 경우】 2-2. 변수의 대입 2-3. 변수의 출력 3. 데이터 타입 3-1. int(정수) 3-2. float(실수) 3-3. str 혹은 object (문자열) 3-4. bool (참/거짓) 3-5. 아무것도 아닌 None타입도 있다 4. 데이터의 응용 4-1. 사칙 연산자 4-2. 문자열의 연결 5. 데이터 타입 변환 5-1. 문자열로 변환: “str( ) 함수” or “따움표” 5-2. 정수로 변환: \" int( ) 함수\" 5-3. 실수로 변환: “float( ) 함수” 1. 출력 (print) print( ) 함수 숫자를 출력할 때 따움표(’ ’ or \" \") 필요없음 문자를 출력할 때 따움표 필요 ’ ’ 와 \" \" 차이없음 ‘’’ ‘’’ 를 사용하면 출력시 “줄 바꿈” 형식이 보류될 수 있음 1print(1) 1 1print(1+2) 3 1print('안녕하세요') 안녕하세요 1print(\"반갑습니다\") 반갑습니다 1234print('''안녕하세요,반갑습니다.''') 안녕하세요, 반갑습니다. 2. 변수와 대입 2-1. 변수의 이름 【가능한 경우】 case 1. 알파벳 1a = 1 1A = 1 case 2. 알파벳 + 숫자 1a1 = 1 case 3. 알파벳 + 언더바(_) 1a_ = 1 case 4. 언더바(_) + 알파벳 1_a = 1 【불가한 경우】 case 1. 언더바(_)를 제외한 특수문자 1* = 1 File \"&lt;ipython-input-23-6d0163a9fd4c&gt;\", line 1 * = 1 ^ SyntaxError: invalid syntax case 2. 알파벳 + 언더바를 제외한 특수문자 1a$ = 1 File \"&lt;ipython-input-25-2501fc576aab&gt;\", line 1 a$ = 1 ^ SyntaxError: invalid syntax case 3. 변수의 이름 사이의 공백 1a b = 1 File \"&lt;ipython-input-26-2bab97d7970c&gt;\", line 1 a b = 1 ^ SyntaxError: invalid syntax 2-2. 변수의 대입 변수 값을 부여할 때 \"=\"를 사용한다 1a = 1 2-3. 변수의 출력 print() 구문 사이에 값을 직접 입력하면, 바로 값이 출력됨. 1print(123) # 숫자는 \"\" 필요없음 123 1print(\"text\") # 문자는 \"\" 필요함 text print()구분 사이에 변수 이름을 입력하면, 변수의 값이 출력됨. 12a = 123print(a) 123 12b = \"text\"print(b) text 3. 데이터 타입 데이터 type: 1. int(정수) 2. float(실수) 3. str(문자열) 4. bool(참/거짓) 3-1. int(정수) 1a = 1 1type(a) int 1print(a) 1 코딩에서 1은 참으로 취급, 0은 거짓으로 취급 다음 코딩으로 진단해보자: 1234if 1: print('1은 참으로 취급')else: print('1은 거짓부렁이') 1은 참으로 취급 1234if 0: print('0은 참으로 취급')else: print('0은 거짓부렁이') 0은 거짓부렁이 1234if 123: print('123은 참으로 취급')else: print('123은 거짓부렁이') 123은 참으로 취급 [0 이외의 정수 다 참으로 취급] 3-2. float(실수) 1a = 3.14 1type(a) float 1print(a) 3.14 3-3. str 혹은 object (문자열) 문자열은 반드시 ’ ’ 혹은 \" \" 로 묶어야 함 1word = '안녕하세요' 1type(word) str 1print(word) 안녕하세요 1word = \"안녕하세요\" 1type(word) str 1print(word) 안녕하세요 ’\" \"’ 를 사용하면 출력시 “줄 바꿈” 형식이 보류될 수 있음 1234print('''안녕하세요,반갑습니다.''') 안녕하세요, 반갑습니다. 3-4. bool (참/거짓) 참: True 거짓: False 1a = True 1a True 1type(a) bool 1b = False 1b False 1type(b) bool 11 == True True 10 == False True 1123 == True False 1 이외의 정수는 조건절에서 참으로 인식되지만, bool과 비교할 때 참이 아니다 3-5. 아무것도 아닌 None타입도 있다 Null값을 넣는다고도 한다. Null: Nullify (무효화하다) – 사전상 의미 Python에서는 None 입니다 1a = None 1print(a) None 1type(a) NoneType 조건문에 None이라면? 1234if None: print(\"None은 참으로 취급\")else: print(\"None은 거짓부렁이\") None은 거짓부렁이 4. 데이터의 응용 4-1. 사칙 연산자 연산자 의미 예 + 더하기 2 + 1 -&gt; 3 - 빼기 1 - 2 -&gt; -1 * 곱하기 1 * 2 -&gt; 2 / 나누기 1 / 2 -&gt; 0.5 // 몫 5 // 2 -&gt; 2 % 나머지 5 % 2 -&gt; 1 ** 멱 2**3 -&gt; 8 4-2. 문자열의 연결 여러 개 문자열을 \"+\"을 통해 연결할 수 있다 12345subject = \"나는 \"object = \"치킨을 \"verb = \"좋아한다\"print(subject + object + verb) 나는 치킨을 좋아한다 하지만 문자열(str)과 숫자(int &amp; float)는 직접 연결할 수 없다 1234567a = \"내가 \"b = \"친구랑 \"c = 12d = \"시에 \"e = \"보기로 했다\"print(a + b + c + d + e) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-82-34cd0f9ce519&gt; in &lt;module&gt; 5 e = \"보기로 했다\" 6 ----&gt; 7 print(a + b + c + d + e) TypeError: can only concatenate str (not \"int\") to str 이 때는 데이터 타입을 변환할 필요가 있다 5. 데이터 타입 변환 5-1. 문자열로 변환: “str( ) 함수” or “따움표” 1type(6) int 1type(str(6)) str 1type('6') str 1type(3.14) float 1type(str(3.14)) str 1type(\"3.14\") str 12345a = \"내가 \"b = \"친구랑 \"c = 12d = \"시에 \"e = \"보기로 했다\" 1print(a + b + str(c) + d + e) 내가 친구랑 12시에 보기로 했다 1print(a + b + '12' + d + e)a 내가 친구랑 12시에 보기로 했다 5-2. 정수로 변환: \" int( ) 함수\" \"str\" --&gt; “int”: str( ) 안 내용이 정수일 때만 가능 1type(int(\"2\")) int 12number1 = \"2\"number2 = \"3\" 1print(int(number1) + int(number2)) 5 1print(int(\"2.6\")) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-103-f4645c45f771&gt; in &lt;module&gt; ----&gt; 1 print(int(\"2.6\")) ValueError: invalid literal for int() with base 10: '2.6' \"float\" --&gt; “int”: 소수점 버림 1type(int(3.6)) int 1print(int(3.6)) 3 5-3. 실수로 변환: “float( ) 함수” \"str\" --&gt; “float”: str( ) 안 내용이 정수일 때만 가능 1type(float(\"3.14\")) float 1print(float(\"3.14\")) 3.14 \"int\" --&gt; “float”: 소수점 하나 추가 1type(float(178)) float 1print(float(178)) 178.0 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"}]},{"title":"利用Git Pages+Hexo搭建博客过程中的参考资料","slug":"Reference","date":"2020-05-07T17:16:53.000Z","updated":"2020-06-24T04:14:29.783Z","comments":true,"path":"2020/05/08/Reference/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/08/Reference/","excerpt":"","text":"博客搭建 bilibili — 超简单易懂的Git入门教程 bilibili — github+hexo搭建个人博客 bilibili — github博客搭建（二）：Markdown语法及hexo主题修改 Git Pages + Jekyll/Hexo搭建自己的博客(最全总结你想知道的都在这里了) 网页配置 &amp; 主题配置 Hexo Usage Documents Hexo Themes default — [Demo] tomotoes — [Demo] / [Documents] Butterfly — [Demo] / [Documents] (应用中) Git Pages + Jekyll/Hexo搭建自己的博客(最全总结你想知道的都在这里了) Hexo主题升级方法（实用！） Markdown渲染 bilibili — github博客搭建（二）：Markdown语法及hexo主题修改 [字体修改方法(17:30)] Markdown在Hexo中的使用实例 [分割线，空行插入方法] Markdown渲染插件 hexo-renderer-markdown-it 插件 快速配置 hexo-renderer-markdown-it [Documents] hexo-renderer-markdown-it-plus （应用中） hexo-renderer-markdown 插入本地图片 markdown插入本地图片小技巧 typora + hexo博客中插入图片（应用中） 其他 记录网站访问量: 不蒜子 hexo博客解决不蒜子统计无法显示问题 设置博客评论： Gitalk申请页面 在个人博客里添加评论系统–Gitalk hexo 使用 gitalk 评论组件的几个注意点 多语言版本: Hexo 巧用 abbrlink 插件实现文章多语言版本 (既然没人帮我，那就)自己弄了个 Hexo 多语言 index 生成插件 更改tag大小写后出现404页面 Hexo 部署到 Github Pages 文件夹大小写问题 更改博客 Front Page 的默认配置 hexo博客Front-matter模板配置 Git &amp; Github bilibili — 【教程】学会Git玩转Github【全】 bilibili — 超简单易懂的Git入门教程 Git与Github的连接与使用 Git和GitHub使用教程 Jupyter Notebook bilibili — python数据分析神器Jupyter notebook快速入门 bilibili —【冷门教学】记笔记神器-jupyter notebook 第二弹 史上最详细、最完全的jupyter notebook使用教程，Python使用者必备！——ipython系列之三 机器学习新手必看：Jupyter Notebook入门指南 Jupyter notebook简介及嵌入Hexo博客中 用 Hexo 搭建个人博客-02：进阶试验（包括添加Jupyter Notebook支持的方法） 如何在你的Jupyter Notebook中使用R语言？ Markdown &amp; Typora bilibili — 二十分钟精通排版神器Markdown Typora官网 [Documents] Typora中下载并安装主题 bilibili — Typora 编辑器 —— 书写即为美学 bilibili — 【软件教程】如何用Typora记笔记？ | 附带Markdown基础教程 Typora设置（中文字体、颜色、行距、内边距等） Markdown中插入本地图片 markdown插入本地图片小技巧 typora + hexo博客中插入图片 HTML 表格样式 好看的table css样式 CSS 列表样式 HTML基础知识 table中 th, td, tr CSS如何设置html table表格边框样式 CSS如何设置表格中的字体大小 CSS padding 属性 [html/css] margin 속성 자세히 알아보기 漂亮的CSS表格样式 在此感谢所有提供了宝贵学习资料的原po主们~ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://hyemin-kim.github.io/tags/Hexo/"},{"name":"Typora","slug":"Typora","permalink":"https://hyemin-kim.github.io/tags/Typora/"},{"name":"Git","slug":"Git","permalink":"https://hyemin-kim.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://hyemin-kim.github.io/tags/Github/"},{"name":"Jupyter notebook","slug":"Jupyter-notebook","permalink":"https://hyemin-kim.github.io/tags/Jupyter-notebook/"}]},{"title":"在Hexo博文中添加本地图片的方法（基于Typora编辑器）","slug":"Hexo-Insert-local-images","date":"2020-05-06T12:20:48.531Z","updated":"2020-05-22T07:31:34.789Z","comments":true,"path":"2020/05/06/Hexo-Insert-local-images/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/06/Hexo-Insert-local-images/","excerpt":"当我们想在markdown文档中添加网络图片时，可以使用命令!['图片名称'](图片网络地址)进行实现，然而这条命令却不适用于添加本地图片。本文将介绍在使用Typora编辑器编辑Hexo博文时，向markdown文档中添加本地图片的方法。快来看看吧","text":"当我们想在markdown文档中添加网络图片时，可以使用命令!['图片名称'](图片网络地址)进行实现，然而这条命令却不适用于添加本地图片。本文将介绍在使用Typora编辑器编辑Hexo博文时，向markdown文档中添加本地图片的方法。快来看看吧 【编写博客前】— 进行配置 【编写博客时】— 图片导入方法 【编写博客后】— 图片存档结果 【编写博客前】— 进行配置 建立 资源文件夹(Asset Floder)，用来保存添加到博文中的本地图片 在本地Hexo根目录下的source文件夹中创建一个名为 images 的文件夹 在Typora中设置图片的相对路径 打开Typora的文件 &gt; 偏好设置 &gt; 图像，进行如下设置： 此设置会使source/images文件夹下新增一个与所编辑的markdown文档同名的文件夹，文档中所添加的 本地图片 都将存档于此（即拥有了如下路径：'hexo根目录'/source/images/'md文档名'/'图片名称'）)。 撰写markdown文档时配置 图片根目录 ，使其能够同步到hexo博客中去 撰写博文时，先点击Typora菜单栏中的格式 &gt; 图像 &gt; 设置图片根目录 , 将根目录配置为'hexo根目录'/source。然后再撰写博文。【注：每篇需要添加本地图片的博文都要先进行此步骤】 【编写博客时】— 图片导入方法 直接拖拽 将原本存放于其他本地文件夹中的图片直接拖拽到文档中的相应位置中去 此时图片会被自动存档至生成的同名文件夹'hexo根目录'/source/images/'md文档名'中 文档中图片地址的代码会显示成 自动生成的相对路径，即/images/'md文档名'/'图片名称' 利用相对路径调取 当利用 方法1 插入了至少一张图片时（即已生成同名文件夹时），便可以把接下来要插入的图片复制到此同名文件夹中，在文档中利用相对路径 调取图片： 所使用的命令是：![图片显示名称](/images/'md文档名'/'图片名称') 这里的图片显示名称不必与文件夹中保存的图片名称保持一致，'图片名称'中要记得包含图片格式（例如：tupian.jpg 或 picture.png 等） 【注意】当还没有利用 方法1 插入过图片时（即同名文件夹尚未生成时），不可以自己创建同名文件夹保存图片。亲测不好使！！（.md文档中可以显示，但是hexo博文中无法显示） 【编写博客后】— 图片存档结果 在利用上述方法完成了含有本地图片的markdown博文后，我们的资源文件夹'hexo根目录'/source/images/内最终会显示成什么样子呢？ 每一篇配置了图片根目录的博文（即【编写博客前】的第3步），都会在'hexo根目录'/source/images/文件夹中有一个与文档名称同名的文件夹'hexo根目录'/source/images/'md文档名' 该文件夹中会保存博文编写中曾经添加的所有本地图片 所有的含义是：即使编辑过程中某些本地图片在添加后又被删除了，它们也仍然会保留在文件夹中，即该文件夹会备份你在博文中添加的 所有本地图片历史 本地图片的含义是：这里只会保存插入的本地图片，而不会保存插入的网络图片。尽管在【编写博客前】的第2步配置中，我们也同样勾选了对网络位置的图片应用上述规则。（请原谅我并不知道其中的缘由。。） 就此，在Typora编辑器中编写Hexo博文时，向markdown文档中添加本地图片的方法就介绍完毕啦！快去应用到你的博文中去吧~ 本文参考了yinyoupoet的typora + hexo博客中插入图片 更多关于Typora中插入图片的内容可以参考Typora的官方说明 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://hyemin-kim.github.io/tags/Hexo/"},{"name":"Typora","slug":"Typora","permalink":"https://hyemin-kim.github.io/tags/Typora/"}]},{"title":"Markdown 常用语法（持续更新）","slug":"Markdown-Syntax","date":"2020-05-03T16:40:07.372Z","updated":"2020-05-22T16:16:06.234Z","comments":true,"path":"2020/05/04/Markdown-Syntax/","link":"","permalink":"https://hyemin-kim.github.io/2020/05/04/Markdown-Syntax/","excerpt":"","text":"Markdown 常用语法 标题 一级标题： “#” + 空格 + “一级标题” 二级标题： “##” + 空格 + “二级标题” 三级标题： “###” + 空格 + “三级标题” …… 以此类推 【最多到6级】 换行 “内容” 末尾 + 2个空格 + Enter 斜体 方法一：“内容”前后加1个 * 号（无空格） 方法二：“内容”前后加1个下划线（无空格） *“内容” * ——&gt; “内容” _ “内容” _ ——&gt; 内容 加粗 方法一：“内容”前后加2个 * 号（无空格） 方法二：“内容”前后加2个下划线（无空格） ** “内容” ** ——&gt; \"内容\" __ “内容” __ ——&gt; “内容” 斜体加粗 “内容”前后加 3 个 * 号 （无空格） “内容” 删除线 ”内容”前后加 2 个波浪线（~） ~~ “内容” ~~ ——&gt; “内容” 高亮 “内容”前后加 2 个 = 号 == “内容” == ——&gt; “内容” 字体，颜色，字号 使用 font 标签 1&lt;font face='Microsift Yahei' color='red' size='6'&gt; 字体，颜色和字号 &lt;/font&gt; 字体，颜色和字号 上标 &amp; 下标 上标：“内容”前后加 1 个 ^ 号 下标：“内容”前后加 1 个 ~ 号 我是 ^ 上标 ^ ——&gt; 我是上标 我是 ~ 下标 ~ ——&gt; 我是下标 引用 “内容”前加 &gt; 号 “内容” 引用号可叠用，&gt;号越多，级数越低 例如：可以使用&gt;, &gt;&gt;, &gt;&gt;&gt; 的形式 一级引用 二级引用 三级引用 文字内容对齐设置 1. 使用div标签： 1&lt;div style=\"text-align: right\"&gt;your-text-here&lt;/div&gt; 居左 居中 居右 2. 使用p标签：(在Jupyter Notebook中不适用) 居中：&lt;center&gt; 内容 &lt;/center&gt; 居左/居右：&lt;p align='left'&gt; 内容 &lt;/p&gt; 居左 居中 居右 插入链接 ​ 中括号内输入“显示的文字”，紧接着小括号内输入“网址链接” ​ 【注意：网站地址需要 http 开头，最好直接复制】 点我进入百度 插入图片 ​ 感叹号 + 中括号内输入“显示的文字”，紧接着小括号内输入“图片链接” ​ 【注意：图片链接非网页的网址栏链接，而是右键“复制图片地址”得到的链接 (Chrome)】 调整图片大小： 1&lt;img src=\"链接\" width=\"宽度(数字or百分比)\" height=\"高度\" alt=\"图片名称\" align=center/left/right&gt; 列表 （1） 有序列表 ​ （序号1+点+空格）+内容+回车 ​ （序号2+点+空格）+内容+回车 ​ （序号3+点+空格）+内容+回车 第一行 第二行 第三行 ​ 【注意】：系统会默认调整有序列表的序列数。即，即使你误输入成了1.，2.，4.，系统也会自动更正为 1.，2.，3. 第一点 第二点 第四点 （2）无序列表 ​ 使用“ + ”+空格+内容 ​ ​ 或者“ - ”+空格+内容 ​ ​ 或者“ * ”+空格+内容 ​ 下一级：前面加 tab 第一章 第二章 第三章 第一节 （3）任务列表 ​ 短横线 + 1 个空格 + 中括号（括号中间带 1 个空格） + 1 个空格 + “内容” [x] 学习python [ ] 学习SQL 添加表格 竖线作为列分界线，换行竖线中间输入短横线作为行分界线 1 2 3 a b c d e f 代码 三个 ` 号，再输入所使用的编程语言 1print(\"Python\") # python 1install.packages(\"ggplot2\") # R语言 插入目录 [Only for Typora] 中括号内输入toc In Hexo: @[toc] (在使用hexo-renderer-markdown-it-plus插件时) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"}]}],"categories":[{"name":"【Exercise】","slug":"【Exercise】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/"},{"name":"Python","slug":"【Exercise】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Exercise%E3%80%91/Python/"},{"name":"【Study】","slug":"【Study】","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/"},{"name":"Python","slug":"【Study】/Python","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Python/"},{"name":"Usage","slug":"【Study】/Usage","permalink":"https://hyemin-kim.github.io/categories/%E3%80%90Study%E3%80%91/Usage/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hyemin-kim.github.io/tags/Python/"},{"name":"Text Mining","slug":"Text-Mining","permalink":"https://hyemin-kim.github.io/tags/Text-Mining/"},{"name":"sklearn","slug":"sklearn","permalink":"https://hyemin-kim.github.io/tags/sklearn/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://hyemin-kim.github.io/tags/Machine-Learning/"},{"name":"분류","slug":"분류","permalink":"https://hyemin-kim.github.io/tags/%EB%B6%84%EB%A5%98/"},{"name":"회귀","slug":"회귀","permalink":"https://hyemin-kim.github.io/tags/%ED%9A%8C%EA%B7%80/"},{"name":"비지도 학습","slug":"비지도-학습","permalink":"https://hyemin-kim.github.io/tags/%EB%B9%84%EC%A7%80%EB%8F%84-%ED%95%99%EC%8A%B5/"},{"name":"앙상블","slug":"앙상블","permalink":"https://hyemin-kim.github.io/tags/%EC%95%99%EC%83%81%EB%B8%94/"},{"name":"전처리","slug":"전처리","permalink":"https://hyemin-kim.github.io/tags/%EC%A0%84%EC%B2%98%EB%A6%AC/"},{"name":"시각화","slug":"시각화","permalink":"https://hyemin-kim.github.io/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"Seaborn","slug":"Seaborn","permalink":"https://hyemin-kim.github.io/tags/Seaborn/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://hyemin-kim.github.io/tags/Matplotlib/"},{"name":"사각화","slug":"사각화","permalink":"https://hyemin-kim.github.io/tags/%EC%82%AC%EA%B0%81%ED%99%94/"},{"name":"Pandas","slug":"Pandas","permalink":"https://hyemin-kim.github.io/tags/Pandas/"},{"name":"데이터파악","slug":"데이터파악","permalink":"https://hyemin-kim.github.io/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%8C%8C%EC%95%85/"},{"name":"Numpy","slug":"Numpy","permalink":"https://hyemin-kim.github.io/tags/Numpy/"},{"name":"Python_Base","slug":"Python-Base","permalink":"https://hyemin-kim.github.io/tags/Python-Base/"},{"name":"Markdown","slug":"Markdown","permalink":"https://hyemin-kim.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://hyemin-kim.github.io/tags/Hexo/"},{"name":"Typora","slug":"Typora","permalink":"https://hyemin-kim.github.io/tags/Typora/"},{"name":"Git","slug":"Git","permalink":"https://hyemin-kim.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://hyemin-kim.github.io/tags/Github/"},{"name":"Jupyter notebook","slug":"Jupyter-notebook","permalink":"https://hyemin-kim.github.io/tags/Jupyter-notebook/"}]}